2022-11-29 20:29:25,934 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.10 (default, Jun  4 2021, 14:48:32) [GCC 7.5.0]
CUDA available: True
GPU 0,1,2,3,4,5,6,7: NVIDIA A100-SXM-80GB
CUDA_HOME: /usr/local/cuda
NVCC: Build cuda_11.3.r11.3/compiler.29920130_0
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.10.2+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.3+cu113
OpenCV: 4.1.2
MMCV: 1.4.2
MMCV Compiler: GCC 7.5
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.20.2+unknown
------------------------------------------------------------

2022-11-29 20:29:25,934 - mmseg - INFO - Distributed training: True
2022-11-29 20:29:26,678 - mmseg - INFO - Config:
num_things_classes = 100
num_stuff_classes = 50
num_classes = 150
norm_cfg = dict(type='SyncBN', requires_grad=True)
model = dict(
    type='EncoderDecoderMask2FormerAug',
    pretrained=
    '/mnt/sfs_turbo/model/mp_rank_00_model_states_renamed-s14tos16.pt',
    backbone=dict(
        type='BEiTAdapter',
        patch_size=16,
        embed_dim=1408,
        depth=40,
        num_heads=16,
        mlp_ratio=4.363636363636363,
        qkv_bias=True,
        use_abs_pos_emb=True,
        use_rel_pos_bias=True,
        img_size=896,
        init_values=1.0,
        drop_path_rate=0.5,
        conv_inplane=64,
        n_points=4,
        deform_num_heads=16,
        cffn_ratio=0.25,
        deform_ratio=0.5,
        with_cp=True,
        interaction_indexes=[[0, 9], [10, 19], [20, 29], [30, 39]]),
    decode_head=dict(
        type='Mask2FormerHead',
        in_channels=[1408, 1408, 1408, 1408],
        feat_channels=1024,
        out_channels=1024,
        in_index=[0, 1, 2, 3],
        num_things_classes=100,
        num_stuff_classes=50,
        num_queries=200,
        num_transformer_feat_level=3,
        pixel_decoder=dict(
            type='MSDeformAttnPixelDecoder',
            num_outs=3,
            norm_cfg=dict(type='GN', num_groups=32),
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                type='DetrTransformerEncoder',
                num_layers=6,
                transformerlayers=dict(
                    type='BaseTransformerLayer',
                    attn_cfgs=dict(
                        type='MultiScaleDeformableAttention',
                        embed_dims=1024,
                        num_heads=32,
                        num_levels=3,
                        num_points=4,
                        im2col_step=64,
                        dropout=0.0,
                        batch_first=False,
                        norm_cfg=None,
                        init_cfg=None),
                    ffn_cfgs=dict(
                        type='FFN',
                        embed_dims=1024,
                        feedforward_channels=4096,
                        num_fcs=2,
                        ffn_drop=0.0,
                        act_cfg=dict(type='ReLU', inplace=True),
                        with_cp=True),
                    operation_order=('self_attn', 'norm', 'ffn', 'norm')),
                init_cfg=None),
            positional_encoding=dict(
                type='SinePositionalEncoding', num_feats=512, normalize=True),
            init_cfg=None),
        enforce_decoder_input_project=False,
        positional_encoding=dict(
            type='SinePositionalEncoding', num_feats=512, normalize=True),
        transformer_decoder=dict(
            type='DetrTransformerDecoder',
            return_intermediate=True,
            num_layers=9,
            transformerlayers=dict(
                type='DetrTransformerDecoderLayer',
                attn_cfgs=dict(
                    type='MultiheadAttention',
                    embed_dims=1024,
                    num_heads=32,
                    attn_drop=0.0,
                    proj_drop=0.0,
                    dropout_layer=None,
                    batch_first=False),
                ffn_cfgs=dict(
                    embed_dims=1024,
                    feedforward_channels=4096,
                    num_fcs=2,
                    act_cfg=dict(type='ReLU', inplace=True),
                    ffn_drop=0.0,
                    dropout_layer=None,
                    add_identity=True,
                    with_cp=True),
                feedforward_channels=4096,
                operation_order=('cross_attn', 'norm', 'self_attn', 'norm',
                                 'ffn', 'norm')),
            init_cfg=None),
        loss_cls=dict(
            type='CrossEntropyLoss',
            use_sigmoid=False,
            loss_weight=2.0,
            reduction='mean',
            class_weight=[
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1
            ]),
        loss_mask=dict(
            type='CrossEntropyLoss',
            use_sigmoid=True,
            reduction='mean',
            loss_weight=5.0),
        loss_dice=dict(
            type='DiceLoss',
            use_sigmoid=True,
            activate=True,
            reduction='mean',
            naive_dice=True,
            eps=1.0,
            loss_weight=5.0)),
    train_cfg=dict(
        num_points=12544,
        oversample_ratio=3.0,
        importance_sample_ratio=0.75,
        assigner=dict(
            type='MaskHungarianAssigner',
            cls_cost=dict(type='ClassificationCost', weight=2.0),
            mask_cost=dict(
                type='CrossEntropyLossCost', weight=5.0, use_sigmoid=True),
            dice_cost=dict(
                type='DiceCost', weight=5.0, pred_act=True, eps=1.0)),
        sampler=dict(type='MaskPseudoSampler')),
    test_cfg=dict(
        panoptic_on=True,
        semantic_on=False,
        instance_on=True,
        max_per_image=100,
        iou_thr=0.8,
        filter_low_score=True,
        mode='slide',
        crop_size=(896, 896),
        stride=(512, 512)),
    init_cfg=None)
dataset_type = 'ADE20KDataset'
data_root = '/mnt/sfs_turbo/data/ADEChallengeData2016'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (896, 896)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(type='Resize', img_scale=(3584, 896), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(896, 896), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(896, 896), pad_val=0, seg_pad_val=255),
    dict(type='ToMask'),
    dict(type='DefaultFormatBundle'),
    dict(
        type='Collect',
        keys=['img', 'gt_semantic_seg', 'gt_masks', 'gt_labels'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(3584, 896),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='ResizeToMultiple', size_divisor=32),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=4,
    train=dict(
        type='ADE20KDataset',
        data_root='/mnt/sfs_turbo/data/ADEChallengeData2016',
        img_dir='images/training',
        ann_dir='annotations/training',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', reduce_zero_label=True),
            dict(type='Resize', img_scale=(3584, 896), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(896, 896), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(896, 896), pad_val=0, seg_pad_val=255),
            dict(type='ToMask'),
            dict(type='DefaultFormatBundle'),
            dict(
                type='Collect',
                keys=['img', 'gt_semantic_seg', 'gt_masks', 'gt_labels'])
        ]),
    val=dict(
        type='ADE20KDataset',
        data_root='/mnt/sfs_turbo/data/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(3584, 896),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='ResizeToMultiple', size_divisor=32),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='ADE20KDataset',
        data_root='/mnt/sfs_turbo/data/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(3584, 896),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='ResizeToMultiple', size_divisor=32),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = '/mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_ls_80k_cocostuff164k_bsz2_ss/averaged.pth'
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(
    type='AdamW',
    lr=1e-05,
    betas=(0.9, 0.999),
    weight_decay=0.05,
    constructor='LayerDecayOptimizerConstructor',
    paramwise_cfg=dict(num_layers=40, layer_decay_rate=0.9))
optimizer_config = dict()
lr_config = dict(
    policy='poly',
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06,
    power=1.0,
    min_lr=0.0,
    by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=40000)
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=10)
evaluation = dict(
    interval=1000, metric='mIoU', pre_eval=True, save_best='mIoU')
pretrained = '/mnt/sfs_turbo/model/mp_rank_00_model_states_renamed-s14tos16.pt'
work_dir = '/mnt/sfs_turbo/output//hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune/lr1.0_lrd0.9'
gpu_ids = range(0, 16)
auto_resume = False

2022-11-29 20:29:26,679 - mmseg - INFO - Set random seed to 0, deterministic: True
2022-11-29 20:29:49,411 - mmseg - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: mask_token, norm.weight, norm.bias, lm_head.weight, lm_head.bias

missing keys in source state_dict: blocks.0.gamma_1, blocks.0.gamma_2, blocks.0.attn.relative_position_bias_table, blocks.0.attn.relative_position_index, blocks.1.gamma_1, blocks.1.gamma_2, blocks.1.attn.relative_position_bias_table, blocks.1.attn.relative_position_index, blocks.2.gamma_1, blocks.2.gamma_2, blocks.2.attn.relative_position_bias_table, blocks.2.attn.relative_position_index, blocks.3.gamma_1, blocks.3.gamma_2, blocks.3.attn.relative_position_bias_table, blocks.3.attn.relative_position_index, blocks.4.gamma_1, blocks.4.gamma_2, blocks.4.attn.relative_position_bias_table, blocks.4.attn.relative_position_index, blocks.5.gamma_1, blocks.5.gamma_2, blocks.5.attn.relative_position_bias_table, blocks.5.attn.relative_position_index, blocks.6.gamma_1, blocks.6.gamma_2, blocks.6.attn.relative_position_bias_table, blocks.6.attn.relative_position_index, blocks.7.gamma_1, blocks.7.gamma_2, blocks.7.attn.relative_position_bias_table, blocks.7.attn.relative_position_index, blocks.8.gamma_1, blocks.8.gamma_2, blocks.8.attn.relative_position_bias_table, blocks.8.attn.relative_position_index, blocks.9.gamma_1, blocks.9.gamma_2, blocks.9.attn.relative_position_bias_table, blocks.9.attn.relative_position_index, blocks.10.gamma_1, blocks.10.gamma_2, blocks.10.attn.relative_position_bias_table, blocks.10.attn.relative_position_index, blocks.11.gamma_1, blocks.11.gamma_2, blocks.11.attn.relative_position_bias_table, blocks.11.attn.relative_position_index, blocks.12.gamma_1, blocks.12.gamma_2, blocks.12.attn.relative_position_bias_table, blocks.12.attn.relative_position_index, blocks.13.gamma_1, blocks.13.gamma_2, blocks.13.attn.relative_position_bias_table, blocks.13.attn.relative_position_index, blocks.14.gamma_1, blocks.14.gamma_2, blocks.14.attn.relative_position_bias_table, blocks.14.attn.relative_position_index, blocks.15.gamma_1, blocks.15.gamma_2, blocks.15.attn.relative_position_bias_table, blocks.15.attn.relative_position_index, blocks.16.gamma_1, blocks.16.gamma_2, blocks.16.attn.relative_position_bias_table, blocks.16.attn.relative_position_index, blocks.17.gamma_1, blocks.17.gamma_2, blocks.17.attn.relative_position_bias_table, blocks.17.attn.relative_position_index, blocks.18.gamma_1, blocks.18.gamma_2, blocks.18.attn.relative_position_bias_table, blocks.18.attn.relative_position_index, blocks.19.gamma_1, blocks.19.gamma_2, blocks.19.attn.relative_position_bias_table, blocks.19.attn.relative_position_index, blocks.20.gamma_1, blocks.20.gamma_2, blocks.20.attn.relative_position_bias_table, blocks.20.attn.relative_position_index, blocks.21.gamma_1, blocks.21.gamma_2, blocks.21.attn.relative_position_bias_table, blocks.21.attn.relative_position_index, blocks.22.gamma_1, blocks.22.gamma_2, blocks.22.attn.relative_position_bias_table, blocks.22.attn.relative_position_index, blocks.23.gamma_1, blocks.23.gamma_2, blocks.23.attn.relative_position_bias_table, blocks.23.attn.relative_position_index, blocks.24.gamma_1, blocks.24.gamma_2, blocks.24.attn.relative_position_bias_table, blocks.24.attn.relative_position_index, blocks.25.gamma_1, blocks.25.gamma_2, blocks.25.attn.relative_position_bias_table, blocks.25.attn.relative_position_index, blocks.26.gamma_1, blocks.26.gamma_2, blocks.26.attn.relative_position_bias_table, blocks.26.attn.relative_position_index, blocks.27.gamma_1, blocks.27.gamma_2, blocks.27.attn.relative_position_bias_table, blocks.27.attn.relative_position_index, blocks.28.gamma_1, blocks.28.gamma_2, blocks.28.attn.relative_position_bias_table, blocks.28.attn.relative_position_index, blocks.29.gamma_1, blocks.29.gamma_2, blocks.29.attn.relative_position_bias_table, blocks.29.attn.relative_position_index, blocks.30.gamma_1, blocks.30.gamma_2, blocks.30.attn.relative_position_bias_table, blocks.30.attn.relative_position_index, blocks.31.gamma_1, blocks.31.gamma_2, blocks.31.attn.relative_position_bias_table, blocks.31.attn.relative_position_index, blocks.32.gamma_1, blocks.32.gamma_2, blocks.32.attn.relative_position_bias_table, blocks.32.attn.relative_position_index, blocks.33.gamma_1, blocks.33.gamma_2, blocks.33.attn.relative_position_bias_table, blocks.33.attn.relative_position_index, blocks.34.gamma_1, blocks.34.gamma_2, blocks.34.attn.relative_position_bias_table, blocks.34.attn.relative_position_index, blocks.35.gamma_1, blocks.35.gamma_2, blocks.35.attn.relative_position_bias_table, blocks.35.attn.relative_position_index, blocks.36.gamma_1, blocks.36.gamma_2, blocks.36.attn.relative_position_bias_table, blocks.36.attn.relative_position_index, blocks.37.gamma_1, blocks.37.gamma_2, blocks.37.attn.relative_position_bias_table, blocks.37.attn.relative_position_index, blocks.38.gamma_1, blocks.38.gamma_2, blocks.38.attn.relative_position_bias_table, blocks.38.attn.relative_position_index, blocks.39.gamma_1, blocks.39.gamma_2, blocks.39.attn.relative_position_bias_table, blocks.39.attn.relative_position_index

Name of parameter - Initialization information

backbone.cls_token - torch.Size([1, 1, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.pos_embed - torch.Size([1, 3137, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.level_embed - torch.Size([3, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.patch_embed.proj.weight - torch.Size([1408, 3, 16, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.patch_embed.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.0.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.0.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.0.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.0.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.0.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.0.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.0.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.0.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.0.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.0.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.0.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.0.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.0.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.0.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.0.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.0.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.1.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.1.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.1.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.1.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.1.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.1.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.1.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.1.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.1.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.1.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.1.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.1.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.1.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.1.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.1.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.1.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.2.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.2.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.2.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.2.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.2.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.2.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.2.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.2.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.2.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.2.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.2.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.2.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.2.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.2.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.2.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.2.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.3.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.3.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.3.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.3.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.3.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.3.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.3.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.3.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.3.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.3.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.3.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.3.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.3.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.3.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.3.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.3.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.4.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.4.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.4.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.4.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.4.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.4.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.4.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.4.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.4.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.4.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.4.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.4.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.4.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.4.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.4.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.4.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.5.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.5.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.5.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.5.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.5.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.5.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.5.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.5.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.5.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.5.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.5.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.5.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.5.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.5.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.5.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.5.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.6.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.6.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.6.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.6.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.6.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.6.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.6.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.6.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.6.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.6.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.6.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.6.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.6.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.6.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.6.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.6.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.7.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.7.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.7.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.7.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.7.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.7.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.7.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.7.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.7.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.7.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.7.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.7.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.7.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.7.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.7.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.7.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.8.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.8.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.8.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.8.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.8.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.8.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.8.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.8.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.8.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.8.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.8.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.8.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.8.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.8.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.8.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.8.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.9.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.9.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.9.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.9.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.9.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.9.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.9.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.9.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.9.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.9.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.9.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.9.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.9.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.9.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.9.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.9.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.10.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.10.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.10.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.10.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.10.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.10.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.10.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.10.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.10.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.10.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.10.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.10.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.10.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.10.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.10.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.10.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.11.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.11.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.11.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.11.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.11.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.11.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.11.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.11.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.11.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.11.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.11.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.11.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.11.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.11.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.11.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.11.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.12.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.12.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.12.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.12.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.12.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.12.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.12.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.12.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.12.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.12.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.12.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.12.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.12.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.12.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.12.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.12.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.13.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.13.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.13.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.13.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.13.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.13.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.13.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.13.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.13.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.13.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.13.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.13.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.13.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.13.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.13.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.13.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.14.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.14.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.14.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.14.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.14.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.14.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.14.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.14.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.14.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.14.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.14.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.14.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.14.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.14.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.14.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.14.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.15.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.15.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.15.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.15.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.15.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.15.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.15.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.15.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.15.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.15.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.15.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.15.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.15.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.15.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.15.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.15.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.16.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.16.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.16.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.16.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.16.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.16.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.16.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.16.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.16.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.16.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.16.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.16.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.16.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.16.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.16.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.16.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.17.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.17.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.17.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.17.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.17.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.17.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.17.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.17.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.17.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.17.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.17.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.17.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.17.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.17.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.17.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.17.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.18.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.18.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.18.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.18.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.18.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.18.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.18.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.18.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.18.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.18.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.18.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.18.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.18.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.18.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.18.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.18.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.19.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.19.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.19.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.19.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.19.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.19.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.19.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.19.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.19.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.19.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.19.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.19.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.19.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.19.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.19.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.19.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.20.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.20.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.20.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.20.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.20.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.20.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.20.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.20.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.20.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.20.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.20.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.20.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.20.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.20.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.20.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.20.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.21.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.21.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.21.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.21.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.21.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.21.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.21.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.21.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.21.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.21.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.21.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.21.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.21.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.21.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.21.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.21.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.22.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.22.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.22.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.22.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.22.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.22.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.22.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.22.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.22.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.22.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.22.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.22.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.22.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.22.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.22.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.22.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.23.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.23.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.23.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.23.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.23.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.23.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.23.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.23.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.23.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.23.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.23.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.23.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.23.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.23.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.23.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.23.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.24.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.24.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.24.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.24.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.24.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.24.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.24.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.24.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.24.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.24.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.24.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.24.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.24.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.24.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.24.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.24.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.25.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.25.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.25.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.25.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.25.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.25.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.25.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.25.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.25.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.25.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.25.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.25.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.25.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.25.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.25.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.25.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.26.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.26.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.26.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.26.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.26.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.26.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.26.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.26.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.26.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.26.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.26.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.26.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.26.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.26.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.26.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.26.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.27.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.27.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.27.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.27.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.27.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.27.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.27.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.27.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.27.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.27.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.27.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.27.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.27.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.27.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.27.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.27.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.28.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.28.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.28.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.28.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.28.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.28.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.28.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.28.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.28.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.28.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.28.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.28.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.28.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.28.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.28.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.28.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.29.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.29.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.29.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.29.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.29.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.29.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.29.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.29.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.29.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.29.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.29.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.29.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.29.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.29.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.29.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.29.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.30.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.30.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.30.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.30.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.30.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.30.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.30.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.30.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.30.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.30.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.30.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.30.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.30.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.30.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.30.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.30.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.31.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.31.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.31.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.31.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.31.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.31.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.31.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.31.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.31.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.31.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.31.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.31.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.31.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.31.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.31.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.31.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.32.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.32.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.32.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.32.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.32.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.32.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.32.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.32.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.32.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.32.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.32.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.32.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.32.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.32.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.32.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.32.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.33.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.33.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.33.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.33.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.33.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.33.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.33.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.33.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.33.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.33.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.33.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.33.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.33.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.33.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.33.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.33.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.34.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.34.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.34.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.34.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.34.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.34.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.34.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.34.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.34.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.34.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.34.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.34.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.34.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.34.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.34.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.34.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.35.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.35.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.35.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.35.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.35.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.35.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.35.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.35.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.35.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.35.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.35.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.35.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.35.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.35.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.35.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.35.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.36.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.36.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.36.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.36.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.36.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.36.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.36.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.36.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.36.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.36.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.36.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.36.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.36.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.36.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.36.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.36.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.37.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.37.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.37.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.37.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.37.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.37.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.37.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.37.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.37.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.37.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.37.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.37.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.37.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.37.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.37.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.37.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.38.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.38.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.38.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.38.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.38.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.38.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.38.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.38.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.38.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.38.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.38.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.38.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.38.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.38.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.38.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.38.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.39.gamma_1 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.39.gamma_2 - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.39.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.39.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.39.attn.q_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.39.attn.v_bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.39.attn.relative_position_bias_table - torch.Size([12324, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.39.attn.qkv.weight - torch.Size([4224, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.39.attn.proj.weight - torch.Size([1408, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.39.attn.proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.39.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.39.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.39.mlp.fc1.weight - torch.Size([6144, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.39.mlp.fc1.bias - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.39.mlp.fc2.weight - torch.Size([1408, 6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.blocks.39.mlp.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.stem.0.weight - torch.Size([64, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.stem.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.stem.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.stem.3.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.stem.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.stem.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.stem.6.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.stem.7.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.stem.7.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.conv2.0.weight - torch.Size([128, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.conv2.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.conv2.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.conv3.0.weight - torch.Size([256, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.conv3.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.conv3.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.conv4.0.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.conv4.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.conv4.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.fc1.weight - torch.Size([1408, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.fc1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.fc2.weight - torch.Size([1408, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.fc3.weight - torch.Size([1408, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.fc3.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.fc4.weight - torch.Size([1408, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.spm.fc4.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.injector.gamma - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.injector.query_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.injector.query_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.injector.feat_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.injector.feat_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.injector.attn.sampling_offsets.weight - torch.Size([384, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.injector.attn.sampling_offsets.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.injector.attn.attention_weights.weight - torch.Size([192, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.injector.attn.attention_weights.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.injector.attn.value_proj.weight - torch.Size([704, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.injector.attn.value_proj.bias - torch.Size([704]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.injector.attn.output_proj.weight - torch.Size([1408, 704]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.injector.attn.output_proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.extractor.query_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.extractor.query_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.extractor.feat_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.extractor.feat_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.extractor.attn.sampling_offsets.weight - torch.Size([128, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.extractor.attn.sampling_offsets.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.extractor.attn.attention_weights.weight - torch.Size([64, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.extractor.attn.attention_weights.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.extractor.attn.value_proj.weight - torch.Size([704, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.extractor.attn.value_proj.bias - torch.Size([704]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.extractor.attn.output_proj.weight - torch.Size([1408, 704]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.extractor.attn.output_proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.extractor.ffn.fc1.weight - torch.Size([352, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.extractor.ffn.fc1.bias - torch.Size([352]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.extractor.ffn.dwconv.dwconv.weight - torch.Size([352, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.extractor.ffn.dwconv.dwconv.bias - torch.Size([352]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.extractor.ffn.fc2.weight - torch.Size([1408, 352]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.extractor.ffn.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.extractor.ffn_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.0.extractor.ffn_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.injector.gamma - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.injector.query_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.injector.query_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.injector.feat_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.injector.feat_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.injector.attn.sampling_offsets.weight - torch.Size([384, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.injector.attn.sampling_offsets.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.injector.attn.attention_weights.weight - torch.Size([192, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.injector.attn.attention_weights.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.injector.attn.value_proj.weight - torch.Size([704, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.injector.attn.value_proj.bias - torch.Size([704]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.injector.attn.output_proj.weight - torch.Size([1408, 704]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.injector.attn.output_proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.extractor.query_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.extractor.query_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.extractor.feat_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.extractor.feat_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.extractor.attn.sampling_offsets.weight - torch.Size([128, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.extractor.attn.sampling_offsets.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.extractor.attn.attention_weights.weight - torch.Size([64, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.extractor.attn.attention_weights.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.extractor.attn.value_proj.weight - torch.Size([704, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.extractor.attn.value_proj.bias - torch.Size([704]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.extractor.attn.output_proj.weight - torch.Size([1408, 704]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.extractor.attn.output_proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.extractor.ffn.fc1.weight - torch.Size([352, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.extractor.ffn.fc1.bias - torch.Size([352]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.extractor.ffn.dwconv.dwconv.weight - torch.Size([352, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.extractor.ffn.dwconv.dwconv.bias - torch.Size([352]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.extractor.ffn.fc2.weight - torch.Size([1408, 352]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.extractor.ffn.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.extractor.ffn_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.1.extractor.ffn_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.injector.gamma - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.injector.query_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.injector.query_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.injector.feat_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.injector.feat_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.injector.attn.sampling_offsets.weight - torch.Size([384, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.injector.attn.sampling_offsets.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.injector.attn.attention_weights.weight - torch.Size([192, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.injector.attn.attention_weights.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.injector.attn.value_proj.weight - torch.Size([704, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.injector.attn.value_proj.bias - torch.Size([704]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.injector.attn.output_proj.weight - torch.Size([1408, 704]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.injector.attn.output_proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.extractor.query_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.extractor.query_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.extractor.feat_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.extractor.feat_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.extractor.attn.sampling_offsets.weight - torch.Size([128, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.extractor.attn.sampling_offsets.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.extractor.attn.attention_weights.weight - torch.Size([64, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.extractor.attn.attention_weights.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.extractor.attn.value_proj.weight - torch.Size([704, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.extractor.attn.value_proj.bias - torch.Size([704]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.extractor.attn.output_proj.weight - torch.Size([1408, 704]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.extractor.attn.output_proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.extractor.ffn.fc1.weight - torch.Size([352, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.extractor.ffn.fc1.bias - torch.Size([352]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.extractor.ffn.dwconv.dwconv.weight - torch.Size([352, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.extractor.ffn.dwconv.dwconv.bias - torch.Size([352]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.extractor.ffn.fc2.weight - torch.Size([1408, 352]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.extractor.ffn.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.extractor.ffn_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.2.extractor.ffn_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.injector.gamma - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.injector.query_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.injector.query_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.injector.feat_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.injector.feat_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.injector.attn.sampling_offsets.weight - torch.Size([384, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.injector.attn.sampling_offsets.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.injector.attn.attention_weights.weight - torch.Size([192, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.injector.attn.attention_weights.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.injector.attn.value_proj.weight - torch.Size([704, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.injector.attn.value_proj.bias - torch.Size([704]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.injector.attn.output_proj.weight - torch.Size([1408, 704]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.injector.attn.output_proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extractor.query_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extractor.query_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extractor.feat_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extractor.feat_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extractor.attn.sampling_offsets.weight - torch.Size([128, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extractor.attn.sampling_offsets.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extractor.attn.attention_weights.weight - torch.Size([64, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extractor.attn.attention_weights.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extractor.attn.value_proj.weight - torch.Size([704, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extractor.attn.value_proj.bias - torch.Size([704]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extractor.attn.output_proj.weight - torch.Size([1408, 704]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extractor.attn.output_proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extractor.ffn.fc1.weight - torch.Size([352, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extractor.ffn.fc1.bias - torch.Size([352]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extractor.ffn.dwconv.dwconv.weight - torch.Size([352, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extractor.ffn.dwconv.dwconv.bias - torch.Size([352]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extractor.ffn.fc2.weight - torch.Size([1408, 352]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extractor.ffn.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extractor.ffn_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extractor.ffn_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.0.query_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.0.query_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.0.feat_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.0.feat_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.0.attn.sampling_offsets.weight - torch.Size([128, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.0.attn.sampling_offsets.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.0.attn.attention_weights.weight - torch.Size([64, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.0.attn.attention_weights.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.0.attn.value_proj.weight - torch.Size([704, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.0.attn.value_proj.bias - torch.Size([704]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.0.attn.output_proj.weight - torch.Size([1408, 704]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.0.attn.output_proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.0.ffn.fc1.weight - torch.Size([352, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.0.ffn.fc1.bias - torch.Size([352]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.0.ffn.dwconv.dwconv.weight - torch.Size([352, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.0.ffn.dwconv.dwconv.bias - torch.Size([352]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.0.ffn.fc2.weight - torch.Size([1408, 352]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.0.ffn.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.0.ffn_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.0.ffn_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.1.query_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.1.query_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.1.feat_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.1.feat_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.1.attn.sampling_offsets.weight - torch.Size([128, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.1.attn.sampling_offsets.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.1.attn.attention_weights.weight - torch.Size([64, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.1.attn.attention_weights.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.1.attn.value_proj.weight - torch.Size([704, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.1.attn.value_proj.bias - torch.Size([704]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.1.attn.output_proj.weight - torch.Size([1408, 704]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.1.attn.output_proj.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.1.ffn.fc1.weight - torch.Size([352, 1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.1.ffn.fc1.bias - torch.Size([352]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.1.ffn.dwconv.dwconv.weight - torch.Size([352, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.1.ffn.dwconv.dwconv.bias - torch.Size([352]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.1.ffn.fc2.weight - torch.Size([1408, 352]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.1.ffn.fc2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.1.ffn_norm.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.interactions.3.extra_extractors.1.ffn_norm.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.up.weight - torch.Size([1408, 1408, 2, 2]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.up.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.norm1.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.norm1.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.norm2.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.norm2.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.norm3.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.norm3.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.norm4.weight - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

backbone.norm4.bias - torch.Size([1408]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.input_convs.0.conv.weight - torch.Size([1024, 1408, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.0.conv.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.input_convs.0.gn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.input_convs.0.gn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.input_convs.1.conv.weight - torch.Size([1024, 1408, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.1.conv.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.input_convs.1.gn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.input_convs.1.gn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.input_convs.2.conv.weight - torch.Size([1024, 1408, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.2.conv.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.input_convs.2.gn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.input_convs.2.gn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.weight - torch.Size([768, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.sampling_offsets.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.weight - torch.Size([384, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.attention_weights.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.value_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.attentions.0.output_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.0.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.0.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.0.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.0.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.weight - torch.Size([768, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.sampling_offsets.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.weight - torch.Size([384, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.attention_weights.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.value_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.attentions.0.output_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.1.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.1.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.1.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.1.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.weight - torch.Size([768, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.sampling_offsets.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.weight - torch.Size([384, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.attention_weights.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.value_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.attentions.0.output_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.2.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.2.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.2.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.2.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.weight - torch.Size([768, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.sampling_offsets.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.weight - torch.Size([384, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.attention_weights.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.value_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.attentions.0.output_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.3.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.3.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.3.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.3.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.weight - torch.Size([768, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.sampling_offsets.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.weight - torch.Size([384, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.attention_weights.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.value_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.attentions.0.output_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.4.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.4.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.4.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.4.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.weight - torch.Size([768, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.sampling_offsets.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.weight - torch.Size([384, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.attention_weights.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.value_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.attentions.0.output_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.5.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.5.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.5.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.encoder.layers.5.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.level_encoding.weight - torch.Size([3, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.conv.weight - torch.Size([1024, 1408, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.gn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.lateral_convs.0.gn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.output_convs.0.conv.weight - torch.Size([1024, 1024, 3, 3]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.output_convs.0.gn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.output_convs.0.gn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.pixel_decoder.mask_feature.weight - torch.Size([1024, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.mask_feature.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.0.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.0.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.1.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.attentions.1.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.0.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.0.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.0.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.0.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.0.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.0.norms.2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.0.norms.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.0.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.0.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.1.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.attentions.1.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.1.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.1.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.1.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.1.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.1.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.1.norms.2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.1.norms.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.0.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.0.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.1.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.attentions.1.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.2.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.2.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.2.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.2.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.2.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.2.norms.2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.2.norms.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.0.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.0.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.1.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.attentions.1.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.3.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.3.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.3.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.3.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.3.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.3.norms.2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.3.norms.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.0.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.0.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.1.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.attentions.1.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.4.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.4.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.4.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.4.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.4.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.4.norms.2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.4.norms.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.0.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.0.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.1.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.attentions.1.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.5.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.5.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.5.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.5.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.5.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.5.norms.2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.5.norms.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.0.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.0.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.1.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.attentions.1.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.6.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.6.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.6.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.6.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.6.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.6.norms.2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.6.norms.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.0.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.0.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.1.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.attentions.1.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.7.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.7.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.7.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.7.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.7.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.7.norms.2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.7.norms.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.0.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.0.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.1.attn.in_proj_bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.attentions.1.attn.out_proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffns.0.layers.0.0.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.8.ffns.0.layers.1.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffns.0.layers.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.8.norms.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.8.norms.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.8.norms.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.8.norms.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.8.norms.2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.layers.8.norms.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.post_norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.transformer_decoder.post_norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.query_embed.weight - torch.Size([200, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.query_feat.weight - torch.Size([200, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.level_embed.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.cls_embed.weight - torch.Size([151, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.cls_embed.bias - torch.Size([151]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.mask_embed.0.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.mask_embed.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.mask_embed.2.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.mask_embed.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.mask_embed.4.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  

decode_head.mask_embed.4.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoderMask2FormerAug  
2022-11-29 20:29:53,203 - mmseg - INFO - EncoderDecoderMask2FormerAug(
  (backbone): BEiTAdapter(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(16, 16), stride=(16, 16))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.012820512987673283)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.025641025975346565)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.03846153989434242)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.05128205195069313)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.06410256773233414)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (6): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.07692307978868484)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (7): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.08974359184503555)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (8): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.10256410390138626)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (9): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.11538461595773697)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (10): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.12820513546466827)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (11): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.14102564752101898)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (12): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.1538461595773697)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (13): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.1666666716337204)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (14): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.1794871836900711)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (15): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.19230769574642181)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (16): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.20512820780277252)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (17): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.21794871985912323)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (18): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.23076923191547394)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (19): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.24358974397182465)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (20): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.25641027092933655)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (21): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.26923078298568726)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (22): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.28205129504203796)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (23): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.29487180709838867)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (24): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.3076923191547394)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (25): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.3205128312110901)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (26): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.3333333432674408)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (27): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.3461538553237915)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (28): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.3589743673801422)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (29): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.3717948794364929)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (30): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.38461539149284363)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (31): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.39743590354919434)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (32): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.41025641560554504)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (33): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.42307692766189575)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (34): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.43589743971824646)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (35): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.44871795177459717)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (36): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.4615384638309479)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (37): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.4743589758872986)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (38): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.4871794879436493)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (39): Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): DropPath(p=0.5)
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (spm): SpatialPriorModule(
      (stem): Sequential(
        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (7): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): ReLU(inplace=True)
        (9): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      )
      (conv2): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (conv3): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (conv4): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (fc1): Conv2d(64, 1408, kernel_size=(1, 1), stride=(1, 1))
      (fc2): Conv2d(128, 1408, kernel_size=(1, 1), stride=(1, 1))
      (fc3): Conv2d(256, 1408, kernel_size=(1, 1), stride=(1, 1))
      (fc4): Conv2d(256, 1408, kernel_size=(1, 1), stride=(1, 1))
    )
    (interactions): Sequential(
      (0): InteractionBlockWithCls(
        (injector): Injector(
          (query_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
          (feat_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
          (attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=1408, out_features=384, bias=True)
            (attention_weights): Linear(in_features=1408, out_features=192, bias=True)
            (value_proj): Linear(in_features=1408, out_features=704, bias=True)
            (output_proj): Linear(in_features=704, out_features=1408, bias=True)
          )
        )
        (extractor): Extractor(
          (query_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
          (feat_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
          (attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=1408, out_features=128, bias=True)
            (attention_weights): Linear(in_features=1408, out_features=64, bias=True)
            (value_proj): Linear(in_features=1408, out_features=704, bias=True)
            (output_proj): Linear(in_features=704, out_features=1408, bias=True)
          )
          (ffn): ConvFFN(
            (fc1): Linear(in_features=1408, out_features=352, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)
            )
            (act): GELU()
            (fc2): Linear(in_features=352, out_features=1408, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (ffn_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
          (drop_path): DropPath()
        )
      )
      (1): InteractionBlockWithCls(
        (injector): Injector(
          (query_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
          (feat_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
          (attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=1408, out_features=384, bias=True)
            (attention_weights): Linear(in_features=1408, out_features=192, bias=True)
            (value_proj): Linear(in_features=1408, out_features=704, bias=True)
            (output_proj): Linear(in_features=704, out_features=1408, bias=True)
          )
        )
        (extractor): Extractor(
          (query_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
          (feat_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
          (attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=1408, out_features=128, bias=True)
            (attention_weights): Linear(in_features=1408, out_features=64, bias=True)
            (value_proj): Linear(in_features=1408, out_features=704, bias=True)
            (output_proj): Linear(in_features=704, out_features=1408, bias=True)
          )
          (ffn): ConvFFN(
            (fc1): Linear(in_features=1408, out_features=352, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)
            )
            (act): GELU()
            (fc2): Linear(in_features=352, out_features=1408, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (ffn_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
          (drop_path): DropPath()
        )
      )
      (2): InteractionBlockWithCls(
        (injector): Injector(
          (query_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
          (feat_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
          (attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=1408, out_features=384, bias=True)
            (attention_weights): Linear(in_features=1408, out_features=192, bias=True)
            (value_proj): Linear(in_features=1408, out_features=704, bias=True)
            (output_proj): Linear(in_features=704, out_features=1408, bias=True)
          )
        )
        (extractor): Extractor(
          (query_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
          (feat_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
          (attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=1408, out_features=128, bias=True)
            (attention_weights): Linear(in_features=1408, out_features=64, bias=True)
            (value_proj): Linear(in_features=1408, out_features=704, bias=True)
            (output_proj): Linear(in_features=704, out_features=1408, bias=True)
          )
          (ffn): ConvFFN(
            (fc1): Linear(in_features=1408, out_features=352, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)
            )
            (act): GELU()
            (fc2): Linear(in_features=352, out_features=1408, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (ffn_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
          (drop_path): DropPath()
        )
      )
      (3): InteractionBlockWithCls(
        (injector): Injector(
          (query_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
          (feat_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
          (attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=1408, out_features=384, bias=True)
            (attention_weights): Linear(in_features=1408, out_features=192, bias=True)
            (value_proj): Linear(in_features=1408, out_features=704, bias=True)
            (output_proj): Linear(in_features=704, out_features=1408, bias=True)
          )
        )
        (extractor): Extractor(
          (query_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
          (feat_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
          (attn): MSDeformAttn(
            (sampling_offsets): Linear(in_features=1408, out_features=128, bias=True)
            (attention_weights): Linear(in_features=1408, out_features=64, bias=True)
            (value_proj): Linear(in_features=1408, out_features=704, bias=True)
            (output_proj): Linear(in_features=704, out_features=1408, bias=True)
          )
          (ffn): ConvFFN(
            (fc1): Linear(in_features=1408, out_features=352, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)
            )
            (act): GELU()
            (fc2): Linear(in_features=352, out_features=1408, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (ffn_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
          (drop_path): DropPath()
        )
        (extra_extractors): Sequential(
          (0): Extractor(
            (query_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
            (feat_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
            (attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=1408, out_features=128, bias=True)
              (attention_weights): Linear(in_features=1408, out_features=64, bias=True)
              (value_proj): Linear(in_features=1408, out_features=704, bias=True)
              (output_proj): Linear(in_features=704, out_features=1408, bias=True)
            )
            (ffn): ConvFFN(
              (fc1): Linear(in_features=1408, out_features=352, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)
              )
              (act): GELU()
              (fc2): Linear(in_features=352, out_features=1408, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ffn_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
            (drop_path): DropPath()
          )
          (1): Extractor(
            (query_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
            (feat_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
            (attn): MSDeformAttn(
              (sampling_offsets): Linear(in_features=1408, out_features=128, bias=True)
              (attention_weights): Linear(in_features=1408, out_features=64, bias=True)
              (value_proj): Linear(in_features=1408, out_features=704, bias=True)
              (output_proj): Linear(in_features=704, out_features=1408, bias=True)
            )
            (ffn): ConvFFN(
              (fc1): Linear(in_features=1408, out_features=352, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352)
              )
              (act): GELU()
              (fc2): Linear(in_features=352, out_features=1408, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ffn_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
            (drop_path): DropPath()
          )
        )
      )
    )
    (up): ConvTranspose2d(1408, 1408, kernel_size=(2, 2), stride=(2, 2))
    (norm1): SyncBatchNorm(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (norm2): SyncBatchNorm(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (norm3): SyncBatchNorm(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (norm4): SyncBatchNorm(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (decode_head): Mask2FormerHead(
    input_transform=multiple_select, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): None
    (dropout): Dropout2d(p=0.1, inplace=False)
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_convs): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(1408, 1024, kernel_size=(1, 1), stride=(1, 1))
          (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)
        )
        (1): ConvModule(
          (conv): Conv2d(1408, 1024, kernel_size=(1, 1), stride=(1, 1))
          (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)
        )
        (2): ConvModule(
          (conv): Conv2d(1408, 1024, kernel_size=(1, 1), stride=(1, 1))
          (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)
        )
      )
      (encoder): DetrTransformerEncoder(
        (layers): ModuleList(
          (0): BaseTransformerLayer(
            (attentions): ModuleList(
              (0): MultiScaleDeformableAttention(
                (dropout): Dropout(p=0.0, inplace=False)
                (sampling_offsets): Linear(in_features=1024, out_features=768, bias=True)
                (attention_weights): Linear(in_features=1024, out_features=384, bias=True)
                (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
                (output_proj): Linear(in_features=1024, out_features=1024, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=1024, out_features=4096, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (1): Linear(in_features=4096, out_features=1024, bias=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): BaseTransformerLayer(
            (attentions): ModuleList(
              (0): MultiScaleDeformableAttention(
                (dropout): Dropout(p=0.0, inplace=False)
                (sampling_offsets): Linear(in_features=1024, out_features=768, bias=True)
                (attention_weights): Linear(in_features=1024, out_features=384, bias=True)
                (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
                (output_proj): Linear(in_features=1024, out_features=1024, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=1024, out_features=4096, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (1): Linear(in_features=4096, out_features=1024, bias=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): BaseTransformerLayer(
            (attentions): ModuleList(
              (0): MultiScaleDeformableAttention(
                (dropout): Dropout(p=0.0, inplace=False)
                (sampling_offsets): Linear(in_features=1024, out_features=768, bias=True)
                (attention_weights): Linear(in_features=1024, out_features=384, bias=True)
                (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
                (output_proj): Linear(in_features=1024, out_features=1024, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=1024, out_features=4096, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (1): Linear(in_features=4096, out_features=1024, bias=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): BaseTransformerLayer(
            (attentions): ModuleList(
              (0): MultiScaleDeformableAttention(
                (dropout): Dropout(p=0.0, inplace=False)
                (sampling_offsets): Linear(in_features=1024, out_features=768, bias=True)
                (attention_weights): Linear(in_features=1024, out_features=384, bias=True)
                (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
                (output_proj): Linear(in_features=1024, out_features=1024, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=1024, out_features=4096, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (1): Linear(in_features=4096, out_features=1024, bias=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            )
          )
          (4): BaseTransformerLayer(
            (attentions): ModuleList(
              (0): MultiScaleDeformableAttention(
                (dropout): Dropout(p=0.0, inplace=False)
                (sampling_offsets): Linear(in_features=1024, out_features=768, bias=True)
                (attention_weights): Linear(in_features=1024, out_features=384, bias=True)
                (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
                (output_proj): Linear(in_features=1024, out_features=1024, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=1024, out_features=4096, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (1): Linear(in_features=4096, out_features=1024, bias=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            )
          )
          (5): BaseTransformerLayer(
            (attentions): ModuleList(
              (0): MultiScaleDeformableAttention(
                (dropout): Dropout(p=0.0, inplace=False)
                (sampling_offsets): Linear(in_features=1024, out_features=768, bias=True)
                (attention_weights): Linear(in_features=1024, out_features=384, bias=True)
                (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
                (output_proj): Linear(in_features=1024, out_features=1024, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=1024, out_features=4096, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (1): Linear(in_features=4096, out_features=1024, bias=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (postional_encoding): SinePositionalEncoding(num_feats=512, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
      (level_encoding): Embedding(3, 1024)
      (lateral_convs): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(1408, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)
        )
      )
      (output_convs): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (gn): GroupNorm(32, 1024, eps=1e-05, affine=True)
          (activate): ReLU(inplace=True)
        )
      )
      (mask_feature): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
    )
    (transformer_decoder): DetrTransformerDecoder(
      (layers): ModuleList(
        (0): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=1024, out_features=4096, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=4096, out_features=1024, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=1024, out_features=4096, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=4096, out_features=1024, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=1024, out_features=4096, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=4096, out_features=1024, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=1024, out_features=4096, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=4096, out_features=1024, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=1024, out_features=4096, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=4096, out_features=1024, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=1024, out_features=4096, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=4096, out_features=1024, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (6): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=1024, out_features=4096, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=4096, out_features=1024, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (7): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=1024, out_features=4096, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=4096, out_features=1024, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (8): DetrTransformerDecoderLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
            (1): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
              (dropout_layer): Identity()
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activate): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=1024, out_features=4096, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (1): Linear(in_features=4096, out_features=1024, bias=True)
                (2): Dropout(p=0.0, inplace=False)
              )
              (dropout_layer): Identity()
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (post_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    )
    (decoder_input_projs): ModuleList(
      (0): Identity()
      (1): Identity()
      (2): Identity()
    )
    (decoder_positional_encoding): SinePositionalEncoding(num_feats=512, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
    (query_embed): Embedding(200, 1024)
    (query_feat): Embedding(200, 1024)
    (level_embed): Embedding(3, 1024)
    (cls_embed): Linear(in_features=1024, out_features=151, bias=True)
    (mask_embed): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=1024, bias=True)
      (3): ReLU(inplace=True)
      (4): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (loss_cls): CrossEntropyLoss(avg_non_ignore=False)
    (loss_mask): CrossEntropyLoss(avg_non_ignore=False)
    (loss_dice): DiceLoss()
  )
)
2022-11-29 20:30:02,090 - mmseg - INFO - Loaded 20210 images
2022-11-29 20:30:16,262 - mmseg - INFO - Loaded 2000 images
2022-11-29 20:30:16,263 - mmseg - INFO - load checkpoint from local path: /mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_ls_80k_cocostuff164k_bsz2_ss/averaged.pth
2022-11-29 20:30:26,168 - mmseg - WARNING - The model and loaded state dict do not match exactly

size mismatch for decode_head.cls_embed.weight: copying a param with shape torch.Size([172, 1024]) from checkpoint, the shape in current model is torch.Size([151, 1024]).
size mismatch for decode_head.cls_embed.bias: copying a param with shape torch.Size([172]) from checkpoint, the shape in current model is torch.Size([151]).
2022-11-29 20:30:26,196 - mmseg - INFO - Start running, host: ma-user@os-node-created-n6brh.novalocal, work_dir: /mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune/lr1.0_lrd0.9
2022-11-29 20:30:26,196 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2022-11-29 20:30:26,196 - mmseg - INFO - workflow: [('train', 1)], max: 40000 iters
2022-11-29 20:30:26,196 - mmseg - INFO - Checkpoints will be saved to /mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune/lr1.0_lrd0.9 by HardDiskBackend.
2022-11-29 20:34:17,048 - mmseg - INFO - Iter [50/40000]	lr: 4.340e-09, eta: 1 day, 22:27:57, time: 4.187, data_time: 0.025, memory: 51902, decode.loss_cls: 9.1636, decode.loss_mask: 0.7530, decode.loss_dice: 1.0568, decode.d0.loss_cls: 10.0718, decode.d0.loss_mask: 0.8397, decode.d0.loss_dice: 1.3003, decode.d1.loss_cls: 9.6946, decode.d1.loss_mask: 0.7717, decode.d1.loss_dice: 1.1459, decode.d2.loss_cls: 9.4171, decode.d2.loss_mask: 0.7512, decode.d2.loss_dice: 1.0861, decode.d3.loss_cls: 9.3689, decode.d3.loss_mask: 0.7487, decode.d3.loss_dice: 1.0681, decode.d4.loss_cls: 9.2507, decode.d4.loss_mask: 0.7484, decode.d4.loss_dice: 1.0649, decode.d5.loss_cls: 9.1774, decode.d5.loss_mask: 0.7478, decode.d5.loss_dice: 1.0604, decode.d6.loss_cls: 9.2030, decode.d6.loss_mask: 0.7527, decode.d6.loss_dice: 1.0558, decode.d7.loss_cls: 9.0523, decode.d7.loss_mask: 0.7519, decode.d7.loss_dice: 1.0589, decode.d8.loss_cls: 9.1471, decode.d8.loss_mask: 0.7516, decode.d8.loss_dice: 1.0547, loss: 112.1152
2022-11-29 20:37:42,970 - mmseg - INFO - Iter [100/40000]	lr: 8.758e-09, eta: 1 day, 22:01:37, time: 4.118, data_time: 0.019, memory: 51902, decode.loss_cls: 6.0885, decode.loss_mask: 0.7028, decode.loss_dice: 1.0211, decode.d0.loss_cls: 10.0707, decode.d0.loss_mask: 0.7950, decode.d0.loss_dice: 1.2595, decode.d1.loss_cls: 8.4884, decode.d1.loss_mask: 0.7332, decode.d1.loss_dice: 1.1073, decode.d2.loss_cls: 7.5166, decode.d2.loss_mask: 0.7087, decode.d2.loss_dice: 1.0494, decode.d3.loss_cls: 7.0711, decode.d3.loss_mask: 0.7024, decode.d3.loss_dice: 1.0335, decode.d4.loss_cls: 6.5975, decode.d4.loss_mask: 0.7010, decode.d4.loss_dice: 1.0314, decode.d5.loss_cls: 6.2902, decode.d5.loss_mask: 0.7015, decode.d5.loss_dice: 1.0289, decode.d6.loss_cls: 6.2130, decode.d6.loss_mask: 0.7063, decode.d6.loss_dice: 1.0260, decode.d7.loss_cls: 5.9206, decode.d7.loss_mask: 0.7021, decode.d7.loss_dice: 1.0305, decode.d8.loss_cls: 5.9890, decode.d8.loss_mask: 0.7026, decode.d8.loss_dice: 1.0220, loss: 88.0106
2022-11-29 20:41:08,735 - mmseg - INFO - Iter [150/40000]	lr: 1.317e-08, eta: 1 day, 21:49:50, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 3.6170, decode.loss_mask: 0.6740, decode.loss_dice: 1.0013, decode.d0.loss_cls: 10.0707, decode.d0.loss_mask: 0.7680, decode.d0.loss_dice: 1.2307, decode.d1.loss_cls: 6.1352, decode.d1.loss_mask: 0.7154, decode.d1.loss_dice: 1.0765, decode.d2.loss_cls: 4.4940, decode.d2.loss_mask: 0.6883, decode.d2.loss_dice: 1.0222, decode.d3.loss_cls: 4.0341, decode.d3.loss_mask: 0.6817, decode.d3.loss_dice: 1.0070, decode.d4.loss_cls: 3.7825, decode.d4.loss_mask: 0.6739, decode.d4.loss_dice: 1.0064, decode.d5.loss_cls: 3.6750, decode.d5.loss_mask: 0.6701, decode.d5.loss_dice: 0.9992, decode.d6.loss_cls: 3.6404, decode.d6.loss_mask: 0.6804, decode.d6.loss_dice: 0.9916, decode.d7.loss_cls: 3.6026, decode.d7.loss_mask: 0.6773, decode.d7.loss_dice: 1.0093, decode.d8.loss_cls: 3.6036, decode.d8.loss_mask: 0.6730, decode.d8.loss_dice: 0.9966, loss: 63.8981
2022-11-29 20:44:34,098 - mmseg - INFO - Iter [200/40000]	lr: 1.756e-08, eta: 1 day, 21:40:55, time: 4.107, data_time: 0.019, memory: 51902, decode.loss_cls: 3.3035, decode.loss_mask: 0.6717, decode.loss_dice: 0.9909, decode.d0.loss_cls: 10.0722, decode.d0.loss_mask: 0.7745, decode.d0.loss_dice: 1.2284, decode.d1.loss_cls: 4.2613, decode.d1.loss_mask: 0.7160, decode.d1.loss_dice: 1.0732, decode.d2.loss_cls: 3.5152, decode.d2.loss_mask: 0.6812, decode.d2.loss_dice: 1.0209, decode.d3.loss_cls: 3.4052, decode.d3.loss_mask: 0.6789, decode.d3.loss_dice: 1.0027, decode.d4.loss_cls: 3.3751, decode.d4.loss_mask: 0.6707, decode.d4.loss_dice: 1.0036, decode.d5.loss_cls: 3.3270, decode.d5.loss_mask: 0.6698, decode.d5.loss_dice: 0.9969, decode.d6.loss_cls: 3.2959, decode.d6.loss_mask: 0.6812, decode.d6.loss_dice: 0.9847, decode.d7.loss_cls: 3.2955, decode.d7.loss_mask: 0.6707, decode.d7.loss_dice: 0.9937, decode.d8.loss_cls: 3.2918, decode.d8.loss_mask: 0.6712, decode.d8.loss_dice: 0.9845, loss: 58.3078
2022-11-29 20:47:59,715 - mmseg - INFO - Iter [250/40000]	lr: 2.195e-08, eta: 1 day, 21:34:51, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 2.9570, decode.loss_mask: 0.6648, decode.loss_dice: 0.9632, decode.d0.loss_cls: 10.0726, decode.d0.loss_mask: 0.7648, decode.d0.loss_dice: 1.2099, decode.d1.loss_cls: 3.5491, decode.d1.loss_mask: 0.6976, decode.d1.loss_dice: 1.0600, decode.d2.loss_cls: 3.2607, decode.d2.loss_mask: 0.6632, decode.d2.loss_dice: 1.0079, decode.d3.loss_cls: 3.1256, decode.d3.loss_mask: 0.6649, decode.d3.loss_dice: 0.9896, decode.d4.loss_cls: 3.0542, decode.d4.loss_mask: 0.6602, decode.d4.loss_dice: 0.9845, decode.d5.loss_cls: 3.0039, decode.d5.loss_mask: 0.6573, decode.d5.loss_dice: 0.9784, decode.d6.loss_cls: 2.9628, decode.d6.loss_mask: 0.6703, decode.d6.loss_dice: 0.9673, decode.d7.loss_cls: 2.9437, decode.d7.loss_mask: 0.6613, decode.d7.loss_dice: 0.9678, decode.d8.loss_cls: 2.9388, decode.d8.loss_mask: 0.6628, decode.d8.loss_dice: 0.9550, loss: 54.7191
2022-11-29 20:51:25,805 - mmseg - INFO - Iter [300/40000]	lr: 2.632e-08, eta: 1 day, 21:30:43, time: 4.122, data_time: 0.019, memory: 51902, decode.loss_cls: 2.7125, decode.loss_mask: 0.6625, decode.loss_dice: 0.9457, decode.d0.loss_cls: 10.0641, decode.d0.loss_mask: 0.7569, decode.d0.loss_dice: 1.2163, decode.d1.loss_cls: 3.3472, decode.d1.loss_mask: 0.6787, decode.d1.loss_dice: 1.0589, decode.d2.loss_cls: 3.0779, decode.d2.loss_mask: 0.6542, decode.d2.loss_dice: 0.9994, decode.d3.loss_cls: 2.9155, decode.d3.loss_mask: 0.6566, decode.d3.loss_dice: 0.9752, decode.d4.loss_cls: 2.8252, decode.d4.loss_mask: 0.6532, decode.d4.loss_dice: 0.9712, decode.d5.loss_cls: 2.7714, decode.d5.loss_mask: 0.6547, decode.d5.loss_dice: 0.9635, decode.d6.loss_cls: 2.7247, decode.d6.loss_mask: 0.6671, decode.d6.loss_dice: 0.9531, decode.d7.loss_cls: 2.7014, decode.d7.loss_mask: 0.6593, decode.d7.loss_dice: 0.9518, decode.d8.loss_cls: 2.6876, decode.d8.loss_mask: 0.6625, decode.d8.loss_dice: 0.9438, loss: 52.5120
2022-11-29 20:54:51,077 - mmseg - INFO - Iter [350/40000]	lr: 3.068e-08, eta: 1 day, 21:25:14, time: 4.105, data_time: 0.020, memory: 51902, decode.loss_cls: 2.4066, decode.loss_mask: 0.6693, decode.loss_dice: 0.9390, decode.d0.loss_cls: 10.0659, decode.d0.loss_mask: 0.7419, decode.d0.loss_dice: 1.1909, decode.d1.loss_cls: 3.1084, decode.d1.loss_mask: 0.6814, decode.d1.loss_dice: 1.0469, decode.d2.loss_cls: 2.8030, decode.d2.loss_mask: 0.6596, decode.d2.loss_dice: 0.9834, decode.d3.loss_cls: 2.6310, decode.d3.loss_mask: 0.6611, decode.d3.loss_dice: 0.9614, decode.d4.loss_cls: 2.5301, decode.d4.loss_mask: 0.6615, decode.d4.loss_dice: 0.9574, decode.d5.loss_cls: 2.4766, decode.d5.loss_mask: 0.6612, decode.d5.loss_dice: 0.9522, decode.d6.loss_cls: 2.4303, decode.d6.loss_mask: 0.6711, decode.d6.loss_dice: 0.9457, decode.d7.loss_cls: 2.4008, decode.d7.loss_mask: 0.6625, decode.d7.loss_dice: 0.9431, decode.d8.loss_cls: 2.3831, decode.d8.loss_mask: 0.6689, decode.d8.loss_dice: 0.9344, loss: 49.8286
2022-11-29 20:58:16,685 - mmseg - INFO - Iter [400/40000]	lr: 3.503e-08, eta: 1 day, 21:20:50, time: 4.112, data_time: 0.018, memory: 51902, decode.loss_cls: 2.1802, decode.loss_mask: 0.6584, decode.loss_dice: 0.9313, decode.d0.loss_cls: 10.0660, decode.d0.loss_mask: 0.7314, decode.d0.loss_dice: 1.1855, decode.d1.loss_cls: 2.9341, decode.d1.loss_mask: 0.6618, decode.d1.loss_dice: 1.0346, decode.d2.loss_cls: 2.5870, decode.d2.loss_mask: 0.6474, decode.d2.loss_dice: 0.9700, decode.d3.loss_cls: 2.4169, decode.d3.loss_mask: 0.6490, decode.d3.loss_dice: 0.9510, decode.d4.loss_cls: 2.3113, decode.d4.loss_mask: 0.6492, decode.d4.loss_dice: 0.9498, decode.d5.loss_cls: 2.2532, decode.d5.loss_mask: 0.6523, decode.d5.loss_dice: 0.9405, decode.d6.loss_cls: 2.2027, decode.d6.loss_mask: 0.6605, decode.d6.loss_dice: 0.9350, decode.d7.loss_cls: 2.1720, decode.d7.loss_mask: 0.6582, decode.d7.loss_dice: 0.9352, decode.d8.loss_cls: 2.1567, decode.d8.loss_mask: 0.6612, decode.d8.loss_dice: 0.9305, loss: 47.6728
2022-11-29 21:01:42,248 - mmseg - INFO - Iter [450/40000]	lr: 3.937e-08, eta: 1 day, 21:16:34, time: 4.111, data_time: 0.020, memory: 51902, decode.loss_cls: 1.9745, decode.loss_mask: 0.6847, decode.loss_dice: 0.9572, decode.d0.loss_cls: 10.0612, decode.d0.loss_mask: 0.7400, decode.d0.loss_dice: 1.2084, decode.d1.loss_cls: 2.7376, decode.d1.loss_mask: 0.6775, decode.d1.loss_dice: 1.0442, decode.d2.loss_cls: 2.3784, decode.d2.loss_mask: 0.6718, decode.d2.loss_dice: 0.9826, decode.d3.loss_cls: 2.2133, decode.d3.loss_mask: 0.6737, decode.d3.loss_dice: 0.9706, decode.d4.loss_cls: 2.1120, decode.d4.loss_mask: 0.6729, decode.d4.loss_dice: 0.9656, decode.d5.loss_cls: 2.0564, decode.d5.loss_mask: 0.6770, decode.d5.loss_dice: 0.9585, decode.d6.loss_cls: 2.0108, decode.d6.loss_mask: 0.6826, decode.d6.loss_dice: 0.9555, decode.d7.loss_cls: 1.9773, decode.d7.loss_mask: 0.6820, decode.d7.loss_dice: 0.9557, decode.d8.loss_cls: 1.9612, decode.d8.loss_mask: 0.6835, decode.d8.loss_dice: 0.9509, loss: 46.2776
2022-11-29 21:05:08,204 - mmseg - INFO - Iter [500/40000]	lr: 4.370e-08, eta: 1 day, 21:13:00, time: 4.119, data_time: 0.020, memory: 51902, decode.loss_cls: 1.8073, decode.loss_mask: 0.6652, decode.loss_dice: 0.9466, decode.d0.loss_cls: 10.0659, decode.d0.loss_mask: 0.7171, decode.d0.loss_dice: 1.1749, decode.d1.loss_cls: 2.5663, decode.d1.loss_mask: 0.6589, decode.d1.loss_dice: 1.0238, decode.d2.loss_cls: 2.2055, decode.d2.loss_mask: 0.6525, decode.d2.loss_dice: 0.9707, decode.d3.loss_cls: 2.0376, decode.d3.loss_mask: 0.6552, decode.d3.loss_dice: 0.9520, decode.d4.loss_cls: 1.9403, decode.d4.loss_mask: 0.6590, decode.d4.loss_dice: 0.9509, decode.d5.loss_cls: 1.8829, decode.d5.loss_mask: 0.6612, decode.d5.loss_dice: 0.9474, decode.d6.loss_cls: 1.8368, decode.d6.loss_mask: 0.6649, decode.d6.loss_dice: 0.9471, decode.d7.loss_cls: 1.8015, decode.d7.loss_mask: 0.6656, decode.d7.loss_dice: 0.9482, decode.d8.loss_cls: 1.7902, decode.d8.loss_mask: 0.6669, decode.d8.loss_dice: 0.9444, loss: 44.4069
2022-11-29 21:08:33,783 - mmseg - INFO - Iter [550/40000]	lr: 4.802e-08, eta: 1 day, 21:09:00, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 1.6816, decode.loss_mask: 0.6782, decode.loss_dice: 0.9490, decode.d0.loss_cls: 10.0595, decode.d0.loss_mask: 0.7181, decode.d0.loss_dice: 1.1741, decode.d1.loss_cls: 2.4105, decode.d1.loss_mask: 0.6747, decode.d1.loss_dice: 1.0239, decode.d2.loss_cls: 2.0583, decode.d2.loss_mask: 0.6683, decode.d2.loss_dice: 0.9709, decode.d3.loss_cls: 1.9014, decode.d3.loss_mask: 0.6660, decode.d3.loss_dice: 0.9528, decode.d4.loss_cls: 1.8122, decode.d4.loss_mask: 0.6693, decode.d4.loss_dice: 0.9503, decode.d5.loss_cls: 1.7524, decode.d5.loss_mask: 0.6720, decode.d5.loss_dice: 0.9489, decode.d6.loss_cls: 1.7129, decode.d6.loss_mask: 0.6799, decode.d6.loss_dice: 0.9478, decode.d7.loss_cls: 1.6854, decode.d7.loss_mask: 0.6797, decode.d7.loss_dice: 0.9531, decode.d8.loss_cls: 1.6674, decode.d8.loss_mask: 0.6794, decode.d8.loss_dice: 0.9516, loss: 43.3495
2022-11-29 21:11:59,571 - mmseg - INFO - Iter [600/40000]	lr: 5.233e-08, eta: 1 day, 21:05:19, time: 4.116, data_time: 0.019, memory: 51902, decode.loss_cls: 1.5886, decode.loss_mask: 0.6729, decode.loss_dice: 0.9565, decode.d0.loss_cls: 10.0562, decode.d0.loss_mask: 0.7060, decode.d0.loss_dice: 1.1703, decode.d1.loss_cls: 2.2926, decode.d1.loss_mask: 0.6736, decode.d1.loss_dice: 1.0176, decode.d2.loss_cls: 1.9475, decode.d2.loss_mask: 0.6687, decode.d2.loss_dice: 0.9601, decode.d3.loss_cls: 1.8001, decode.d3.loss_mask: 0.6626, decode.d3.loss_dice: 0.9432, decode.d4.loss_cls: 1.7137, decode.d4.loss_mask: 0.6669, decode.d4.loss_dice: 0.9457, decode.d5.loss_cls: 1.6567, decode.d5.loss_mask: 0.6696, decode.d5.loss_dice: 0.9424, decode.d6.loss_cls: 1.6193, decode.d6.loss_mask: 0.6720, decode.d6.loss_dice: 0.9472, decode.d7.loss_cls: 1.5891, decode.d7.loss_mask: 0.6724, decode.d7.loss_dice: 0.9517, decode.d8.loss_cls: 1.5748, decode.d8.loss_mask: 0.6754, decode.d8.loss_dice: 0.9536, loss: 42.3669
2022-11-29 21:15:27,516 - mmseg - INFO - Iter [650/40000]	lr: 5.662e-08, eta: 1 day, 21:03:52, time: 4.159, data_time: 0.066, memory: 51902, decode.loss_cls: 1.4779, decode.loss_mask: 0.6751, decode.loss_dice: 0.9747, decode.d0.loss_cls: 10.0580, decode.d0.loss_mask: 0.6971, decode.d0.loss_dice: 1.1793, decode.d1.loss_cls: 2.1639, decode.d1.loss_mask: 0.6734, decode.d1.loss_dice: 1.0362, decode.d2.loss_cls: 1.8302, decode.d2.loss_mask: 0.6700, decode.d2.loss_dice: 0.9875, decode.d3.loss_cls: 1.6820, decode.d3.loss_mask: 0.6663, decode.d3.loss_dice: 0.9675, decode.d4.loss_cls: 1.6008, decode.d4.loss_mask: 0.6668, decode.d4.loss_dice: 0.9695, decode.d5.loss_cls: 1.5456, decode.d5.loss_mask: 0.6697, decode.d5.loss_dice: 0.9680, decode.d6.loss_cls: 1.5053, decode.d6.loss_mask: 0.6737, decode.d6.loss_dice: 0.9714, decode.d7.loss_cls: 1.4779, decode.d7.loss_mask: 0.6741, decode.d7.loss_dice: 0.9750, decode.d8.loss_cls: 1.4634, decode.d8.loss_mask: 0.6787, decode.d8.loss_dice: 0.9741, loss: 41.5533
2022-11-29 21:18:53,014 - mmseg - INFO - Iter [700/40000]	lr: 6.091e-08, eta: 1 day, 20:59:50, time: 4.110, data_time: 0.019, memory: 51902, decode.loss_cls: 1.3706, decode.loss_mask: 0.6725, decode.loss_dice: 0.9392, decode.d0.loss_cls: 10.0631, decode.d0.loss_mask: 0.6908, decode.d0.loss_dice: 1.1303, decode.d1.loss_cls: 2.0182, decode.d1.loss_mask: 0.6738, decode.d1.loss_dice: 0.9953, decode.d2.loss_cls: 1.7065, decode.d2.loss_mask: 0.6665, decode.d2.loss_dice: 0.9511, decode.d3.loss_cls: 1.5685, decode.d3.loss_mask: 0.6632, decode.d3.loss_dice: 0.9345, decode.d4.loss_cls: 1.4878, decode.d4.loss_mask: 0.6681, decode.d4.loss_dice: 0.9395, decode.d5.loss_cls: 1.4349, decode.d5.loss_mask: 0.6683, decode.d5.loss_dice: 0.9351, decode.d6.loss_cls: 1.3998, decode.d6.loss_mask: 0.6726, decode.d6.loss_dice: 0.9363, decode.d7.loss_cls: 1.3741, decode.d7.loss_mask: 0.6737, decode.d7.loss_dice: 0.9440, decode.d8.loss_cls: 1.3588, decode.d8.loss_mask: 0.6750, decode.d8.loss_dice: 0.9406, loss: 40.1528
2022-11-29 21:22:18,612 - mmseg - INFO - Iter [750/40000]	lr: 6.518e-08, eta: 1 day, 20:55:58, time: 4.112, data_time: 0.021, memory: 51902, decode.loss_cls: 1.3279, decode.loss_mask: 0.6779, decode.loss_dice: 0.9694, decode.d0.loss_cls: 10.0567, decode.d0.loss_mask: 0.6842, decode.d0.loss_dice: 1.1508, decode.d1.loss_cls: 1.9672, decode.d1.loss_mask: 0.6762, decode.d1.loss_dice: 1.0158, decode.d2.loss_cls: 1.6619, decode.d2.loss_mask: 0.6677, decode.d2.loss_dice: 0.9739, decode.d3.loss_cls: 1.5215, decode.d3.loss_mask: 0.6676, decode.d3.loss_dice: 0.9646, decode.d4.loss_cls: 1.4405, decode.d4.loss_mask: 0.6701, decode.d4.loss_dice: 0.9696, decode.d5.loss_cls: 1.3847, decode.d5.loss_mask: 0.6747, decode.d5.loss_dice: 0.9645, decode.d6.loss_cls: 1.3567, decode.d6.loss_mask: 0.6763, decode.d6.loss_dice: 0.9680, decode.d7.loss_cls: 1.3305, decode.d7.loss_mask: 0.6804, decode.d7.loss_dice: 0.9722, decode.d8.loss_cls: 1.3157, decode.d8.loss_mask: 0.6817, decode.d8.loss_dice: 0.9697, loss: 40.0387
2022-11-29 21:25:44,233 - mmseg - INFO - Iter [800/40000]	lr: 6.944e-08, eta: 1 day, 20:52:10, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 1.2485, decode.loss_mask: 0.6817, decode.loss_dice: 0.9636, decode.d0.loss_cls: 10.0505, decode.d0.loss_mask: 0.6932, decode.d0.loss_dice: 1.1319, decode.d1.loss_cls: 1.8555, decode.d1.loss_mask: 0.6842, decode.d1.loss_dice: 1.0028, decode.d2.loss_cls: 1.5634, decode.d2.loss_mask: 0.6753, decode.d2.loss_dice: 0.9518, decode.d3.loss_cls: 1.4332, decode.d3.loss_mask: 0.6684, decode.d3.loss_dice: 0.9442, decode.d4.loss_cls: 1.3558, decode.d4.loss_mask: 0.6730, decode.d4.loss_dice: 0.9525, decode.d5.loss_cls: 1.3041, decode.d5.loss_mask: 0.6740, decode.d5.loss_dice: 0.9505, decode.d6.loss_cls: 1.2707, decode.d6.loss_mask: 0.6802, decode.d6.loss_dice: 0.9491, decode.d7.loss_cls: 1.2479, decode.d7.loss_mask: 0.6802, decode.d7.loss_dice: 0.9569, decode.d8.loss_cls: 1.2353, decode.d8.loss_mask: 0.6808, decode.d8.loss_dice: 0.9585, loss: 39.1178
2022-11-29 21:29:10,125 - mmseg - INFO - Iter [850/40000]	lr: 7.370e-08, eta: 1 day, 20:48:37, time: 4.118, data_time: 0.020, memory: 51902, decode.loss_cls: 1.2428, decode.loss_mask: 0.6551, decode.loss_dice: 0.9626, decode.d0.loss_cls: 10.0500, decode.d0.loss_mask: 0.6654, decode.d0.loss_dice: 1.1477, decode.d1.loss_cls: 1.8730, decode.d1.loss_mask: 0.6518, decode.d1.loss_dice: 1.0094, decode.d2.loss_cls: 1.5657, decode.d2.loss_mask: 0.6490, decode.d2.loss_dice: 0.9712, decode.d3.loss_cls: 1.4381, decode.d3.loss_mask: 0.6437, decode.d3.loss_dice: 0.9614, decode.d4.loss_cls: 1.3590, decode.d4.loss_mask: 0.6468, decode.d4.loss_dice: 0.9679, decode.d5.loss_cls: 1.2995, decode.d5.loss_mask: 0.6501, decode.d5.loss_dice: 0.9594, decode.d6.loss_cls: 1.2623, decode.d6.loss_mask: 0.6506, decode.d6.loss_dice: 0.9539, decode.d7.loss_cls: 1.2436, decode.d7.loss_mask: 0.6521, decode.d7.loss_dice: 0.9639, decode.d8.loss_cls: 1.2320, decode.d8.loss_mask: 0.6539, decode.d8.loss_dice: 0.9622, loss: 38.9440
2022-11-29 21:32:35,729 - mmseg - INFO - Iter [900/40000]	lr: 7.794e-08, eta: 1 day, 20:44:53, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 1.1241, decode.loss_mask: 0.6764, decode.loss_dice: 0.9490, decode.d0.loss_cls: 10.0422, decode.d0.loss_mask: 0.6808, decode.d0.loss_dice: 1.1012, decode.d1.loss_cls: 1.7068, decode.d1.loss_mask: 0.6775, decode.d1.loss_dice: 0.9835, decode.d2.loss_cls: 1.4303, decode.d2.loss_mask: 0.6718, decode.d2.loss_dice: 0.9502, decode.d3.loss_cls: 1.3074, decode.d3.loss_mask: 0.6674, decode.d3.loss_dice: 0.9383, decode.d4.loss_cls: 1.2346, decode.d4.loss_mask: 0.6698, decode.d4.loss_dice: 0.9473, decode.d5.loss_cls: 1.1831, decode.d5.loss_mask: 0.6743, decode.d5.loss_dice: 0.9456, decode.d6.loss_cls: 1.1497, decode.d6.loss_mask: 0.6791, decode.d6.loss_dice: 0.9419, decode.d7.loss_cls: 1.1249, decode.d7.loss_mask: 0.6790, decode.d7.loss_dice: 0.9478, decode.d8.loss_cls: 1.1156, decode.d8.loss_mask: 0.6755, decode.d8.loss_dice: 0.9497, loss: 37.8250
2022-11-29 21:36:01,115 - mmseg - INFO - Iter [950/40000]	lr: 8.217e-08, eta: 1 day, 20:41:02, time: 4.108, data_time: 0.020, memory: 51902, decode.loss_cls: 1.1170, decode.loss_mask: 0.6889, decode.loss_dice: 0.9733, decode.d0.loss_cls: 10.0382, decode.d0.loss_mask: 0.6881, decode.d0.loss_dice: 1.1356, decode.d1.loss_cls: 1.7079, decode.d1.loss_mask: 0.6895, decode.d1.loss_dice: 1.0163, decode.d2.loss_cls: 1.4268, decode.d2.loss_mask: 0.6869, decode.d2.loss_dice: 0.9774, decode.d3.loss_cls: 1.3061, decode.d3.loss_mask: 0.6815, decode.d3.loss_dice: 0.9674, decode.d4.loss_cls: 1.2234, decode.d4.loss_mask: 0.6901, decode.d4.loss_dice: 0.9781, decode.d5.loss_cls: 1.1720, decode.d5.loss_mask: 0.6917, decode.d5.loss_dice: 0.9724, decode.d6.loss_cls: 1.1393, decode.d6.loss_mask: 0.6955, decode.d6.loss_dice: 0.9655, decode.d7.loss_cls: 1.1209, decode.d7.loss_mask: 0.6913, decode.d7.loss_dice: 0.9764, decode.d8.loss_cls: 1.1057, decode.d8.loss_mask: 0.6926, decode.d8.loss_dice: 0.9729, loss: 38.1888
2022-11-29 21:39:26,733 - mmseg - INFO - Saving checkpoint at 1000 iterations
2022-11-29 21:40:17,382 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-29 21:40:17,382 - mmseg - INFO - Iter [1000/40000]	lr: 8.638e-08, eta: 1 day, 21:10:17, time: 5.125, data_time: 0.020, memory: 51902, decode.loss_cls: 1.0804, decode.loss_mask: 0.6913, decode.loss_dice: 0.9591, decode.d0.loss_cls: 10.0381, decode.d0.loss_mask: 0.6894, decode.d0.loss_dice: 1.1135, decode.d1.loss_cls: 1.6410, decode.d1.loss_mask: 0.6992, decode.d1.loss_dice: 1.0073, decode.d2.loss_cls: 1.3776, decode.d2.loss_mask: 0.6857, decode.d2.loss_dice: 0.9629, decode.d3.loss_cls: 1.2588, decode.d3.loss_mask: 0.6809, decode.d3.loss_dice: 0.9499, decode.d4.loss_cls: 1.1846, decode.d4.loss_mask: 0.6829, decode.d4.loss_dice: 0.9619, decode.d5.loss_cls: 1.1314, decode.d5.loss_mask: 0.6840, decode.d5.loss_dice: 0.9520, decode.d6.loss_cls: 1.1006, decode.d6.loss_mask: 0.6868, decode.d6.loss_dice: 0.9549, decode.d7.loss_cls: 1.0793, decode.d7.loss_mask: 0.6880, decode.d7.loss_dice: 0.9614, decode.d8.loss_cls: 1.0681, decode.d8.loss_mask: 0.6916, decode.d8.loss_dice: 0.9589, loss: 37.6216
2022-11-29 21:43:24,664 - mmseg - INFO - per class results:
2022-11-29 21:43:24,669 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 79.63 | 91.53 |
|       building      |  81.9 | 93.72 |
|         sky         | 94.66 | 97.41 |
|        floor        | 84.32 |  91.3 |
|         tree        | 76.58 | 88.04 |
|       ceiling       | 87.03 | 93.86 |
|         road        | 81.16 | 91.37 |
|         bed         | 88.61 | 96.85 |
|      windowpane     | 64.05 | 82.48 |
|        grass        | 70.31 | 92.54 |
|       cabinet       |  58.5 | 87.14 |
|       sidewalk      |  67.0 |  88.7 |
|        person       | 87.28 | 94.19 |
|        earth        |  40.2 | 56.52 |
|         door        | 55.98 | 77.94 |
|        table        | 59.92 | 84.61 |
|       mountain      | 46.09 | 56.17 |
|        plant        | 55.23 | 79.89 |
|       curtain       |  72.7 | 89.66 |
|        chair        |  55.2 | 85.35 |
|         car         |  85.0 |  94.1 |
|        water        |  50.9 | 77.69 |
|       painting      | 74.71 | 93.11 |
|         sofa        | 76.18 | 90.29 |
|        shelf        | 37.45 | 72.85 |
|        house        |  1.31 |  1.34 |
|         sea         | 52.89 | 70.56 |
|        mirror       | 77.43 | 88.29 |
|         rug         |  73.8 | 88.27 |
|        field        |  6.88 |  6.88 |
|       armchair      | 41.19 | 59.24 |
|         seat        | 24.43 | 28.07 |
|        fence        | 31.84 | 53.76 |
|         desk        | 38.28 | 58.15 |
|         rock        | 47.92 |  88.5 |
|       wardrobe      |  0.0  |  0.0  |
|         lamp        |  70.1 | 85.96 |
|       bathtub       | 75.84 | 91.05 |
|       railing       | 17.53 | 20.16 |
|       cushion       | 68.09 | 87.65 |
|         base        |  0.0  |  0.0  |
|         box         | 28.67 | 53.34 |
|        column       | 54.22 | 62.68 |
|      signboard      | 32.45 | 67.79 |
|   chest of drawers  |  0.0  |  0.0  |
|       counter       |  0.0  |  0.0  |
|         sand        | 24.06 | 24.08 |
|         sink        | 71.52 | 89.97 |
|      skyscraper     | 24.14 | 24.32 |
|      fireplace      | 36.58 | 37.62 |
|     refrigerator    | 69.89 | 70.41 |
|      grandstand     |  0.0  |  0.0  |
|         path        |  0.0  |  0.0  |
|        stairs       | 38.12 | 69.41 |
|        runway       |  0.0  |  0.0  |
|         case        |  0.0  |  0.0  |
|      pool table     | 60.05 | 60.63 |
|        pillow       | 61.92 | 77.42 |
|     screen door     |  0.0  |  0.0  |
|       stairway      |  10.3 | 10.87 |
|        river        |  0.0  |  0.0  |
|        bridge       | 37.83 | 38.47 |
|       bookcase      |  0.0  |  0.0  |
|        blind        |  0.0  |  0.0  |
|     coffee table    | 58.69 |  85.6 |
|        toilet       |  90.4 | 93.68 |
|        flower       |  48.7 | 63.92 |
|         book        | 51.16 | 85.29 |
|         hill        |  0.0  |  0.0  |
|        bench        | 36.76 | 37.76 |
|      countertop     | 24.27 | 27.27 |
|        stove        | 45.69 | 91.29 |
|         palm        |  0.0  |  0.0  |
|    kitchen island   |  0.0  |  0.0  |
|       computer      |  5.27 |  5.33 |
|     swivel chair    |  0.0  |  0.0  |
|         boat        | 75.33 | 83.59 |
|         bar         |  0.0  |  0.0  |
|    arcade machine   |  0.0  |  0.0  |
|        hovel        |  0.0  |  0.0  |
|         bus         |  0.0  |  0.0  |
|        towel        | 55.17 | 89.72 |
|        light        | 51.61 | 74.86 |
|        truck        |  0.0  |  0.0  |
|        tower        |  0.0  |  0.0  |
|      chandelier     | 59.94 | 67.17 |
|        awning       | 21.23 |  43.6 |
|     streetlight     | 37.49 | 60.18 |
|        booth        |  0.0  |  0.0  |
| television receiver | 22.26 | 91.31 |
|       airplane      | 87.69 | 88.32 |
|      dirt track     |  0.0  |  0.0  |
|       apparel       |  0.27 |  0.29 |
|         pole        | 32.55 | 58.07 |
|         land        |  0.0  |  0.0  |
|      bannister      |  0.0  |  0.0  |
|      escalator      |  0.0  |  0.0  |
|       ottoman       |  3.05 |  3.08 |
|        bottle       | 33.15 | 43.28 |
|        buffet       |  0.0  |  0.0  |
|        poster       |  0.0  |  0.0  |
|        stage        |  0.0  |  0.0  |
|         van         | 18.97 | 51.47 |
|         ship        |  0.0  |  0.0  |
|       fountain      |  0.0  |  0.0  |
|    conveyer belt    |  0.0  |  0.0  |
|        canopy       |  0.0  |  0.0  |
|        washer       |  0.0  |  0.0  |
|      plaything      | 13.46 | 13.63 |
|    swimming pool    |  0.0  |  0.0  |
|        stool        |  0.0  |  0.0  |
|        barrel       |  0.0  |  0.0  |
|        basket       | 15.57 | 16.63 |
|      waterfall      |  0.0  |  0.0  |
|         tent        |  0.0  |  0.0  |
|         bag         |  8.01 |  8.2  |
|       minibike      |  2.45 |  2.58 |
|        cradle       |  0.0  |  0.0  |
|         oven        |  0.0  |  0.0  |
|         ball        |  0.0  |  0.0  |
|         food        |  0.0  |  0.0  |
|         step        |  0.0  |  0.0  |
|         tank        |  0.0  |  0.0  |
|      trade name     |  0.0  |  0.0  |
|      microwave      | 86.19 | 89.03 |
|         pot         |  58.8 | 71.27 |
|        animal       |  0.0  |  0.0  |
|       bicycle       | 37.41 | 62.65 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     |  0.0  |  0.0  |
|        screen       |  0.0  |  0.0  |
|       blanket       |  0.0  |  0.0  |
|      sculpture      | 41.62 | 44.46 |
|         hood        |  11.4 | 11.41 |
|        sconce       | 15.73 | 17.52 |
|         vase        |  49.3 | 80.19 |
|    traffic light    | 29.59 | 32.09 |
|         tray        |  0.0  |  0.0  |
|        ashcan       | 49.04 | 55.18 |
|         fan         | 61.86 | 70.18 |
|         pier        |  0.0  |  0.0  |
|      crt screen     |  0.0  |  0.0  |
|        plate        | 57.72 | 76.37 |
|       monitor       |  0.0  |  0.0  |
|    bulletin board   |  0.0  |  0.0  |
|        shower       |  0.0  |  0.0  |
|       radiator      |  0.0  |  0.0  |
|        glass        | 15.37 | 15.79 |
|        clock        | 27.22 | 50.22 |
|         flag        | 33.44 | 34.74 |
+---------------------+-------+-------+
2022-11-29 21:43:24,669 - mmseg - INFO - Summary:
2022-11-29 21:43:24,670 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 81.77 | 29.21 | 37.73 |
+-------+-------+-------+
2022-11-29 21:44:15,696 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_1000.pth.
2022-11-29 21:44:15,697 - mmseg - INFO - Best mIoU is 0.2921 at 1000 iter.
2022-11-29 21:44:15,706 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-29 21:44:15,706 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8177, mIoU: 0.2921, mAcc: 0.3773, IoU.wall: 0.7963, IoU.building: 0.8190, IoU.sky: 0.9466, IoU.floor: 0.8432, IoU.tree: 0.7658, IoU.ceiling: 0.8703, IoU.road: 0.8116, IoU.bed : 0.8861, IoU.windowpane: 0.6405, IoU.grass: 0.7031, IoU.cabinet: 0.5850, IoU.sidewalk: 0.6700, IoU.person: 0.8728, IoU.earth: 0.4020, IoU.door: 0.5598, IoU.table: 0.5992, IoU.mountain: 0.4609, IoU.plant: 0.5523, IoU.curtain: 0.7270, IoU.chair: 0.5520, IoU.car: 0.8500, IoU.water: 0.5090, IoU.painting: 0.7471, IoU.sofa: 0.7618, IoU.shelf: 0.3745, IoU.house: 0.0131, IoU.sea: 0.5289, IoU.mirror: 0.7743, IoU.rug: 0.7380, IoU.field: 0.0688, IoU.armchair: 0.4119, IoU.seat: 0.2443, IoU.fence: 0.3184, IoU.desk: 0.3828, IoU.rock: 0.4792, IoU.wardrobe: 0.0000, IoU.lamp: 0.7010, IoU.bathtub: 0.7584, IoU.railing: 0.1753, IoU.cushion: 0.6809, IoU.base: 0.0000, IoU.box: 0.2867, IoU.column: 0.5422, IoU.signboard: 0.3245, IoU.chest of drawers: 0.0000, IoU.counter: 0.0000, IoU.sand: 0.2406, IoU.sink: 0.7152, IoU.skyscraper: 0.2414, IoU.fireplace: 0.3658, IoU.refrigerator: 0.6989, IoU.grandstand: 0.0000, IoU.path: 0.0000, IoU.stairs: 0.3812, IoU.runway: 0.0000, IoU.case: 0.0000, IoU.pool table: 0.6005, IoU.pillow: 0.6192, IoU.screen door: 0.0000, IoU.stairway: 0.1030, IoU.river: 0.0000, IoU.bridge: 0.3783, IoU.bookcase: 0.0000, IoU.blind: 0.0000, IoU.coffee table: 0.5869, IoU.toilet: 0.9040, IoU.flower: 0.4870, IoU.book: 0.5116, IoU.hill: 0.0000, IoU.bench: 0.3676, IoU.countertop: 0.2427, IoU.stove: 0.4569, IoU.palm: 0.0000, IoU.kitchen island: 0.0000, IoU.computer: 0.0527, IoU.swivel chair: 0.0000, IoU.boat: 0.7533, IoU.bar: 0.0000, IoU.arcade machine: 0.0000, IoU.hovel: 0.0000, IoU.bus: 0.0000, IoU.towel: 0.5517, IoU.light: 0.5161, IoU.truck: 0.0000, IoU.tower: 0.0000, IoU.chandelier: 0.5994, IoU.awning: 0.2123, IoU.streetlight: 0.3749, IoU.booth: 0.0000, IoU.television receiver: 0.2226, IoU.airplane: 0.8769, IoU.dirt track: 0.0000, IoU.apparel: 0.0027, IoU.pole: 0.3255, IoU.land: 0.0000, IoU.bannister: 0.0000, IoU.escalator: 0.0000, IoU.ottoman: 0.0305, IoU.bottle: 0.3315, IoU.buffet: 0.0000, IoU.poster: 0.0000, IoU.stage: 0.0000, IoU.van: 0.1897, IoU.ship: 0.0000, IoU.fountain: 0.0000, IoU.conveyer belt: 0.0000, IoU.canopy: 0.0000, IoU.washer: 0.0000, IoU.plaything: 0.1346, IoU.swimming pool: 0.0000, IoU.stool: 0.0000, IoU.barrel: 0.0000, IoU.basket: 0.1557, IoU.waterfall: 0.0000, IoU.tent: 0.0000, IoU.bag: 0.0801, IoU.minibike: 0.0245, IoU.cradle: 0.0000, IoU.oven: 0.0000, IoU.ball: 0.0000, IoU.food: 0.0000, IoU.step: 0.0000, IoU.tank: 0.0000, IoU.trade name: 0.0000, IoU.microwave: 0.8619, IoU.pot: 0.5880, IoU.animal: 0.0000, IoU.bicycle: 0.3741, IoU.lake: 0.0000, IoU.dishwasher: 0.0000, IoU.screen: 0.0000, IoU.blanket: 0.0000, IoU.sculpture: 0.4162, IoU.hood: 0.1140, IoU.sconce: 0.1573, IoU.vase: 0.4930, IoU.traffic light: 0.2959, IoU.tray: 0.0000, IoU.ashcan: 0.4904, IoU.fan: 0.6186, IoU.pier: 0.0000, IoU.crt screen: 0.0000, IoU.plate: 0.5772, IoU.monitor: 0.0000, IoU.bulletin board: 0.0000, IoU.shower: 0.0000, IoU.radiator: 0.0000, IoU.glass: 0.1537, IoU.clock: 0.2722, IoU.flag: 0.3344, Acc.wall: 0.9153, Acc.building: 0.9372, Acc.sky: 0.9741, Acc.floor: 0.9130, Acc.tree: 0.8804, Acc.ceiling: 0.9386, Acc.road: 0.9137, Acc.bed : 0.9685, Acc.windowpane: 0.8248, Acc.grass: 0.9254, Acc.cabinet: 0.8714, Acc.sidewalk: 0.8870, Acc.person: 0.9419, Acc.earth: 0.5652, Acc.door: 0.7794, Acc.table: 0.8461, Acc.mountain: 0.5617, Acc.plant: 0.7989, Acc.curtain: 0.8966, Acc.chair: 0.8535, Acc.car: 0.9410, Acc.water: 0.7769, Acc.painting: 0.9311, Acc.sofa: 0.9029, Acc.shelf: 0.7285, Acc.house: 0.0134, Acc.sea: 0.7056, Acc.mirror: 0.8829, Acc.rug: 0.8827, Acc.field: 0.0688, Acc.armchair: 0.5924, Acc.seat: 0.2807, Acc.fence: 0.5376, Acc.desk: 0.5815, Acc.rock: 0.8850, Acc.wardrobe: 0.0000, Acc.lamp: 0.8596, Acc.bathtub: 0.9105, Acc.railing: 0.2016, Acc.cushion: 0.8765, Acc.base: 0.0000, Acc.box: 0.5334, Acc.column: 0.6268, Acc.signboard: 0.6779, Acc.chest of drawers: 0.0000, Acc.counter: 0.0000, Acc.sand: 0.2408, Acc.sink: 0.8997, Acc.skyscraper: 0.2432, Acc.fireplace: 0.3762, Acc.refrigerator: 0.7041, Acc.grandstand: 0.0000, Acc.path: 0.0000, Acc.stairs: 0.6941, Acc.runway: 0.0000, Acc.case: 0.0000, Acc.pool table: 0.6063, Acc.pillow: 0.7742, Acc.screen door: 0.0000, Acc.stairway: 0.1087, Acc.river: 0.0000, Acc.bridge: 0.3847, Acc.bookcase: 0.0000, Acc.blind: 0.0000, Acc.coffee table: 0.8560, Acc.toilet: 0.9368, Acc.flower: 0.6392, Acc.book: 0.8529, Acc.hill: 0.0000, Acc.bench: 0.3776, Acc.countertop: 0.2727, Acc.stove: 0.9129, Acc.palm: 0.0000, Acc.kitchen island: 0.0000, Acc.computer: 0.0533, Acc.swivel chair: 0.0000, Acc.boat: 0.8359, Acc.bar: 0.0000, Acc.arcade machine: 0.0000, Acc.hovel: 0.0000, Acc.bus: 0.0000, Acc.towel: 0.8972, Acc.light: 0.7486, Acc.truck: 0.0000, Acc.tower: 0.0000, Acc.chandelier: 0.6717, Acc.awning: 0.4360, Acc.streetlight: 0.6018, Acc.booth: 0.0000, Acc.television receiver: 0.9131, Acc.airplane: 0.8832, Acc.dirt track: 0.0000, Acc.apparel: 0.0029, Acc.pole: 0.5807, Acc.land: 0.0000, Acc.bannister: 0.0000, Acc.escalator: 0.0000, Acc.ottoman: 0.0308, Acc.bottle: 0.4328, Acc.buffet: 0.0000, Acc.poster: 0.0000, Acc.stage: 0.0000, Acc.van: 0.5147, Acc.ship: 0.0000, Acc.fountain: 0.0000, Acc.conveyer belt: 0.0000, Acc.canopy: 0.0000, Acc.washer: 0.0000, Acc.plaything: 0.1363, Acc.swimming pool: 0.0000, Acc.stool: 0.0000, Acc.barrel: 0.0000, Acc.basket: 0.1663, Acc.waterfall: 0.0000, Acc.tent: 0.0000, Acc.bag: 0.0820, Acc.minibike: 0.0258, Acc.cradle: 0.0000, Acc.oven: 0.0000, Acc.ball: 0.0000, Acc.food: 0.0000, Acc.step: 0.0000, Acc.tank: 0.0000, Acc.trade name: 0.0000, Acc.microwave: 0.8903, Acc.pot: 0.7127, Acc.animal: 0.0000, Acc.bicycle: 0.6265, Acc.lake: 0.0000, Acc.dishwasher: 0.0000, Acc.screen: 0.0000, Acc.blanket: 0.0000, Acc.sculpture: 0.4446, Acc.hood: 0.1141, Acc.sconce: 0.1752, Acc.vase: 0.8019, Acc.traffic light: 0.3209, Acc.tray: 0.0000, Acc.ashcan: 0.5518, Acc.fan: 0.7018, Acc.pier: 0.0000, Acc.crt screen: 0.0000, Acc.plate: 0.7637, Acc.monitor: 0.0000, Acc.bulletin board: 0.0000, Acc.shower: 0.0000, Acc.radiator: 0.0000, Acc.glass: 0.1579, Acc.clock: 0.5022, Acc.flag: 0.3474
2022-11-29 21:47:41,876 - mmseg - INFO - Iter [1050/40000]	lr: 9.059e-08, eta: 1 day, 23:32:44, time: 8.890, data_time: 4.786, memory: 51902, decode.loss_cls: 1.0609, decode.loss_mask: 0.6494, decode.loss_dice: 0.9424, decode.d0.loss_cls: 10.0374, decode.d0.loss_mask: 0.6578, decode.d0.loss_dice: 1.1123, decode.d1.loss_cls: 1.6381, decode.d1.loss_mask: 0.6554, decode.d1.loss_dice: 1.0062, decode.d2.loss_cls: 1.3702, decode.d2.loss_mask: 0.6444, decode.d2.loss_dice: 0.9575, decode.d3.loss_cls: 1.2403, decode.d3.loss_mask: 0.6408, decode.d3.loss_dice: 0.9434, decode.d4.loss_cls: 1.1674, decode.d4.loss_mask: 0.6433, decode.d4.loss_dice: 0.9506, decode.d5.loss_cls: 1.1148, decode.d5.loss_mask: 0.6437, decode.d5.loss_dice: 0.9431, decode.d6.loss_cls: 1.0825, decode.d6.loss_mask: 0.6485, decode.d6.loss_dice: 0.9429, decode.d7.loss_cls: 1.0656, decode.d7.loss_mask: 0.6482, decode.d7.loss_dice: 0.9475, decode.d8.loss_cls: 1.0535, decode.d8.loss_mask: 0.6500, decode.d8.loss_dice: 0.9464, loss: 37.0044
2022-11-29 21:51:07,692 - mmseg - INFO - Iter [1100/40000]	lr: 9.479e-08, eta: 1 day, 23:20:52, time: 4.116, data_time: 0.019, memory: 51902, decode.loss_cls: 1.0081, decode.loss_mask: 0.6723, decode.loss_dice: 0.9737, decode.d0.loss_cls: 10.0318, decode.d0.loss_mask: 0.6698, decode.d0.loss_dice: 1.1168, decode.d1.loss_cls: 1.5507, decode.d1.loss_mask: 0.6794, decode.d1.loss_dice: 1.0187, decode.d2.loss_cls: 1.2971, decode.d2.loss_mask: 0.6665, decode.d2.loss_dice: 0.9801, decode.d3.loss_cls: 1.1828, decode.d3.loss_mask: 0.6642, decode.d3.loss_dice: 0.9695, decode.d4.loss_cls: 1.1015, decode.d4.loss_mask: 0.6684, decode.d4.loss_dice: 0.9760, decode.d5.loss_cls: 1.0545, decode.d5.loss_mask: 0.6688, decode.d5.loss_dice: 0.9732, decode.d6.loss_cls: 1.0346, decode.d6.loss_mask: 0.6690, decode.d6.loss_dice: 0.9706, decode.d7.loss_cls: 1.0146, decode.d7.loss_mask: 0.6728, decode.d7.loss_dice: 0.9771, decode.d8.loss_cls: 1.0024, decode.d8.loss_mask: 0.6747, decode.d8.loss_dice: 0.9768, loss: 36.9163
2022-11-29 21:54:33,246 - mmseg - INFO - Iter [1150/40000]	lr: 9.897e-08, eta: 1 day, 23:09:36, time: 4.111, data_time: 0.020, memory: 51902, decode.loss_cls: 0.9766, decode.loss_mask: 0.6736, decode.loss_dice: 0.9622, decode.d0.loss_cls: 10.0188, decode.d0.loss_mask: 0.6713, decode.d0.loss_dice: 1.1110, decode.d1.loss_cls: 1.5154, decode.d1.loss_mask: 0.6797, decode.d1.loss_dice: 1.0090, decode.d2.loss_cls: 1.2660, decode.d2.loss_mask: 0.6692, decode.d2.loss_dice: 0.9617, decode.d3.loss_cls: 1.1468, decode.d3.loss_mask: 0.6646, decode.d3.loss_dice: 0.9611, decode.d4.loss_cls: 1.0700, decode.d4.loss_mask: 0.6689, decode.d4.loss_dice: 0.9621, decode.d5.loss_cls: 1.0254, decode.d5.loss_mask: 0.6683, decode.d5.loss_dice: 0.9561, decode.d6.loss_cls: 0.9969, decode.d6.loss_mask: 0.6695, decode.d6.loss_dice: 0.9533, decode.d7.loss_cls: 0.9803, decode.d7.loss_mask: 0.6703, decode.d7.loss_dice: 0.9602, decode.d8.loss_cls: 0.9697, decode.d8.loss_mask: 0.6725, decode.d8.loss_dice: 0.9601, loss: 36.4706
2022-11-29 21:57:59,045 - mmseg - INFO - Iter [1200/40000]	lr: 1.031e-07, eta: 1 day, 22:59:06, time: 4.116, data_time: 0.019, memory: 51902, decode.loss_cls: 0.9228, decode.loss_mask: 0.6766, decode.loss_dice: 0.9705, decode.d0.loss_cls: 10.0171, decode.d0.loss_mask: 0.6672, decode.d0.loss_dice: 1.1089, decode.d1.loss_cls: 1.4471, decode.d1.loss_mask: 0.6809, decode.d1.loss_dice: 1.0110, decode.d2.loss_cls: 1.2003, decode.d2.loss_mask: 0.6658, decode.d2.loss_dice: 0.9694, decode.d3.loss_cls: 1.0859, decode.d3.loss_mask: 0.6608, decode.d3.loss_dice: 0.9621, decode.d4.loss_cls: 1.0124, decode.d4.loss_mask: 0.6672, decode.d4.loss_dice: 0.9711, decode.d5.loss_cls: 0.9633, decode.d5.loss_mask: 0.6694, decode.d5.loss_dice: 0.9718, decode.d6.loss_cls: 0.9439, decode.d6.loss_mask: 0.6721, decode.d6.loss_dice: 0.9615, decode.d7.loss_cls: 0.9229, decode.d7.loss_mask: 0.6750, decode.d7.loss_dice: 0.9680, decode.d8.loss_cls: 0.9161, decode.d8.loss_mask: 0.6723, decode.d8.loss_dice: 0.9725, loss: 36.0060
2022-11-29 22:01:24,742 - mmseg - INFO - Iter [1250/40000]	lr: 1.073e-07, eta: 1 day, 22:49:08, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.9444, decode.loss_mask: 0.6629, decode.loss_dice: 0.9566, decode.d0.loss_cls: 10.0139, decode.d0.loss_mask: 0.6519, decode.d0.loss_dice: 1.0967, decode.d1.loss_cls: 1.4477, decode.d1.loss_mask: 0.6706, decode.d1.loss_dice: 0.9937, decode.d2.loss_cls: 1.2059, decode.d2.loss_mask: 0.6597, decode.d2.loss_dice: 0.9577, decode.d3.loss_cls: 1.0962, decode.d3.loss_mask: 0.6559, decode.d3.loss_dice: 0.9543, decode.d4.loss_cls: 1.0258, decode.d4.loss_mask: 0.6589, decode.d4.loss_dice: 0.9559, decode.d5.loss_cls: 0.9862, decode.d5.loss_mask: 0.6610, decode.d5.loss_dice: 0.9588, decode.d6.loss_cls: 0.9607, decode.d6.loss_mask: 0.6631, decode.d6.loss_dice: 0.9535, decode.d7.loss_cls: 0.9483, decode.d7.loss_mask: 0.6644, decode.d7.loss_dice: 0.9584, decode.d8.loss_cls: 0.9438, decode.d8.loss_mask: 0.6641, decode.d8.loss_dice: 0.9549, loss: 35.9258
2022-11-29 22:04:52,672 - mmseg - INFO - Iter [1300/40000]	lr: 1.115e-07, eta: 1 day, 22:40:46, time: 4.159, data_time: 0.064, memory: 51902, decode.loss_cls: 0.8854, decode.loss_mask: 0.6837, decode.loss_dice: 0.9612, decode.d0.loss_cls: 10.0094, decode.d0.loss_mask: 0.6696, decode.d0.loss_dice: 1.0871, decode.d1.loss_cls: 1.3709, decode.d1.loss_mask: 0.6885, decode.d1.loss_dice: 1.0043, decode.d2.loss_cls: 1.1361, decode.d2.loss_mask: 0.6800, decode.d2.loss_dice: 0.9622, decode.d3.loss_cls: 1.0320, decode.d3.loss_mask: 0.6752, decode.d3.loss_dice: 0.9572, decode.d4.loss_cls: 0.9674, decode.d4.loss_mask: 0.6795, decode.d4.loss_dice: 0.9560, decode.d5.loss_cls: 0.9234, decode.d5.loss_mask: 0.6824, decode.d5.loss_dice: 0.9582, decode.d6.loss_cls: 0.9024, decode.d6.loss_mask: 0.6832, decode.d6.loss_dice: 0.9532, decode.d7.loss_cls: 0.8862, decode.d7.loss_mask: 0.6852, decode.d7.loss_dice: 0.9606, decode.d8.loss_cls: 0.8808, decode.d8.loss_mask: 0.6827, decode.d8.loss_dice: 0.9578, loss: 35.5622
2022-11-29 22:08:18,267 - mmseg - INFO - Iter [1350/40000]	lr: 1.156e-07, eta: 1 day, 22:31:39, time: 4.112, data_time: 0.018, memory: 51902, decode.loss_cls: 0.8838, decode.loss_mask: 0.6611, decode.loss_dice: 0.9601, decode.d0.loss_cls: 10.0005, decode.d0.loss_mask: 0.6522, decode.d0.loss_dice: 1.0868, decode.d1.loss_cls: 1.3629, decode.d1.loss_mask: 0.6709, decode.d1.loss_dice: 1.0014, decode.d2.loss_cls: 1.1252, decode.d2.loss_mask: 0.6628, decode.d2.loss_dice: 0.9743, decode.d3.loss_cls: 1.0221, decode.d3.loss_mask: 0.6568, decode.d3.loss_dice: 0.9571, decode.d4.loss_cls: 0.9607, decode.d4.loss_mask: 0.6575, decode.d4.loss_dice: 0.9588, decode.d5.loss_cls: 0.9226, decode.d5.loss_mask: 0.6587, decode.d5.loss_dice: 0.9554, decode.d6.loss_cls: 0.8998, decode.d6.loss_mask: 0.6600, decode.d6.loss_dice: 0.9569, decode.d7.loss_cls: 0.8867, decode.d7.loss_mask: 0.6642, decode.d7.loss_dice: 0.9593, decode.d8.loss_cls: 0.8834, decode.d8.loss_mask: 0.6610, decode.d8.loss_dice: 0.9581, loss: 35.3213
2022-11-29 22:11:44,317 - mmseg - INFO - Iter [1400/40000]	lr: 1.197e-07, eta: 1 day, 22:23:09, time: 4.121, data_time: 0.019, memory: 51902, decode.loss_cls: 0.8708, decode.loss_mask: 0.6557, decode.loss_dice: 0.9469, decode.d0.loss_cls: 9.9946, decode.d0.loss_mask: 0.6450, decode.d0.loss_dice: 1.0875, decode.d1.loss_cls: 1.3640, decode.d1.loss_mask: 0.6625, decode.d1.loss_dice: 0.9996, decode.d2.loss_cls: 1.1263, decode.d2.loss_mask: 0.6524, decode.d2.loss_dice: 0.9495, decode.d3.loss_cls: 1.0205, decode.d3.loss_mask: 0.6454, decode.d3.loss_dice: 0.9407, decode.d4.loss_cls: 0.9504, decode.d4.loss_mask: 0.6500, decode.d4.loss_dice: 0.9437, decode.d5.loss_cls: 0.9084, decode.d5.loss_mask: 0.6520, decode.d5.loss_dice: 0.9460, decode.d6.loss_cls: 0.8894, decode.d6.loss_mask: 0.6561, decode.d6.loss_dice: 0.9414, decode.d7.loss_cls: 0.8755, decode.d7.loss_mask: 0.6534, decode.d7.loss_dice: 0.9441, decode.d8.loss_cls: 0.8667, decode.d8.loss_mask: 0.6544, decode.d8.loss_dice: 0.9443, loss: 35.0370
2022-11-29 22:15:09,675 - mmseg - INFO - Iter [1450/40000]	lr: 1.238e-07, eta: 1 day, 22:14:42, time: 4.107, data_time: 0.020, memory: 51902, decode.loss_cls: 0.8694, decode.loss_mask: 0.6760, decode.loss_dice: 0.9661, decode.d0.loss_cls: 9.9866, decode.d0.loss_mask: 0.6685, decode.d0.loss_dice: 1.0961, decode.d1.loss_cls: 1.3200, decode.d1.loss_mask: 0.6882, decode.d1.loss_dice: 1.0124, decode.d2.loss_cls: 1.0891, decode.d2.loss_mask: 0.6758, decode.d2.loss_dice: 0.9734, decode.d3.loss_cls: 0.9954, decode.d3.loss_mask: 0.6702, decode.d3.loss_dice: 0.9609, decode.d4.loss_cls: 0.9352, decode.d4.loss_mask: 0.6756, decode.d4.loss_dice: 0.9651, decode.d5.loss_cls: 0.9011, decode.d5.loss_mask: 0.6746, decode.d5.loss_dice: 0.9680, decode.d6.loss_cls: 0.8801, decode.d6.loss_mask: 0.6748, decode.d6.loss_dice: 0.9606, decode.d7.loss_cls: 0.8687, decode.d7.loss_mask: 0.6789, decode.d7.loss_dice: 0.9673, decode.d8.loss_cls: 0.8647, decode.d8.loss_mask: 0.6775, decode.d8.loss_dice: 0.9678, loss: 35.3081
2022-11-29 22:18:35,223 - mmseg - INFO - Iter [1500/40000]	lr: 1.280e-07, eta: 1 day, 22:06:39, time: 4.111, data_time: 0.018, memory: 51902, decode.loss_cls: 0.8311, decode.loss_mask: 0.6821, decode.loss_dice: 0.9672, decode.d0.loss_cls: 9.9746, decode.d0.loss_mask: 0.6599, decode.d0.loss_dice: 1.0805, decode.d1.loss_cls: 1.2625, decode.d1.loss_mask: 0.6863, decode.d1.loss_dice: 1.0072, decode.d2.loss_cls: 1.0406, decode.d2.loss_mask: 0.6806, decode.d2.loss_dice: 0.9678, decode.d3.loss_cls: 0.9483, decode.d3.loss_mask: 0.6791, decode.d3.loss_dice: 0.9591, decode.d4.loss_cls: 0.8932, decode.d4.loss_mask: 0.6818, decode.d4.loss_dice: 0.9634, decode.d5.loss_cls: 0.8633, decode.d5.loss_mask: 0.6806, decode.d5.loss_dice: 0.9670, decode.d6.loss_cls: 0.8445, decode.d6.loss_mask: 0.6810, decode.d6.loss_dice: 0.9646, decode.d7.loss_cls: 0.8339, decode.d7.loss_mask: 0.6816, decode.d7.loss_dice: 0.9685, decode.d8.loss_cls: 0.8273, decode.d8.loss_mask: 0.6844, decode.d8.loss_dice: 0.9710, loss: 34.9332
2022-11-29 22:22:00,920 - mmseg - INFO - Iter [1550/40000]	lr: 1.279e-07, eta: 1 day, 21:58:58, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.8232, decode.loss_mask: 0.6613, decode.loss_dice: 0.9490, decode.d0.loss_cls: 9.9685, decode.d0.loss_mask: 0.6424, decode.d0.loss_dice: 1.0776, decode.d1.loss_cls: 1.2508, decode.d1.loss_mask: 0.6684, decode.d1.loss_dice: 1.0000, decode.d2.loss_cls: 1.0351, decode.d2.loss_mask: 0.6551, decode.d2.loss_dice: 0.9576, decode.d3.loss_cls: 0.9391, decode.d3.loss_mask: 0.6544, decode.d3.loss_dice: 0.9455, decode.d4.loss_cls: 0.8796, decode.d4.loss_mask: 0.6568, decode.d4.loss_dice: 0.9509, decode.d5.loss_cls: 0.8504, decode.d5.loss_mask: 0.6575, decode.d5.loss_dice: 0.9475, decode.d6.loss_cls: 0.8314, decode.d6.loss_mask: 0.6608, decode.d6.loss_dice: 0.9460, decode.d7.loss_cls: 0.8213, decode.d7.loss_mask: 0.6594, decode.d7.loss_dice: 0.9558, decode.d8.loss_cls: 0.8190, decode.d8.loss_mask: 0.6591, decode.d8.loss_dice: 0.9494, loss: 34.4729
2022-11-29 22:25:26,758 - mmseg - INFO - Iter [1600/40000]	lr: 1.277e-07, eta: 1 day, 21:51:37, time: 4.117, data_time: 0.020, memory: 51902, decode.loss_cls: 0.8049, decode.loss_mask: 0.6563, decode.loss_dice: 0.9492, decode.d0.loss_cls: 9.9633, decode.d0.loss_mask: 0.6374, decode.d0.loss_dice: 1.0634, decode.d1.loss_cls: 1.2266, decode.d1.loss_mask: 0.6668, decode.d1.loss_dice: 0.9879, decode.d2.loss_cls: 1.0087, decode.d2.loss_mask: 0.6559, decode.d2.loss_dice: 0.9530, decode.d3.loss_cls: 0.9166, decode.d3.loss_mask: 0.6489, decode.d3.loss_dice: 0.9402, decode.d4.loss_cls: 0.8621, decode.d4.loss_mask: 0.6573, decode.d4.loss_dice: 0.9481, decode.d5.loss_cls: 0.8336, decode.d5.loss_mask: 0.6523, decode.d5.loss_dice: 0.9442, decode.d6.loss_cls: 0.8205, decode.d6.loss_mask: 0.6552, decode.d6.loss_dice: 0.9400, decode.d7.loss_cls: 0.8081, decode.d7.loss_mask: 0.6547, decode.d7.loss_dice: 0.9440, decode.d8.loss_cls: 0.8036, decode.d8.loss_mask: 0.6560, decode.d8.loss_dice: 0.9448, loss: 34.2037
2022-11-29 22:28:52,269 - mmseg - INFO - Iter [1650/40000]	lr: 1.275e-07, eta: 1 day, 21:44:22, time: 4.110, data_time: 0.019, memory: 51902, decode.loss_cls: 0.8022, decode.loss_mask: 0.6699, decode.loss_dice: 0.9610, decode.d0.loss_cls: 9.9541, decode.d0.loss_mask: 0.6529, decode.d0.loss_dice: 1.0724, decode.d1.loss_cls: 1.2121, decode.d1.loss_mask: 0.6763, decode.d1.loss_dice: 1.0054, decode.d2.loss_cls: 1.0002, decode.d2.loss_mask: 0.6703, decode.d2.loss_dice: 0.9650, decode.d3.loss_cls: 0.9093, decode.d3.loss_mask: 0.6637, decode.d3.loss_dice: 0.9509, decode.d4.loss_cls: 0.8612, decode.d4.loss_mask: 0.6696, decode.d4.loss_dice: 0.9605, decode.d5.loss_cls: 0.8328, decode.d5.loss_mask: 0.6653, decode.d5.loss_dice: 0.9584, decode.d6.loss_cls: 0.8182, decode.d6.loss_mask: 0.6721, decode.d6.loss_dice: 0.9523, decode.d7.loss_cls: 0.8035, decode.d7.loss_mask: 0.6706, decode.d7.loss_dice: 0.9575, decode.d8.loss_cls: 0.7968, decode.d8.loss_mask: 0.6706, decode.d8.loss_dice: 0.9557, loss: 34.4107
2022-11-29 22:32:17,927 - mmseg - INFO - Iter [1700/40000]	lr: 1.274e-07, eta: 1 day, 21:37:24, time: 4.113, data_time: 0.019, memory: 51902, decode.loss_cls: 0.7917, decode.loss_mask: 0.6665, decode.loss_dice: 0.9491, decode.d0.loss_cls: 9.9486, decode.d0.loss_mask: 0.6423, decode.d0.loss_dice: 1.0607, decode.d1.loss_cls: 1.1891, decode.d1.loss_mask: 0.6708, decode.d1.loss_dice: 0.9933, decode.d2.loss_cls: 0.9676, decode.d2.loss_mask: 0.6645, decode.d2.loss_dice: 0.9573, decode.d3.loss_cls: 0.8821, decode.d3.loss_mask: 0.6617, decode.d3.loss_dice: 0.9483, decode.d4.loss_cls: 0.8329, decode.d4.loss_mask: 0.6628, decode.d4.loss_dice: 0.9542, decode.d5.loss_cls: 0.8104, decode.d5.loss_mask: 0.6634, decode.d5.loss_dice: 0.9479, decode.d6.loss_cls: 0.8000, decode.d6.loss_mask: 0.6611, decode.d6.loss_dice: 0.9447, decode.d7.loss_cls: 0.7923, decode.d7.loss_mask: 0.6657, decode.d7.loss_dice: 0.9495, decode.d8.loss_cls: 0.7886, decode.d8.loss_mask: 0.6660, decode.d8.loss_dice: 0.9477, loss: 34.0807
2022-11-29 22:35:44,036 - mmseg - INFO - Iter [1750/40000]	lr: 1.272e-07, eta: 1 day, 21:30:48, time: 4.122, data_time: 0.018, memory: 51902, decode.loss_cls: 0.7721, decode.loss_mask: 0.6675, decode.loss_dice: 0.9706, decode.d0.loss_cls: 9.9417, decode.d0.loss_mask: 0.6443, decode.d0.loss_dice: 1.0831, decode.d1.loss_cls: 1.1782, decode.d1.loss_mask: 0.6746, decode.d1.loss_dice: 1.0168, decode.d2.loss_cls: 0.9642, decode.d2.loss_mask: 0.6693, decode.d2.loss_dice: 0.9805, decode.d3.loss_cls: 0.8784, decode.d3.loss_mask: 0.6634, decode.d3.loss_dice: 0.9729, decode.d4.loss_cls: 0.8286, decode.d4.loss_mask: 0.6683, decode.d4.loss_dice: 0.9726, decode.d5.loss_cls: 0.7981, decode.d5.loss_mask: 0.6688, decode.d5.loss_dice: 0.9709, decode.d6.loss_cls: 0.7832, decode.d6.loss_mask: 0.6684, decode.d6.loss_dice: 0.9666, decode.d7.loss_cls: 0.7752, decode.d7.loss_mask: 0.6687, decode.d7.loss_dice: 0.9740, decode.d8.loss_cls: 0.7755, decode.d8.loss_mask: 0.6699, decode.d8.loss_dice: 0.9729, loss: 34.2394
2022-11-29 22:39:09,563 - mmseg - INFO - Iter [1800/40000]	lr: 1.270e-07, eta: 1 day, 21:24:10, time: 4.111, data_time: 0.020, memory: 51902, decode.loss_cls: 0.7801, decode.loss_mask: 0.6855, decode.loss_dice: 0.9618, decode.d0.loss_cls: 9.9353, decode.d0.loss_mask: 0.6618, decode.d0.loss_dice: 1.0790, decode.d1.loss_cls: 1.1526, decode.d1.loss_mask: 0.6961, decode.d1.loss_dice: 1.0183, decode.d2.loss_cls: 0.9570, decode.d2.loss_mask: 0.6856, decode.d2.loss_dice: 0.9795, decode.d3.loss_cls: 0.8722, decode.d3.loss_mask: 0.6823, decode.d3.loss_dice: 0.9599, decode.d4.loss_cls: 0.8285, decode.d4.loss_mask: 0.6836, decode.d4.loss_dice: 0.9661, decode.d5.loss_cls: 0.7981, decode.d5.loss_mask: 0.6836, decode.d5.loss_dice: 0.9684, decode.d6.loss_cls: 0.7868, decode.d6.loss_mask: 0.6843, decode.d6.loss_dice: 0.9630, decode.d7.loss_cls: 0.7788, decode.d7.loss_mask: 0.6829, decode.d7.loss_dice: 0.9628, decode.d8.loss_cls: 0.7742, decode.d8.loss_mask: 0.6822, decode.d8.loss_dice: 0.9669, loss: 34.3172
2022-11-29 22:42:35,297 - mmseg - INFO - Iter [1850/40000]	lr: 1.269e-07, eta: 1 day, 21:17:47, time: 4.115, data_time: 0.020, memory: 51902, decode.loss_cls: 0.7821, decode.loss_mask: 0.6612, decode.loss_dice: 0.9696, decode.d0.loss_cls: 9.9261, decode.d0.loss_mask: 0.6467, decode.d0.loss_dice: 1.0867, decode.d1.loss_cls: 1.1453, decode.d1.loss_mask: 0.6717, decode.d1.loss_dice: 1.0250, decode.d2.loss_cls: 0.9487, decode.d2.loss_mask: 0.6627, decode.d2.loss_dice: 0.9806, decode.d3.loss_cls: 0.8743, decode.d3.loss_mask: 0.6580, decode.d3.loss_dice: 0.9702, decode.d4.loss_cls: 0.8309, decode.d4.loss_mask: 0.6611, decode.d4.loss_dice: 0.9635, decode.d5.loss_cls: 0.8028, decode.d5.loss_mask: 0.6600, decode.d5.loss_dice: 0.9725, decode.d6.loss_cls: 0.7874, decode.d6.loss_mask: 0.6612, decode.d6.loss_dice: 0.9678, decode.d7.loss_cls: 0.7822, decode.d7.loss_mask: 0.6626, decode.d7.loss_dice: 0.9744, decode.d8.loss_cls: 0.7793, decode.d8.loss_mask: 0.6616, decode.d8.loss_dice: 0.9699, loss: 34.1462
2022-11-29 22:46:03,206 - mmseg - INFO - Iter [1900/40000]	lr: 1.267e-07, eta: 1 day, 21:12:17, time: 4.158, data_time: 0.064, memory: 51902, decode.loss_cls: 0.7533, decode.loss_mask: 0.6599, decode.loss_dice: 0.9515, decode.d0.loss_cls: 9.9093, decode.d0.loss_mask: 0.6350, decode.d0.loss_dice: 1.0594, decode.d1.loss_cls: 1.1148, decode.d1.loss_mask: 0.6690, decode.d1.loss_dice: 0.9886, decode.d2.loss_cls: 0.9206, decode.d2.loss_mask: 0.6589, decode.d2.loss_dice: 0.9462, decode.d3.loss_cls: 0.8372, decode.d3.loss_mask: 0.6568, decode.d3.loss_dice: 0.9414, decode.d4.loss_cls: 0.8057, decode.d4.loss_mask: 0.6584, decode.d4.loss_dice: 0.9454, decode.d5.loss_cls: 0.7766, decode.d5.loss_mask: 0.6591, decode.d5.loss_dice: 0.9492, decode.d6.loss_cls: 0.7661, decode.d6.loss_mask: 0.6607, decode.d6.loss_dice: 0.9437, decode.d7.loss_cls: 0.7597, decode.d7.loss_mask: 0.6599, decode.d7.loss_dice: 0.9490, decode.d8.loss_cls: 0.7510, decode.d8.loss_mask: 0.6599, decode.d8.loss_dice: 0.9495, loss: 33.5959
2022-11-29 22:49:28,854 - mmseg - INFO - Iter [1950/40000]	lr: 1.265e-07, eta: 1 day, 21:06:09, time: 4.113, data_time: 0.019, memory: 51902, decode.loss_cls: 0.7637, decode.loss_mask: 0.6765, decode.loss_dice: 0.9883, decode.d0.loss_cls: 9.9057, decode.d0.loss_mask: 0.6603, decode.d0.loss_dice: 1.1067, decode.d1.loss_cls: 1.1392, decode.d1.loss_mask: 0.6865, decode.d1.loss_dice: 1.0316, decode.d2.loss_cls: 0.9346, decode.d2.loss_mask: 0.6798, decode.d2.loss_dice: 0.9973, decode.d3.loss_cls: 0.8540, decode.d3.loss_mask: 0.6743, decode.d3.loss_dice: 0.9847, decode.d4.loss_cls: 0.8082, decode.d4.loss_mask: 0.6716, decode.d4.loss_dice: 0.9904, decode.d5.loss_cls: 0.7832, decode.d5.loss_mask: 0.6750, decode.d5.loss_dice: 0.9891, decode.d6.loss_cls: 0.7708, decode.d6.loss_mask: 0.6741, decode.d6.loss_dice: 0.9871, decode.d7.loss_cls: 0.7616, decode.d7.loss_mask: 0.6783, decode.d7.loss_dice: 0.9859, decode.d8.loss_cls: 0.7622, decode.d8.loss_mask: 0.6742, decode.d8.loss_dice: 0.9869, loss: 34.2817
2022-11-29 22:52:54,605 - mmseg - INFO - Saving checkpoint at 2000 iterations
2022-11-29 22:53:44,966 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-29 22:53:44,966 - mmseg - INFO - Iter [2000/40000]	lr: 1.264e-07, eta: 1 day, 21:16:08, time: 5.122, data_time: 0.018, memory: 51902, decode.loss_cls: 0.7112, decode.loss_mask: 0.6632, decode.loss_dice: 0.9498, decode.d0.loss_cls: 9.8934, decode.d0.loss_mask: 0.6386, decode.d0.loss_dice: 1.0513, decode.d1.loss_cls: 1.0658, decode.d1.loss_mask: 0.6752, decode.d1.loss_dice: 1.0012, decode.d2.loss_cls: 0.8741, decode.d2.loss_mask: 0.6671, decode.d2.loss_dice: 0.9654, decode.d3.loss_cls: 0.7991, decode.d3.loss_mask: 0.6611, decode.d3.loss_dice: 0.9523, decode.d4.loss_cls: 0.7594, decode.d4.loss_mask: 0.6609, decode.d4.loss_dice: 0.9550, decode.d5.loss_cls: 0.7354, decode.d5.loss_mask: 0.6629, decode.d5.loss_dice: 0.9525, decode.d6.loss_cls: 0.7240, decode.d6.loss_mask: 0.6648, decode.d6.loss_dice: 0.9493, decode.d7.loss_cls: 0.7121, decode.d7.loss_mask: 0.6642, decode.d7.loss_dice: 0.9540, decode.d8.loss_cls: 0.7121, decode.d8.loss_mask: 0.6622, decode.d8.loss_dice: 0.9501, loss: 33.2878
2022-11-29 22:56:42,974 - mmseg - INFO - per class results:
2022-11-29 22:56:42,979 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 81.53 |  90.6 |
|       building      | 83.88 | 90.78 |
|         sky         | 94.73 | 97.42 |
|        floor        | 84.83 | 90.25 |
|         tree        | 77.72 | 88.04 |
|       ceiling       | 87.75 | 93.48 |
|         road        | 83.48 | 91.44 |
|         bed         |  91.5 | 96.91 |
|      windowpane     | 66.08 |  81.3 |
|        grass        | 66.46 | 81.53 |
|       cabinet       |  64.3 | 80.15 |
|       sidewalk      | 69.35 | 87.67 |
|        person       | 87.97 | 93.52 |
|        earth        | 42.61 | 56.41 |
|         door        | 59.91 | 80.36 |
|        table        | 68.19 | 83.52 |
|       mountain      | 63.54 | 85.41 |
|        plant        | 56.11 | 68.15 |
|       curtain       |  73.7 | 90.79 |
|        chair        | 61.73 | 74.23 |
|         car         | 88.18 | 92.46 |
|        water        | 52.26 | 75.24 |
|       painting      | 81.29 | 92.83 |
|         sofa        | 81.73 | 90.97 |
|        shelf        | 41.33 | 69.17 |
|        house        | 51.07 | 73.46 |
|         sea         | 53.07 |  71.1 |
|        mirror       | 79.92 |  92.7 |
|         rug         |  70.4 |  88.6 |
|        field        | 18.03 |  33.2 |
|       armchair      | 53.72 | 81.26 |
|         seat        | 63.64 | 87.42 |
|        fence        |  52.5 | 74.55 |
|         desk        | 52.07 | 67.39 |
|         rock        | 63.17 |  80.3 |
|       wardrobe      | 21.39 | 22.62 |
|         lamp        | 76.37 |  87.2 |
|       bathtub       | 84.09 | 93.29 |
|       railing       | 43.07 | 69.69 |
|       cushion       | 69.54 |  87.5 |
|         base        | 10.21 | 12.24 |
|         box         | 39.48 | 52.57 |
|        column       | 61.79 | 83.31 |
|      signboard      | 43.96 | 60.46 |
|   chest of drawers  |  29.7 | 48.12 |
|       counter       | 27.38 | 76.64 |
|         sand        | 64.11 | 87.45 |
|         sink        | 82.02 | 87.38 |
|      skyscraper     |  37.9 | 61.83 |
|      fireplace      | 72.03 | 90.73 |
|     refrigerator    |  80.5 |  91.1 |
|      grandstand     |  5.85 |  5.86 |
|         path        | 18.87 | 22.57 |
|        stairs       | 24.19 | 31.08 |
|        runway       |  0.0  |  0.0  |
|         case        | 13.88 | 15.68 |
|      pool table     | 93.69 | 97.35 |
|        pillow       | 66.92 |  78.3 |
|     screen door     | 32.17 | 32.24 |
|       stairway      | 33.63 | 72.42 |
|        river        |  24.8 | 36.92 |
|        bridge       |  78.6 | 89.74 |
|       bookcase      |  15.0 | 20.78 |
|        blind        | 19.57 | 22.22 |
|     coffee table    | 66.47 | 89.77 |
|        toilet       | 90.82 | 94.94 |
|        flower       |  44.4 | 79.35 |
|         book        | 55.48 | 80.46 |
|         hill        |  0.0  |  0.0  |
|        bench        | 68.46 | 80.36 |
|      countertop     | 51.44 | 80.62 |
|        stove        | 80.27 | 89.88 |
|         palm        | 53.38 | 86.08 |
|    kitchen island   |  7.64 |  7.64 |
|       computer      | 71.75 | 92.83 |
|     swivel chair    | 44.79 | 68.12 |
|         boat        | 79.66 | 93.12 |
|         bar         |  0.0  |  0.0  |
|    arcade machine   |  0.0  |  0.0  |
|        hovel        |  0.0  |  0.0  |
|         bus         | 94.23 | 96.18 |
|        towel        | 74.14 | 90.26 |
|        light        | 63.67 | 76.44 |
|        truck        |  45.7 | 73.58 |
|        tower        |  4.66 |  7.63 |
|      chandelier     |  71.2 | 89.18 |
|        awning       | 21.12 |  50.8 |
|     streetlight     | 40.48 | 65.92 |
|        booth        |  0.0  |  0.0  |
| television receiver | 59.81 | 93.88 |
|       airplane      | 90.86 | 95.89 |
|      dirt track     |  0.0  |  0.0  |
|       apparel       | 50.34 | 84.36 |
|         pole        |  36.6 | 55.56 |
|         land        |  0.0  |  0.0  |
|      bannister      |  5.48 |  5.7  |
|      escalator      |  0.0  |  0.0  |
|       ottoman       | 48.86 | 78.64 |
|        bottle       | 40.75 | 53.52 |
|        buffet       |  0.0  |  0.0  |
|        poster       | 21.34 | 37.29 |
|        stage        |  0.0  |  0.0  |
|         van         | 44.18 | 81.21 |
|         ship        |  0.0  |  0.0  |
|       fountain      |  0.0  |  0.0  |
|    conveyer belt    |  0.0  |  0.0  |
|        canopy       |  0.0  |  0.0  |
|        washer       | 21.42 | 21.42 |
|      plaything      | 23.71 | 41.97 |
|    swimming pool    |  0.0  |  0.0  |
|        stool        |  54.3 | 70.47 |
|        barrel       |  0.0  |  0.0  |
|        basket       | 39.21 | 64.46 |
|      waterfall      | 44.21 | 47.33 |
|         tent        |  0.0  |  0.0  |
|         bag         | 38.31 | 53.89 |
|       minibike      |  80.5 | 92.23 |
|        cradle       |  0.0  |  0.0  |
|         oven        | 58.49 |  65.2 |
|         ball        | 55.11 | 82.95 |
|         food        | 58.97 | 63.34 |
|         step        |  0.0  |  0.0  |
|         tank        |  0.0  |  0.0  |
|      trade name     | 31.53 | 57.68 |
|      microwave      | 90.35 | 96.84 |
|         pot         | 60.16 | 71.32 |
|        animal       | 71.82 | 72.56 |
|       bicycle       | 61.73 | 82.87 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 52.44 |  91.2 |
|        screen       | 50.51 | 54.06 |
|       blanket       | 29.53 | 41.96 |
|      sculpture      | 55.81 | 82.84 |
|         hood        | 55.75 | 77.99 |
|        sconce       | 52.89 | 74.04 |
|         vase        | 52.32 | 81.23 |
|    traffic light    | 43.71 | 60.74 |
|         tray        |  3.33 |  3.58 |
|        ashcan       | 51.84 | 73.53 |
|         fan         | 71.86 | 88.25 |
|         pier        |  0.0  |  0.0  |
|      crt screen     |  0.0  |  0.0  |
|        plate        | 50.58 |  91.2 |
|       monitor       | 43.03 | 44.81 |
|    bulletin board   |  0.0  |  0.0  |
|        shower       |  0.0  |  0.0  |
|       radiator      | 64.33 | 72.28 |
|        glass        | 27.88 | 31.58 |
|        clock        | 39.85 | 51.91 |
|         flag        | 64.63 | 90.33 |
+---------------------+-------+-------+
2022-11-29 22:56:42,979 - mmseg - INFO - Summary:
2022-11-29 22:56:42,979 - mmseg - INFO - 
+-------+-------+------+
|  aAcc |  mIoU | mAcc |
+-------+-------+------+
| 84.41 | 45.11 | 57.9 |
+-------+-------+------+
2022-11-29 22:56:42,983 - mmseg - INFO - The previous best checkpoint /mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune/lr1.0_lrd0.9/best_mIoU_iter_1000.pth was removed
2022-11-29 22:57:33,886 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_2000.pth.
2022-11-29 22:57:33,887 - mmseg - INFO - Best mIoU is 0.4511 at 2000 iter.
2022-11-29 22:57:33,895 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-29 22:57:33,895 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8441, mIoU: 0.4511, mAcc: 0.5790, IoU.wall: 0.8153, IoU.building: 0.8388, IoU.sky: 0.9473, IoU.floor: 0.8483, IoU.tree: 0.7772, IoU.ceiling: 0.8775, IoU.road: 0.8348, IoU.bed : 0.9150, IoU.windowpane: 0.6608, IoU.grass: 0.6646, IoU.cabinet: 0.6430, IoU.sidewalk: 0.6935, IoU.person: 0.8797, IoU.earth: 0.4261, IoU.door: 0.5991, IoU.table: 0.6819, IoU.mountain: 0.6354, IoU.plant: 0.5611, IoU.curtain: 0.7370, IoU.chair: 0.6173, IoU.car: 0.8818, IoU.water: 0.5226, IoU.painting: 0.8129, IoU.sofa: 0.8173, IoU.shelf: 0.4133, IoU.house: 0.5107, IoU.sea: 0.5307, IoU.mirror: 0.7992, IoU.rug: 0.7040, IoU.field: 0.1803, IoU.armchair: 0.5372, IoU.seat: 0.6364, IoU.fence: 0.5250, IoU.desk: 0.5207, IoU.rock: 0.6317, IoU.wardrobe: 0.2139, IoU.lamp: 0.7637, IoU.bathtub: 0.8409, IoU.railing: 0.4307, IoU.cushion: 0.6954, IoU.base: 0.1021, IoU.box: 0.3948, IoU.column: 0.6179, IoU.signboard: 0.4396, IoU.chest of drawers: 0.2970, IoU.counter: 0.2738, IoU.sand: 0.6411, IoU.sink: 0.8202, IoU.skyscraper: 0.3790, IoU.fireplace: 0.7203, IoU.refrigerator: 0.8050, IoU.grandstand: 0.0585, IoU.path: 0.1887, IoU.stairs: 0.2419, IoU.runway: 0.0000, IoU.case: 0.1388, IoU.pool table: 0.9369, IoU.pillow: 0.6692, IoU.screen door: 0.3217, IoU.stairway: 0.3363, IoU.river: 0.2480, IoU.bridge: 0.7860, IoU.bookcase: 0.1500, IoU.blind: 0.1957, IoU.coffee table: 0.6647, IoU.toilet: 0.9082, IoU.flower: 0.4440, IoU.book: 0.5548, IoU.hill: 0.0000, IoU.bench: 0.6846, IoU.countertop: 0.5144, IoU.stove: 0.8027, IoU.palm: 0.5338, IoU.kitchen island: 0.0764, IoU.computer: 0.7175, IoU.swivel chair: 0.4479, IoU.boat: 0.7966, IoU.bar: 0.0000, IoU.arcade machine: 0.0000, IoU.hovel: 0.0000, IoU.bus: 0.9423, IoU.towel: 0.7414, IoU.light: 0.6367, IoU.truck: 0.4570, IoU.tower: 0.0466, IoU.chandelier: 0.7120, IoU.awning: 0.2112, IoU.streetlight: 0.4048, IoU.booth: 0.0000, IoU.television receiver: 0.5981, IoU.airplane: 0.9086, IoU.dirt track: 0.0000, IoU.apparel: 0.5034, IoU.pole: 0.3660, IoU.land: 0.0000, IoU.bannister: 0.0548, IoU.escalator: 0.0000, IoU.ottoman: 0.4886, IoU.bottle: 0.4075, IoU.buffet: 0.0000, IoU.poster: 0.2134, IoU.stage: 0.0000, IoU.van: 0.4418, IoU.ship: 0.0000, IoU.fountain: 0.0000, IoU.conveyer belt: 0.0000, IoU.canopy: 0.0000, IoU.washer: 0.2142, IoU.plaything: 0.2371, IoU.swimming pool: 0.0000, IoU.stool: 0.5430, IoU.barrel: 0.0000, IoU.basket: 0.3921, IoU.waterfall: 0.4421, IoU.tent: 0.0000, IoU.bag: 0.3831, IoU.minibike: 0.8050, IoU.cradle: 0.0000, IoU.oven: 0.5849, IoU.ball: 0.5511, IoU.food: 0.5897, IoU.step: 0.0000, IoU.tank: 0.0000, IoU.trade name: 0.3153, IoU.microwave: 0.9035, IoU.pot: 0.6016, IoU.animal: 0.7182, IoU.bicycle: 0.6173, IoU.lake: 0.0000, IoU.dishwasher: 0.5244, IoU.screen: 0.5051, IoU.blanket: 0.2953, IoU.sculpture: 0.5581, IoU.hood: 0.5575, IoU.sconce: 0.5289, IoU.vase: 0.5232, IoU.traffic light: 0.4371, IoU.tray: 0.0333, IoU.ashcan: 0.5184, IoU.fan: 0.7186, IoU.pier: 0.0000, IoU.crt screen: 0.0000, IoU.plate: 0.5058, IoU.monitor: 0.4303, IoU.bulletin board: 0.0000, IoU.shower: 0.0000, IoU.radiator: 0.6433, IoU.glass: 0.2788, IoU.clock: 0.3985, IoU.flag: 0.6463, Acc.wall: 0.9060, Acc.building: 0.9078, Acc.sky: 0.9742, Acc.floor: 0.9025, Acc.tree: 0.8804, Acc.ceiling: 0.9348, Acc.road: 0.9144, Acc.bed : 0.9691, Acc.windowpane: 0.8130, Acc.grass: 0.8153, Acc.cabinet: 0.8015, Acc.sidewalk: 0.8767, Acc.person: 0.9352, Acc.earth: 0.5641, Acc.door: 0.8036, Acc.table: 0.8352, Acc.mountain: 0.8541, Acc.plant: 0.6815, Acc.curtain: 0.9079, Acc.chair: 0.7423, Acc.car: 0.9246, Acc.water: 0.7524, Acc.painting: 0.9283, Acc.sofa: 0.9097, Acc.shelf: 0.6917, Acc.house: 0.7346, Acc.sea: 0.7110, Acc.mirror: 0.9270, Acc.rug: 0.8860, Acc.field: 0.3320, Acc.armchair: 0.8126, Acc.seat: 0.8742, Acc.fence: 0.7455, Acc.desk: 0.6739, Acc.rock: 0.8030, Acc.wardrobe: 0.2262, Acc.lamp: 0.8720, Acc.bathtub: 0.9329, Acc.railing: 0.6969, Acc.cushion: 0.8750, Acc.base: 0.1224, Acc.box: 0.5257, Acc.column: 0.8331, Acc.signboard: 0.6046, Acc.chest of drawers: 0.4812, Acc.counter: 0.7664, Acc.sand: 0.8745, Acc.sink: 0.8738, Acc.skyscraper: 0.6183, Acc.fireplace: 0.9073, Acc.refrigerator: 0.9110, Acc.grandstand: 0.0586, Acc.path: 0.2257, Acc.stairs: 0.3108, Acc.runway: 0.0000, Acc.case: 0.1568, Acc.pool table: 0.9735, Acc.pillow: 0.7830, Acc.screen door: 0.3224, Acc.stairway: 0.7242, Acc.river: 0.3692, Acc.bridge: 0.8974, Acc.bookcase: 0.2078, Acc.blind: 0.2222, Acc.coffee table: 0.8977, Acc.toilet: 0.9494, Acc.flower: 0.7935, Acc.book: 0.8046, Acc.hill: 0.0000, Acc.bench: 0.8036, Acc.countertop: 0.8062, Acc.stove: 0.8988, Acc.palm: 0.8608, Acc.kitchen island: 0.0764, Acc.computer: 0.9283, Acc.swivel chair: 0.6812, Acc.boat: 0.9312, Acc.bar: 0.0000, Acc.arcade machine: 0.0000, Acc.hovel: 0.0000, Acc.bus: 0.9618, Acc.towel: 0.9026, Acc.light: 0.7644, Acc.truck: 0.7358, Acc.tower: 0.0763, Acc.chandelier: 0.8918, Acc.awning: 0.5080, Acc.streetlight: 0.6592, Acc.booth: 0.0000, Acc.television receiver: 0.9388, Acc.airplane: 0.9589, Acc.dirt track: 0.0000, Acc.apparel: 0.8436, Acc.pole: 0.5556, Acc.land: 0.0000, Acc.bannister: 0.0570, Acc.escalator: 0.0000, Acc.ottoman: 0.7864, Acc.bottle: 0.5352, Acc.buffet: 0.0000, Acc.poster: 0.3729, Acc.stage: 0.0000, Acc.van: 0.8121, Acc.ship: 0.0000, Acc.fountain: 0.0000, Acc.conveyer belt: 0.0000, Acc.canopy: 0.0000, Acc.washer: 0.2142, Acc.plaything: 0.4197, Acc.swimming pool: 0.0000, Acc.stool: 0.7047, Acc.barrel: 0.0000, Acc.basket: 0.6446, Acc.waterfall: 0.4733, Acc.tent: 0.0000, Acc.bag: 0.5389, Acc.minibike: 0.9223, Acc.cradle: 0.0000, Acc.oven: 0.6520, Acc.ball: 0.8295, Acc.food: 0.6334, Acc.step: 0.0000, Acc.tank: 0.0000, Acc.trade name: 0.5768, Acc.microwave: 0.9684, Acc.pot: 0.7132, Acc.animal: 0.7256, Acc.bicycle: 0.8287, Acc.lake: 0.0000, Acc.dishwasher: 0.9120, Acc.screen: 0.5406, Acc.blanket: 0.4196, Acc.sculpture: 0.8284, Acc.hood: 0.7799, Acc.sconce: 0.7404, Acc.vase: 0.8123, Acc.traffic light: 0.6074, Acc.tray: 0.0358, Acc.ashcan: 0.7353, Acc.fan: 0.8825, Acc.pier: 0.0000, Acc.crt screen: 0.0000, Acc.plate: 0.9120, Acc.monitor: 0.4481, Acc.bulletin board: 0.0000, Acc.shower: 0.0000, Acc.radiator: 0.7228, Acc.glass: 0.3158, Acc.clock: 0.5191, Acc.flag: 0.9033
2022-11-29 23:00:59,600 - mmseg - INFO - Iter [2050/40000]	lr: 1.262e-07, eta: 1 day, 22:20:29, time: 8.693, data_time: 4.596, memory: 51902, decode.loss_cls: 0.7005, decode.loss_mask: 0.6679, decode.loss_dice: 0.9292, decode.d0.loss_cls: 9.8876, decode.d0.loss_mask: 0.6430, decode.d0.loss_dice: 1.0362, decode.d1.loss_cls: 1.0476, decode.d1.loss_mask: 0.6742, decode.d1.loss_dice: 0.9716, decode.d2.loss_cls: 0.8571, decode.d2.loss_mask: 0.6645, decode.d2.loss_dice: 0.9341, decode.d3.loss_cls: 0.7873, decode.d3.loss_mask: 0.6619, decode.d3.loss_dice: 0.9233, decode.d4.loss_cls: 0.7494, decode.d4.loss_mask: 0.6621, decode.d4.loss_dice: 0.9274, decode.d5.loss_cls: 0.7235, decode.d5.loss_mask: 0.6656, decode.d5.loss_dice: 0.9304, decode.d6.loss_cls: 0.7090, decode.d6.loss_mask: 0.6658, decode.d6.loss_dice: 0.9265, decode.d7.loss_cls: 0.7040, decode.d7.loss_mask: 0.6653, decode.d7.loss_dice: 0.9363, decode.d8.loss_cls: 0.7011, decode.d8.loss_mask: 0.6652, decode.d8.loss_dice: 0.9298, loss: 32.9475
2022-11-29 23:04:25,159 - mmseg - INFO - Iter [2100/40000]	lr: 1.260e-07, eta: 1 day, 22:12:33, time: 4.111, data_time: 0.019, memory: 51902, decode.loss_cls: 0.7390, decode.loss_mask: 0.6452, decode.loss_dice: 0.9485, decode.d0.loss_cls: 9.8753, decode.d0.loss_mask: 0.6160, decode.d0.loss_dice: 1.0564, decode.d1.loss_cls: 1.0815, decode.d1.loss_mask: 0.6537, decode.d1.loss_dice: 1.0013, decode.d2.loss_cls: 0.8946, decode.d2.loss_mask: 0.6440, decode.d2.loss_dice: 0.9627, decode.d3.loss_cls: 0.8236, decode.d3.loss_mask: 0.6375, decode.d3.loss_dice: 0.9452, decode.d4.loss_cls: 0.7805, decode.d4.loss_mask: 0.6434, decode.d4.loss_dice: 0.9526, decode.d5.loss_cls: 0.7576, decode.d5.loss_mask: 0.6428, decode.d5.loss_dice: 0.9510, decode.d6.loss_cls: 0.7432, decode.d6.loss_mask: 0.6436, decode.d6.loss_dice: 0.9435, decode.d7.loss_cls: 0.7371, decode.d7.loss_mask: 0.6456, decode.d7.loss_dice: 0.9483, decode.d8.loss_cls: 0.7400, decode.d8.loss_mask: 0.6457, decode.d8.loss_dice: 0.9474, loss: 33.2471
2022-11-29 23:07:51,273 - mmseg - INFO - Iter [2150/40000]	lr: 1.259e-07, eta: 1 day, 22:04:58, time: 4.122, data_time: 0.019, memory: 51902, decode.loss_cls: 0.7232, decode.loss_mask: 0.6508, decode.loss_dice: 0.9395, decode.d0.loss_cls: 9.8622, decode.d0.loss_mask: 0.6238, decode.d0.loss_dice: 1.0520, decode.d1.loss_cls: 1.0583, decode.d1.loss_mask: 0.6551, decode.d1.loss_dice: 0.9869, decode.d2.loss_cls: 0.8796, decode.d2.loss_mask: 0.6483, decode.d2.loss_dice: 0.9513, decode.d3.loss_cls: 0.8007, decode.d3.loss_mask: 0.6465, decode.d3.loss_dice: 0.9393, decode.d4.loss_cls: 0.7641, decode.d4.loss_mask: 0.6471, decode.d4.loss_dice: 0.9465, decode.d5.loss_cls: 0.7431, decode.d5.loss_mask: 0.6481, decode.d5.loss_dice: 0.9442, decode.d6.loss_cls: 0.7324, decode.d6.loss_mask: 0.6445, decode.d6.loss_dice: 0.9369, decode.d7.loss_cls: 0.7276, decode.d7.loss_mask: 0.6500, decode.d7.loss_dice: 0.9438, decode.d8.loss_cls: 0.7253, decode.d8.loss_mask: 0.6485, decode.d8.loss_dice: 0.9417, loss: 33.0614
2022-11-29 23:11:16,969 - mmseg - INFO - Iter [2200/40000]	lr: 1.257e-07, eta: 1 day, 21:57:28, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.7324, decode.loss_mask: 0.6548, decode.loss_dice: 0.9518, decode.d0.loss_cls: 9.8560, decode.d0.loss_mask: 0.6299, decode.d0.loss_dice: 1.0650, decode.d1.loss_cls: 1.0650, decode.d1.loss_mask: 0.6729, decode.d1.loss_dice: 1.0081, decode.d2.loss_cls: 0.8781, decode.d2.loss_mask: 0.6631, decode.d2.loss_dice: 0.9682, decode.d3.loss_cls: 0.8041, decode.d3.loss_mask: 0.6585, decode.d3.loss_dice: 0.9552, decode.d4.loss_cls: 0.7707, decode.d4.loss_mask: 0.6583, decode.d4.loss_dice: 0.9566, decode.d5.loss_cls: 0.7456, decode.d5.loss_mask: 0.6576, decode.d5.loss_dice: 0.9569, decode.d6.loss_cls: 0.7368, decode.d6.loss_mask: 0.6573, decode.d6.loss_dice: 0.9523, decode.d7.loss_cls: 0.7259, decode.d7.loss_mask: 0.6592, decode.d7.loss_dice: 0.9563, decode.d8.loss_cls: 0.7287, decode.d8.loss_mask: 0.6554, decode.d8.loss_dice: 0.9531, loss: 33.3339
2022-11-29 23:14:42,368 - mmseg - INFO - Iter [2250/40000]	lr: 1.255e-07, eta: 1 day, 21:50:03, time: 4.108, data_time: 0.019, memory: 51902, decode.loss_cls: 0.7060, decode.loss_mask: 0.6622, decode.loss_dice: 0.9585, decode.d0.loss_cls: 9.8487, decode.d0.loss_mask: 0.6303, decode.d0.loss_dice: 1.0571, decode.d1.loss_cls: 1.0118, decode.d1.loss_mask: 0.6748, decode.d1.loss_dice: 1.0040, decode.d2.loss_cls: 0.8466, decode.d2.loss_mask: 0.6617, decode.d2.loss_dice: 0.9684, decode.d3.loss_cls: 0.7839, decode.d3.loss_mask: 0.6550, decode.d3.loss_dice: 0.9474, decode.d4.loss_cls: 0.7479, decode.d4.loss_mask: 0.6547, decode.d4.loss_dice: 0.9515, decode.d5.loss_cls: 0.7248, decode.d5.loss_mask: 0.6580, decode.d5.loss_dice: 0.9529, decode.d6.loss_cls: 0.7140, decode.d6.loss_mask: 0.6567, decode.d6.loss_dice: 0.9507, decode.d7.loss_cls: 0.7096, decode.d7.loss_mask: 0.6573, decode.d7.loss_dice: 0.9588, decode.d8.loss_cls: 0.7053, decode.d8.loss_mask: 0.6592, decode.d8.loss_dice: 0.9557, loss: 33.0733
2022-11-29 23:18:08,140 - mmseg - INFO - Iter [2300/40000]	lr: 1.254e-07, eta: 1 day, 21:42:55, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.7084, decode.loss_mask: 0.6693, decode.loss_dice: 0.9586, decode.d0.loss_cls: 9.8428, decode.d0.loss_mask: 0.6416, decode.d0.loss_dice: 1.0529, decode.d1.loss_cls: 1.0210, decode.d1.loss_mask: 0.6807, decode.d1.loss_dice: 1.0096, decode.d2.loss_cls: 0.8517, decode.d2.loss_mask: 0.6701, decode.d2.loss_dice: 0.9750, decode.d3.loss_cls: 0.7801, decode.d3.loss_mask: 0.6697, decode.d3.loss_dice: 0.9558, decode.d4.loss_cls: 0.7463, decode.d4.loss_mask: 0.6671, decode.d4.loss_dice: 0.9616, decode.d5.loss_cls: 0.7275, decode.d5.loss_mask: 0.6651, decode.d5.loss_dice: 0.9590, decode.d6.loss_cls: 0.7150, decode.d6.loss_mask: 0.6698, decode.d6.loss_dice: 0.9540, decode.d7.loss_cls: 0.7038, decode.d7.loss_mask: 0.6697, decode.d7.loss_dice: 0.9612, decode.d8.loss_cls: 0.7088, decode.d8.loss_mask: 0.6694, decode.d8.loss_dice: 0.9547, loss: 33.2205
2022-11-29 23:21:33,879 - mmseg - INFO - Iter [2350/40000]	lr: 1.252e-07, eta: 1 day, 21:35:56, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.6975, decode.loss_mask: 0.6636, decode.loss_dice: 0.9287, decode.d0.loss_cls: 9.8251, decode.d0.loss_mask: 0.6346, decode.d0.loss_dice: 1.0364, decode.d1.loss_cls: 1.0057, decode.d1.loss_mask: 0.6748, decode.d1.loss_dice: 0.9871, decode.d2.loss_cls: 0.8385, decode.d2.loss_mask: 0.6649, decode.d2.loss_dice: 0.9448, decode.d3.loss_cls: 0.7735, decode.d3.loss_mask: 0.6612, decode.d3.loss_dice: 0.9356, decode.d4.loss_cls: 0.7354, decode.d4.loss_mask: 0.6617, decode.d4.loss_dice: 0.9401, decode.d5.loss_cls: 0.7105, decode.d5.loss_mask: 0.6621, decode.d5.loss_dice: 0.9343, decode.d6.loss_cls: 0.7026, decode.d6.loss_mask: 0.6600, decode.d6.loss_dice: 0.9275, decode.d7.loss_cls: 0.6999, decode.d7.loss_mask: 0.6600, decode.d7.loss_dice: 0.9325, decode.d8.loss_cls: 0.6949, decode.d8.loss_mask: 0.6622, decode.d8.loss_dice: 0.9305, loss: 32.7864
2022-11-29 23:24:59,503 - mmseg - INFO - Iter [2400/40000]	lr: 1.250e-07, eta: 1 day, 21:29:04, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 0.7123, decode.loss_mask: 0.6708, decode.loss_dice: 0.9556, decode.d0.loss_cls: 9.8164, decode.d0.loss_mask: 0.6462, decode.d0.loss_dice: 1.0596, decode.d1.loss_cls: 1.0100, decode.d1.loss_mask: 0.6877, decode.d1.loss_dice: 1.0062, decode.d2.loss_cls: 0.8504, decode.d2.loss_mask: 0.6719, decode.d2.loss_dice: 0.9696, decode.d3.loss_cls: 0.7839, decode.d3.loss_mask: 0.6684, decode.d3.loss_dice: 0.9538, decode.d4.loss_cls: 0.7547, decode.d4.loss_mask: 0.6677, decode.d4.loss_dice: 0.9586, decode.d5.loss_cls: 0.7318, decode.d5.loss_mask: 0.6711, decode.d5.loss_dice: 0.9551, decode.d6.loss_cls: 0.7169, decode.d6.loss_mask: 0.6736, decode.d6.loss_dice: 0.9556, decode.d7.loss_cls: 0.7144, decode.d7.loss_mask: 0.6730, decode.d7.loss_dice: 0.9584, decode.d8.loss_cls: 0.7082, decode.d8.loss_mask: 0.6725, decode.d8.loss_dice: 0.9552, loss: 33.2294
2022-11-29 23:28:25,116 - mmseg - INFO - Iter [2450/40000]	lr: 1.249e-07, eta: 1 day, 21:22:21, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.7006, decode.loss_mask: 0.6633, decode.loss_dice: 0.9492, decode.d0.loss_cls: 9.8105, decode.d0.loss_mask: 0.6393, decode.d0.loss_dice: 1.0444, decode.d1.loss_cls: 0.9848, decode.d1.loss_mask: 0.6784, decode.d1.loss_dice: 1.0054, decode.d2.loss_cls: 0.8302, decode.d2.loss_mask: 0.6697, decode.d2.loss_dice: 0.9701, decode.d3.loss_cls: 0.7630, decode.d3.loss_mask: 0.6629, decode.d3.loss_dice: 0.9513, decode.d4.loss_cls: 0.7279, decode.d4.loss_mask: 0.6648, decode.d4.loss_dice: 0.9549, decode.d5.loss_cls: 0.7112, decode.d5.loss_mask: 0.6657, decode.d5.loss_dice: 0.9577, decode.d6.loss_cls: 0.7023, decode.d6.loss_mask: 0.6651, decode.d6.loss_dice: 0.9544, decode.d7.loss_cls: 0.6966, decode.d7.loss_mask: 0.6669, decode.d7.loss_dice: 0.9508, decode.d8.loss_cls: 0.6964, decode.d8.loss_mask: 0.6647, decode.d8.loss_dice: 0.9501, loss: 32.9524
2022-11-29 23:31:51,085 - mmseg - INFO - Iter [2500/40000]	lr: 1.247e-07, eta: 1 day, 21:15:50, time: 4.119, data_time: 0.020, memory: 51902, decode.loss_cls: 0.7180, decode.loss_mask: 0.6663, decode.loss_dice: 0.9520, decode.d0.loss_cls: 9.7990, decode.d0.loss_mask: 0.6381, decode.d0.loss_dice: 1.0672, decode.d1.loss_cls: 1.0135, decode.d1.loss_mask: 0.6775, decode.d1.loss_dice: 1.0166, decode.d2.loss_cls: 0.8572, decode.d2.loss_mask: 0.6633, decode.d2.loss_dice: 0.9659, decode.d3.loss_cls: 0.7889, decode.d3.loss_mask: 0.6641, decode.d3.loss_dice: 0.9507, decode.d4.loss_cls: 0.7558, decode.d4.loss_mask: 0.6663, decode.d4.loss_dice: 0.9555, decode.d5.loss_cls: 0.7383, decode.d5.loss_mask: 0.6650, decode.d5.loss_dice: 0.9526, decode.d6.loss_cls: 0.7239, decode.d6.loss_mask: 0.6652, decode.d6.loss_dice: 0.9522, decode.d7.loss_cls: 0.7228, decode.d7.loss_mask: 0.6659, decode.d7.loss_dice: 0.9551, decode.d8.loss_cls: 0.7172, decode.d8.loss_mask: 0.6658, decode.d8.loss_dice: 0.9531, loss: 33.1931
2022-11-29 23:35:19,096 - mmseg - INFO - Iter [2550/40000]	lr: 1.246e-07, eta: 1 day, 21:09:57, time: 4.160, data_time: 0.064, memory: 51902, decode.loss_cls: 0.6934, decode.loss_mask: 0.6624, decode.loss_dice: 0.9496, decode.d0.loss_cls: 9.7891, decode.d0.loss_mask: 0.6378, decode.d0.loss_dice: 1.0482, decode.d1.loss_cls: 0.9772, decode.d1.loss_mask: 0.6755, decode.d1.loss_dice: 0.9990, decode.d2.loss_cls: 0.8183, decode.d2.loss_mask: 0.6656, decode.d2.loss_dice: 0.9567, decode.d3.loss_cls: 0.7640, decode.d3.loss_mask: 0.6605, decode.d3.loss_dice: 0.9455, decode.d4.loss_cls: 0.7307, decode.d4.loss_mask: 0.6636, decode.d4.loss_dice: 0.9506, decode.d5.loss_cls: 0.7113, decode.d5.loss_mask: 0.6620, decode.d5.loss_dice: 0.9509, decode.d6.loss_cls: 0.7035, decode.d6.loss_mask: 0.6662, decode.d6.loss_dice: 0.9489, decode.d7.loss_cls: 0.6934, decode.d7.loss_mask: 0.6675, decode.d7.loss_dice: 0.9511, decode.d8.loss_cls: 0.6922, decode.d8.loss_mask: 0.6652, decode.d8.loss_dice: 0.9479, loss: 32.8477
2022-11-29 23:38:44,818 - mmseg - INFO - Iter [2600/40000]	lr: 1.244e-07, eta: 1 day, 21:03:36, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.6679, decode.loss_mask: 0.6697, decode.loss_dice: 0.9477, decode.d0.loss_cls: 9.7812, decode.d0.loss_mask: 0.6407, decode.d0.loss_dice: 1.0466, decode.d1.loss_cls: 0.9532, decode.d1.loss_mask: 0.6742, decode.d1.loss_dice: 1.0008, decode.d2.loss_cls: 0.7984, decode.d2.loss_mask: 0.6690, decode.d2.loss_dice: 0.9574, decode.d3.loss_cls: 0.7361, decode.d3.loss_mask: 0.6666, decode.d3.loss_dice: 0.9409, decode.d4.loss_cls: 0.7034, decode.d4.loss_mask: 0.6636, decode.d4.loss_dice: 0.9466, decode.d5.loss_cls: 0.6827, decode.d5.loss_mask: 0.6653, decode.d5.loss_dice: 0.9462, decode.d6.loss_cls: 0.6713, decode.d6.loss_mask: 0.6653, decode.d6.loss_dice: 0.9447, decode.d7.loss_cls: 0.6665, decode.d7.loss_mask: 0.6669, decode.d7.loss_dice: 0.9478, decode.d8.loss_cls: 0.6634, decode.d8.loss_mask: 0.6668, decode.d8.loss_dice: 0.9458, loss: 32.5969
2022-11-29 23:42:10,567 - mmseg - INFO - Iter [2650/40000]	lr: 1.242e-07, eta: 1 day, 20:57:23, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.6880, decode.loss_mask: 0.6649, decode.loss_dice: 0.9541, decode.d0.loss_cls: 9.7688, decode.d0.loss_mask: 0.6382, decode.d0.loss_dice: 1.0464, decode.d1.loss_cls: 0.9763, decode.d1.loss_mask: 0.6768, decode.d1.loss_dice: 1.0010, decode.d2.loss_cls: 0.8188, decode.d2.loss_mask: 0.6648, decode.d2.loss_dice: 0.9576, decode.d3.loss_cls: 0.7522, decode.d3.loss_mask: 0.6609, decode.d3.loss_dice: 0.9434, decode.d4.loss_cls: 0.7252, decode.d4.loss_mask: 0.6599, decode.d4.loss_dice: 0.9482, decode.d5.loss_cls: 0.7085, decode.d5.loss_mask: 0.6609, decode.d5.loss_dice: 0.9501, decode.d6.loss_cls: 0.6965, decode.d6.loss_mask: 0.6587, decode.d6.loss_dice: 0.9459, decode.d7.loss_cls: 0.6924, decode.d7.loss_mask: 0.6620, decode.d7.loss_dice: 0.9488, decode.d8.loss_cls: 0.6888, decode.d8.loss_mask: 0.6636, decode.d8.loss_dice: 0.9489, loss: 32.7707
2022-11-29 23:45:36,491 - mmseg - INFO - Iter [2700/40000]	lr: 1.241e-07, eta: 1 day, 20:51:18, time: 4.118, data_time: 0.019, memory: 51902, decode.loss_cls: 0.6732, decode.loss_mask: 0.6601, decode.loss_dice: 0.9413, decode.d0.loss_cls: 9.7564, decode.d0.loss_mask: 0.6330, decode.d0.loss_dice: 1.0344, decode.d1.loss_cls: 0.9469, decode.d1.loss_mask: 0.6763, decode.d1.loss_dice: 0.9918, decode.d2.loss_cls: 0.8031, decode.d2.loss_mask: 0.6634, decode.d2.loss_dice: 0.9533, decode.d3.loss_cls: 0.7432, decode.d3.loss_mask: 0.6575, decode.d3.loss_dice: 0.9419, decode.d4.loss_cls: 0.7105, decode.d4.loss_mask: 0.6560, decode.d4.loss_dice: 0.9445, decode.d5.loss_cls: 0.6959, decode.d5.loss_mask: 0.6587, decode.d5.loss_dice: 0.9385, decode.d6.loss_cls: 0.6854, decode.d6.loss_mask: 0.6582, decode.d6.loss_dice: 0.9349, decode.d7.loss_cls: 0.6768, decode.d7.loss_mask: 0.6573, decode.d7.loss_dice: 0.9374, decode.d8.loss_cls: 0.6770, decode.d8.loss_mask: 0.6570, decode.d8.loss_dice: 0.9364, loss: 32.5001
2022-11-29 23:49:01,921 - mmseg - INFO - Iter [2750/40000]	lr: 1.239e-07, eta: 1 day, 20:45:12, time: 4.109, data_time: 0.021, memory: 51902, decode.loss_cls: 0.6710, decode.loss_mask: 0.6428, decode.loss_dice: 0.9385, decode.d0.loss_cls: 9.7481, decode.d0.loss_mask: 0.6162, decode.d0.loss_dice: 1.0387, decode.d1.loss_cls: 0.9359, decode.d1.loss_mask: 0.6528, decode.d1.loss_dice: 0.9942, decode.d2.loss_cls: 0.7949, decode.d2.loss_mask: 0.6408, decode.d2.loss_dice: 0.9539, decode.d3.loss_cls: 0.7338, decode.d3.loss_mask: 0.6405, decode.d3.loss_dice: 0.9440, decode.d4.loss_cls: 0.7084, decode.d4.loss_mask: 0.6425, decode.d4.loss_dice: 0.9422, decode.d5.loss_cls: 0.6887, decode.d5.loss_mask: 0.6419, decode.d5.loss_dice: 0.9422, decode.d6.loss_cls: 0.6809, decode.d6.loss_mask: 0.6421, decode.d6.loss_dice: 0.9396, decode.d7.loss_cls: 0.6776, decode.d7.loss_mask: 0.6439, decode.d7.loss_dice: 0.9399, decode.d8.loss_cls: 0.6714, decode.d8.loss_mask: 0.6423, decode.d8.loss_dice: 0.9398, loss: 32.2898
2022-11-29 23:52:27,657 - mmseg - INFO - Iter [2800/40000]	lr: 1.237e-07, eta: 1 day, 20:39:16, time: 4.115, data_time: 0.018, memory: 51902, decode.loss_cls: 0.6587, decode.loss_mask: 0.6343, decode.loss_dice: 0.9265, decode.d0.loss_cls: 9.7391, decode.d0.loss_mask: 0.6080, decode.d0.loss_dice: 1.0270, decode.d1.loss_cls: 0.9257, decode.d1.loss_mask: 0.6455, decode.d1.loss_dice: 0.9883, decode.d2.loss_cls: 0.7800, decode.d2.loss_mask: 0.6392, decode.d2.loss_dice: 0.9474, decode.d3.loss_cls: 0.7255, decode.d3.loss_mask: 0.6322, decode.d3.loss_dice: 0.9274, decode.d4.loss_cls: 0.6964, decode.d4.loss_mask: 0.6337, decode.d4.loss_dice: 0.9264, decode.d5.loss_cls: 0.6766, decode.d5.loss_mask: 0.6324, decode.d5.loss_dice: 0.9297, decode.d6.loss_cls: 0.6683, decode.d6.loss_mask: 0.6334, decode.d6.loss_dice: 0.9237, decode.d7.loss_cls: 0.6653, decode.d7.loss_mask: 0.6307, decode.d7.loss_dice: 0.9296, decode.d8.loss_cls: 0.6611, decode.d8.loss_mask: 0.6320, decode.d8.loss_dice: 0.9262, loss: 31.9700
2022-11-29 23:55:53,321 - mmseg - INFO - Iter [2850/40000]	lr: 1.236e-07, eta: 1 day, 20:33:24, time: 4.113, data_time: 0.018, memory: 51902, decode.loss_cls: 0.6521, decode.loss_mask: 0.6507, decode.loss_dice: 0.9382, decode.d0.loss_cls: 9.7252, decode.d0.loss_mask: 0.6204, decode.d0.loss_dice: 1.0319, decode.d1.loss_cls: 0.9228, decode.d1.loss_mask: 0.6621, decode.d1.loss_dice: 0.9934, decode.d2.loss_cls: 0.7747, decode.d2.loss_mask: 0.6533, decode.d2.loss_dice: 0.9538, decode.d3.loss_cls: 0.7126, decode.d3.loss_mask: 0.6523, decode.d3.loss_dice: 0.9422, decode.d4.loss_cls: 0.6864, decode.d4.loss_mask: 0.6487, decode.d4.loss_dice: 0.9413, decode.d5.loss_cls: 0.6707, decode.d5.loss_mask: 0.6475, decode.d5.loss_dice: 0.9409, decode.d6.loss_cls: 0.6638, decode.d6.loss_mask: 0.6457, decode.d6.loss_dice: 0.9383, decode.d7.loss_cls: 0.6547, decode.d7.loss_mask: 0.6501, decode.d7.loss_dice: 0.9468, decode.d8.loss_cls: 0.6521, decode.d8.loss_mask: 0.6509, decode.d8.loss_dice: 0.9444, loss: 32.1680
2022-11-29 23:59:18,958 - mmseg - INFO - Iter [2900/40000]	lr: 1.234e-07, eta: 1 day, 20:27:37, time: 4.113, data_time: 0.019, memory: 51902, decode.loss_cls: 0.6734, decode.loss_mask: 0.6572, decode.loss_dice: 0.9495, decode.d0.loss_cls: 9.7220, decode.d0.loss_mask: 0.6263, decode.d0.loss_dice: 1.0505, decode.d1.loss_cls: 0.9414, decode.d1.loss_mask: 0.6716, decode.d1.loss_dice: 1.0089, decode.d2.loss_cls: 0.7915, decode.d2.loss_mask: 0.6582, decode.d2.loss_dice: 0.9639, decode.d3.loss_cls: 0.7323, decode.d3.loss_mask: 0.6542, decode.d3.loss_dice: 0.9503, decode.d4.loss_cls: 0.7080, decode.d4.loss_mask: 0.6576, decode.d4.loss_dice: 0.9515, decode.d5.loss_cls: 0.6904, decode.d5.loss_mask: 0.6562, decode.d5.loss_dice: 0.9454, decode.d6.loss_cls: 0.6813, decode.d6.loss_mask: 0.6566, decode.d6.loss_dice: 0.9403, decode.d7.loss_cls: 0.6765, decode.d7.loss_mask: 0.6574, decode.d7.loss_dice: 0.9478, decode.d8.loss_cls: 0.6719, decode.d8.loss_mask: 0.6579, decode.d8.loss_dice: 0.9471, loss: 32.4971
2022-11-30 00:02:44,571 - mmseg - INFO - Iter [2950/40000]	lr: 1.232e-07, eta: 1 day, 20:21:55, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.6453, decode.loss_mask: 0.6483, decode.loss_dice: 0.9472, decode.d0.loss_cls: 9.7004, decode.d0.loss_mask: 0.6199, decode.d0.loss_dice: 1.0407, decode.d1.loss_cls: 0.9038, decode.d1.loss_mask: 0.6637, decode.d1.loss_dice: 1.0060, decode.d2.loss_cls: 0.7624, decode.d2.loss_mask: 0.6531, decode.d2.loss_dice: 0.9603, decode.d3.loss_cls: 0.7046, decode.d3.loss_mask: 0.6483, decode.d3.loss_dice: 0.9538, decode.d4.loss_cls: 0.6763, decode.d4.loss_mask: 0.6498, decode.d4.loss_dice: 0.9537, decode.d5.loss_cls: 0.6611, decode.d5.loss_mask: 0.6498, decode.d5.loss_dice: 0.9515, decode.d6.loss_cls: 0.6462, decode.d6.loss_mask: 0.6513, decode.d6.loss_dice: 0.9466, decode.d7.loss_cls: 0.6490, decode.d7.loss_mask: 0.6499, decode.d7.loss_dice: 0.9502, decode.d8.loss_cls: 0.6478, decode.d8.loss_mask: 0.6489, decode.d8.loss_dice: 0.9504, loss: 32.1403
2022-11-30 00:06:10,296 - mmseg - INFO - Saving checkpoint at 3000 iterations
2022-11-30 00:06:59,286 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 00:06:59,286 - mmseg - INFO - Iter [3000/40000]	lr: 1.231e-07, eta: 1 day, 20:26:22, time: 5.094, data_time: 0.020, memory: 51902, decode.loss_cls: 0.6336, decode.loss_mask: 0.6665, decode.loss_dice: 0.9345, decode.d0.loss_cls: 9.6903, decode.d0.loss_mask: 0.6334, decode.d0.loss_dice: 1.0218, decode.d1.loss_cls: 0.8820, decode.d1.loss_mask: 0.6750, decode.d1.loss_dice: 0.9946, decode.d2.loss_cls: 0.7412, decode.d2.loss_mask: 0.6631, decode.d2.loss_dice: 0.9540, decode.d3.loss_cls: 0.6899, decode.d3.loss_mask: 0.6598, decode.d3.loss_dice: 0.9416, decode.d4.loss_cls: 0.6684, decode.d4.loss_mask: 0.6602, decode.d4.loss_dice: 0.9379, decode.d5.loss_cls: 0.6459, decode.d5.loss_mask: 0.6642, decode.d5.loss_dice: 0.9381, decode.d6.loss_cls: 0.6363, decode.d6.loss_mask: 0.6630, decode.d6.loss_dice: 0.9351, decode.d7.loss_cls: 0.6361, decode.d7.loss_mask: 0.6646, decode.d7.loss_dice: 0.9372, decode.d8.loss_cls: 0.6308, decode.d8.loss_mask: 0.6673, decode.d8.loss_dice: 0.9389, loss: 32.0053
2022-11-30 00:09:57,338 - mmseg - INFO - per class results:
2022-11-30 00:09:57,343 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 82.38 | 88.58 |
|       building      | 83.91 | 92.05 |
|         sky         | 94.99 | 97.68 |
|        floor        | 85.14 | 90.64 |
|         tree        | 77.31 | 86.59 |
|       ceiling       | 87.25 | 95.03 |
|         road        | 82.31 |  92.1 |
|         bed         | 92.48 | 96.85 |
|      windowpane     | 66.85 | 84.06 |
|        grass        | 66.45 |  76.0 |
|       cabinet       | 63.98 |  76.5 |
|       sidewalk      | 69.97 | 86.04 |
|        person       | 88.36 | 94.63 |
|        earth        | 42.93 | 56.79 |
|         door        | 61.27 | 80.05 |
|        table        | 71.63 | 82.77 |
|       mountain      |  63.9 | 80.42 |
|        plant        | 57.42 | 76.17 |
|       curtain       | 79.42 | 90.03 |
|        chair        | 62.08 | 71.95 |
|         car         | 88.26 | 92.82 |
|        water        | 56.74 | 85.05 |
|       painting      | 79.49 | 93.52 |
|         sofa        | 82.89 | 90.77 |
|        shelf        | 46.45 |  69.3 |
|        house        | 39.96 | 50.65 |
|         sea         | 53.84 | 63.73 |
|        mirror       | 80.21 |  93.3 |
|         rug         | 71.43 | 84.78 |
|        field        | 28.33 | 62.98 |
|       armchair      | 53.56 | 82.76 |
|         seat        | 69.72 | 87.67 |
|        fence        | 54.86 | 77.12 |
|         desk        | 46.47 |  73.2 |
|         rock        | 58.33 | 70.55 |
|       wardrobe      | 50.38 | 61.48 |
|         lamp        | 77.75 | 86.73 |
|       bathtub       | 90.76 | 92.74 |
|       railing       | 41.62 | 71.53 |
|       cushion       | 73.37 | 87.48 |
|         base        |  28.7 | 39.01 |
|         box         |  38.5 | 52.33 |
|        column       | 63.24 | 82.13 |
|      signboard      | 43.42 | 61.83 |
|   chest of drawers  | 36.94 | 72.59 |
|       counter       | 35.44 | 60.43 |
|         sand        | 60.98 | 85.98 |
|         sink        | 80.42 | 85.49 |
|      skyscraper     | 42.95 | 69.49 |
|      fireplace      | 80.87 | 97.16 |
|     refrigerator    | 78.14 |  90.6 |
|      grandstand     | 50.66 | 73.36 |
|         path        | 23.17 | 30.66 |
|        stairs       | 35.02 | 42.45 |
|        runway       | 15.06 |  15.1 |
|         case        | 65.25 | 78.55 |
|      pool table     | 94.88 | 98.58 |
|        pillow       | 71.39 | 81.87 |
|     screen door     | 70.57 | 74.81 |
|       stairway      | 47.32 |  69.6 |
|        river        | 25.98 | 34.64 |
|        bridge       | 78.55 | 89.88 |
|       bookcase      | 32.05 | 54.83 |
|        blind        | 34.39 | 38.93 |
|     coffee table    | 70.61 | 92.73 |
|        toilet       | 91.15 | 94.92 |
|        flower       | 42.37 | 58.96 |
|         book        | 57.83 |  81.1 |
|         hill        |  5.39 |  7.33 |
|        bench        | 68.72 | 84.25 |
|      countertop     | 62.49 | 85.37 |
|        stove        | 84.46 | 87.84 |
|         palm        | 48.99 | 84.39 |
|    kitchen island   | 39.07 | 88.96 |
|       computer      | 81.84 | 91.56 |
|     swivel chair    | 51.64 |  86.6 |
|         boat        | 79.94 | 93.64 |
|         bar         |  4.04 |  4.04 |
|    arcade machine   | 45.57 | 47.36 |
|        hovel        |  0.0  |  0.0  |
|         bus         |  93.4 | 96.47 |
|        towel        | 78.61 | 93.51 |
|        light        | 64.12 | 78.91 |
|        truck        |  51.3 | 68.74 |
|        tower        | 20.69 | 40.98 |
|      chandelier     | 71.37 | 89.84 |
|        awning       | 36.76 | 50.87 |
|     streetlight     | 42.08 | 64.48 |
|        booth        |  0.0  |  0.0  |
| television receiver | 73.52 | 87.38 |
|       airplane      | 90.97 | 96.45 |
|      dirt track     |  0.0  |  0.0  |
|       apparel       | 54.32 | 93.68 |
|         pole        | 38.37 | 59.19 |
|         land        |  0.0  |  0.0  |
|      bannister      | 15.09 | 19.03 |
|      escalator      |  0.0  |  0.0  |
|       ottoman       | 51.78 | 79.46 |
|        bottle       | 38.18 | 51.43 |
|        buffet       |  0.0  |  0.0  |
|        poster       | 26.54 | 48.84 |
|        stage        |  11.9 | 16.31 |
|         van         |  42.9 | 86.43 |
|         ship        |  0.0  |  0.0  |
|       fountain      |  0.09 |  0.09 |
|    conveyer belt    | 80.74 | 81.88 |
|        canopy       |  2.38 |  2.38 |
|        washer       |  67.8 | 69.16 |
|      plaything      | 30.87 | 48.22 |
|    swimming pool    | 22.46 | 22.48 |
|        stool        |  48.6 | 81.43 |
|        barrel       |  0.0  |  0.0  |
|        basket       |  46.5 | 63.35 |
|      waterfall      |  47.8 |  50.7 |
|         tent        | 95.33 | 97.73 |
|         bag         | 39.96 | 60.96 |
|       minibike      | 80.48 | 91.88 |
|        cradle       | 84.41 | 87.82 |
|         oven        | 67.66 | 81.31 |
|         ball        | 55.44 | 83.91 |
|         food        | 67.03 | 81.39 |
|         step        | 23.84 | 25.29 |
|         tank        |  0.0  |  0.0  |
|      trade name     | 31.93 | 44.47 |
|      microwave      | 91.89 |  97.6 |
|         pot         | 59.79 |  71.9 |
|        animal       | 84.35 | 86.32 |
|       bicycle       | 60.85 | 83.27 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 66.86 | 93.87 |
|        screen       | 55.83 | 87.07 |
|       blanket       | 31.94 | 44.28 |
|      sculpture      | 65.57 | 81.96 |
|         hood        | 68.22 | 77.96 |
|        sconce       | 61.26 | 79.91 |
|         vase        | 55.39 |  81.7 |
|    traffic light    | 48.48 | 73.59 |
|         tray        | 22.02 | 31.53 |
|        ashcan       | 43.21 | 76.43 |
|         fan         | 71.33 | 84.83 |
|         pier        |  0.0  |  0.0  |
|      crt screen     |  0.0  |  0.0  |
|        plate        | 68.17 | 85.71 |
|       monitor       | 38.72 | 53.48 |
|    bulletin board   | 42.02 | 42.95 |
|        shower       | 12.89 | 13.51 |
|       radiator      | 60.27 |  79.3 |
|        glass        | 27.94 | 32.35 |
|        clock        | 42.26 |  52.6 |
|         flag        | 65.75 | 86.94 |
+---------------------+-------+-------+
2022-11-30 00:09:57,343 - mmseg - INFO - Summary:
2022-11-30 00:09:57,343 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 85.32 | 52.22 | 65.59 |
+-------+-------+-------+
2022-11-30 00:09:57,347 - mmseg - INFO - The previous best checkpoint /mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune/lr1.0_lrd0.9/best_mIoU_iter_2000.pth was removed
2022-11-30 00:10:45,751 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_3000.pth.
2022-11-30 00:10:45,751 - mmseg - INFO - Best mIoU is 0.5222 at 3000 iter.
2022-11-30 00:10:45,760 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 00:10:45,760 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8532, mIoU: 0.5222, mAcc: 0.6559, IoU.wall: 0.8238, IoU.building: 0.8391, IoU.sky: 0.9499, IoU.floor: 0.8514, IoU.tree: 0.7731, IoU.ceiling: 0.8725, IoU.road: 0.8231, IoU.bed : 0.9248, IoU.windowpane: 0.6685, IoU.grass: 0.6645, IoU.cabinet: 0.6398, IoU.sidewalk: 0.6997, IoU.person: 0.8836, IoU.earth: 0.4293, IoU.door: 0.6127, IoU.table: 0.7163, IoU.mountain: 0.6390, IoU.plant: 0.5742, IoU.curtain: 0.7942, IoU.chair: 0.6208, IoU.car: 0.8826, IoU.water: 0.5674, IoU.painting: 0.7949, IoU.sofa: 0.8289, IoU.shelf: 0.4645, IoU.house: 0.3996, IoU.sea: 0.5384, IoU.mirror: 0.8021, IoU.rug: 0.7143, IoU.field: 0.2833, IoU.armchair: 0.5356, IoU.seat: 0.6972, IoU.fence: 0.5486, IoU.desk: 0.4647, IoU.rock: 0.5833, IoU.wardrobe: 0.5038, IoU.lamp: 0.7775, IoU.bathtub: 0.9076, IoU.railing: 0.4162, IoU.cushion: 0.7337, IoU.base: 0.2870, IoU.box: 0.3850, IoU.column: 0.6324, IoU.signboard: 0.4342, IoU.chest of drawers: 0.3694, IoU.counter: 0.3544, IoU.sand: 0.6098, IoU.sink: 0.8042, IoU.skyscraper: 0.4295, IoU.fireplace: 0.8087, IoU.refrigerator: 0.7814, IoU.grandstand: 0.5066, IoU.path: 0.2317, IoU.stairs: 0.3502, IoU.runway: 0.1506, IoU.case: 0.6525, IoU.pool table: 0.9488, IoU.pillow: 0.7139, IoU.screen door: 0.7057, IoU.stairway: 0.4732, IoU.river: 0.2598, IoU.bridge: 0.7855, IoU.bookcase: 0.3205, IoU.blind: 0.3439, IoU.coffee table: 0.7061, IoU.toilet: 0.9115, IoU.flower: 0.4237, IoU.book: 0.5783, IoU.hill: 0.0539, IoU.bench: 0.6872, IoU.countertop: 0.6249, IoU.stove: 0.8446, IoU.palm: 0.4899, IoU.kitchen island: 0.3907, IoU.computer: 0.8184, IoU.swivel chair: 0.5164, IoU.boat: 0.7994, IoU.bar: 0.0404, IoU.arcade machine: 0.4557, IoU.hovel: 0.0000, IoU.bus: 0.9340, IoU.towel: 0.7861, IoU.light: 0.6412, IoU.truck: 0.5130, IoU.tower: 0.2069, IoU.chandelier: 0.7137, IoU.awning: 0.3676, IoU.streetlight: 0.4208, IoU.booth: 0.0000, IoU.television receiver: 0.7352, IoU.airplane: 0.9097, IoU.dirt track: 0.0000, IoU.apparel: 0.5432, IoU.pole: 0.3837, IoU.land: 0.0000, IoU.bannister: 0.1509, IoU.escalator: 0.0000, IoU.ottoman: 0.5178, IoU.bottle: 0.3818, IoU.buffet: 0.0000, IoU.poster: 0.2654, IoU.stage: 0.1190, IoU.van: 0.4290, IoU.ship: 0.0000, IoU.fountain: 0.0009, IoU.conveyer belt: 0.8074, IoU.canopy: 0.0238, IoU.washer: 0.6780, IoU.plaything: 0.3087, IoU.swimming pool: 0.2246, IoU.stool: 0.4860, IoU.barrel: 0.0000, IoU.basket: 0.4650, IoU.waterfall: 0.4780, IoU.tent: 0.9533, IoU.bag: 0.3996, IoU.minibike: 0.8048, IoU.cradle: 0.8441, IoU.oven: 0.6766, IoU.ball: 0.5544, IoU.food: 0.6703, IoU.step: 0.2384, IoU.tank: 0.0000, IoU.trade name: 0.3193, IoU.microwave: 0.9189, IoU.pot: 0.5979, IoU.animal: 0.8435, IoU.bicycle: 0.6085, IoU.lake: 0.0000, IoU.dishwasher: 0.6686, IoU.screen: 0.5583, IoU.blanket: 0.3194, IoU.sculpture: 0.6557, IoU.hood: 0.6822, IoU.sconce: 0.6126, IoU.vase: 0.5539, IoU.traffic light: 0.4848, IoU.tray: 0.2202, IoU.ashcan: 0.4321, IoU.fan: 0.7133, IoU.pier: 0.0000, IoU.crt screen: 0.0000, IoU.plate: 0.6817, IoU.monitor: 0.3872, IoU.bulletin board: 0.4202, IoU.shower: 0.1289, IoU.radiator: 0.6027, IoU.glass: 0.2794, IoU.clock: 0.4226, IoU.flag: 0.6575, Acc.wall: 0.8858, Acc.building: 0.9205, Acc.sky: 0.9768, Acc.floor: 0.9064, Acc.tree: 0.8659, Acc.ceiling: 0.9503, Acc.road: 0.9210, Acc.bed : 0.9685, Acc.windowpane: 0.8406, Acc.grass: 0.7600, Acc.cabinet: 0.7650, Acc.sidewalk: 0.8604, Acc.person: 0.9463, Acc.earth: 0.5679, Acc.door: 0.8005, Acc.table: 0.8277, Acc.mountain: 0.8042, Acc.plant: 0.7617, Acc.curtain: 0.9003, Acc.chair: 0.7195, Acc.car: 0.9282, Acc.water: 0.8505, Acc.painting: 0.9352, Acc.sofa: 0.9077, Acc.shelf: 0.6930, Acc.house: 0.5065, Acc.sea: 0.6373, Acc.mirror: 0.9330, Acc.rug: 0.8478, Acc.field: 0.6298, Acc.armchair: 0.8276, Acc.seat: 0.8767, Acc.fence: 0.7712, Acc.desk: 0.7320, Acc.rock: 0.7055, Acc.wardrobe: 0.6148, Acc.lamp: 0.8673, Acc.bathtub: 0.9274, Acc.railing: 0.7153, Acc.cushion: 0.8748, Acc.base: 0.3901, Acc.box: 0.5233, Acc.column: 0.8213, Acc.signboard: 0.6183, Acc.chest of drawers: 0.7259, Acc.counter: 0.6043, Acc.sand: 0.8598, Acc.sink: 0.8549, Acc.skyscraper: 0.6949, Acc.fireplace: 0.9716, Acc.refrigerator: 0.9060, Acc.grandstand: 0.7336, Acc.path: 0.3066, Acc.stairs: 0.4245, Acc.runway: 0.1510, Acc.case: 0.7855, Acc.pool table: 0.9858, Acc.pillow: 0.8187, Acc.screen door: 0.7481, Acc.stairway: 0.6960, Acc.river: 0.3464, Acc.bridge: 0.8988, Acc.bookcase: 0.5483, Acc.blind: 0.3893, Acc.coffee table: 0.9273, Acc.toilet: 0.9492, Acc.flower: 0.5896, Acc.book: 0.8110, Acc.hill: 0.0733, Acc.bench: 0.8425, Acc.countertop: 0.8537, Acc.stove: 0.8784, Acc.palm: 0.8439, Acc.kitchen island: 0.8896, Acc.computer: 0.9156, Acc.swivel chair: 0.8660, Acc.boat: 0.9364, Acc.bar: 0.0404, Acc.arcade machine: 0.4736, Acc.hovel: 0.0000, Acc.bus: 0.9647, Acc.towel: 0.9351, Acc.light: 0.7891, Acc.truck: 0.6874, Acc.tower: 0.4098, Acc.chandelier: 0.8984, Acc.awning: 0.5087, Acc.streetlight: 0.6448, Acc.booth: 0.0000, Acc.television receiver: 0.8738, Acc.airplane: 0.9645, Acc.dirt track: 0.0000, Acc.apparel: 0.9368, Acc.pole: 0.5919, Acc.land: 0.0000, Acc.bannister: 0.1903, Acc.escalator: 0.0000, Acc.ottoman: 0.7946, Acc.bottle: 0.5143, Acc.buffet: 0.0000, Acc.poster: 0.4884, Acc.stage: 0.1631, Acc.van: 0.8643, Acc.ship: 0.0000, Acc.fountain: 0.0009, Acc.conveyer belt: 0.8188, Acc.canopy: 0.0238, Acc.washer: 0.6916, Acc.plaything: 0.4822, Acc.swimming pool: 0.2248, Acc.stool: 0.8143, Acc.barrel: 0.0000, Acc.basket: 0.6335, Acc.waterfall: 0.5070, Acc.tent: 0.9773, Acc.bag: 0.6096, Acc.minibike: 0.9188, Acc.cradle: 0.8782, Acc.oven: 0.8131, Acc.ball: 0.8391, Acc.food: 0.8139, Acc.step: 0.2529, Acc.tank: 0.0000, Acc.trade name: 0.4447, Acc.microwave: 0.9760, Acc.pot: 0.7190, Acc.animal: 0.8632, Acc.bicycle: 0.8327, Acc.lake: 0.0000, Acc.dishwasher: 0.9387, Acc.screen: 0.8707, Acc.blanket: 0.4428, Acc.sculpture: 0.8196, Acc.hood: 0.7796, Acc.sconce: 0.7991, Acc.vase: 0.8170, Acc.traffic light: 0.7359, Acc.tray: 0.3153, Acc.ashcan: 0.7643, Acc.fan: 0.8483, Acc.pier: 0.0000, Acc.crt screen: 0.0000, Acc.plate: 0.8571, Acc.monitor: 0.5348, Acc.bulletin board: 0.4295, Acc.shower: 0.1351, Acc.radiator: 0.7930, Acc.glass: 0.3235, Acc.clock: 0.5260, Acc.flag: 0.8694
2022-11-30 00:14:11,626 - mmseg - INFO - Iter [3050/40000]	lr: 1.229e-07, eta: 1 day, 21:06:25, time: 8.647, data_time: 4.548, memory: 51902, decode.loss_cls: 0.6631, decode.loss_mask: 0.6549, decode.loss_dice: 0.9503, decode.d0.loss_cls: 9.6835, decode.d0.loss_mask: 0.6300, decode.d0.loss_dice: 1.0522, decode.d1.loss_cls: 0.9130, decode.d1.loss_mask: 0.6669, decode.d1.loss_dice: 1.0180, decode.d2.loss_cls: 0.7789, decode.d2.loss_mask: 0.6559, decode.d2.loss_dice: 0.9713, decode.d3.loss_cls: 0.7198, decode.d3.loss_mask: 0.6535, decode.d3.loss_dice: 0.9538, decode.d4.loss_cls: 0.6972, decode.d4.loss_mask: 0.6542, decode.d4.loss_dice: 0.9573, decode.d5.loss_cls: 0.6798, decode.d5.loss_mask: 0.6549, decode.d5.loss_dice: 0.9579, decode.d6.loss_cls: 0.6712, decode.d6.loss_mask: 0.6543, decode.d6.loss_dice: 0.9554, decode.d7.loss_cls: 0.6628, decode.d7.loss_mask: 0.6561, decode.d7.loss_dice: 0.9539, decode.d8.loss_cls: 0.6635, decode.d8.loss_mask: 0.6534, decode.d8.loss_dice: 0.9571, loss: 32.3942
2022-11-30 00:17:37,350 - mmseg - INFO - Iter [3100/40000]	lr: 1.227e-07, eta: 1 day, 20:59:58, time: 4.114, data_time: 0.020, memory: 51902, decode.loss_cls: 0.6540, decode.loss_mask: 0.6431, decode.loss_dice: 0.9459, decode.d0.loss_cls: 9.6715, decode.d0.loss_mask: 0.6079, decode.d0.loss_dice: 1.0401, decode.d1.loss_cls: 0.9136, decode.d1.loss_mask: 0.6545, decode.d1.loss_dice: 0.9976, decode.d2.loss_cls: 0.7743, decode.d2.loss_mask: 0.6427, decode.d2.loss_dice: 0.9552, decode.d3.loss_cls: 0.7142, decode.d3.loss_mask: 0.6375, decode.d3.loss_dice: 0.9396, decode.d4.loss_cls: 0.6855, decode.d4.loss_mask: 0.6397, decode.d4.loss_dice: 0.9461, decode.d5.loss_cls: 0.6711, decode.d5.loss_mask: 0.6385, decode.d5.loss_dice: 0.9447, decode.d6.loss_cls: 0.6654, decode.d6.loss_mask: 0.6389, decode.d6.loss_dice: 0.9389, decode.d7.loss_cls: 0.6627, decode.d7.loss_mask: 0.6416, decode.d7.loss_dice: 0.9415, decode.d8.loss_cls: 0.6581, decode.d8.loss_mask: 0.6427, decode.d8.loss_dice: 0.9416, loss: 32.0487
2022-11-30 00:21:03,026 - mmseg - INFO - Iter [3150/40000]	lr: 1.226e-07, eta: 1 day, 20:53:37, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.6235, decode.loss_mask: 0.6401, decode.loss_dice: 0.9127, decode.d0.loss_cls: 9.6564, decode.d0.loss_mask: 0.6119, decode.d0.loss_dice: 1.0024, decode.d1.loss_cls: 0.8554, decode.d1.loss_mask: 0.6603, decode.d1.loss_dice: 0.9683, decode.d2.loss_cls: 0.7270, decode.d2.loss_mask: 0.6459, decode.d2.loss_dice: 0.9301, decode.d3.loss_cls: 0.6738, decode.d3.loss_mask: 0.6397, decode.d3.loss_dice: 0.9124, decode.d4.loss_cls: 0.6523, decode.d4.loss_mask: 0.6406, decode.d4.loss_dice: 0.9165, decode.d5.loss_cls: 0.6375, decode.d5.loss_mask: 0.6382, decode.d5.loss_dice: 0.9160, decode.d6.loss_cls: 0.6276, decode.d6.loss_mask: 0.6374, decode.d6.loss_dice: 0.9124, decode.d7.loss_cls: 0.6249, decode.d7.loss_mask: 0.6390, decode.d7.loss_dice: 0.9104, decode.d8.loss_cls: 0.6196, decode.d8.loss_mask: 0.6409, decode.d8.loss_dice: 0.9129, loss: 31.3862
2022-11-30 00:24:30,817 - mmseg - INFO - Iter [3200/40000]	lr: 1.224e-07, eta: 1 day, 20:47:45, time: 4.156, data_time: 0.064, memory: 51902, decode.loss_cls: 0.6527, decode.loss_mask: 0.6311, decode.loss_dice: 0.9119, decode.d0.loss_cls: 9.6548, decode.d0.loss_mask: 0.6062, decode.d0.loss_dice: 1.0205, decode.d1.loss_cls: 0.9017, decode.d1.loss_mask: 0.6461, decode.d1.loss_dice: 0.9860, decode.d2.loss_cls: 0.7675, decode.d2.loss_mask: 0.6361, decode.d2.loss_dice: 0.9376, decode.d3.loss_cls: 0.7130, decode.d3.loss_mask: 0.6272, decode.d3.loss_dice: 0.9202, decode.d4.loss_cls: 0.6835, decode.d4.loss_mask: 0.6286, decode.d4.loss_dice: 0.9211, decode.d5.loss_cls: 0.6704, decode.d5.loss_mask: 0.6292, decode.d5.loss_dice: 0.9159, decode.d6.loss_cls: 0.6566, decode.d6.loss_mask: 0.6282, decode.d6.loss_dice: 0.9131, decode.d7.loss_cls: 0.6533, decode.d7.loss_mask: 0.6283, decode.d7.loss_dice: 0.9197, decode.d8.loss_cls: 0.6490, decode.d8.loss_mask: 0.6299, decode.d8.loss_dice: 0.9151, loss: 31.6546
2022-11-30 00:27:56,560 - mmseg - INFO - Iter [3250/40000]	lr: 1.222e-07, eta: 1 day, 20:41:35, time: 4.115, data_time: 0.018, memory: 51902, decode.loss_cls: 0.6183, decode.loss_mask: 0.6527, decode.loss_dice: 0.9388, decode.d0.loss_cls: 9.6394, decode.d0.loss_mask: 0.6217, decode.d0.loss_dice: 1.0320, decode.d1.loss_cls: 0.8584, decode.d1.loss_mask: 0.6670, decode.d1.loss_dice: 1.0011, decode.d2.loss_cls: 0.7288, decode.d2.loss_mask: 0.6549, decode.d2.loss_dice: 0.9633, decode.d3.loss_cls: 0.6764, decode.d3.loss_mask: 0.6516, decode.d3.loss_dice: 0.9437, decode.d4.loss_cls: 0.6525, decode.d4.loss_mask: 0.6521, decode.d4.loss_dice: 0.9465, decode.d5.loss_cls: 0.6365, decode.d5.loss_mask: 0.6535, decode.d5.loss_dice: 0.9474, decode.d6.loss_cls: 0.6289, decode.d6.loss_mask: 0.6508, decode.d6.loss_dice: 0.9395, decode.d7.loss_cls: 0.6208, decode.d7.loss_mask: 0.6544, decode.d7.loss_dice: 0.9457, decode.d8.loss_cls: 0.6191, decode.d8.loss_mask: 0.6522, decode.d8.loss_dice: 0.9461, loss: 31.7941
2022-11-30 00:31:22,329 - mmseg - INFO - Iter [3300/40000]	lr: 1.221e-07, eta: 1 day, 20:35:30, time: 4.115, data_time: 0.018, memory: 51902, decode.loss_cls: 0.6334, decode.loss_mask: 0.6532, decode.loss_dice: 0.9328, decode.d0.loss_cls: 9.6305, decode.d0.loss_mask: 0.6205, decode.d0.loss_dice: 1.0258, decode.d1.loss_cls: 0.8704, decode.d1.loss_mask: 0.6686, decode.d1.loss_dice: 0.9950, decode.d2.loss_cls: 0.7421, decode.d2.loss_mask: 0.6569, decode.d2.loss_dice: 0.9482, decode.d3.loss_cls: 0.6879, decode.d3.loss_mask: 0.6526, decode.d3.loss_dice: 0.9355, decode.d4.loss_cls: 0.6612, decode.d4.loss_mask: 0.6523, decode.d4.loss_dice: 0.9366, decode.d5.loss_cls: 0.6471, decode.d5.loss_mask: 0.6509, decode.d5.loss_dice: 0.9317, decode.d6.loss_cls: 0.6371, decode.d6.loss_mask: 0.6510, decode.d6.loss_dice: 0.9337, decode.d7.loss_cls: 0.6358, decode.d7.loss_mask: 0.6523, decode.d7.loss_dice: 0.9340, decode.d8.loss_cls: 0.6345, decode.d8.loss_mask: 0.6506, decode.d8.loss_dice: 0.9336, loss: 31.7957
2022-11-30 00:34:47,903 - mmseg - INFO - Iter [3350/40000]	lr: 1.219e-07, eta: 1 day, 20:29:28, time: 4.111, data_time: 0.018, memory: 51902, decode.loss_cls: 0.6206, decode.loss_mask: 0.6544, decode.loss_dice: 0.9483, decode.d0.loss_cls: 9.6125, decode.d0.loss_mask: 0.6197, decode.d0.loss_dice: 1.0337, decode.d1.loss_cls: 0.8618, decode.d1.loss_mask: 0.6655, decode.d1.loss_dice: 1.0073, decode.d2.loss_cls: 0.7298, decode.d2.loss_mask: 0.6555, decode.d2.loss_dice: 0.9605, decode.d3.loss_cls: 0.6738, decode.d3.loss_mask: 0.6548, decode.d3.loss_dice: 0.9486, decode.d4.loss_cls: 0.6564, decode.d4.loss_mask: 0.6527, decode.d4.loss_dice: 0.9472, decode.d5.loss_cls: 0.6393, decode.d5.loss_mask: 0.6491, decode.d5.loss_dice: 0.9472, decode.d6.loss_cls: 0.6265, decode.d6.loss_mask: 0.6521, decode.d6.loss_dice: 0.9484, decode.d7.loss_cls: 0.6267, decode.d7.loss_mask: 0.6527, decode.d7.loss_dice: 0.9540, decode.d8.loss_cls: 0.6202, decode.d8.loss_mask: 0.6534, decode.d8.loss_dice: 0.9495, loss: 31.8221
2022-11-30 00:38:13,695 - mmseg - INFO - Iter [3400/40000]	lr: 1.217e-07, eta: 1 day, 20:23:32, time: 4.116, data_time: 0.019, memory: 51902, decode.loss_cls: 0.6113, decode.loss_mask: 0.6364, decode.loss_dice: 0.9268, decode.d0.loss_cls: 9.6088, decode.d0.loss_mask: 0.6069, decode.d0.loss_dice: 1.0176, decode.d1.loss_cls: 0.8537, decode.d1.loss_mask: 0.6483, decode.d1.loss_dice: 0.9815, decode.d2.loss_cls: 0.7146, decode.d2.loss_mask: 0.6452, decode.d2.loss_dice: 0.9439, decode.d3.loss_cls: 0.6592, decode.d3.loss_mask: 0.6389, decode.d3.loss_dice: 0.9334, decode.d4.loss_cls: 0.6376, decode.d4.loss_mask: 0.6415, decode.d4.loss_dice: 0.9402, decode.d5.loss_cls: 0.6258, decode.d5.loss_mask: 0.6384, decode.d5.loss_dice: 0.9302, decode.d6.loss_cls: 0.6132, decode.d6.loss_mask: 0.6380, decode.d6.loss_dice: 0.9317, decode.d7.loss_cls: 0.6107, decode.d7.loss_mask: 0.6362, decode.d7.loss_dice: 0.9279, decode.d8.loss_cls: 0.6073, decode.d8.loss_mask: 0.6381, decode.d8.loss_dice: 0.9303, loss: 31.3739
2022-11-30 00:41:39,536 - mmseg - INFO - Iter [3450/40000]	lr: 1.216e-07, eta: 1 day, 20:17:42, time: 4.117, data_time: 0.020, memory: 51902, decode.loss_cls: 0.6333, decode.loss_mask: 0.6350, decode.loss_dice: 0.9335, decode.d0.loss_cls: 9.5964, decode.d0.loss_mask: 0.6077, decode.d0.loss_dice: 1.0281, decode.d1.loss_cls: 0.8729, decode.d1.loss_mask: 0.6515, decode.d1.loss_dice: 0.9859, decode.d2.loss_cls: 0.7404, decode.d2.loss_mask: 0.6396, decode.d2.loss_dice: 0.9482, decode.d3.loss_cls: 0.6868, decode.d3.loss_mask: 0.6338, decode.d3.loss_dice: 0.9315, decode.d4.loss_cls: 0.6658, decode.d4.loss_mask: 0.6353, decode.d4.loss_dice: 0.9366, decode.d5.loss_cls: 0.6500, decode.d5.loss_mask: 0.6370, decode.d5.loss_dice: 0.9322, decode.d6.loss_cls: 0.6421, decode.d6.loss_mask: 0.6363, decode.d6.loss_dice: 0.9320, decode.d7.loss_cls: 0.6375, decode.d7.loss_mask: 0.6378, decode.d7.loss_dice: 0.9338, decode.d8.loss_cls: 0.6391, decode.d8.loss_mask: 0.6350, decode.d8.loss_dice: 0.9323, loss: 31.6074
2022-11-30 00:45:05,150 - mmseg - INFO - Iter [3500/40000]	lr: 1.214e-07, eta: 1 day, 20:11:53, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.6440, decode.loss_mask: 0.6467, decode.loss_dice: 0.9407, decode.d0.loss_cls: 9.5807, decode.d0.loss_mask: 0.6209, decode.d0.loss_dice: 1.0230, decode.d1.loss_cls: 0.8716, decode.d1.loss_mask: 0.6669, decode.d1.loss_dice: 0.9971, decode.d2.loss_cls: 0.7472, decode.d2.loss_mask: 0.6554, decode.d2.loss_dice: 0.9617, decode.d3.loss_cls: 0.6948, decode.d3.loss_mask: 0.6509, decode.d3.loss_dice: 0.9451, decode.d4.loss_cls: 0.6744, decode.d4.loss_mask: 0.6489, decode.d4.loss_dice: 0.9447, decode.d5.loss_cls: 0.6578, decode.d5.loss_mask: 0.6459, decode.d5.loss_dice: 0.9445, decode.d6.loss_cls: 0.6472, decode.d6.loss_mask: 0.6489, decode.d6.loss_dice: 0.9464, decode.d7.loss_cls: 0.6483, decode.d7.loss_mask: 0.6468, decode.d7.loss_dice: 0.9443, decode.d8.loss_cls: 0.6457, decode.d8.loss_mask: 0.6474, decode.d8.loss_dice: 0.9439, loss: 31.8818
2022-11-30 00:48:30,741 - mmseg - INFO - Iter [3550/40000]	lr: 1.212e-07, eta: 1 day, 20:06:08, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 0.6057, decode.loss_mask: 0.6452, decode.loss_dice: 0.9221, decode.d0.loss_cls: 9.5623, decode.d0.loss_mask: 0.6137, decode.d0.loss_dice: 1.0044, decode.d1.loss_cls: 0.8395, decode.d1.loss_mask: 0.6566, decode.d1.loss_dice: 0.9735, decode.d2.loss_cls: 0.7076, decode.d2.loss_mask: 0.6482, decode.d2.loss_dice: 0.9375, decode.d3.loss_cls: 0.6572, decode.d3.loss_mask: 0.6435, decode.d3.loss_dice: 0.9288, decode.d4.loss_cls: 0.6349, decode.d4.loss_mask: 0.6438, decode.d4.loss_dice: 0.9278, decode.d5.loss_cls: 0.6211, decode.d5.loss_mask: 0.6430, decode.d5.loss_dice: 0.9284, decode.d6.loss_cls: 0.6069, decode.d6.loss_mask: 0.6411, decode.d6.loss_dice: 0.9235, decode.d7.loss_cls: 0.6070, decode.d7.loss_mask: 0.6397, decode.d7.loss_dice: 0.9252, decode.d8.loss_cls: 0.6051, decode.d8.loss_mask: 0.6432, decode.d8.loss_dice: 0.9259, loss: 31.2626
2022-11-30 00:51:56,437 - mmseg - INFO - Iter [3600/40000]	lr: 1.211e-07, eta: 1 day, 20:00:28, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.6204, decode.loss_mask: 0.6565, decode.loss_dice: 0.9363, decode.d0.loss_cls: 9.5568, decode.d0.loss_mask: 0.6265, decode.d0.loss_dice: 1.0354, decode.d1.loss_cls: 0.8428, decode.d1.loss_mask: 0.6725, decode.d1.loss_dice: 0.9928, decode.d2.loss_cls: 0.7229, decode.d2.loss_mask: 0.6597, decode.d2.loss_dice: 0.9561, decode.d3.loss_cls: 0.6712, decode.d3.loss_mask: 0.6567, decode.d3.loss_dice: 0.9428, decode.d4.loss_cls: 0.6484, decode.d4.loss_mask: 0.6582, decode.d4.loss_dice: 0.9417, decode.d5.loss_cls: 0.6320, decode.d5.loss_mask: 0.6581, decode.d5.loss_dice: 0.9441, decode.d6.loss_cls: 0.6277, decode.d6.loss_mask: 0.6539, decode.d6.loss_dice: 0.9373, decode.d7.loss_cls: 0.6228, decode.d7.loss_mask: 0.6546, decode.d7.loss_dice: 0.9341, decode.d8.loss_cls: 0.6198, decode.d8.loss_mask: 0.6537, decode.d8.loss_dice: 0.9358, loss: 31.6716
2022-11-30 00:55:22,008 - mmseg - INFO - Iter [3650/40000]	lr: 1.209e-07, eta: 1 day, 19:54:50, time: 4.111, data_time: 0.020, memory: 51902, decode.loss_cls: 0.6255, decode.loss_mask: 0.6413, decode.loss_dice: 0.9214, decode.d0.loss_cls: 9.5490, decode.d0.loss_mask: 0.6129, decode.d0.loss_dice: 1.0244, decode.d1.loss_cls: 0.8413, decode.d1.loss_mask: 0.6568, decode.d1.loss_dice: 0.9810, decode.d2.loss_cls: 0.7215, decode.d2.loss_mask: 0.6505, decode.d2.loss_dice: 0.9440, decode.d3.loss_cls: 0.6706, decode.d3.loss_mask: 0.6427, decode.d3.loss_dice: 0.9310, decode.d4.loss_cls: 0.6529, decode.d4.loss_mask: 0.6428, decode.d4.loss_dice: 0.9254, decode.d5.loss_cls: 0.6359, decode.d5.loss_mask: 0.6428, decode.d5.loss_dice: 0.9277, decode.d6.loss_cls: 0.6278, decode.d6.loss_mask: 0.6449, decode.d6.loss_dice: 0.9207, decode.d7.loss_cls: 0.6234, decode.d7.loss_mask: 0.6428, decode.d7.loss_dice: 0.9271, decode.d8.loss_cls: 0.6233, decode.d8.loss_mask: 0.6442, decode.d8.loss_dice: 0.9261, loss: 31.4217
2022-11-30 00:58:47,822 - mmseg - INFO - Iter [3700/40000]	lr: 1.207e-07, eta: 1 day, 19:49:18, time: 4.116, data_time: 0.019, memory: 51902, decode.loss_cls: 0.6509, decode.loss_mask: 0.6369, decode.loss_dice: 0.9204, decode.d0.loss_cls: 9.5355, decode.d0.loss_mask: 0.6146, decode.d0.loss_dice: 1.0300, decode.d1.loss_cls: 0.8711, decode.d1.loss_mask: 0.6516, decode.d1.loss_dice: 0.9853, decode.d2.loss_cls: 0.7486, decode.d2.loss_mask: 0.6435, decode.d2.loss_dice: 0.9455, decode.d3.loss_cls: 0.7014, decode.d3.loss_mask: 0.6362, decode.d3.loss_dice: 0.9274, decode.d4.loss_cls: 0.6798, decode.d4.loss_mask: 0.6363, decode.d4.loss_dice: 0.9243, decode.d5.loss_cls: 0.6641, decode.d5.loss_mask: 0.6377, decode.d5.loss_dice: 0.9246, decode.d6.loss_cls: 0.6570, decode.d6.loss_mask: 0.6374, decode.d6.loss_dice: 0.9202, decode.d7.loss_cls: 0.6493, decode.d7.loss_mask: 0.6379, decode.d7.loss_dice: 0.9255, decode.d8.loss_cls: 0.6513, decode.d8.loss_mask: 0.6411, decode.d8.loss_dice: 0.9196, loss: 31.6048
2022-11-30 01:02:13,537 - mmseg - INFO - Iter [3750/40000]	lr: 1.206e-07, eta: 1 day, 19:43:49, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.6073, decode.loss_mask: 0.6336, decode.loss_dice: 0.9220, decode.d0.loss_cls: 9.5214, decode.d0.loss_mask: 0.6066, decode.d0.loss_dice: 1.0027, decode.d1.loss_cls: 0.8150, decode.d1.loss_mask: 0.6499, decode.d1.loss_dice: 0.9794, decode.d2.loss_cls: 0.7035, decode.d2.loss_mask: 0.6389, decode.d2.loss_dice: 0.9343, decode.d3.loss_cls: 0.6506, decode.d3.loss_mask: 0.6345, decode.d3.loss_dice: 0.9243, decode.d4.loss_cls: 0.6302, decode.d4.loss_mask: 0.6336, decode.d4.loss_dice: 0.9290, decode.d5.loss_cls: 0.6169, decode.d5.loss_mask: 0.6330, decode.d5.loss_dice: 0.9254, decode.d6.loss_cls: 0.6081, decode.d6.loss_mask: 0.6316, decode.d6.loss_dice: 0.9194, decode.d7.loss_cls: 0.6056, decode.d7.loss_mask: 0.6312, decode.d7.loss_dice: 0.9222, decode.d8.loss_cls: 0.6069, decode.d8.loss_mask: 0.6326, decode.d8.loss_dice: 0.9177, loss: 31.0673
2022-11-30 01:05:41,391 - mmseg - INFO - Iter [3800/40000]	lr: 1.204e-07, eta: 1 day, 19:38:43, time: 4.157, data_time: 0.064, memory: 51902, decode.loss_cls: 0.6183, decode.loss_mask: 0.6505, decode.loss_dice: 0.9237, decode.d0.loss_cls: 9.5081, decode.d0.loss_mask: 0.6204, decode.d0.loss_dice: 1.0110, decode.d1.loss_cls: 0.8416, decode.d1.loss_mask: 0.6646, decode.d1.loss_dice: 0.9797, decode.d2.loss_cls: 0.7196, decode.d2.loss_mask: 0.6552, decode.d2.loss_dice: 0.9382, decode.d3.loss_cls: 0.6667, decode.d3.loss_mask: 0.6489, decode.d3.loss_dice: 0.9238, decode.d4.loss_cls: 0.6452, decode.d4.loss_mask: 0.6508, decode.d4.loss_dice: 0.9266, decode.d5.loss_cls: 0.6307, decode.d5.loss_mask: 0.6497, decode.d5.loss_dice: 0.9184, decode.d6.loss_cls: 0.6190, decode.d6.loss_mask: 0.6480, decode.d6.loss_dice: 0.9181, decode.d7.loss_cls: 0.6233, decode.d7.loss_mask: 0.6463, decode.d7.loss_dice: 0.9201, decode.d8.loss_cls: 0.6213, decode.d8.loss_mask: 0.6449, decode.d8.loss_dice: 0.9224, loss: 31.3553
2022-11-30 01:09:06,988 - mmseg - INFO - Iter [3850/40000]	lr: 1.202e-07, eta: 1 day, 19:33:19, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 0.6188, decode.loss_mask: 0.6345, decode.loss_dice: 0.9207, decode.d0.loss_cls: 9.4984, decode.d0.loss_mask: 0.6043, decode.d0.loss_dice: 1.0092, decode.d1.loss_cls: 0.8286, decode.d1.loss_mask: 0.6505, decode.d1.loss_dice: 0.9826, decode.d2.loss_cls: 0.7091, decode.d2.loss_mask: 0.6396, decode.d2.loss_dice: 0.9479, decode.d3.loss_cls: 0.6594, decode.d3.loss_mask: 0.6351, decode.d3.loss_dice: 0.9339, decode.d4.loss_cls: 0.6441, decode.d4.loss_mask: 0.6339, decode.d4.loss_dice: 0.9307, decode.d5.loss_cls: 0.6304, decode.d5.loss_mask: 0.6321, decode.d5.loss_dice: 0.9306, decode.d6.loss_cls: 0.6182, decode.d6.loss_mask: 0.6325, decode.d6.loss_dice: 0.9262, decode.d7.loss_cls: 0.6161, decode.d7.loss_mask: 0.6316, decode.d7.loss_dice: 0.9213, decode.d8.loss_cls: 0.6165, decode.d8.loss_mask: 0.6341, decode.d8.loss_dice: 0.9238, loss: 31.1947
2022-11-30 01:12:32,799 - mmseg - INFO - Iter [3900/40000]	lr: 1.201e-07, eta: 1 day, 19:28:00, time: 4.116, data_time: 0.018, memory: 51902, decode.loss_cls: 0.6144, decode.loss_mask: 0.6375, decode.loss_dice: 0.9323, decode.d0.loss_cls: 9.4985, decode.d0.loss_mask: 0.6071, decode.d0.loss_dice: 1.0257, decode.d1.loss_cls: 0.8339, decode.d1.loss_mask: 0.6536, decode.d1.loss_dice: 0.9928, decode.d2.loss_cls: 0.7135, decode.d2.loss_mask: 0.6410, decode.d2.loss_dice: 0.9497, decode.d3.loss_cls: 0.6579, decode.d3.loss_mask: 0.6378, decode.d3.loss_dice: 0.9435, decode.d4.loss_cls: 0.6361, decode.d4.loss_mask: 0.6380, decode.d4.loss_dice: 0.9429, decode.d5.loss_cls: 0.6231, decode.d5.loss_mask: 0.6359, decode.d5.loss_dice: 0.9359, decode.d6.loss_cls: 0.6151, decode.d6.loss_mask: 0.6336, decode.d6.loss_dice: 0.9358, decode.d7.loss_cls: 0.6134, decode.d7.loss_mask: 0.6358, decode.d7.loss_dice: 0.9351, decode.d8.loss_cls: 0.6101, decode.d8.loss_mask: 0.6364, decode.d8.loss_dice: 0.9344, loss: 31.3009
2022-11-30 01:15:58,491 - mmseg - INFO - Iter [3950/40000]	lr: 1.199e-07, eta: 1 day, 19:22:42, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.6198, decode.loss_mask: 0.6541, decode.loss_dice: 0.9305, decode.d0.loss_cls: 9.4772, decode.d0.loss_mask: 0.6283, decode.d0.loss_dice: 1.0250, decode.d1.loss_cls: 0.8141, decode.d1.loss_mask: 0.6719, decode.d1.loss_dice: 0.9888, decode.d2.loss_cls: 0.7051, decode.d2.loss_mask: 0.6593, decode.d2.loss_dice: 0.9470, decode.d3.loss_cls: 0.6599, decode.d3.loss_mask: 0.6553, decode.d3.loss_dice: 0.9342, decode.d4.loss_cls: 0.6418, decode.d4.loss_mask: 0.6556, decode.d4.loss_dice: 0.9358, decode.d5.loss_cls: 0.6274, decode.d5.loss_mask: 0.6544, decode.d5.loss_dice: 0.9334, decode.d6.loss_cls: 0.6206, decode.d6.loss_mask: 0.6551, decode.d6.loss_dice: 0.9280, decode.d7.loss_cls: 0.6178, decode.d7.loss_mask: 0.6538, decode.d7.loss_dice: 0.9315, decode.d8.loss_cls: 0.6155, decode.d8.loss_mask: 0.6548, decode.d8.loss_dice: 0.9306, loss: 31.4263
2022-11-30 01:19:24,255 - mmseg - INFO - Saving checkpoint at 4000 iterations
2022-11-30 01:20:09,192 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 01:20:09,192 - mmseg - INFO - Iter [4000/40000]	lr: 1.197e-07, eta: 1 day, 19:24:13, time: 5.014, data_time: 0.019, memory: 51902, decode.loss_cls: 0.6005, decode.loss_mask: 0.6447, decode.loss_dice: 0.9263, decode.d0.loss_cls: 9.4613, decode.d0.loss_mask: 0.6152, decode.d0.loss_dice: 1.0099, decode.d1.loss_cls: 0.8046, decode.d1.loss_mask: 0.6568, decode.d1.loss_dice: 0.9817, decode.d2.loss_cls: 0.6946, decode.d2.loss_mask: 0.6465, decode.d2.loss_dice: 0.9461, decode.d3.loss_cls: 0.6488, decode.d3.loss_mask: 0.6449, decode.d3.loss_dice: 0.9314, decode.d4.loss_cls: 0.6285, decode.d4.loss_mask: 0.6427, decode.d4.loss_dice: 0.9286, decode.d5.loss_cls: 0.6127, decode.d5.loss_mask: 0.6460, decode.d5.loss_dice: 0.9273, decode.d6.loss_cls: 0.6048, decode.d6.loss_mask: 0.6440, decode.d6.loss_dice: 0.9280, decode.d7.loss_cls: 0.6037, decode.d7.loss_mask: 0.6440, decode.d7.loss_dice: 0.9273, decode.d8.loss_cls: 0.5990, decode.d8.loss_mask: 0.6432, decode.d8.loss_dice: 0.9289, loss: 31.1220
2022-11-30 01:23:07,240 - mmseg - INFO - per class results:
2022-11-30 01:23:07,245 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 82.16 |  88.7 |
|       building      | 84.43 | 92.26 |
|         sky         | 95.05 | 97.58 |
|        floor        | 85.06 | 90.53 |
|         tree        | 77.42 | 86.63 |
|       ceiling       | 87.76 | 94.15 |
|         road        | 86.96 | 90.36 |
|         bed         | 92.57 | 95.89 |
|      windowpane     |  66.2 |  83.4 |
|        grass        | 69.66 | 86.08 |
|       cabinet       | 62.82 | 73.92 |
|       sidewalk      |  68.9 | 88.33 |
|        person       | 88.34 | 94.24 |
|        earth        | 43.21 | 55.48 |
|         door        | 60.48 | 77.42 |
|        table        | 71.15 | 82.39 |
|       mountain      | 65.62 | 77.39 |
|        plant        | 58.05 | 75.25 |
|       curtain       | 80.12 | 90.09 |
|        chair        | 64.98 | 76.32 |
|         car         | 89.13 | 94.24 |
|        water        | 57.72 | 80.91 |
|       painting      | 81.48 | 92.38 |
|         sofa        | 85.12 | 90.87 |
|        shelf        | 44.57 | 57.16 |
|        house        | 47.06 | 66.28 |
|         sea         | 61.45 | 76.12 |
|        mirror       | 80.38 | 92.82 |
|         rug         | 71.18 | 84.33 |
|        field        | 28.82 | 48.72 |
|       armchair      |  59.5 | 84.81 |
|         seat        | 70.78 | 92.51 |
|        fence        | 56.01 | 73.01 |
|         desk        |  50.8 | 66.98 |
|         rock        | 66.41 | 89.85 |
|       wardrobe      | 46.25 | 74.72 |
|         lamp        | 77.93 | 87.14 |
|       bathtub       | 82.68 | 93.81 |
|       railing       |  47.4 | 74.18 |
|       cushion       | 72.38 | 90.89 |
|         base        | 36.32 | 64.46 |
|         box         | 39.58 | 53.64 |
|        column       | 62.48 |  84.5 |
|      signboard      | 45.72 |  64.5 |
|   chest of drawers  | 42.44 | 70.01 |
|       counter       | 43.43 | 63.35 |
|         sand        |  56.0 | 76.71 |
|         sink        | 82.21 | 87.08 |
|      skyscraper     | 48.61 | 61.73 |
|      fireplace      | 79.19 | 90.19 |
|     refrigerator    | 81.57 | 91.24 |
|      grandstand     | 47.88 | 75.65 |
|         path        | 18.35 | 20.83 |
|        stairs       | 52.29 | 69.02 |
|        runway       |  73.7 | 93.17 |
|         case        | 72.36 | 83.03 |
|      pool table     | 93.64 | 98.61 |
|        pillow       | 70.22 | 81.73 |
|     screen door     | 81.14 | 84.77 |
|       stairway      | 60.56 | 69.42 |
|        river        | 22.82 |  26.1 |
|        bridge       | 79.41 | 90.51 |
|       bookcase      | 28.11 | 53.88 |
|        blind        | 38.43 | 42.39 |
|     coffee table    | 69.56 | 90.28 |
|        toilet       | 92.38 | 96.72 |
|        flower       | 43.79 | 65.32 |
|         book        | 56.36 | 82.01 |
|         hill        | 12.61 | 16.88 |
|        bench        | 75.69 | 86.48 |
|      countertop     | 65.08 | 85.82 |
|        stove        | 83.92 | 88.02 |
|         palm        | 49.58 | 83.05 |
|    kitchen island   | 41.46 | 81.04 |
|       computer      | 82.07 | 92.26 |
|     swivel chair    | 53.69 | 83.42 |
|         boat        |  60.6 | 92.45 |
|         bar         | 41.87 | 44.62 |
|    arcade machine   | 76.29 | 82.12 |
|        hovel        |  5.69 |  7.31 |
|         bus         | 93.38 | 95.47 |
|        towel        |  76.8 | 94.78 |
|        light        | 63.56 | 78.71 |
|        truck        | 53.22 | 71.74 |
|        tower        | 20.66 | 35.43 |
|      chandelier     | 73.92 | 88.78 |
|        awning       | 38.24 | 48.87 |
|     streetlight     | 41.51 | 60.23 |
|        booth        |  0.0  |  0.0  |
| television receiver | 72.46 | 91.83 |
|       airplane      | 88.91 | 96.14 |
|      dirt track     |  0.0  |  0.0  |
|       apparel       | 56.49 | 92.17 |
|         pole        | 30.49 | 65.43 |
|         land        |  0.0  |  0.0  |
|      bannister      | 14.32 | 20.01 |
|      escalator      |  59.0 | 71.44 |
|       ottoman       | 55.13 | 80.32 |
|        bottle       | 48.25 | 65.65 |
|        buffet       |  4.77 |  4.8  |
|        poster       | 31.97 | 50.91 |
|        stage        | 14.49 | 23.42 |
|         van         | 52.24 | 82.28 |
|         ship        |  1.48 |  1.51 |
|       fountain      | 10.05 |  10.2 |
|    conveyer belt    | 87.45 | 97.26 |
|        canopy       | 40.59 | 41.89 |
|        washer       |  78.9 | 79.48 |
|      plaything      | 33.71 | 56.64 |
|    swimming pool    | 50.35 | 74.46 |
|        stool        | 55.41 | 85.09 |
|        barrel       | 47.41 | 52.75 |
|        basket       | 39.77 | 70.58 |
|      waterfall      | 57.44 | 61.07 |
|         tent        | 94.86 | 98.17 |
|         bag         | 34.42 | 46.95 |
|       minibike      | 80.28 | 92.82 |
|        cradle       | 87.44 | 91.93 |
|         oven        | 68.57 | 82.58 |
|         ball        |  55.6 |  85.4 |
|         food        |  66.6 | 81.74 |
|         step        | 24.41 |  32.1 |
|         tank        |  0.69 |  0.69 |
|      trade name     |  36.2 | 47.89 |
|      microwave      | 91.61 | 98.01 |
|         pot         | 54.85 | 64.85 |
|        animal       | 86.27 | 89.55 |
|       bicycle       | 60.83 | 84.68 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 69.16 | 95.77 |
|        screen       |  54.2 | 92.91 |
|       blanket       | 31.33 | 45.19 |
|      sculpture      | 69.35 | 91.66 |
|         hood        | 65.03 | 82.25 |
|        sconce       | 64.13 | 79.77 |
|         vase        | 55.08 | 82.32 |
|    traffic light    | 48.79 | 71.04 |
|         tray        | 24.09 | 39.54 |
|        ashcan       | 43.35 | 78.84 |
|         fan         | 72.31 | 84.63 |
|         pier        | 23.25 | 23.41 |
|      crt screen     |  0.31 |  0.32 |
|        plate        | 69.14 | 85.37 |
|       monitor       | 46.01 | 67.57 |
|    bulletin board   |  50.2 | 75.34 |
|        shower       | 19.71 | 28.27 |
|       radiator      | 61.36 | 80.56 |
|        glass        | 28.96 | 33.38 |
|        clock        | 45.44 | 51.19 |
|         flag        | 69.42 | 84.16 |
+---------------------+-------+-------+
2022-11-30 01:23:07,245 - mmseg - INFO - Summary:
2022-11-30 01:23:07,245 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 86.04 | 55.87 | 70.02 |
+-------+-------+-------+
2022-11-30 01:23:07,249 - mmseg - INFO - The previous best checkpoint /mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune/lr1.0_lrd0.9/best_mIoU_iter_3000.pth was removed
2022-11-30 01:23:51,174 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_4000.pth.
2022-11-30 01:23:51,175 - mmseg - INFO - Best mIoU is 0.5587 at 4000 iter.
2022-11-30 01:23:51,187 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 01:23:51,187 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8604, mIoU: 0.5587, mAcc: 0.7002, IoU.wall: 0.8216, IoU.building: 0.8443, IoU.sky: 0.9505, IoU.floor: 0.8506, IoU.tree: 0.7742, IoU.ceiling: 0.8776, IoU.road: 0.8696, IoU.bed : 0.9257, IoU.windowpane: 0.6620, IoU.grass: 0.6966, IoU.cabinet: 0.6282, IoU.sidewalk: 0.6890, IoU.person: 0.8834, IoU.earth: 0.4321, IoU.door: 0.6048, IoU.table: 0.7115, IoU.mountain: 0.6562, IoU.plant: 0.5805, IoU.curtain: 0.8012, IoU.chair: 0.6498, IoU.car: 0.8913, IoU.water: 0.5772, IoU.painting: 0.8148, IoU.sofa: 0.8512, IoU.shelf: 0.4457, IoU.house: 0.4706, IoU.sea: 0.6145, IoU.mirror: 0.8038, IoU.rug: 0.7118, IoU.field: 0.2882, IoU.armchair: 0.5950, IoU.seat: 0.7078, IoU.fence: 0.5601, IoU.desk: 0.5080, IoU.rock: 0.6641, IoU.wardrobe: 0.4625, IoU.lamp: 0.7793, IoU.bathtub: 0.8268, IoU.railing: 0.4740, IoU.cushion: 0.7238, IoU.base: 0.3632, IoU.box: 0.3958, IoU.column: 0.6248, IoU.signboard: 0.4572, IoU.chest of drawers: 0.4244, IoU.counter: 0.4343, IoU.sand: 0.5600, IoU.sink: 0.8221, IoU.skyscraper: 0.4861, IoU.fireplace: 0.7919, IoU.refrigerator: 0.8157, IoU.grandstand: 0.4788, IoU.path: 0.1835, IoU.stairs: 0.5229, IoU.runway: 0.7370, IoU.case: 0.7236, IoU.pool table: 0.9364, IoU.pillow: 0.7022, IoU.screen door: 0.8114, IoU.stairway: 0.6056, IoU.river: 0.2282, IoU.bridge: 0.7941, IoU.bookcase: 0.2811, IoU.blind: 0.3843, IoU.coffee table: 0.6956, IoU.toilet: 0.9238, IoU.flower: 0.4379, IoU.book: 0.5636, IoU.hill: 0.1261, IoU.bench: 0.7569, IoU.countertop: 0.6508, IoU.stove: 0.8392, IoU.palm: 0.4958, IoU.kitchen island: 0.4146, IoU.computer: 0.8207, IoU.swivel chair: 0.5369, IoU.boat: 0.6060, IoU.bar: 0.4187, IoU.arcade machine: 0.7629, IoU.hovel: 0.0569, IoU.bus: 0.9338, IoU.towel: 0.7680, IoU.light: 0.6356, IoU.truck: 0.5322, IoU.tower: 0.2066, IoU.chandelier: 0.7392, IoU.awning: 0.3824, IoU.streetlight: 0.4151, IoU.booth: 0.0000, IoU.television receiver: 0.7246, IoU.airplane: 0.8891, IoU.dirt track: 0.0000, IoU.apparel: 0.5649, IoU.pole: 0.3049, IoU.land: 0.0000, IoU.bannister: 0.1432, IoU.escalator: 0.5900, IoU.ottoman: 0.5513, IoU.bottle: 0.4825, IoU.buffet: 0.0477, IoU.poster: 0.3197, IoU.stage: 0.1449, IoU.van: 0.5224, IoU.ship: 0.0148, IoU.fountain: 0.1005, IoU.conveyer belt: 0.8745, IoU.canopy: 0.4059, IoU.washer: 0.7890, IoU.plaything: 0.3371, IoU.swimming pool: 0.5035, IoU.stool: 0.5541, IoU.barrel: 0.4741, IoU.basket: 0.3977, IoU.waterfall: 0.5744, IoU.tent: 0.9486, IoU.bag: 0.3442, IoU.minibike: 0.8028, IoU.cradle: 0.8744, IoU.oven: 0.6857, IoU.ball: 0.5560, IoU.food: 0.6660, IoU.step: 0.2441, IoU.tank: 0.0069, IoU.trade name: 0.3620, IoU.microwave: 0.9161, IoU.pot: 0.5485, IoU.animal: 0.8627, IoU.bicycle: 0.6083, IoU.lake: 0.0000, IoU.dishwasher: 0.6916, IoU.screen: 0.5420, IoU.blanket: 0.3133, IoU.sculpture: 0.6935, IoU.hood: 0.6503, IoU.sconce: 0.6413, IoU.vase: 0.5508, IoU.traffic light: 0.4879, IoU.tray: 0.2409, IoU.ashcan: 0.4335, IoU.fan: 0.7231, IoU.pier: 0.2325, IoU.crt screen: 0.0031, IoU.plate: 0.6914, IoU.monitor: 0.4601, IoU.bulletin board: 0.5020, IoU.shower: 0.1971, IoU.radiator: 0.6136, IoU.glass: 0.2896, IoU.clock: 0.4544, IoU.flag: 0.6942, Acc.wall: 0.8870, Acc.building: 0.9226, Acc.sky: 0.9758, Acc.floor: 0.9053, Acc.tree: 0.8663, Acc.ceiling: 0.9415, Acc.road: 0.9036, Acc.bed : 0.9589, Acc.windowpane: 0.8340, Acc.grass: 0.8608, Acc.cabinet: 0.7392, Acc.sidewalk: 0.8833, Acc.person: 0.9424, Acc.earth: 0.5548, Acc.door: 0.7742, Acc.table: 0.8239, Acc.mountain: 0.7739, Acc.plant: 0.7525, Acc.curtain: 0.9009, Acc.chair: 0.7632, Acc.car: 0.9424, Acc.water: 0.8091, Acc.painting: 0.9238, Acc.sofa: 0.9087, Acc.shelf: 0.5716, Acc.house: 0.6628, Acc.sea: 0.7612, Acc.mirror: 0.9282, Acc.rug: 0.8433, Acc.field: 0.4872, Acc.armchair: 0.8481, Acc.seat: 0.9251, Acc.fence: 0.7301, Acc.desk: 0.6698, Acc.rock: 0.8985, Acc.wardrobe: 0.7472, Acc.lamp: 0.8714, Acc.bathtub: 0.9381, Acc.railing: 0.7418, Acc.cushion: 0.9089, Acc.base: 0.6446, Acc.box: 0.5364, Acc.column: 0.8450, Acc.signboard: 0.6450, Acc.chest of drawers: 0.7001, Acc.counter: 0.6335, Acc.sand: 0.7671, Acc.sink: 0.8708, Acc.skyscraper: 0.6173, Acc.fireplace: 0.9019, Acc.refrigerator: 0.9124, Acc.grandstand: 0.7565, Acc.path: 0.2083, Acc.stairs: 0.6902, Acc.runway: 0.9317, Acc.case: 0.8303, Acc.pool table: 0.9861, Acc.pillow: 0.8173, Acc.screen door: 0.8477, Acc.stairway: 0.6942, Acc.river: 0.2610, Acc.bridge: 0.9051, Acc.bookcase: 0.5388, Acc.blind: 0.4239, Acc.coffee table: 0.9028, Acc.toilet: 0.9672, Acc.flower: 0.6532, Acc.book: 0.8201, Acc.hill: 0.1688, Acc.bench: 0.8648, Acc.countertop: 0.8582, Acc.stove: 0.8802, Acc.palm: 0.8305, Acc.kitchen island: 0.8104, Acc.computer: 0.9226, Acc.swivel chair: 0.8342, Acc.boat: 0.9245, Acc.bar: 0.4462, Acc.arcade machine: 0.8212, Acc.hovel: 0.0731, Acc.bus: 0.9547, Acc.towel: 0.9478, Acc.light: 0.7871, Acc.truck: 0.7174, Acc.tower: 0.3543, Acc.chandelier: 0.8878, Acc.awning: 0.4887, Acc.streetlight: 0.6023, Acc.booth: 0.0000, Acc.television receiver: 0.9183, Acc.airplane: 0.9614, Acc.dirt track: 0.0000, Acc.apparel: 0.9217, Acc.pole: 0.6543, Acc.land: 0.0000, Acc.bannister: 0.2001, Acc.escalator: 0.7144, Acc.ottoman: 0.8032, Acc.bottle: 0.6565, Acc.buffet: 0.0480, Acc.poster: 0.5091, Acc.stage: 0.2342, Acc.van: 0.8228, Acc.ship: 0.0151, Acc.fountain: 0.1020, Acc.conveyer belt: 0.9726, Acc.canopy: 0.4189, Acc.washer: 0.7948, Acc.plaything: 0.5664, Acc.swimming pool: 0.7446, Acc.stool: 0.8509, Acc.barrel: 0.5275, Acc.basket: 0.7058, Acc.waterfall: 0.6107, Acc.tent: 0.9817, Acc.bag: 0.4695, Acc.minibike: 0.9282, Acc.cradle: 0.9193, Acc.oven: 0.8258, Acc.ball: 0.8540, Acc.food: 0.8174, Acc.step: 0.3210, Acc.tank: 0.0069, Acc.trade name: 0.4789, Acc.microwave: 0.9801, Acc.pot: 0.6485, Acc.animal: 0.8955, Acc.bicycle: 0.8468, Acc.lake: 0.0000, Acc.dishwasher: 0.9577, Acc.screen: 0.9291, Acc.blanket: 0.4519, Acc.sculpture: 0.9166, Acc.hood: 0.8225, Acc.sconce: 0.7977, Acc.vase: 0.8232, Acc.traffic light: 0.7104, Acc.tray: 0.3954, Acc.ashcan: 0.7884, Acc.fan: 0.8463, Acc.pier: 0.2341, Acc.crt screen: 0.0032, Acc.plate: 0.8537, Acc.monitor: 0.6757, Acc.bulletin board: 0.7534, Acc.shower: 0.2827, Acc.radiator: 0.8056, Acc.glass: 0.3338, Acc.clock: 0.5119, Acc.flag: 0.8416
2022-11-30 01:27:17,329 - mmseg - INFO - Iter [4050/40000]	lr: 1.196e-07, eta: 1 day, 19:51:50, time: 8.563, data_time: 4.458, memory: 51902, decode.loss_cls: 0.5946, decode.loss_mask: 0.6438, decode.loss_dice: 0.9107, decode.d0.loss_cls: 9.4538, decode.d0.loss_mask: 0.6171, decode.d0.loss_dice: 1.0029, decode.d1.loss_cls: 0.8063, decode.d1.loss_mask: 0.6606, decode.d1.loss_dice: 0.9727, decode.d2.loss_cls: 0.6908, decode.d2.loss_mask: 0.6476, decode.d2.loss_dice: 0.9285, decode.d3.loss_cls: 0.6388, decode.d3.loss_mask: 0.6441, decode.d3.loss_dice: 0.9141, decode.d4.loss_cls: 0.6182, decode.d4.loss_mask: 0.6430, decode.d4.loss_dice: 0.9089, decode.d5.loss_cls: 0.6031, decode.d5.loss_mask: 0.6441, decode.d5.loss_dice: 0.9115, decode.d6.loss_cls: 0.5983, decode.d6.loss_mask: 0.6396, decode.d6.loss_dice: 0.9069, decode.d7.loss_cls: 0.5935, decode.d7.loss_mask: 0.6406, decode.d7.loss_dice: 0.9140, decode.d8.loss_cls: 0.5916, decode.d8.loss_mask: 0.6416, decode.d8.loss_dice: 0.9091, loss: 30.8904
2022-11-30 01:30:43,200 - mmseg - INFO - Iter [4100/40000]	lr: 1.194e-07, eta: 1 day, 19:46:10, time: 4.117, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5912, decode.loss_mask: 0.6393, decode.loss_dice: 0.9159, decode.d0.loss_cls: 9.4345, decode.d0.loss_mask: 0.6045, decode.d0.loss_dice: 0.9931, decode.d1.loss_cls: 0.7836, decode.d1.loss_mask: 0.6539, decode.d1.loss_dice: 0.9686, decode.d2.loss_cls: 0.6779, decode.d2.loss_mask: 0.6398, decode.d2.loss_dice: 0.9323, decode.d3.loss_cls: 0.6316, decode.d3.loss_mask: 0.6372, decode.d3.loss_dice: 0.9124, decode.d4.loss_cls: 0.6145, decode.d4.loss_mask: 0.6393, decode.d4.loss_dice: 0.9237, decode.d5.loss_cls: 0.6025, decode.d5.loss_mask: 0.6386, decode.d5.loss_dice: 0.9145, decode.d6.loss_cls: 0.5977, decode.d6.loss_mask: 0.6362, decode.d6.loss_dice: 0.9095, decode.d7.loss_cls: 0.5938, decode.d7.loss_mask: 0.6394, decode.d7.loss_dice: 0.9159, decode.d8.loss_cls: 0.5904, decode.d8.loss_mask: 0.6420, decode.d8.loss_dice: 0.9148, loss: 30.7887
2022-11-30 01:34:08,865 - mmseg - INFO - Iter [4150/40000]	lr: 1.192e-07, eta: 1 day, 19:40:31, time: 4.113, data_time: 0.019, memory: 51902, decode.loss_cls: 0.6203, decode.loss_mask: 0.6446, decode.loss_dice: 0.9548, decode.d0.loss_cls: 9.4291, decode.d0.loss_mask: 0.6196, decode.d0.loss_dice: 1.0368, decode.d1.loss_cls: 0.8316, decode.d1.loss_mask: 0.6606, decode.d1.loss_dice: 1.0167, decode.d2.loss_cls: 0.7179, decode.d2.loss_mask: 0.6489, decode.d2.loss_dice: 0.9691, decode.d3.loss_cls: 0.6641, decode.d3.loss_mask: 0.6467, decode.d3.loss_dice: 0.9561, decode.d4.loss_cls: 0.6486, decode.d4.loss_mask: 0.6483, decode.d4.loss_dice: 0.9619, decode.d5.loss_cls: 0.6344, decode.d5.loss_mask: 0.6411, decode.d5.loss_dice: 0.9516, decode.d6.loss_cls: 0.6278, decode.d6.loss_mask: 0.6424, decode.d6.loss_dice: 0.9513, decode.d7.loss_cls: 0.6194, decode.d7.loss_mask: 0.6430, decode.d7.loss_dice: 0.9564, decode.d8.loss_cls: 0.6158, decode.d8.loss_mask: 0.6431, decode.d8.loss_dice: 0.9543, loss: 31.5565
2022-11-30 01:37:34,768 - mmseg - INFO - Iter [4200/40000]	lr: 1.191e-07, eta: 1 day, 19:34:58, time: 4.118, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5926, decode.loss_mask: 0.6439, decode.loss_dice: 0.9187, decode.d0.loss_cls: 9.4161, decode.d0.loss_mask: 0.6090, decode.d0.loss_dice: 1.0032, decode.d1.loss_cls: 0.7917, decode.d1.loss_mask: 0.6586, decode.d1.loss_dice: 0.9814, decode.d2.loss_cls: 0.6820, decode.d2.loss_mask: 0.6468, decode.d2.loss_dice: 0.9374, decode.d3.loss_cls: 0.6349, decode.d3.loss_mask: 0.6413, decode.d3.loss_dice: 0.9201, decode.d4.loss_cls: 0.6211, decode.d4.loss_mask: 0.6419, decode.d4.loss_dice: 0.9227, decode.d5.loss_cls: 0.6072, decode.d5.loss_mask: 0.6387, decode.d5.loss_dice: 0.9218, decode.d6.loss_cls: 0.5964, decode.d6.loss_mask: 0.6392, decode.d6.loss_dice: 0.9175, decode.d7.loss_cls: 0.5946, decode.d7.loss_mask: 0.6412, decode.d7.loss_dice: 0.9155, decode.d8.loss_cls: 0.5945, decode.d8.loss_mask: 0.6410, decode.d8.loss_dice: 0.9216, loss: 30.8924
2022-11-30 01:41:00,329 - mmseg - INFO - Iter [4250/40000]	lr: 1.189e-07, eta: 1 day, 19:29:24, time: 4.111, data_time: 0.020, memory: 51902, decode.loss_cls: 0.6067, decode.loss_mask: 0.6319, decode.loss_dice: 0.9149, decode.d0.loss_cls: 9.4011, decode.d0.loss_mask: 0.6090, decode.d0.loss_dice: 1.0080, decode.d1.loss_cls: 0.8165, decode.d1.loss_mask: 0.6515, decode.d1.loss_dice: 0.9784, decode.d2.loss_cls: 0.6993, decode.d2.loss_mask: 0.6384, decode.d2.loss_dice: 0.9322, decode.d3.loss_cls: 0.6515, decode.d3.loss_mask: 0.6341, decode.d3.loss_dice: 0.9202, decode.d4.loss_cls: 0.6374, decode.d4.loss_mask: 0.6337, decode.d4.loss_dice: 0.9192, decode.d5.loss_cls: 0.6218, decode.d5.loss_mask: 0.6322, decode.d5.loss_dice: 0.9202, decode.d6.loss_cls: 0.6141, decode.d6.loss_mask: 0.6294, decode.d6.loss_dice: 0.9145, decode.d7.loss_cls: 0.6079, decode.d7.loss_mask: 0.6330, decode.d7.loss_dice: 0.9169, decode.d8.loss_cls: 0.6081, decode.d8.loss_mask: 0.6329, decode.d8.loss_dice: 0.9170, loss: 30.9319
2022-11-30 01:44:25,664 - mmseg - INFO - Iter [4300/40000]	lr: 1.187e-07, eta: 1 day, 19:23:52, time: 4.107, data_time: 0.019, memory: 51902, decode.loss_cls: 0.6083, decode.loss_mask: 0.6422, decode.loss_dice: 0.9213, decode.d0.loss_cls: 9.3853, decode.d0.loss_mask: 0.6051, decode.d0.loss_dice: 1.0010, decode.d1.loss_cls: 0.8071, decode.d1.loss_mask: 0.6576, decode.d1.loss_dice: 0.9713, decode.d2.loss_cls: 0.6919, decode.d2.loss_mask: 0.6484, decode.d2.loss_dice: 0.9359, decode.d3.loss_cls: 0.6423, decode.d3.loss_mask: 0.6449, decode.d3.loss_dice: 0.9248, decode.d4.loss_cls: 0.6279, decode.d4.loss_mask: 0.6395, decode.d4.loss_dice: 0.9288, decode.d5.loss_cls: 0.6182, decode.d5.loss_mask: 0.6376, decode.d5.loss_dice: 0.9226, decode.d6.loss_cls: 0.6122, decode.d6.loss_mask: 0.6408, decode.d6.loss_dice: 0.9188, decode.d7.loss_cls: 0.6051, decode.d7.loss_mask: 0.6409, decode.d7.loss_dice: 0.9199, decode.d8.loss_cls: 0.6098, decode.d8.loss_mask: 0.6387, decode.d8.loss_dice: 0.9195, loss: 30.9676
2022-11-30 01:47:51,633 - mmseg - INFO - Iter [4350/40000]	lr: 1.186e-07, eta: 1 day, 19:18:28, time: 4.119, data_time: 0.019, memory: 51902, decode.loss_cls: 0.6173, decode.loss_mask: 0.6338, decode.loss_dice: 0.9153, decode.d0.loss_cls: 9.3836, decode.d0.loss_mask: 0.6083, decode.d0.loss_dice: 1.0104, decode.d1.loss_cls: 0.8240, decode.d1.loss_mask: 0.6512, decode.d1.loss_dice: 0.9723, decode.d2.loss_cls: 0.7076, decode.d2.loss_mask: 0.6406, decode.d2.loss_dice: 0.9303, decode.d3.loss_cls: 0.6596, decode.d3.loss_mask: 0.6352, decode.d3.loss_dice: 0.9212, decode.d4.loss_cls: 0.6437, decode.d4.loss_mask: 0.6362, decode.d4.loss_dice: 0.9181, decode.d5.loss_cls: 0.6316, decode.d5.loss_mask: 0.6323, decode.d5.loss_dice: 0.9180, decode.d6.loss_cls: 0.6239, decode.d6.loss_mask: 0.6351, decode.d6.loss_dice: 0.9112, decode.d7.loss_cls: 0.6201, decode.d7.loss_mask: 0.6369, decode.d7.loss_dice: 0.9200, decode.d8.loss_cls: 0.6171, decode.d8.loss_mask: 0.6391, decode.d8.loss_dice: 0.9134, loss: 31.0072
2022-11-30 01:51:17,617 - mmseg - INFO - Iter [4400/40000]	lr: 1.184e-07, eta: 1 day, 19:13:07, time: 4.120, data_time: 0.018, memory: 51902, decode.loss_cls: 0.5943, decode.loss_mask: 0.6286, decode.loss_dice: 0.9340, decode.d0.loss_cls: 9.3664, decode.d0.loss_mask: 0.6011, decode.d0.loss_dice: 1.0249, decode.d1.loss_cls: 0.7915, decode.d1.loss_mask: 0.6463, decode.d1.loss_dice: 0.9972, decode.d2.loss_cls: 0.6852, decode.d2.loss_mask: 0.6389, decode.d2.loss_dice: 0.9574, decode.d3.loss_cls: 0.6363, decode.d3.loss_mask: 0.6304, decode.d3.loss_dice: 0.9407, decode.d4.loss_cls: 0.6184, decode.d4.loss_mask: 0.6315, decode.d4.loss_dice: 0.9462, decode.d5.loss_cls: 0.6050, decode.d5.loss_mask: 0.6336, decode.d5.loss_dice: 0.9392, decode.d6.loss_cls: 0.5999, decode.d6.loss_mask: 0.6315, decode.d6.loss_dice: 0.9345, decode.d7.loss_cls: 0.6008, decode.d7.loss_mask: 0.6298, decode.d7.loss_dice: 0.9376, decode.d8.loss_cls: 0.5976, decode.d8.loss_mask: 0.6274, decode.d8.loss_dice: 0.9371, loss: 30.9431
2022-11-30 01:54:45,495 - mmseg - INFO - Iter [4450/40000]	lr: 1.182e-07, eta: 1 day, 19:08:03, time: 4.158, data_time: 0.065, memory: 51902, decode.loss_cls: 0.5864, decode.loss_mask: 0.6151, decode.loss_dice: 0.9080, decode.d0.loss_cls: 9.3531, decode.d0.loss_mask: 0.5848, decode.d0.loss_dice: 0.9924, decode.d1.loss_cls: 0.7859, decode.d1.loss_mask: 0.6297, decode.d1.loss_dice: 0.9685, decode.d2.loss_cls: 0.6808, decode.d2.loss_mask: 0.6177, decode.d2.loss_dice: 0.9287, decode.d3.loss_cls: 0.6275, decode.d3.loss_mask: 0.6161, decode.d3.loss_dice: 0.9142, decode.d4.loss_cls: 0.6134, decode.d4.loss_mask: 0.6159, decode.d4.loss_dice: 0.9107, decode.d5.loss_cls: 0.6048, decode.d5.loss_mask: 0.6126, decode.d5.loss_dice: 0.9089, decode.d6.loss_cls: 0.5929, decode.d6.loss_mask: 0.6133, decode.d6.loss_dice: 0.9036, decode.d7.loss_cls: 0.5926, decode.d7.loss_mask: 0.6144, decode.d7.loss_dice: 0.9060, decode.d8.loss_cls: 0.5883, decode.d8.loss_mask: 0.6139, decode.d8.loss_dice: 0.9074, loss: 30.4073
2022-11-30 01:58:11,209 - mmseg - INFO - Iter [4500/40000]	lr: 1.181e-07, eta: 1 day, 19:02:45, time: 4.114, data_time: 0.017, memory: 51902, decode.loss_cls: 0.5851, decode.loss_mask: 0.6270, decode.loss_dice: 0.9127, decode.d0.loss_cls: 9.3406, decode.d0.loss_mask: 0.5996, decode.d0.loss_dice: 0.9976, decode.d1.loss_cls: 0.7809, decode.d1.loss_mask: 0.6469, decode.d1.loss_dice: 0.9722, decode.d2.loss_cls: 0.6760, decode.d2.loss_mask: 0.6294, decode.d2.loss_dice: 0.9323, decode.d3.loss_cls: 0.6232, decode.d3.loss_mask: 0.6286, decode.d3.loss_dice: 0.9158, decode.d4.loss_cls: 0.6096, decode.d4.loss_mask: 0.6257, decode.d4.loss_dice: 0.9182, decode.d5.loss_cls: 0.5922, decode.d5.loss_mask: 0.6271, decode.d5.loss_dice: 0.9124, decode.d6.loss_cls: 0.5872, decode.d6.loss_mask: 0.6258, decode.d6.loss_dice: 0.9118, decode.d7.loss_cls: 0.5828, decode.d7.loss_mask: 0.6284, decode.d7.loss_dice: 0.9114, decode.d8.loss_cls: 0.5804, decode.d8.loss_mask: 0.6277, decode.d8.loss_dice: 0.9168, loss: 30.5252
2022-11-30 02:01:37,195 - mmseg - INFO - Iter [4550/40000]	lr: 1.179e-07, eta: 1 day, 18:57:31, time: 4.120, data_time: 0.018, memory: 51902, decode.loss_cls: 0.6036, decode.loss_mask: 0.6414, decode.loss_dice: 0.9136, decode.d0.loss_cls: 9.3325, decode.d0.loss_mask: 0.6126, decode.d0.loss_dice: 1.0042, decode.d1.loss_cls: 0.7949, decode.d1.loss_mask: 0.6574, decode.d1.loss_dice: 0.9732, decode.d2.loss_cls: 0.6903, decode.d2.loss_mask: 0.6429, decode.d2.loss_dice: 0.9357, decode.d3.loss_cls: 0.6386, decode.d3.loss_mask: 0.6418, decode.d3.loss_dice: 0.9236, decode.d4.loss_cls: 0.6277, decode.d4.loss_mask: 0.6402, decode.d4.loss_dice: 0.9181, decode.d5.loss_cls: 0.6120, decode.d5.loss_mask: 0.6407, decode.d5.loss_dice: 0.9198, decode.d6.loss_cls: 0.6043, decode.d6.loss_mask: 0.6411, decode.d6.loss_dice: 0.9166, decode.d7.loss_cls: 0.6034, decode.d7.loss_mask: 0.6366, decode.d7.loss_dice: 0.9180, decode.d8.loss_cls: 0.6004, decode.d8.loss_mask: 0.6412, decode.d8.loss_dice: 0.9187, loss: 30.8450
2022-11-30 02:05:02,770 - mmseg - INFO - Iter [4600/40000]	lr: 1.177e-07, eta: 1 day, 18:52:16, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5936, decode.loss_mask: 0.6417, decode.loss_dice: 0.9187, decode.d0.loss_cls: 9.3193, decode.d0.loss_mask: 0.6078, decode.d0.loss_dice: 0.9949, decode.d1.loss_cls: 0.7825, decode.d1.loss_mask: 0.6568, decode.d1.loss_dice: 0.9689, decode.d2.loss_cls: 0.6837, decode.d2.loss_mask: 0.6456, decode.d2.loss_dice: 0.9303, decode.d3.loss_cls: 0.6393, decode.d3.loss_mask: 0.6403, decode.d3.loss_dice: 0.9178, decode.d4.loss_cls: 0.6208, decode.d4.loss_mask: 0.6411, decode.d4.loss_dice: 0.9175, decode.d5.loss_cls: 0.6086, decode.d5.loss_mask: 0.6405, decode.d5.loss_dice: 0.9187, decode.d6.loss_cls: 0.5974, decode.d6.loss_mask: 0.6395, decode.d6.loss_dice: 0.9154, decode.d7.loss_cls: 0.5936, decode.d7.loss_mask: 0.6428, decode.d7.loss_dice: 0.9208, decode.d8.loss_cls: 0.5946, decode.d8.loss_mask: 0.6409, decode.d8.loss_dice: 0.9172, loss: 30.7508
2022-11-30 02:08:28,438 - mmseg - INFO - Iter [4650/40000]	lr: 1.176e-07, eta: 1 day, 18:47:05, time: 4.113, data_time: 0.020, memory: 51902, decode.loss_cls: 0.5907, decode.loss_mask: 0.6215, decode.loss_dice: 0.9152, decode.d0.loss_cls: 9.3109, decode.d0.loss_mask: 0.5967, decode.d0.loss_dice: 1.0042, decode.d1.loss_cls: 0.7828, decode.d1.loss_mask: 0.6372, decode.d1.loss_dice: 0.9795, decode.d2.loss_cls: 0.6800, decode.d2.loss_mask: 0.6209, decode.d2.loss_dice: 0.9307, decode.d3.loss_cls: 0.6350, decode.d3.loss_mask: 0.6218, decode.d3.loss_dice: 0.9150, decode.d4.loss_cls: 0.6167, decode.d4.loss_mask: 0.6185, decode.d4.loss_dice: 0.9174, decode.d5.loss_cls: 0.6089, decode.d5.loss_mask: 0.6163, decode.d5.loss_dice: 0.9162, decode.d6.loss_cls: 0.6000, decode.d6.loss_mask: 0.6178, decode.d6.loss_dice: 0.9109, decode.d7.loss_cls: 0.5963, decode.d7.loss_mask: 0.6208, decode.d7.loss_dice: 0.9153, decode.d8.loss_cls: 0.5874, decode.d8.loss_mask: 0.6209, decode.d8.loss_dice: 0.9148, loss: 30.5202
2022-11-30 02:11:54,288 - mmseg - INFO - Iter [4700/40000]	lr: 1.174e-07, eta: 1 day, 18:41:56, time: 4.117, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5776, decode.loss_mask: 0.6485, decode.loss_dice: 0.9183, decode.d0.loss_cls: 9.2903, decode.d0.loss_mask: 0.6176, decode.d0.loss_dice: 1.0039, decode.d1.loss_cls: 0.7674, decode.d1.loss_mask: 0.6672, decode.d1.loss_dice: 0.9815, decode.d2.loss_cls: 0.6649, decode.d2.loss_mask: 0.6536, decode.d2.loss_dice: 0.9376, decode.d3.loss_cls: 0.6196, decode.d3.loss_mask: 0.6484, decode.d3.loss_dice: 0.9202, decode.d4.loss_cls: 0.6073, decode.d4.loss_mask: 0.6472, decode.d4.loss_dice: 0.9177, decode.d5.loss_cls: 0.5925, decode.d5.loss_mask: 0.6476, decode.d5.loss_dice: 0.9140, decode.d6.loss_cls: 0.5862, decode.d6.loss_mask: 0.6457, decode.d6.loss_dice: 0.9081, decode.d7.loss_cls: 0.5817, decode.d7.loss_mask: 0.6483, decode.d7.loss_dice: 0.9151, decode.d8.loss_cls: 0.5814, decode.d8.loss_mask: 0.6484, decode.d8.loss_dice: 0.9138, loss: 30.6715
2022-11-30 02:15:20,007 - mmseg - INFO - Iter [4750/40000]	lr: 1.172e-07, eta: 1 day, 18:36:50, time: 4.114, data_time: 0.020, memory: 51902, decode.loss_cls: 0.5818, decode.loss_mask: 0.6218, decode.loss_dice: 0.9040, decode.d0.loss_cls: 9.2820, decode.d0.loss_mask: 0.5969, decode.d0.loss_dice: 0.9905, decode.d1.loss_cls: 0.7802, decode.d1.loss_mask: 0.6370, decode.d1.loss_dice: 0.9656, decode.d2.loss_cls: 0.6753, decode.d2.loss_mask: 0.6223, decode.d2.loss_dice: 0.9192, decode.d3.loss_cls: 0.6286, decode.d3.loss_mask: 0.6188, decode.d3.loss_dice: 0.9079, decode.d4.loss_cls: 0.6096, decode.d4.loss_mask: 0.6185, decode.d4.loss_dice: 0.9069, decode.d5.loss_cls: 0.5991, decode.d5.loss_mask: 0.6173, decode.d5.loss_dice: 0.9080, decode.d6.loss_cls: 0.5884, decode.d6.loss_mask: 0.6190, decode.d6.loss_dice: 0.9027, decode.d7.loss_cls: 0.5841, decode.d7.loss_mask: 0.6191, decode.d7.loss_dice: 0.9056, decode.d8.loss_cls: 0.5836, decode.d8.loss_mask: 0.6207, decode.d8.loss_dice: 0.9048, loss: 30.3193
2022-11-30 02:18:45,668 - mmseg - INFO - Iter [4800/40000]	lr: 1.171e-07, eta: 1 day, 18:31:44, time: 4.113, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5768, decode.loss_mask: 0.6097, decode.loss_dice: 0.8980, decode.d0.loss_cls: 9.2711, decode.d0.loss_mask: 0.5860, decode.d0.loss_dice: 0.9859, decode.d1.loss_cls: 0.7635, decode.d1.loss_mask: 0.6284, decode.d1.loss_dice: 0.9548, decode.d2.loss_cls: 0.6597, decode.d2.loss_mask: 0.6173, decode.d2.loss_dice: 0.9175, decode.d3.loss_cls: 0.6189, decode.d3.loss_mask: 0.6092, decode.d3.loss_dice: 0.9046, decode.d4.loss_cls: 0.6007, decode.d4.loss_mask: 0.6082, decode.d4.loss_dice: 0.9008, decode.d5.loss_cls: 0.5883, decode.d5.loss_mask: 0.6085, decode.d5.loss_dice: 0.8984, decode.d6.loss_cls: 0.5808, decode.d6.loss_mask: 0.6087, decode.d6.loss_dice: 0.8972, decode.d7.loss_cls: 0.5750, decode.d7.loss_mask: 0.6081, decode.d7.loss_dice: 0.9017, decode.d8.loss_cls: 0.5786, decode.d8.loss_mask: 0.6088, decode.d8.loss_dice: 0.9010, loss: 30.0661
2022-11-30 02:22:11,400 - mmseg - INFO - Iter [4850/40000]	lr: 1.169e-07, eta: 1 day, 18:26:42, time: 4.115, data_time: 0.020, memory: 51902, decode.loss_cls: 0.5884, decode.loss_mask: 0.6391, decode.loss_dice: 0.9312, decode.d0.loss_cls: 9.2572, decode.d0.loss_mask: 0.6090, decode.d0.loss_dice: 1.0229, decode.d1.loss_cls: 0.7770, decode.d1.loss_mask: 0.6560, decode.d1.loss_dice: 0.9920, decode.d2.loss_cls: 0.6733, decode.d2.loss_mask: 0.6475, decode.d2.loss_dice: 0.9516, decode.d3.loss_cls: 0.6269, decode.d3.loss_mask: 0.6403, decode.d3.loss_dice: 0.9393, decode.d4.loss_cls: 0.6116, decode.d4.loss_mask: 0.6384, decode.d4.loss_dice: 0.9374, decode.d5.loss_cls: 0.5980, decode.d5.loss_mask: 0.6387, decode.d5.loss_dice: 0.9353, decode.d6.loss_cls: 0.5882, decode.d6.loss_mask: 0.6395, decode.d6.loss_dice: 0.9314, decode.d7.loss_cls: 0.5863, decode.d7.loss_mask: 0.6410, decode.d7.loss_dice: 0.9401, decode.d8.loss_cls: 0.5856, decode.d8.loss_mask: 0.6401, decode.d8.loss_dice: 0.9379, loss: 30.8011
2022-11-30 02:25:37,121 - mmseg - INFO - Iter [4900/40000]	lr: 1.167e-07, eta: 1 day, 18:21:41, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5701, decode.loss_mask: 0.6492, decode.loss_dice: 0.9195, decode.d0.loss_cls: 9.2428, decode.d0.loss_mask: 0.6132, decode.d0.loss_dice: 1.0002, decode.d1.loss_cls: 0.7524, decode.d1.loss_mask: 0.6613, decode.d1.loss_dice: 0.9786, decode.d2.loss_cls: 0.6482, decode.d2.loss_mask: 0.6484, decode.d2.loss_dice: 0.9379, decode.d3.loss_cls: 0.6062, decode.d3.loss_mask: 0.6489, decode.d3.loss_dice: 0.9290, decode.d4.loss_cls: 0.5896, decode.d4.loss_mask: 0.6486, decode.d4.loss_dice: 0.9339, decode.d5.loss_cls: 0.5757, decode.d5.loss_mask: 0.6470, decode.d5.loss_dice: 0.9213, decode.d6.loss_cls: 0.5751, decode.d6.loss_mask: 0.6463, decode.d6.loss_dice: 0.9193, decode.d7.loss_cls: 0.5700, decode.d7.loss_mask: 0.6467, decode.d7.loss_dice: 0.9253, decode.d8.loss_cls: 0.5726, decode.d8.loss_mask: 0.6464, decode.d8.loss_dice: 0.9182, loss: 30.5419
2022-11-30 02:29:02,804 - mmseg - INFO - Iter [4950/40000]	lr: 1.166e-07, eta: 1 day, 18:16:42, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5747, decode.loss_mask: 0.6451, decode.loss_dice: 0.9190, decode.d0.loss_cls: 9.2221, decode.d0.loss_mask: 0.6202, decode.d0.loss_dice: 0.9999, decode.d1.loss_cls: 0.7542, decode.d1.loss_mask: 0.6654, decode.d1.loss_dice: 0.9783, decode.d2.loss_cls: 0.6513, decode.d2.loss_mask: 0.6553, decode.d2.loss_dice: 0.9408, decode.d3.loss_cls: 0.6142, decode.d3.loss_mask: 0.6462, decode.d3.loss_dice: 0.9242, decode.d4.loss_cls: 0.5977, decode.d4.loss_mask: 0.6489, decode.d4.loss_dice: 0.9229, decode.d5.loss_cls: 0.5867, decode.d5.loss_mask: 0.6464, decode.d5.loss_dice: 0.9222, decode.d6.loss_cls: 0.5789, decode.d6.loss_mask: 0.6464, decode.d6.loss_dice: 0.9167, decode.d7.loss_cls: 0.5769, decode.d7.loss_mask: 0.6487, decode.d7.loss_dice: 0.9213, decode.d8.loss_cls: 0.5743, decode.d8.loss_mask: 0.6475, decode.d8.loss_dice: 0.9228, loss: 30.5690
2022-11-30 02:32:28,565 - mmseg - INFO - Saving checkpoint at 5000 iterations
2022-11-30 02:33:12,565 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 02:33:12,565 - mmseg - INFO - Iter [5000/40000]	lr: 1.164e-07, eta: 1 day, 18:16:53, time: 4.995, data_time: 0.018, memory: 51902, decode.loss_cls: 0.5717, decode.loss_mask: 0.6272, decode.loss_dice: 0.9175, decode.d0.loss_cls: 9.2153, decode.d0.loss_mask: 0.5914, decode.d0.loss_dice: 0.9984, decode.d1.loss_cls: 0.7613, decode.d1.loss_mask: 0.6398, decode.d1.loss_dice: 0.9773, decode.d2.loss_cls: 0.6658, decode.d2.loss_mask: 0.6324, decode.d2.loss_dice: 0.9387, decode.d3.loss_cls: 0.6171, decode.d3.loss_mask: 0.6249, decode.d3.loss_dice: 0.9277, decode.d4.loss_cls: 0.6014, decode.d4.loss_mask: 0.6262, decode.d4.loss_dice: 0.9227, decode.d5.loss_cls: 0.5812, decode.d5.loss_mask: 0.6262, decode.d5.loss_dice: 0.9221, decode.d6.loss_cls: 0.5784, decode.d6.loss_mask: 0.6250, decode.d6.loss_dice: 0.9191, decode.d7.loss_cls: 0.5733, decode.d7.loss_mask: 0.6244, decode.d7.loss_dice: 0.9238, decode.d8.loss_cls: 0.5704, decode.d8.loss_mask: 0.6252, decode.d8.loss_dice: 0.9200, loss: 30.3457
2022-11-30 02:36:10,685 - mmseg - INFO - per class results:
2022-11-30 02:36:10,690 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 82.22 | 88.06 |
|       building      | 84.37 |  92.0 |
|         sky         | 95.07 | 97.49 |
|        floor        | 85.13 | 90.32 |
|         tree        | 78.01 | 89.95 |
|       ceiling       | 87.54 | 93.38 |
|         road        | 87.26 | 92.75 |
|         bed         | 92.84 | 96.03 |
|      windowpane     |  66.9 | 82.77 |
|        grass        | 69.39 | 80.75 |
|       cabinet       | 64.57 | 80.99 |
|       sidewalk      | 72.02 |  84.1 |
|        person       | 88.06 | 93.94 |
|        earth        | 42.76 | 60.69 |
|         door        | 60.31 | 79.93 |
|        table        | 69.68 | 79.33 |
|       mountain      | 62.21 | 71.07 |
|        plant        | 56.73 | 69.07 |
|       curtain       | 80.88 | 89.76 |
|        chair        | 64.78 | 76.48 |
|         car         | 88.72 | 93.33 |
|        water        | 56.84 | 70.61 |
|       painting      | 81.76 | 91.59 |
|         sofa        | 84.73 | 91.04 |
|        shelf        | 46.37 | 59.81 |
|        house        | 47.58 | 62.55 |
|         sea         | 72.21 | 89.32 |
|        mirror       | 80.11 | 93.46 |
|         rug         | 71.25 | 85.61 |
|        field        | 31.43 | 61.82 |
|       armchair      | 57.37 | 79.81 |
|         seat        |  68.4 | 89.44 |
|        fence        | 55.35 | 67.87 |
|         desk        | 54.11 | 74.83 |
|         rock        | 67.67 | 83.64 |
|       wardrobe      | 57.78 | 73.12 |
|         lamp        | 77.25 | 87.32 |
|       bathtub       | 90.39 | 94.19 |
|       railing       | 45.69 | 68.72 |
|       cushion       | 76.13 | 89.89 |
|         base        | 37.07 | 66.25 |
|         box         | 39.24 | 54.15 |
|        column       |  62.8 | 86.99 |
|      signboard      | 44.47 | 68.46 |
|   chest of drawers  | 37.34 | 60.06 |
|       counter       | 52.94 | 73.41 |
|         sand        | 63.46 | 87.49 |
|         sink        | 82.34 | 86.28 |
|      skyscraper     | 40.14 | 46.66 |
|      fireplace      | 73.03 | 97.17 |
|     refrigerator    | 81.83 | 90.29 |
|      grandstand     | 44.84 | 78.69 |
|         path        | 21.51 | 25.56 |
|        stairs       | 36.39 | 43.84 |
|        runway       | 74.82 | 95.13 |
|         case        | 71.15 | 82.51 |
|      pool table     | 94.88 | 98.78 |
|        pillow       |  71.6 | 82.74 |
|     screen door     | 80.37 | 84.67 |
|       stairway      |  50.0 | 75.34 |
|        river        | 21.91 | 40.41 |
|        bridge       | 83.17 |  89.7 |
|       bookcase      |  31.1 | 52.47 |
|        blind        | 37.15 | 43.44 |
|     coffee table    | 67.57 | 91.67 |
|        toilet       | 92.52 | 97.05 |
|        flower       | 40.19 | 64.41 |
|         book        | 56.18 |  85.3 |
|         hill        | 11.62 |  28.2 |
|        bench        | 67.15 | 87.22 |
|      countertop     | 62.99 | 86.02 |
|        stove        | 85.08 | 89.67 |
|         palm        |  56.9 | 79.68 |
|    kitchen island   | 40.39 | 81.67 |
|       computer      | 81.75 | 90.53 |
|     swivel chair    | 55.44 | 80.84 |
|         boat        | 60.64 | 91.68 |
|         bar         | 58.79 | 61.97 |
|    arcade machine   | 91.36 | 98.33 |
|        hovel        |  6.72 |  7.26 |
|         bus         | 93.47 | 96.03 |
|        towel        | 78.54 | 94.94 |
|        light        | 62.47 | 81.34 |
|        truck        | 53.59 | 72.94 |
|        tower        | 30.84 | 62.53 |
|      chandelier     | 71.32 | 90.41 |
|        awning       | 29.96 | 52.65 |
|     streetlight     | 42.08 | 58.72 |
|        booth        |  9.53 |  9.54 |
| television receiver | 72.11 | 91.57 |
|       airplane      | 90.82 | 95.51 |
|      dirt track     |  0.0  |  0.0  |
|       apparel       | 53.08 | 92.99 |
|         pole        | 37.06 | 63.74 |
|         land        |  0.01 |  0.01 |
|      bannister      | 14.71 | 29.03 |
|      escalator      | 62.01 | 77.66 |
|       ottoman       | 50.54 | 81.54 |
|        bottle       | 53.42 | 73.26 |
|        buffet       |  0.0  |  0.0  |
|        poster       | 34.71 | 53.88 |
|        stage        | 13.81 | 25.98 |
|         van         | 46.28 | 82.35 |
|         ship        |  4.01 |  4.12 |
|       fountain      |  27.0 |  27.4 |
|    conveyer belt    | 83.38 | 96.96 |
|        canopy       | 40.02 | 52.21 |
|        washer       | 85.02 | 85.44 |
|      plaything      | 34.09 | 52.95 |
|    swimming pool    | 42.74 | 75.53 |
|        stool        | 51.52 | 87.41 |
|        barrel       | 57.55 | 64.42 |
|        basket       | 41.15 | 71.39 |
|      waterfall      | 62.78 | 79.01 |
|         tent        | 94.13 | 97.82 |
|         bag         | 35.04 | 50.17 |
|       minibike      | 81.33 | 93.28 |
|        cradle       | 89.22 | 95.02 |
|         oven        | 64.62 | 82.09 |
|         ball        | 66.53 | 83.09 |
|         food        | 62.79 | 80.87 |
|         step        | 25.03 | 33.81 |
|         tank        | 23.25 | 23.29 |
|      trade name     | 33.29 |  42.9 |
|      microwave      | 89.08 | 94.46 |
|         pot         | 53.66 | 66.64 |
|        animal       | 86.79 | 89.96 |
|       bicycle       | 59.73 | 85.13 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 75.69 | 92.21 |
|        screen       | 59.21 | 93.36 |
|       blanket       | 39.68 | 65.21 |
|      sculpture      | 70.17 | 90.46 |
|         hood        | 64.03 | 80.87 |
|        sconce       | 63.89 | 81.57 |
|         vase        | 55.48 |  81.2 |
|    traffic light    | 49.58 | 72.37 |
|         tray        |  22.1 | 38.56 |
|        ashcan       | 44.53 | 70.69 |
|         fan         | 71.01 | 84.09 |
|         pier        | 45.29 | 47.57 |
|      crt screen     |  5.93 |  14.4 |
|        plate        | 67.79 | 83.84 |
|       monitor       | 10.49 | 11.71 |
|    bulletin board   | 57.88 | 66.43 |
|        shower       | 23.11 | 29.31 |
|       radiator      | 67.53 | 88.32 |
|        glass        | 28.88 | 33.76 |
|        clock        |  59.9 | 71.88 |
|         flag        | 68.54 | 86.97 |
+---------------------+-------+-------+
2022-11-30 02:36:10,690 - mmseg - INFO - Summary:
2022-11-30 02:36:10,690 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 86.05 | 56.77 | 71.44 |
+-------+-------+-------+
2022-11-30 02:36:10,694 - mmseg - INFO - The previous best checkpoint /mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune/lr1.0_lrd0.9/best_mIoU_iter_4000.pth was removed
2022-11-30 02:36:54,054 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_5000.pth.
2022-11-30 02:36:54,054 - mmseg - INFO - Best mIoU is 0.5677 at 5000 iter.
2022-11-30 02:36:54,063 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 02:36:54,063 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8605, mIoU: 0.5677, mAcc: 0.7144, IoU.wall: 0.8222, IoU.building: 0.8437, IoU.sky: 0.9507, IoU.floor: 0.8513, IoU.tree: 0.7801, IoU.ceiling: 0.8754, IoU.road: 0.8726, IoU.bed : 0.9284, IoU.windowpane: 0.6690, IoU.grass: 0.6939, IoU.cabinet: 0.6457, IoU.sidewalk: 0.7202, IoU.person: 0.8806, IoU.earth: 0.4276, IoU.door: 0.6031, IoU.table: 0.6968, IoU.mountain: 0.6221, IoU.plant: 0.5673, IoU.curtain: 0.8088, IoU.chair: 0.6478, IoU.car: 0.8872, IoU.water: 0.5684, IoU.painting: 0.8176, IoU.sofa: 0.8473, IoU.shelf: 0.4637, IoU.house: 0.4758, IoU.sea: 0.7221, IoU.mirror: 0.8011, IoU.rug: 0.7125, IoU.field: 0.3143, IoU.armchair: 0.5737, IoU.seat: 0.6840, IoU.fence: 0.5535, IoU.desk: 0.5411, IoU.rock: 0.6767, IoU.wardrobe: 0.5778, IoU.lamp: 0.7725, IoU.bathtub: 0.9039, IoU.railing: 0.4569, IoU.cushion: 0.7613, IoU.base: 0.3707, IoU.box: 0.3924, IoU.column: 0.6280, IoU.signboard: 0.4447, IoU.chest of drawers: 0.3734, IoU.counter: 0.5294, IoU.sand: 0.6346, IoU.sink: 0.8234, IoU.skyscraper: 0.4014, IoU.fireplace: 0.7303, IoU.refrigerator: 0.8183, IoU.grandstand: 0.4484, IoU.path: 0.2151, IoU.stairs: 0.3639, IoU.runway: 0.7482, IoU.case: 0.7115, IoU.pool table: 0.9488, IoU.pillow: 0.7160, IoU.screen door: 0.8037, IoU.stairway: 0.5000, IoU.river: 0.2191, IoU.bridge: 0.8317, IoU.bookcase: 0.3110, IoU.blind: 0.3715, IoU.coffee table: 0.6757, IoU.toilet: 0.9252, IoU.flower: 0.4019, IoU.book: 0.5618, IoU.hill: 0.1162, IoU.bench: 0.6715, IoU.countertop: 0.6299, IoU.stove: 0.8508, IoU.palm: 0.5690, IoU.kitchen island: 0.4039, IoU.computer: 0.8175, IoU.swivel chair: 0.5544, IoU.boat: 0.6064, IoU.bar: 0.5879, IoU.arcade machine: 0.9136, IoU.hovel: 0.0672, IoU.bus: 0.9347, IoU.towel: 0.7854, IoU.light: 0.6247, IoU.truck: 0.5359, IoU.tower: 0.3084, IoU.chandelier: 0.7132, IoU.awning: 0.2996, IoU.streetlight: 0.4208, IoU.booth: 0.0953, IoU.television receiver: 0.7211, IoU.airplane: 0.9082, IoU.dirt track: 0.0000, IoU.apparel: 0.5308, IoU.pole: 0.3706, IoU.land: 0.0001, IoU.bannister: 0.1471, IoU.escalator: 0.6201, IoU.ottoman: 0.5054, IoU.bottle: 0.5342, IoU.buffet: 0.0000, IoU.poster: 0.3471, IoU.stage: 0.1381, IoU.van: 0.4628, IoU.ship: 0.0401, IoU.fountain: 0.2700, IoU.conveyer belt: 0.8338, IoU.canopy: 0.4002, IoU.washer: 0.8502, IoU.plaything: 0.3409, IoU.swimming pool: 0.4274, IoU.stool: 0.5152, IoU.barrel: 0.5755, IoU.basket: 0.4115, IoU.waterfall: 0.6278, IoU.tent: 0.9413, IoU.bag: 0.3504, IoU.minibike: 0.8133, IoU.cradle: 0.8922, IoU.oven: 0.6462, IoU.ball: 0.6653, IoU.food: 0.6279, IoU.step: 0.2503, IoU.tank: 0.2325, IoU.trade name: 0.3329, IoU.microwave: 0.8908, IoU.pot: 0.5366, IoU.animal: 0.8679, IoU.bicycle: 0.5973, IoU.lake: 0.0000, IoU.dishwasher: 0.7569, IoU.screen: 0.5921, IoU.blanket: 0.3968, IoU.sculpture: 0.7017, IoU.hood: 0.6403, IoU.sconce: 0.6389, IoU.vase: 0.5548, IoU.traffic light: 0.4958, IoU.tray: 0.2210, IoU.ashcan: 0.4453, IoU.fan: 0.7101, IoU.pier: 0.4529, IoU.crt screen: 0.0593, IoU.plate: 0.6779, IoU.monitor: 0.1049, IoU.bulletin board: 0.5788, IoU.shower: 0.2311, IoU.radiator: 0.6753, IoU.glass: 0.2888, IoU.clock: 0.5990, IoU.flag: 0.6854, Acc.wall: 0.8806, Acc.building: 0.9200, Acc.sky: 0.9749, Acc.floor: 0.9032, Acc.tree: 0.8995, Acc.ceiling: 0.9338, Acc.road: 0.9275, Acc.bed : 0.9603, Acc.windowpane: 0.8277, Acc.grass: 0.8075, Acc.cabinet: 0.8099, Acc.sidewalk: 0.8410, Acc.person: 0.9394, Acc.earth: 0.6069, Acc.door: 0.7993, Acc.table: 0.7933, Acc.mountain: 0.7107, Acc.plant: 0.6907, Acc.curtain: 0.8976, Acc.chair: 0.7648, Acc.car: 0.9333, Acc.water: 0.7061, Acc.painting: 0.9159, Acc.sofa: 0.9104, Acc.shelf: 0.5981, Acc.house: 0.6255, Acc.sea: 0.8932, Acc.mirror: 0.9346, Acc.rug: 0.8561, Acc.field: 0.6182, Acc.armchair: 0.7981, Acc.seat: 0.8944, Acc.fence: 0.6787, Acc.desk: 0.7483, Acc.rock: 0.8364, Acc.wardrobe: 0.7312, Acc.lamp: 0.8732, Acc.bathtub: 0.9419, Acc.railing: 0.6872, Acc.cushion: 0.8989, Acc.base: 0.6625, Acc.box: 0.5415, Acc.column: 0.8699, Acc.signboard: 0.6846, Acc.chest of drawers: 0.6006, Acc.counter: 0.7341, Acc.sand: 0.8749, Acc.sink: 0.8628, Acc.skyscraper: 0.4666, Acc.fireplace: 0.9717, Acc.refrigerator: 0.9029, Acc.grandstand: 0.7869, Acc.path: 0.2556, Acc.stairs: 0.4384, Acc.runway: 0.9513, Acc.case: 0.8251, Acc.pool table: 0.9878, Acc.pillow: 0.8274, Acc.screen door: 0.8467, Acc.stairway: 0.7534, Acc.river: 0.4041, Acc.bridge: 0.8970, Acc.bookcase: 0.5247, Acc.blind: 0.4344, Acc.coffee table: 0.9167, Acc.toilet: 0.9705, Acc.flower: 0.6441, Acc.book: 0.8530, Acc.hill: 0.2820, Acc.bench: 0.8722, Acc.countertop: 0.8602, Acc.stove: 0.8967, Acc.palm: 0.7968, Acc.kitchen island: 0.8167, Acc.computer: 0.9053, Acc.swivel chair: 0.8084, Acc.boat: 0.9168, Acc.bar: 0.6197, Acc.arcade machine: 0.9833, Acc.hovel: 0.0726, Acc.bus: 0.9603, Acc.towel: 0.9494, Acc.light: 0.8134, Acc.truck: 0.7294, Acc.tower: 0.6253, Acc.chandelier: 0.9041, Acc.awning: 0.5265, Acc.streetlight: 0.5872, Acc.booth: 0.0954, Acc.television receiver: 0.9157, Acc.airplane: 0.9551, Acc.dirt track: 0.0000, Acc.apparel: 0.9299, Acc.pole: 0.6374, Acc.land: 0.0001, Acc.bannister: 0.2903, Acc.escalator: 0.7766, Acc.ottoman: 0.8154, Acc.bottle: 0.7326, Acc.buffet: 0.0000, Acc.poster: 0.5388, Acc.stage: 0.2598, Acc.van: 0.8235, Acc.ship: 0.0412, Acc.fountain: 0.2740, Acc.conveyer belt: 0.9696, Acc.canopy: 0.5221, Acc.washer: 0.8544, Acc.plaything: 0.5295, Acc.swimming pool: 0.7553, Acc.stool: 0.8741, Acc.barrel: 0.6442, Acc.basket: 0.7139, Acc.waterfall: 0.7901, Acc.tent: 0.9782, Acc.bag: 0.5017, Acc.minibike: 0.9328, Acc.cradle: 0.9502, Acc.oven: 0.8209, Acc.ball: 0.8309, Acc.food: 0.8087, Acc.step: 0.3381, Acc.tank: 0.2329, Acc.trade name: 0.4290, Acc.microwave: 0.9446, Acc.pot: 0.6664, Acc.animal: 0.8996, Acc.bicycle: 0.8513, Acc.lake: 0.0000, Acc.dishwasher: 0.9221, Acc.screen: 0.9336, Acc.blanket: 0.6521, Acc.sculpture: 0.9046, Acc.hood: 0.8087, Acc.sconce: 0.8157, Acc.vase: 0.8120, Acc.traffic light: 0.7237, Acc.tray: 0.3856, Acc.ashcan: 0.7069, Acc.fan: 0.8409, Acc.pier: 0.4757, Acc.crt screen: 0.1440, Acc.plate: 0.8384, Acc.monitor: 0.1171, Acc.bulletin board: 0.6643, Acc.shower: 0.2931, Acc.radiator: 0.8832, Acc.glass: 0.3376, Acc.clock: 0.7188, Acc.flag: 0.8697
2022-11-30 02:40:19,792 - mmseg - INFO - Iter [5050/40000]	lr: 1.162e-07, eta: 1 day, 18:37:28, time: 8.545, data_time: 4.448, memory: 51902, decode.loss_cls: 0.5659, decode.loss_mask: 0.6462, decode.loss_dice: 0.9176, decode.d0.loss_cls: 9.2015, decode.d0.loss_mask: 0.6167, decode.d0.loss_dice: 0.9937, decode.d1.loss_cls: 0.7311, decode.d1.loss_mask: 0.6669, decode.d1.loss_dice: 0.9811, decode.d2.loss_cls: 0.6425, decode.d2.loss_mask: 0.6509, decode.d2.loss_dice: 0.9385, decode.d3.loss_cls: 0.6003, decode.d3.loss_mask: 0.6463, decode.d3.loss_dice: 0.9262, decode.d4.loss_cls: 0.5838, decode.d4.loss_mask: 0.6468, decode.d4.loss_dice: 0.9243, decode.d5.loss_cls: 0.5718, decode.d5.loss_mask: 0.6460, decode.d5.loss_dice: 0.9215, decode.d6.loss_cls: 0.5675, decode.d6.loss_mask: 0.6471, decode.d6.loss_dice: 0.9161, decode.d7.loss_cls: 0.5633, decode.d7.loss_mask: 0.6452, decode.d7.loss_dice: 0.9172, decode.d8.loss_cls: 0.5614, decode.d8.loss_mask: 0.6431, decode.d8.loss_dice: 0.9182, loss: 30.3985
2022-11-30 02:43:47,661 - mmseg - INFO - Iter [5100/40000]	lr: 1.161e-07, eta: 1 day, 18:32:28, time: 4.157, data_time: 0.063, memory: 51902, decode.loss_cls: 0.5817, decode.loss_mask: 0.6110, decode.loss_dice: 0.9087, decode.d0.loss_cls: 9.1977, decode.d0.loss_mask: 0.5832, decode.d0.loss_dice: 0.9948, decode.d1.loss_cls: 0.7677, decode.d1.loss_mask: 0.6329, decode.d1.loss_dice: 0.9744, decode.d2.loss_cls: 0.6644, decode.d2.loss_mask: 0.6203, decode.d2.loss_dice: 0.9255, decode.d3.loss_cls: 0.6194, decode.d3.loss_mask: 0.6128, decode.d3.loss_dice: 0.9176, decode.d4.loss_cls: 0.6090, decode.d4.loss_mask: 0.6107, decode.d4.loss_dice: 0.9099, decode.d5.loss_cls: 0.5910, decode.d5.loss_mask: 0.6094, decode.d5.loss_dice: 0.9118, decode.d6.loss_cls: 0.5848, decode.d6.loss_mask: 0.6092, decode.d6.loss_dice: 0.9094, decode.d7.loss_cls: 0.5835, decode.d7.loss_mask: 0.6092, decode.d7.loss_dice: 0.9100, decode.d8.loss_cls: 0.5820, decode.d8.loss_mask: 0.6113, decode.d8.loss_dice: 0.9090, loss: 30.1623
2022-11-30 02:47:13,768 - mmseg - INFO - Iter [5150/40000]	lr: 1.159e-07, eta: 1 day, 18:27:19, time: 4.122, data_time: 0.018, memory: 51902, decode.loss_cls: 0.5557, decode.loss_mask: 0.6088, decode.loss_dice: 0.9128, decode.d0.loss_cls: 9.1843, decode.d0.loss_mask: 0.5769, decode.d0.loss_dice: 0.9878, decode.d1.loss_cls: 0.7503, decode.d1.loss_mask: 0.6197, decode.d1.loss_dice: 0.9753, decode.d2.loss_cls: 0.6432, decode.d2.loss_mask: 0.6119, decode.d2.loss_dice: 0.9319, decode.d3.loss_cls: 0.5964, decode.d3.loss_mask: 0.6064, decode.d3.loss_dice: 0.9185, decode.d4.loss_cls: 0.5837, decode.d4.loss_mask: 0.6035, decode.d4.loss_dice: 0.9161, decode.d5.loss_cls: 0.5671, decode.d5.loss_mask: 0.6078, decode.d5.loss_dice: 0.9104, decode.d6.loss_cls: 0.5647, decode.d6.loss_mask: 0.6070, decode.d6.loss_dice: 0.9058, decode.d7.loss_cls: 0.5581, decode.d7.loss_mask: 0.6082, decode.d7.loss_dice: 0.9164, decode.d8.loss_cls: 0.5577, decode.d8.loss_mask: 0.6067, decode.d8.loss_dice: 0.9096, loss: 29.9030
2022-11-30 02:50:39,539 - mmseg - INFO - Iter [5200/40000]	lr: 1.157e-07, eta: 1 day, 18:22:09, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5406, decode.loss_mask: 0.6335, decode.loss_dice: 0.8911, decode.d0.loss_cls: 9.1651, decode.d0.loss_mask: 0.6018, decode.d0.loss_dice: 0.9730, decode.d1.loss_cls: 0.7147, decode.d1.loss_mask: 0.6505, decode.d1.loss_dice: 0.9575, decode.d2.loss_cls: 0.6243, decode.d2.loss_mask: 0.6383, decode.d2.loss_dice: 0.9139, decode.d3.loss_cls: 0.5767, decode.d3.loss_mask: 0.6331, decode.d3.loss_dice: 0.9009, decode.d4.loss_cls: 0.5644, decode.d4.loss_mask: 0.6317, decode.d4.loss_dice: 0.8966, decode.d5.loss_cls: 0.5498, decode.d5.loss_mask: 0.6307, decode.d5.loss_dice: 0.8935, decode.d6.loss_cls: 0.5413, decode.d6.loss_mask: 0.6301, decode.d6.loss_dice: 0.8935, decode.d7.loss_cls: 0.5427, decode.d7.loss_mask: 0.6343, decode.d7.loss_dice: 0.8956, decode.d8.loss_cls: 0.5371, decode.d8.loss_mask: 0.6361, decode.d8.loss_dice: 0.8937, loss: 29.7861
2022-11-30 02:54:04,892 - mmseg - INFO - Iter [5250/40000]	lr: 1.156e-07, eta: 1 day, 18:16:59, time: 4.107, data_time: 0.020, memory: 51902, decode.loss_cls: 0.5619, decode.loss_mask: 0.6345, decode.loss_dice: 0.9244, decode.d0.loss_cls: 9.1578, decode.d0.loss_mask: 0.6040, decode.d0.loss_dice: 0.9939, decode.d1.loss_cls: 0.7480, decode.d1.loss_mask: 0.6506, decode.d1.loss_dice: 0.9767, decode.d2.loss_cls: 0.6438, decode.d2.loss_mask: 0.6394, decode.d2.loss_dice: 0.9399, decode.d3.loss_cls: 0.5945, decode.d3.loss_mask: 0.6369, decode.d3.loss_dice: 0.9284, decode.d4.loss_cls: 0.5840, decode.d4.loss_mask: 0.6361, decode.d4.loss_dice: 0.9295, decode.d5.loss_cls: 0.5711, decode.d5.loss_mask: 0.6353, decode.d5.loss_dice: 0.9263, decode.d6.loss_cls: 0.5655, decode.d6.loss_mask: 0.6356, decode.d6.loss_dice: 0.9215, decode.d7.loss_cls: 0.5613, decode.d7.loss_mask: 0.6381, decode.d7.loss_dice: 0.9215, decode.d8.loss_cls: 0.5607, decode.d8.loss_mask: 0.6380, decode.d8.loss_dice: 0.9229, loss: 30.2823
2022-11-30 02:57:30,668 - mmseg - INFO - Iter [5300/40000]	lr: 1.154e-07, eta: 1 day, 18:11:53, time: 4.116, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5534, decode.loss_mask: 0.6152, decode.loss_dice: 0.9004, decode.d0.loss_cls: 9.1445, decode.d0.loss_mask: 0.5808, decode.d0.loss_dice: 0.9792, decode.d1.loss_cls: 0.7345, decode.d1.loss_mask: 0.6333, decode.d1.loss_dice: 0.9630, decode.d2.loss_cls: 0.6310, decode.d2.loss_mask: 0.6262, decode.d2.loss_dice: 0.9207, decode.d3.loss_cls: 0.5859, decode.d3.loss_mask: 0.6153, decode.d3.loss_dice: 0.9129, decode.d4.loss_cls: 0.5724, decode.d4.loss_mask: 0.6160, decode.d4.loss_dice: 0.9097, decode.d5.loss_cls: 0.5638, decode.d5.loss_mask: 0.6151, decode.d5.loss_dice: 0.9000, decode.d6.loss_cls: 0.5604, decode.d6.loss_mask: 0.6133, decode.d6.loss_dice: 0.9003, decode.d7.loss_cls: 0.5535, decode.d7.loss_mask: 0.6130, decode.d7.loss_dice: 0.9076, decode.d8.loss_cls: 0.5531, decode.d8.loss_mask: 0.6145, decode.d8.loss_dice: 0.9065, loss: 29.7954
2022-11-30 03:00:56,631 - mmseg - INFO - Iter [5350/40000]	lr: 1.152e-07, eta: 1 day, 18:06:50, time: 4.119, data_time: 0.020, memory: 51902, decode.loss_cls: 0.5713, decode.loss_mask: 0.6362, decode.loss_dice: 0.9250, decode.d0.loss_cls: 9.1355, decode.d0.loss_mask: 0.6041, decode.d0.loss_dice: 1.0036, decode.d1.loss_cls: 0.7550, decode.d1.loss_mask: 0.6542, decode.d1.loss_dice: 0.9807, decode.d2.loss_cls: 0.6551, decode.d2.loss_mask: 0.6407, decode.d2.loss_dice: 0.9394, decode.d3.loss_cls: 0.6070, decode.d3.loss_mask: 0.6391, decode.d3.loss_dice: 0.9353, decode.d4.loss_cls: 0.5896, decode.d4.loss_mask: 0.6377, decode.d4.loss_dice: 0.9326, decode.d5.loss_cls: 0.5854, decode.d5.loss_mask: 0.6340, decode.d5.loss_dice: 0.9258, decode.d6.loss_cls: 0.5750, decode.d6.loss_mask: 0.6331, decode.d6.loss_dice: 0.9238, decode.d7.loss_cls: 0.5766, decode.d7.loss_mask: 0.6365, decode.d7.loss_dice: 0.9259, decode.d8.loss_cls: 0.5753, decode.d8.loss_mask: 0.6336, decode.d8.loss_dice: 0.9275, loss: 30.3948
2022-11-30 03:04:21,726 - mmseg - INFO - Iter [5400/40000]	lr: 1.151e-07, eta: 1 day, 18:01:44, time: 4.102, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5583, decode.loss_mask: 0.6444, decode.loss_dice: 0.9264, decode.d0.loss_cls: 9.1213, decode.d0.loss_mask: 0.6047, decode.d0.loss_dice: 0.9986, decode.d1.loss_cls: 0.7373, decode.d1.loss_mask: 0.6561, decode.d1.loss_dice: 0.9784, decode.d2.loss_cls: 0.6365, decode.d2.loss_mask: 0.6440, decode.d2.loss_dice: 0.9441, decode.d3.loss_cls: 0.5962, decode.d3.loss_mask: 0.6405, decode.d3.loss_dice: 0.9306, decode.d4.loss_cls: 0.5805, decode.d4.loss_mask: 0.6434, decode.d4.loss_dice: 0.9300, decode.d5.loss_cls: 0.5664, decode.d5.loss_mask: 0.6411, decode.d5.loss_dice: 0.9257, decode.d6.loss_cls: 0.5651, decode.d6.loss_mask: 0.6420, decode.d6.loss_dice: 0.9222, decode.d7.loss_cls: 0.5590, decode.d7.loss_mask: 0.6415, decode.d7.loss_dice: 0.9235, decode.d8.loss_cls: 0.5565, decode.d8.loss_mask: 0.6426, decode.d8.loss_dice: 0.9240, loss: 30.2808
2022-11-30 03:07:47,587 - mmseg - INFO - Iter [5450/40000]	lr: 1.149e-07, eta: 1 day, 17:56:44, time: 4.117, data_time: 0.018, memory: 51902, decode.loss_cls: 0.5671, decode.loss_mask: 0.6296, decode.loss_dice: 0.8984, decode.d0.loss_cls: 9.1215, decode.d0.loss_mask: 0.5997, decode.d0.loss_dice: 0.9833, decode.d1.loss_cls: 0.7582, decode.d1.loss_mask: 0.6526, decode.d1.loss_dice: 0.9656, decode.d2.loss_cls: 0.6591, decode.d2.loss_mask: 0.6347, decode.d2.loss_dice: 0.9190, decode.d3.loss_cls: 0.6100, decode.d3.loss_mask: 0.6308, decode.d3.loss_dice: 0.9089, decode.d4.loss_cls: 0.5942, decode.d4.loss_mask: 0.6284, decode.d4.loss_dice: 0.9086, decode.d5.loss_cls: 0.5813, decode.d5.loss_mask: 0.6291, decode.d5.loss_dice: 0.9059, decode.d6.loss_cls: 0.5732, decode.d6.loss_mask: 0.6293, decode.d6.loss_dice: 0.8983, decode.d7.loss_cls: 0.5693, decode.d7.loss_mask: 0.6275, decode.d7.loss_dice: 0.9051, decode.d8.loss_cls: 0.5687, decode.d8.loss_mask: 0.6274, decode.d8.loss_dice: 0.8988, loss: 30.0835
2022-11-30 03:11:13,151 - mmseg - INFO - Iter [5500/40000]	lr: 1.147e-07, eta: 1 day, 17:51:44, time: 4.111, data_time: 0.018, memory: 51902, decode.loss_cls: 0.5815, decode.loss_mask: 0.6396, decode.loss_dice: 0.9260, decode.d0.loss_cls: 9.0918, decode.d0.loss_mask: 0.6113, decode.d0.loss_dice: 1.0085, decode.d1.loss_cls: 0.7609, decode.d1.loss_mask: 0.6536, decode.d1.loss_dice: 0.9987, decode.d2.loss_cls: 0.6684, decode.d2.loss_mask: 0.6445, decode.d2.loss_dice: 0.9485, decode.d3.loss_cls: 0.6155, decode.d3.loss_mask: 0.6408, decode.d3.loss_dice: 0.9343, decode.d4.loss_cls: 0.6029, decode.d4.loss_mask: 0.6388, decode.d4.loss_dice: 0.9354, decode.d5.loss_cls: 0.5929, decode.d5.loss_mask: 0.6362, decode.d5.loss_dice: 0.9305, decode.d6.loss_cls: 0.5836, decode.d6.loss_mask: 0.6369, decode.d6.loss_dice: 0.9295, decode.d7.loss_cls: 0.5798, decode.d7.loss_mask: 0.6388, decode.d7.loss_dice: 0.9294, decode.d8.loss_cls: 0.5821, decode.d8.loss_mask: 0.6375, decode.d8.loss_dice: 0.9269, loss: 30.5051
2022-11-30 03:14:38,738 - mmseg - INFO - Iter [5550/40000]	lr: 1.146e-07, eta: 1 day, 17:46:46, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5707, decode.loss_mask: 0.6069, decode.loss_dice: 0.9034, decode.d0.loss_cls: 9.0830, decode.d0.loss_mask: 0.5808, decode.d0.loss_dice: 0.9843, decode.d1.loss_cls: 0.7534, decode.d1.loss_mask: 0.6302, decode.d1.loss_dice: 0.9585, decode.d2.loss_cls: 0.6562, decode.d2.loss_mask: 0.6159, decode.d2.loss_dice: 0.9190, decode.d3.loss_cls: 0.6043, decode.d3.loss_mask: 0.6089, decode.d3.loss_dice: 0.9006, decode.d4.loss_cls: 0.5923, decode.d4.loss_mask: 0.6061, decode.d4.loss_dice: 0.9015, decode.d5.loss_cls: 0.5840, decode.d5.loss_mask: 0.6044, decode.d5.loss_dice: 0.8988, decode.d6.loss_cls: 0.5748, decode.d6.loss_mask: 0.6055, decode.d6.loss_dice: 0.8987, decode.d7.loss_cls: 0.5734, decode.d7.loss_mask: 0.6073, decode.d7.loss_dice: 0.8992, decode.d8.loss_cls: 0.5698, decode.d8.loss_mask: 0.6095, decode.d8.loss_dice: 0.9012, loss: 29.8025
2022-11-30 03:18:04,124 - mmseg - INFO - Iter [5600/40000]	lr: 1.144e-07, eta: 1 day, 17:41:49, time: 4.108, data_time: 0.018, memory: 51902, decode.loss_cls: 0.5535, decode.loss_mask: 0.6519, decode.loss_dice: 0.9137, decode.d0.loss_cls: 9.0636, decode.d0.loss_mask: 0.6200, decode.d0.loss_dice: 0.9883, decode.d1.loss_cls: 0.7252, decode.d1.loss_mask: 0.6754, decode.d1.loss_dice: 0.9674, decode.d2.loss_cls: 0.6400, decode.d2.loss_mask: 0.6575, decode.d2.loss_dice: 0.9286, decode.d3.loss_cls: 0.5966, decode.d3.loss_mask: 0.6543, decode.d3.loss_dice: 0.9139, decode.d4.loss_cls: 0.5814, decode.d4.loss_mask: 0.6580, decode.d4.loss_dice: 0.9168, decode.d5.loss_cls: 0.5703, decode.d5.loss_mask: 0.6532, decode.d5.loss_dice: 0.9143, decode.d6.loss_cls: 0.5630, decode.d6.loss_mask: 0.6506, decode.d6.loss_dice: 0.9115, decode.d7.loss_cls: 0.5588, decode.d7.loss_mask: 0.6508, decode.d7.loss_dice: 0.9128, decode.d8.loss_cls: 0.5570, decode.d8.loss_mask: 0.6507, decode.d8.loss_dice: 0.9110, loss: 30.2102
2022-11-30 03:21:29,909 - mmseg - INFO - Iter [5650/40000]	lr: 1.142e-07, eta: 1 day, 17:36:55, time: 4.116, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5626, decode.loss_mask: 0.6394, decode.loss_dice: 0.9038, decode.d0.loss_cls: 9.0601, decode.d0.loss_mask: 0.6132, decode.d0.loss_dice: 0.9916, decode.d1.loss_cls: 0.7322, decode.d1.loss_mask: 0.6583, decode.d1.loss_dice: 0.9637, decode.d2.loss_cls: 0.6424, decode.d2.loss_mask: 0.6461, decode.d2.loss_dice: 0.9259, decode.d3.loss_cls: 0.5930, decode.d3.loss_mask: 0.6424, decode.d3.loss_dice: 0.9087, decode.d4.loss_cls: 0.5830, decode.d4.loss_mask: 0.6421, decode.d4.loss_dice: 0.9078, decode.d5.loss_cls: 0.5659, decode.d5.loss_mask: 0.6394, decode.d5.loss_dice: 0.9070, decode.d6.loss_cls: 0.5616, decode.d6.loss_mask: 0.6403, decode.d6.loss_dice: 0.9022, decode.d7.loss_cls: 0.5623, decode.d7.loss_mask: 0.6390, decode.d7.loss_dice: 0.9052, decode.d8.loss_cls: 0.5612, decode.d8.loss_mask: 0.6379, decode.d8.loss_dice: 0.9017, loss: 30.0400
2022-11-30 03:24:58,016 - mmseg - INFO - Iter [5700/40000]	lr: 1.141e-07, eta: 1 day, 17:32:17, time: 4.162, data_time: 0.064, memory: 51902, decode.loss_cls: 0.5424, decode.loss_mask: 0.6291, decode.loss_dice: 0.9048, decode.d0.loss_cls: 9.0459, decode.d0.loss_mask: 0.6053, decode.d0.loss_dice: 0.9746, decode.d1.loss_cls: 0.6950, decode.d1.loss_mask: 0.6473, decode.d1.loss_dice: 0.9600, decode.d2.loss_cls: 0.6073, decode.d2.loss_mask: 0.6381, decode.d2.loss_dice: 0.9252, decode.d3.loss_cls: 0.5741, decode.d3.loss_mask: 0.6347, decode.d3.loss_dice: 0.9063, decode.d4.loss_cls: 0.5573, decode.d4.loss_mask: 0.6334, decode.d4.loss_dice: 0.9049, decode.d5.loss_cls: 0.5523, decode.d5.loss_mask: 0.6300, decode.d5.loss_dice: 0.8982, decode.d6.loss_cls: 0.5453, decode.d6.loss_mask: 0.6303, decode.d6.loss_dice: 0.8974, decode.d7.loss_cls: 0.5409, decode.d7.loss_mask: 0.6304, decode.d7.loss_dice: 0.9023, decode.d8.loss_cls: 0.5427, decode.d8.loss_mask: 0.6299, decode.d8.loss_dice: 0.9010, loss: 29.6865
2022-11-30 03:28:23,712 - mmseg - INFO - Iter [5750/40000]	lr: 1.139e-07, eta: 1 day, 17:27:26, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5523, decode.loss_mask: 0.6266, decode.loss_dice: 0.9013, decode.d0.loss_cls: 9.0411, decode.d0.loss_mask: 0.6004, decode.d0.loss_dice: 0.9810, decode.d1.loss_cls: 0.7110, decode.d1.loss_mask: 0.6476, decode.d1.loss_dice: 0.9594, decode.d2.loss_cls: 0.6267, decode.d2.loss_mask: 0.6321, decode.d2.loss_dice: 0.9170, decode.d3.loss_cls: 0.5855, decode.d3.loss_mask: 0.6258, decode.d3.loss_dice: 0.9058, decode.d4.loss_cls: 0.5700, decode.d4.loss_mask: 0.6260, decode.d4.loss_dice: 0.9032, decode.d5.loss_cls: 0.5572, decode.d5.loss_mask: 0.6255, decode.d5.loss_dice: 0.9000, decode.d6.loss_cls: 0.5524, decode.d6.loss_mask: 0.6250, decode.d6.loss_dice: 0.8988, decode.d7.loss_cls: 0.5494, decode.d7.loss_mask: 0.6247, decode.d7.loss_dice: 0.8937, decode.d8.loss_cls: 0.5505, decode.d8.loss_mask: 0.6262, decode.d8.loss_dice: 0.8961, loss: 29.7123
2022-11-30 03:31:49,177 - mmseg - INFO - Iter [5800/40000]	lr: 1.137e-07, eta: 1 day, 17:22:35, time: 4.109, data_time: 0.018, memory: 51902, decode.loss_cls: 0.5236, decode.loss_mask: 0.6212, decode.loss_dice: 0.8898, decode.d0.loss_cls: 9.0191, decode.d0.loss_mask: 0.5842, decode.d0.loss_dice: 0.9504, decode.d1.loss_cls: 0.6939, decode.d1.loss_mask: 0.6341, decode.d1.loss_dice: 0.9349, decode.d2.loss_cls: 0.6061, decode.d2.loss_mask: 0.6240, decode.d2.loss_dice: 0.9044, decode.d3.loss_cls: 0.5593, decode.d3.loss_mask: 0.6219, decode.d3.loss_dice: 0.8880, decode.d4.loss_cls: 0.5462, decode.d4.loss_mask: 0.6207, decode.d4.loss_dice: 0.8917, decode.d5.loss_cls: 0.5364, decode.d5.loss_mask: 0.6198, decode.d5.loss_dice: 0.8856, decode.d6.loss_cls: 0.5254, decode.d6.loss_mask: 0.6218, decode.d6.loss_dice: 0.8860, decode.d7.loss_cls: 0.5213, decode.d7.loss_mask: 0.6241, decode.d7.loss_dice: 0.8916, decode.d8.loss_cls: 0.5247, decode.d8.loss_mask: 0.6238, decode.d8.loss_dice: 0.8859, loss: 29.2597
2022-11-30 03:35:14,865 - mmseg - INFO - Iter [5850/40000]	lr: 1.136e-07, eta: 1 day, 17:17:47, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5459, decode.loss_mask: 0.6237, decode.loss_dice: 0.9000, decode.d0.loss_cls: 9.0139, decode.d0.loss_mask: 0.5995, decode.d0.loss_dice: 0.9849, decode.d1.loss_cls: 0.7177, decode.d1.loss_mask: 0.6458, decode.d1.loss_dice: 0.9632, decode.d2.loss_cls: 0.6202, decode.d2.loss_mask: 0.6337, decode.d2.loss_dice: 0.9196, decode.d3.loss_cls: 0.5777, decode.d3.loss_mask: 0.6280, decode.d3.loss_dice: 0.9062, decode.d4.loss_cls: 0.5648, decode.d4.loss_mask: 0.6268, decode.d4.loss_dice: 0.9054, decode.d5.loss_cls: 0.5516, decode.d5.loss_mask: 0.6259, decode.d5.loss_dice: 0.9013, decode.d6.loss_cls: 0.5448, decode.d6.loss_mask: 0.6265, decode.d6.loss_dice: 0.8941, decode.d7.loss_cls: 0.5436, decode.d7.loss_mask: 0.6247, decode.d7.loss_dice: 0.9002, decode.d8.loss_cls: 0.5426, decode.d8.loss_mask: 0.6248, decode.d8.loss_dice: 0.9028, loss: 29.6598
2022-11-30 03:38:40,586 - mmseg - INFO - Iter [5900/40000]	lr: 1.134e-07, eta: 1 day, 17:13:00, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5595, decode.loss_mask: 0.6394, decode.loss_dice: 0.9221, decode.d0.loss_cls: 8.9885, decode.d0.loss_mask: 0.6091, decode.d0.loss_dice: 1.0009, decode.d1.loss_cls: 0.7107, decode.d1.loss_mask: 0.6638, decode.d1.loss_dice: 0.9863, decode.d2.loss_cls: 0.6268, decode.d2.loss_mask: 0.6522, decode.d2.loss_dice: 0.9418, decode.d3.loss_cls: 0.5812, decode.d3.loss_mask: 0.6458, decode.d3.loss_dice: 0.9258, decode.d4.loss_cls: 0.5723, decode.d4.loss_mask: 0.6426, decode.d4.loss_dice: 0.9234, decode.d5.loss_cls: 0.5644, decode.d5.loss_mask: 0.6381, decode.d5.loss_dice: 0.9246, decode.d6.loss_cls: 0.5563, decode.d6.loss_mask: 0.6422, decode.d6.loss_dice: 0.9177, decode.d7.loss_cls: 0.5547, decode.d7.loss_mask: 0.6407, decode.d7.loss_dice: 0.9218, decode.d8.loss_cls: 0.5552, decode.d8.loss_mask: 0.6396, decode.d8.loss_dice: 0.9230, loss: 30.0704
2022-11-30 03:42:06,422 - mmseg - INFO - Iter [5950/40000]	lr: 1.132e-07, eta: 1 day, 17:08:15, time: 4.117, data_time: 0.018, memory: 51902, decode.loss_cls: 0.5845, decode.loss_mask: 0.6291, decode.loss_dice: 0.9096, decode.d0.loss_cls: 8.9895, decode.d0.loss_mask: 0.6000, decode.d0.loss_dice: 0.9959, decode.d1.loss_cls: 0.7520, decode.d1.loss_mask: 0.6451, decode.d1.loss_dice: 0.9767, decode.d2.loss_cls: 0.6643, decode.d2.loss_mask: 0.6332, decode.d2.loss_dice: 0.9370, decode.d3.loss_cls: 0.6142, decode.d3.loss_mask: 0.6284, decode.d3.loss_dice: 0.9188, decode.d4.loss_cls: 0.6048, decode.d4.loss_mask: 0.6272, decode.d4.loss_dice: 0.9154, decode.d5.loss_cls: 0.5932, decode.d5.loss_mask: 0.6270, decode.d5.loss_dice: 0.9130, decode.d6.loss_cls: 0.5837, decode.d6.loss_mask: 0.6282, decode.d6.loss_dice: 0.9130, decode.d7.loss_cls: 0.5786, decode.d7.loss_mask: 0.6294, decode.d7.loss_dice: 0.9159, decode.d8.loss_cls: 0.5833, decode.d8.loss_mask: 0.6302, decode.d8.loss_dice: 0.9144, loss: 30.1356
2022-11-30 03:45:32,029 - mmseg - INFO - Saving checkpoint at 6000 iterations
2022-11-30 03:46:14,577 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 03:46:14,578 - mmseg - INFO - Iter [6000/40000]	lr: 1.131e-07, eta: 1 day, 17:07:32, time: 4.963, data_time: 0.020, memory: 51902, decode.loss_cls: 0.5571, decode.loss_mask: 0.6114, decode.loss_dice: 0.8948, decode.d0.loss_cls: 8.9696, decode.d0.loss_mask: 0.5865, decode.d0.loss_dice: 0.9871, decode.d1.loss_cls: 0.7211, decode.d1.loss_mask: 0.6337, decode.d1.loss_dice: 0.9579, decode.d2.loss_cls: 0.6336, decode.d2.loss_mask: 0.6238, decode.d2.loss_dice: 0.9203, decode.d3.loss_cls: 0.5892, decode.d3.loss_mask: 0.6134, decode.d3.loss_dice: 0.9013, decode.d4.loss_cls: 0.5726, decode.d4.loss_mask: 0.6173, decode.d4.loss_dice: 0.9014, decode.d5.loss_cls: 0.5594, decode.d5.loss_mask: 0.6146, decode.d5.loss_dice: 0.8961, decode.d6.loss_cls: 0.5565, decode.d6.loss_mask: 0.6122, decode.d6.loss_dice: 0.8946, decode.d7.loss_cls: 0.5531, decode.d7.loss_mask: 0.6149, decode.d7.loss_dice: 0.9012, decode.d8.loss_cls: 0.5533, decode.d8.loss_mask: 0.6142, decode.d8.loss_dice: 0.8999, loss: 29.5619
2022-11-30 03:49:12,648 - mmseg - INFO - per class results:
2022-11-30 03:49:12,653 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        |  82.6 | 89.31 |
|       building      | 84.22 | 90.63 |
|         sky         | 95.04 | 97.07 |
|        floor        | 84.92 | 89.72 |
|         tree        | 78.63 | 89.11 |
|       ceiling       | 87.52 |  94.4 |
|         road        | 87.91 | 92.12 |
|         bed         | 93.09 | 96.77 |
|      windowpane     | 66.86 | 81.67 |
|        grass        | 69.26 | 85.07 |
|       cabinet       | 62.54 | 73.79 |
|       sidewalk      | 70.65 | 83.45 |
|        person       | 88.35 | 94.25 |
|        earth        | 42.59 | 55.88 |
|         door        | 59.59 | 78.14 |
|        table        | 71.32 | 81.02 |
|       mountain      |  64.6 | 70.12 |
|        plant        | 57.94 | 72.05 |
|       curtain       | 81.28 | 90.46 |
|        chair        | 63.48 | 72.26 |
|         car         | 88.61 | 94.32 |
|        water        | 60.97 | 78.41 |
|       painting      | 80.94 |  92.7 |
|         sofa        | 84.48 | 89.97 |
|        shelf        |  47.2 | 62.43 |
|        house        | 46.89 | 63.33 |
|         sea         | 70.71 | 88.78 |
|        mirror       | 80.92 | 91.63 |
|         rug         | 71.43 | 85.81 |
|        field        | 28.21 | 52.46 |
|       armchair      | 58.33 | 87.76 |
|         seat        |  67.9 |  89.7 |
|        fence        |  56.1 |  78.6 |
|         desk        | 57.91 | 81.74 |
|         rock        | 67.12 |  85.1 |
|       wardrobe      | 49.89 | 77.51 |
|         lamp        | 78.84 | 89.26 |
|       bathtub       | 91.74 | 94.36 |
|       railing       | 48.63 | 72.99 |
|       cushion       | 77.12 | 88.68 |
|         base        | 39.74 | 66.27 |
|         box         | 39.72 | 51.53 |
|        column       | 62.43 | 80.96 |
|      signboard      | 44.93 | 67.87 |
|   chest of drawers  | 36.93 | 72.59 |
|       counter       | 53.48 | 73.84 |
|         sand        | 63.75 | 90.61 |
|         sink        | 80.56 | 87.01 |
|      skyscraper     | 42.49 | 60.23 |
|      fireplace      | 78.45 | 89.92 |
|     refrigerator    | 83.38 | 95.09 |
|      grandstand     | 40.77 | 74.51 |
|         path        | 20.98 | 33.31 |
|        stairs       | 32.81 | 40.88 |
|        runway       | 75.22 | 94.89 |
|         case        | 69.02 | 83.34 |
|      pool table     | 94.06 | 98.44 |
|        pillow       | 71.99 | 83.28 |
|     screen door     | 81.11 | 84.29 |
|       stairway      | 54.52 | 75.53 |
|        river        | 26.86 | 31.99 |
|        bridge       |  82.0 | 89.97 |
|       bookcase      | 30.53 | 51.47 |
|        blind        | 41.24 | 49.45 |
|     coffee table    | 72.61 | 86.16 |
|        toilet       | 92.63 | 95.99 |
|        flower       | 41.95 | 65.77 |
|         book        | 56.65 | 80.22 |
|         hill        | 11.56 | 30.94 |
|        bench        | 70.93 | 85.01 |
|      countertop     | 62.62 | 88.86 |
|        stove        | 81.84 | 86.03 |
|         palm        | 54.91 | 84.23 |
|    kitchen island   | 34.97 | 70.76 |
|       computer      | 81.55 |  90.6 |
|     swivel chair    | 54.69 | 84.52 |
|         boat        |  64.2 | 92.99 |
|         bar         | 56.82 | 61.37 |
|    arcade machine   | 90.77 | 98.79 |
|        hovel        | 10.85 | 15.28 |
|         bus         | 93.76 | 96.44 |
|        towel        | 79.26 | 93.88 |
|        light        | 63.27 | 81.35 |
|        truck        | 47.85 | 62.96 |
|        tower        | 28.67 | 61.14 |
|      chandelier     | 73.63 | 83.99 |
|        awning       | 36.41 | 49.91 |
|     streetlight     | 42.13 | 65.31 |
|        booth        | 36.03 | 36.46 |
| television receiver | 74.23 | 91.64 |
|       airplane      | 90.91 | 95.91 |
|      dirt track     | 20.14 | 20.15 |
|       apparel       | 49.92 | 92.13 |
|         pole        | 35.67 |  62.7 |
|         land        |  0.04 |  0.04 |
|      bannister      | 17.36 | 30.15 |
|      escalator      | 65.98 | 84.09 |
|       ottoman       | 51.77 | 81.73 |
|        bottle       | 54.02 | 75.41 |
|        buffet       | 11.03 | 12.17 |
|        poster       | 32.66 | 51.23 |
|        stage        | 24.05 | 51.02 |
|         van         | 49.33 | 85.36 |
|         ship        |  1.73 |  1.76 |
|       fountain      | 32.36 |  33.1 |
|    conveyer belt    | 82.65 | 97.62 |
|        canopy       | 45.93 | 54.47 |
|        washer       | 89.65 |  92.0 |
|      plaything      | 28.57 |  55.3 |
|    swimming pool    | 43.15 | 74.51 |
|        stool        |  39.7 | 88.17 |
|        barrel       | 54.84 | 64.57 |
|        basket       | 46.22 | 76.51 |
|      waterfall      | 52.52 | 57.57 |
|         tent        | 94.87 | 97.92 |
|         bag         |  41.3 | 58.08 |
|       minibike      | 80.94 | 93.31 |
|        cradle       | 91.23 |  97.2 |
|         oven        | 59.33 | 83.18 |
|         ball        | 65.92 | 84.69 |
|         food        | 67.51 | 78.88 |
|         step        | 27.29 | 49.28 |
|         tank        | 31.25 | 31.52 |
|      trade name     | 34.49 | 52.98 |
|      microwave      | 89.09 | 94.33 |
|         pot         | 55.37 | 70.74 |
|        animal       | 86.68 |  90.3 |
|       bicycle       | 60.56 | 85.31 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 73.71 | 95.54 |
|        screen       | 57.95 | 88.56 |
|       blanket       | 35.89 | 42.49 |
|      sculpture      | 69.47 | 91.97 |
|         hood        | 70.46 | 79.59 |
|        sconce       |  64.0 | 82.88 |
|         vase        | 54.21 | 82.66 |
|    traffic light    | 48.07 | 69.42 |
|         tray        | 25.52 | 40.65 |
|        ashcan       | 46.98 | 75.77 |
|         fan         | 72.12 | 84.26 |
|         pier        | 34.67 | 36.21 |
|      crt screen     |  0.35 |  0.41 |
|        plate        | 68.52 | 84.74 |
|       monitor       |  54.4 | 70.47 |
|    bulletin board   | 67.67 | 72.56 |
|        shower       | 21.55 | 30.05 |
|       radiator      | 67.64 | 89.65 |
|        glass        | 28.85 | 32.64 |
|        clock        | 58.57 | 71.52 |
|         flag        | 68.17 | 87.13 |
+---------------------+-------+-------+
2022-11-30 03:49:12,653 - mmseg - INFO - Summary:
2022-11-30 03:49:12,653 - mmseg - INFO - 
+-------+-------+------+
|  aAcc |  mIoU | mAcc |
+-------+-------+------+
| 86.16 | 57.75 | 72.7 |
+-------+-------+------+
2022-11-30 03:49:12,656 - mmseg - INFO - The previous best checkpoint /mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune/lr1.0_lrd0.9/best_mIoU_iter_5000.pth was removed
2022-11-30 03:49:55,380 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_6000.pth.
2022-11-30 03:49:55,381 - mmseg - INFO - Best mIoU is 0.5775 at 6000 iter.
2022-11-30 03:49:55,389 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 03:49:55,389 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8616, mIoU: 0.5775, mAcc: 0.7270, IoU.wall: 0.8260, IoU.building: 0.8422, IoU.sky: 0.9504, IoU.floor: 0.8492, IoU.tree: 0.7863, IoU.ceiling: 0.8752, IoU.road: 0.8791, IoU.bed : 0.9309, IoU.windowpane: 0.6686, IoU.grass: 0.6926, IoU.cabinet: 0.6254, IoU.sidewalk: 0.7065, IoU.person: 0.8835, IoU.earth: 0.4259, IoU.door: 0.5959, IoU.table: 0.7132, IoU.mountain: 0.6460, IoU.plant: 0.5794, IoU.curtain: 0.8128, IoU.chair: 0.6348, IoU.car: 0.8861, IoU.water: 0.6097, IoU.painting: 0.8094, IoU.sofa: 0.8448, IoU.shelf: 0.4720, IoU.house: 0.4689, IoU.sea: 0.7071, IoU.mirror: 0.8092, IoU.rug: 0.7143, IoU.field: 0.2821, IoU.armchair: 0.5833, IoU.seat: 0.6790, IoU.fence: 0.5610, IoU.desk: 0.5791, IoU.rock: 0.6712, IoU.wardrobe: 0.4989, IoU.lamp: 0.7884, IoU.bathtub: 0.9174, IoU.railing: 0.4863, IoU.cushion: 0.7712, IoU.base: 0.3974, IoU.box: 0.3972, IoU.column: 0.6243, IoU.signboard: 0.4493, IoU.chest of drawers: 0.3693, IoU.counter: 0.5348, IoU.sand: 0.6375, IoU.sink: 0.8056, IoU.skyscraper: 0.4249, IoU.fireplace: 0.7845, IoU.refrigerator: 0.8338, IoU.grandstand: 0.4077, IoU.path: 0.2098, IoU.stairs: 0.3281, IoU.runway: 0.7522, IoU.case: 0.6902, IoU.pool table: 0.9406, IoU.pillow: 0.7199, IoU.screen door: 0.8111, IoU.stairway: 0.5452, IoU.river: 0.2686, IoU.bridge: 0.8200, IoU.bookcase: 0.3053, IoU.blind: 0.4124, IoU.coffee table: 0.7261, IoU.toilet: 0.9263, IoU.flower: 0.4195, IoU.book: 0.5665, IoU.hill: 0.1156, IoU.bench: 0.7093, IoU.countertop: 0.6262, IoU.stove: 0.8184, IoU.palm: 0.5491, IoU.kitchen island: 0.3497, IoU.computer: 0.8155, IoU.swivel chair: 0.5469, IoU.boat: 0.6420, IoU.bar: 0.5682, IoU.arcade machine: 0.9077, IoU.hovel: 0.1085, IoU.bus: 0.9376, IoU.towel: 0.7926, IoU.light: 0.6327, IoU.truck: 0.4785, IoU.tower: 0.2867, IoU.chandelier: 0.7363, IoU.awning: 0.3641, IoU.streetlight: 0.4213, IoU.booth: 0.3603, IoU.television receiver: 0.7423, IoU.airplane: 0.9091, IoU.dirt track: 0.2014, IoU.apparel: 0.4992, IoU.pole: 0.3567, IoU.land: 0.0004, IoU.bannister: 0.1736, IoU.escalator: 0.6598, IoU.ottoman: 0.5177, IoU.bottle: 0.5402, IoU.buffet: 0.1103, IoU.poster: 0.3266, IoU.stage: 0.2405, IoU.van: 0.4933, IoU.ship: 0.0173, IoU.fountain: 0.3236, IoU.conveyer belt: 0.8265, IoU.canopy: 0.4593, IoU.washer: 0.8965, IoU.plaything: 0.2857, IoU.swimming pool: 0.4315, IoU.stool: 0.3970, IoU.barrel: 0.5484, IoU.basket: 0.4622, IoU.waterfall: 0.5252, IoU.tent: 0.9487, IoU.bag: 0.4130, IoU.minibike: 0.8094, IoU.cradle: 0.9123, IoU.oven: 0.5933, IoU.ball: 0.6592, IoU.food: 0.6751, IoU.step: 0.2729, IoU.tank: 0.3125, IoU.trade name: 0.3449, IoU.microwave: 0.8909, IoU.pot: 0.5537, IoU.animal: 0.8668, IoU.bicycle: 0.6056, IoU.lake: 0.0000, IoU.dishwasher: 0.7371, IoU.screen: 0.5795, IoU.blanket: 0.3589, IoU.sculpture: 0.6947, IoU.hood: 0.7046, IoU.sconce: 0.6400, IoU.vase: 0.5421, IoU.traffic light: 0.4807, IoU.tray: 0.2552, IoU.ashcan: 0.4698, IoU.fan: 0.7212, IoU.pier: 0.3467, IoU.crt screen: 0.0035, IoU.plate: 0.6852, IoU.monitor: 0.5440, IoU.bulletin board: 0.6767, IoU.shower: 0.2155, IoU.radiator: 0.6764, IoU.glass: 0.2885, IoU.clock: 0.5857, IoU.flag: 0.6817, Acc.wall: 0.8931, Acc.building: 0.9063, Acc.sky: 0.9707, Acc.floor: 0.8972, Acc.tree: 0.8911, Acc.ceiling: 0.9440, Acc.road: 0.9212, Acc.bed : 0.9677, Acc.windowpane: 0.8167, Acc.grass: 0.8507, Acc.cabinet: 0.7379, Acc.sidewalk: 0.8345, Acc.person: 0.9425, Acc.earth: 0.5588, Acc.door: 0.7814, Acc.table: 0.8102, Acc.mountain: 0.7012, Acc.plant: 0.7205, Acc.curtain: 0.9046, Acc.chair: 0.7226, Acc.car: 0.9432, Acc.water: 0.7841, Acc.painting: 0.9270, Acc.sofa: 0.8997, Acc.shelf: 0.6243, Acc.house: 0.6333, Acc.sea: 0.8878, Acc.mirror: 0.9163, Acc.rug: 0.8581, Acc.field: 0.5246, Acc.armchair: 0.8776, Acc.seat: 0.8970, Acc.fence: 0.7860, Acc.desk: 0.8174, Acc.rock: 0.8510, Acc.wardrobe: 0.7751, Acc.lamp: 0.8926, Acc.bathtub: 0.9436, Acc.railing: 0.7299, Acc.cushion: 0.8868, Acc.base: 0.6627, Acc.box: 0.5153, Acc.column: 0.8096, Acc.signboard: 0.6787, Acc.chest of drawers: 0.7259, Acc.counter: 0.7384, Acc.sand: 0.9061, Acc.sink: 0.8701, Acc.skyscraper: 0.6023, Acc.fireplace: 0.8992, Acc.refrigerator: 0.9509, Acc.grandstand: 0.7451, Acc.path: 0.3331, Acc.stairs: 0.4088, Acc.runway: 0.9489, Acc.case: 0.8334, Acc.pool table: 0.9844, Acc.pillow: 0.8328, Acc.screen door: 0.8429, Acc.stairway: 0.7553, Acc.river: 0.3199, Acc.bridge: 0.8997, Acc.bookcase: 0.5147, Acc.blind: 0.4945, Acc.coffee table: 0.8616, Acc.toilet: 0.9599, Acc.flower: 0.6577, Acc.book: 0.8022, Acc.hill: 0.3094, Acc.bench: 0.8501, Acc.countertop: 0.8886, Acc.stove: 0.8603, Acc.palm: 0.8423, Acc.kitchen island: 0.7076, Acc.computer: 0.9060, Acc.swivel chair: 0.8452, Acc.boat: 0.9299, Acc.bar: 0.6137, Acc.arcade machine: 0.9879, Acc.hovel: 0.1528, Acc.bus: 0.9644, Acc.towel: 0.9388, Acc.light: 0.8135, Acc.truck: 0.6296, Acc.tower: 0.6114, Acc.chandelier: 0.8399, Acc.awning: 0.4991, Acc.streetlight: 0.6531, Acc.booth: 0.3646, Acc.television receiver: 0.9164, Acc.airplane: 0.9591, Acc.dirt track: 0.2015, Acc.apparel: 0.9213, Acc.pole: 0.6270, Acc.land: 0.0004, Acc.bannister: 0.3015, Acc.escalator: 0.8409, Acc.ottoman: 0.8173, Acc.bottle: 0.7541, Acc.buffet: 0.1217, Acc.poster: 0.5123, Acc.stage: 0.5102, Acc.van: 0.8536, Acc.ship: 0.0176, Acc.fountain: 0.3310, Acc.conveyer belt: 0.9762, Acc.canopy: 0.5447, Acc.washer: 0.9200, Acc.plaything: 0.5530, Acc.swimming pool: 0.7451, Acc.stool: 0.8817, Acc.barrel: 0.6457, Acc.basket: 0.7651, Acc.waterfall: 0.5757, Acc.tent: 0.9792, Acc.bag: 0.5808, Acc.minibike: 0.9331, Acc.cradle: 0.9720, Acc.oven: 0.8318, Acc.ball: 0.8469, Acc.food: 0.7888, Acc.step: 0.4928, Acc.tank: 0.3152, Acc.trade name: 0.5298, Acc.microwave: 0.9433, Acc.pot: 0.7074, Acc.animal: 0.9030, Acc.bicycle: 0.8531, Acc.lake: 0.0000, Acc.dishwasher: 0.9554, Acc.screen: 0.8856, Acc.blanket: 0.4249, Acc.sculpture: 0.9197, Acc.hood: 0.7959, Acc.sconce: 0.8288, Acc.vase: 0.8266, Acc.traffic light: 0.6942, Acc.tray: 0.4065, Acc.ashcan: 0.7577, Acc.fan: 0.8426, Acc.pier: 0.3621, Acc.crt screen: 0.0041, Acc.plate: 0.8474, Acc.monitor: 0.7047, Acc.bulletin board: 0.7256, Acc.shower: 0.3005, Acc.radiator: 0.8965, Acc.glass: 0.3264, Acc.clock: 0.7152, Acc.flag: 0.8713
2022-11-30 03:53:20,866 - mmseg - INFO - Iter [6050/40000]	lr: 1.129e-07, eta: 1 day, 17:23:24, time: 8.526, data_time: 4.435, memory: 51902, decode.loss_cls: 0.5532, decode.loss_mask: 0.6280, decode.loss_dice: 0.9060, decode.d0.loss_cls: 8.9547, decode.d0.loss_mask: 0.5973, decode.d0.loss_dice: 0.9873, decode.d1.loss_cls: 0.7169, decode.d1.loss_mask: 0.6457, decode.d1.loss_dice: 0.9807, decode.d2.loss_cls: 0.6352, decode.d2.loss_mask: 0.6337, decode.d2.loss_dice: 0.9378, decode.d3.loss_cls: 0.5889, decode.d3.loss_mask: 0.6318, decode.d3.loss_dice: 0.9171, decode.d4.loss_cls: 0.5766, decode.d4.loss_mask: 0.6267, decode.d4.loss_dice: 0.9192, decode.d5.loss_cls: 0.5606, decode.d5.loss_mask: 0.6279, decode.d5.loss_dice: 0.9118, decode.d6.loss_cls: 0.5554, decode.d6.loss_mask: 0.6226, decode.d6.loss_dice: 0.9104, decode.d7.loss_cls: 0.5481, decode.d7.loss_mask: 0.6241, decode.d7.loss_dice: 0.9165, decode.d8.loss_cls: 0.5487, decode.d8.loss_mask: 0.6258, decode.d8.loss_dice: 0.9148, loss: 29.8034
2022-11-30 03:56:46,765 - mmseg - INFO - Iter [6100/40000]	lr: 1.127e-07, eta: 1 day, 17:18:30, time: 4.118, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5529, decode.loss_mask: 0.6087, decode.loss_dice: 0.8878, decode.d0.loss_cls: 8.9522, decode.d0.loss_mask: 0.5866, decode.d0.loss_dice: 0.9759, decode.d1.loss_cls: 0.7279, decode.d1.loss_mask: 0.6334, decode.d1.loss_dice: 0.9530, decode.d2.loss_cls: 0.6342, decode.d2.loss_mask: 0.6191, decode.d2.loss_dice: 0.9122, decode.d3.loss_cls: 0.5920, decode.d3.loss_mask: 0.6101, decode.d3.loss_dice: 0.8914, decode.d4.loss_cls: 0.5777, decode.d4.loss_mask: 0.6100, decode.d4.loss_dice: 0.8930, decode.d5.loss_cls: 0.5595, decode.d5.loss_mask: 0.6081, decode.d5.loss_dice: 0.8887, decode.d6.loss_cls: 0.5547, decode.d6.loss_mask: 0.6088, decode.d6.loss_dice: 0.8853, decode.d7.loss_cls: 0.5498, decode.d7.loss_mask: 0.6095, decode.d7.loss_dice: 0.8904, decode.d8.loss_cls: 0.5517, decode.d8.loss_mask: 0.6088, decode.d8.loss_dice: 0.8884, loss: 29.4218
2022-11-30 04:00:12,279 - mmseg - INFO - Iter [6150/40000]	lr: 1.126e-07, eta: 1 day, 17:13:34, time: 4.110, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5343, decode.loss_mask: 0.6462, decode.loss_dice: 0.9173, decode.d0.loss_cls: 8.9394, decode.d0.loss_mask: 0.6134, decode.d0.loss_dice: 0.9963, decode.d1.loss_cls: 0.7115, decode.d1.loss_mask: 0.6630, decode.d1.loss_dice: 0.9747, decode.d2.loss_cls: 0.6181, decode.d2.loss_mask: 0.6499, decode.d2.loss_dice: 0.9342, decode.d3.loss_cls: 0.5717, decode.d3.loss_mask: 0.6522, decode.d3.loss_dice: 0.9219, decode.d4.loss_cls: 0.5580, decode.d4.loss_mask: 0.6482, decode.d4.loss_dice: 0.9205, decode.d5.loss_cls: 0.5458, decode.d5.loss_mask: 0.6473, decode.d5.loss_dice: 0.9157, decode.d6.loss_cls: 0.5377, decode.d6.loss_mask: 0.6450, decode.d6.loss_dice: 0.9100, decode.d7.loss_cls: 0.5385, decode.d7.loss_mask: 0.6444, decode.d7.loss_dice: 0.9138, decode.d8.loss_cls: 0.5340, decode.d8.loss_mask: 0.6463, decode.d8.loss_dice: 0.9140, loss: 29.8633
2022-11-30 04:03:37,738 - mmseg - INFO - Iter [6200/40000]	lr: 1.124e-07, eta: 1 day, 17:08:40, time: 4.109, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5485, decode.loss_mask: 0.6263, decode.loss_dice: 0.9094, decode.d0.loss_cls: 8.9237, decode.d0.loss_mask: 0.5996, decode.d0.loss_dice: 0.9876, decode.d1.loss_cls: 0.7154, decode.d1.loss_mask: 0.6489, decode.d1.loss_dice: 0.9787, decode.d2.loss_cls: 0.6245, decode.d2.loss_mask: 0.6347, decode.d2.loss_dice: 0.9359, decode.d3.loss_cls: 0.5788, decode.d3.loss_mask: 0.6347, decode.d3.loss_dice: 0.9203, decode.d4.loss_cls: 0.5680, decode.d4.loss_mask: 0.6305, decode.d4.loss_dice: 0.9217, decode.d5.loss_cls: 0.5565, decode.d5.loss_mask: 0.6292, decode.d5.loss_dice: 0.9141, decode.d6.loss_cls: 0.5514, decode.d6.loss_mask: 0.6246, decode.d6.loss_dice: 0.9089, decode.d7.loss_cls: 0.5450, decode.d7.loss_mask: 0.6252, decode.d7.loss_dice: 0.9085, decode.d8.loss_cls: 0.5440, decode.d8.loss_mask: 0.6276, decode.d8.loss_dice: 0.9059, loss: 29.7277
2022-11-30 04:07:03,561 - mmseg - INFO - Iter [6250/40000]	lr: 1.122e-07, eta: 1 day, 17:03:49, time: 4.116, data_time: 0.018, memory: 51902, decode.loss_cls: 0.5530, decode.loss_mask: 0.6185, decode.loss_dice: 0.9047, decode.d0.loss_cls: 8.9047, decode.d0.loss_mask: 0.5838, decode.d0.loss_dice: 0.9840, decode.d1.loss_cls: 0.7139, decode.d1.loss_mask: 0.6384, decode.d1.loss_dice: 0.9648, decode.d2.loss_cls: 0.6305, decode.d2.loss_mask: 0.6230, decode.d2.loss_dice: 0.9255, decode.d3.loss_cls: 0.5849, decode.d3.loss_mask: 0.6226, decode.d3.loss_dice: 0.9137, decode.d4.loss_cls: 0.5765, decode.d4.loss_mask: 0.6203, decode.d4.loss_dice: 0.9133, decode.d5.loss_cls: 0.5649, decode.d5.loss_mask: 0.6189, decode.d5.loss_dice: 0.9090, decode.d6.loss_cls: 0.5575, decode.d6.loss_mask: 0.6181, decode.d6.loss_dice: 0.9021, decode.d7.loss_cls: 0.5552, decode.d7.loss_mask: 0.6158, decode.d7.loss_dice: 0.9059, decode.d8.loss_cls: 0.5533, decode.d8.loss_mask: 0.6161, decode.d8.loss_dice: 0.9112, loss: 29.6041
2022-11-30 04:10:29,118 - mmseg - INFO - Iter [6300/40000]	lr: 1.121e-07, eta: 1 day, 16:58:58, time: 4.111, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5635, decode.loss_mask: 0.6252, decode.loss_dice: 0.9260, decode.d0.loss_cls: 8.9013, decode.d0.loss_mask: 0.5966, decode.d0.loss_dice: 1.0014, decode.d1.loss_cls: 0.7217, decode.d1.loss_mask: 0.6496, decode.d1.loss_dice: 0.9859, decode.d2.loss_cls: 0.6422, decode.d2.loss_mask: 0.6346, decode.d2.loss_dice: 0.9396, decode.d3.loss_cls: 0.6008, decode.d3.loss_mask: 0.6288, decode.d3.loss_dice: 0.9256, decode.d4.loss_cls: 0.5888, decode.d4.loss_mask: 0.6248, decode.d4.loss_dice: 0.9280, decode.d5.loss_cls: 0.5786, decode.d5.loss_mask: 0.6233, decode.d5.loss_dice: 0.9219, decode.d6.loss_cls: 0.5687, decode.d6.loss_mask: 0.6238, decode.d6.loss_dice: 0.9209, decode.d7.loss_cls: 0.5668, decode.d7.loss_mask: 0.6242, decode.d7.loss_dice: 0.9248, decode.d8.loss_cls: 0.5650, decode.d8.loss_mask: 0.6237, decode.d8.loss_dice: 0.9260, loss: 29.9522
2022-11-30 04:13:56,746 - mmseg - INFO - Iter [6350/40000]	lr: 1.119e-07, eta: 1 day, 16:54:19, time: 4.153, data_time: 0.062, memory: 51902, decode.loss_cls: 0.5398, decode.loss_mask: 0.6207, decode.loss_dice: 0.8959, decode.d0.loss_cls: 8.8786, decode.d0.loss_mask: 0.5935, decode.d0.loss_dice: 0.9762, decode.d1.loss_cls: 0.6909, decode.d1.loss_mask: 0.6466, decode.d1.loss_dice: 0.9659, decode.d2.loss_cls: 0.6094, decode.d2.loss_mask: 0.6325, decode.d2.loss_dice: 0.9306, decode.d3.loss_cls: 0.5713, decode.d3.loss_mask: 0.6255, decode.d3.loss_dice: 0.9109, decode.d4.loss_cls: 0.5608, decode.d4.loss_mask: 0.6238, decode.d4.loss_dice: 0.9076, decode.d5.loss_cls: 0.5485, decode.d5.loss_mask: 0.6234, decode.d5.loss_dice: 0.9079, decode.d6.loss_cls: 0.5439, decode.d6.loss_mask: 0.6215, decode.d6.loss_dice: 0.9020, decode.d7.loss_cls: 0.5402, decode.d7.loss_mask: 0.6223, decode.d7.loss_dice: 0.9044, decode.d8.loss_cls: 0.5436, decode.d8.loss_mask: 0.6177, decode.d8.loss_dice: 0.8995, loss: 29.4555
2022-11-30 04:17:22,385 - mmseg - INFO - Iter [6400/40000]	lr: 1.117e-07, eta: 1 day, 16:49:31, time: 4.113, data_time: 0.018, memory: 51902, decode.loss_cls: 0.5428, decode.loss_mask: 0.6215, decode.loss_dice: 0.9024, decode.d0.loss_cls: 8.8729, decode.d0.loss_mask: 0.5990, decode.d0.loss_dice: 0.9868, decode.d1.loss_cls: 0.6996, decode.d1.loss_mask: 0.6448, decode.d1.loss_dice: 0.9788, decode.d2.loss_cls: 0.6144, decode.d2.loss_mask: 0.6272, decode.d2.loss_dice: 0.9253, decode.d3.loss_cls: 0.5752, decode.d3.loss_mask: 0.6213, decode.d3.loss_dice: 0.9114, decode.d4.loss_cls: 0.5629, decode.d4.loss_mask: 0.6229, decode.d4.loss_dice: 0.9123, decode.d5.loss_cls: 0.5446, decode.d5.loss_mask: 0.6223, decode.d5.loss_dice: 0.9127, decode.d6.loss_cls: 0.5465, decode.d6.loss_mask: 0.6228, decode.d6.loss_dice: 0.9035, decode.d7.loss_cls: 0.5394, decode.d7.loss_mask: 0.6239, decode.d7.loss_dice: 0.9070, decode.d8.loss_cls: 0.5435, decode.d8.loss_mask: 0.6237, decode.d8.loss_dice: 0.9030, loss: 29.5146
2022-11-30 04:20:48,002 - mmseg - INFO - Iter [6450/40000]	lr: 1.116e-07, eta: 1 day, 16:44:45, time: 4.112, data_time: 0.018, memory: 51902, decode.loss_cls: 0.5437, decode.loss_mask: 0.6162, decode.loss_dice: 0.9035, decode.d0.loss_cls: 8.8637, decode.d0.loss_mask: 0.5879, decode.d0.loss_dice: 0.9755, decode.d1.loss_cls: 0.7117, decode.d1.loss_mask: 0.6367, decode.d1.loss_dice: 0.9610, decode.d2.loss_cls: 0.6204, decode.d2.loss_mask: 0.6286, decode.d2.loss_dice: 0.9202, decode.d3.loss_cls: 0.5778, decode.d3.loss_mask: 0.6200, decode.d3.loss_dice: 0.9076, decode.d4.loss_cls: 0.5636, decode.d4.loss_mask: 0.6188, decode.d4.loss_dice: 0.9040, decode.d5.loss_cls: 0.5537, decode.d5.loss_mask: 0.6155, decode.d5.loss_dice: 0.9031, decode.d6.loss_cls: 0.5491, decode.d6.loss_mask: 0.6158, decode.d6.loss_dice: 0.8982, decode.d7.loss_cls: 0.5432, decode.d7.loss_mask: 0.6172, decode.d7.loss_dice: 0.9022, decode.d8.loss_cls: 0.5451, decode.d8.loss_mask: 0.6150, decode.d8.loss_dice: 0.8983, loss: 29.4172
2022-11-30 04:24:13,270 - mmseg - INFO - Iter [6500/40000]	lr: 1.114e-07, eta: 1 day, 16:39:57, time: 4.105, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5263, decode.loss_mask: 0.6153, decode.loss_dice: 0.8830, decode.d0.loss_cls: 8.8499, decode.d0.loss_mask: 0.5881, decode.d0.loss_dice: 0.9540, decode.d1.loss_cls: 0.6962, decode.d1.loss_mask: 0.6372, decode.d1.loss_dice: 0.9412, decode.d2.loss_cls: 0.6002, decode.d2.loss_mask: 0.6253, decode.d2.loss_dice: 0.9034, decode.d3.loss_cls: 0.5621, decode.d3.loss_mask: 0.6183, decode.d3.loss_dice: 0.8925, decode.d4.loss_cls: 0.5515, decode.d4.loss_mask: 0.6142, decode.d4.loss_dice: 0.8857, decode.d5.loss_cls: 0.5387, decode.d5.loss_mask: 0.6144, decode.d5.loss_dice: 0.8840, decode.d6.loss_cls: 0.5302, decode.d6.loss_mask: 0.6137, decode.d6.loss_dice: 0.8768, decode.d7.loss_cls: 0.5282, decode.d7.loss_mask: 0.6148, decode.d7.loss_dice: 0.8813, decode.d8.loss_cls: 0.5286, decode.d8.loss_mask: 0.6175, decode.d8.loss_dice: 0.8784, loss: 29.0508
2022-11-30 04:27:38,802 - mmseg - INFO - Iter [6550/40000]	lr: 1.112e-07, eta: 1 day, 16:35:13, time: 4.111, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5365, decode.loss_mask: 0.6188, decode.loss_dice: 0.8951, decode.d0.loss_cls: 8.8399, decode.d0.loss_mask: 0.5909, decode.d0.loss_dice: 0.9664, decode.d1.loss_cls: 0.7122, decode.d1.loss_mask: 0.6365, decode.d1.loss_dice: 0.9524, decode.d2.loss_cls: 0.6182, decode.d2.loss_mask: 0.6268, decode.d2.loss_dice: 0.9124, decode.d3.loss_cls: 0.5706, decode.d3.loss_mask: 0.6201, decode.d3.loss_dice: 0.9059, decode.d4.loss_cls: 0.5596, decode.d4.loss_mask: 0.6203, decode.d4.loss_dice: 0.9028, decode.d5.loss_cls: 0.5456, decode.d5.loss_mask: 0.6195, decode.d5.loss_dice: 0.8974, decode.d6.loss_cls: 0.5447, decode.d6.loss_mask: 0.6172, decode.d6.loss_dice: 0.8955, decode.d7.loss_cls: 0.5372, decode.d7.loss_mask: 0.6177, decode.d7.loss_dice: 0.8992, decode.d8.loss_cls: 0.5356, decode.d8.loss_mask: 0.6180, decode.d8.loss_dice: 0.8942, loss: 29.3072
2022-11-30 04:31:04,487 - mmseg - INFO - Iter [6600/40000]	lr: 1.111e-07, eta: 1 day, 16:30:30, time: 4.114, data_time: 0.018, memory: 51902, decode.loss_cls: 0.5470, decode.loss_mask: 0.6179, decode.loss_dice: 0.9139, decode.d0.loss_cls: 8.8229, decode.d0.loss_mask: 0.5893, decode.d0.loss_dice: 0.9831, decode.d1.loss_cls: 0.7089, decode.d1.loss_mask: 0.6399, decode.d1.loss_dice: 0.9754, decode.d2.loss_cls: 0.6193, decode.d2.loss_mask: 0.6283, decode.d2.loss_dice: 0.9312, decode.d3.loss_cls: 0.5738, decode.d3.loss_mask: 0.6240, decode.d3.loss_dice: 0.9202, decode.d4.loss_cls: 0.5674, decode.d4.loss_mask: 0.6221, decode.d4.loss_dice: 0.9137, decode.d5.loss_cls: 0.5546, decode.d5.loss_mask: 0.6196, decode.d5.loss_dice: 0.9123, decode.d6.loss_cls: 0.5498, decode.d6.loss_mask: 0.6187, decode.d6.loss_dice: 0.9096, decode.d7.loss_cls: 0.5510, decode.d7.loss_mask: 0.6147, decode.d7.loss_dice: 0.9154, decode.d8.loss_cls: 0.5503, decode.d8.loss_mask: 0.6165, decode.d8.loss_dice: 0.9111, loss: 29.5218
2022-11-30 04:34:29,851 - mmseg - INFO - Iter [6650/40000]	lr: 1.109e-07, eta: 1 day, 16:25:47, time: 4.107, data_time: 0.021, memory: 51902, decode.loss_cls: 0.5166, decode.loss_mask: 0.6338, decode.loss_dice: 0.9179, decode.d0.loss_cls: 8.8020, decode.d0.loss_mask: 0.5974, decode.d0.loss_dice: 0.9821, decode.d1.loss_cls: 0.6743, decode.d1.loss_mask: 0.6526, decode.d1.loss_dice: 0.9736, decode.d2.loss_cls: 0.5965, decode.d2.loss_mask: 0.6407, decode.d2.loss_dice: 0.9296, decode.d3.loss_cls: 0.5565, decode.d3.loss_mask: 0.6328, decode.d3.loss_dice: 0.9159, decode.d4.loss_cls: 0.5442, decode.d4.loss_mask: 0.6306, decode.d4.loss_dice: 0.9174, decode.d5.loss_cls: 0.5331, decode.d5.loss_mask: 0.6330, decode.d5.loss_dice: 0.9120, decode.d6.loss_cls: 0.5262, decode.d6.loss_mask: 0.6308, decode.d6.loss_dice: 0.9120, decode.d7.loss_cls: 0.5233, decode.d7.loss_mask: 0.6342, decode.d7.loss_dice: 0.9104, decode.d8.loss_cls: 0.5191, decode.d8.loss_mask: 0.6327, decode.d8.loss_dice: 0.9132, loss: 29.3945
2022-11-30 04:37:55,435 - mmseg - INFO - Iter [6700/40000]	lr: 1.107e-07, eta: 1 day, 16:21:06, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5399, decode.loss_mask: 0.6249, decode.loss_dice: 0.9128, decode.d0.loss_cls: 8.7958, decode.d0.loss_mask: 0.6016, decode.d0.loss_dice: 0.9908, decode.d1.loss_cls: 0.7005, decode.d1.loss_mask: 0.6462, decode.d1.loss_dice: 0.9777, decode.d2.loss_cls: 0.6162, decode.d2.loss_mask: 0.6315, decode.d2.loss_dice: 0.9351, decode.d3.loss_cls: 0.5761, decode.d3.loss_mask: 0.6253, decode.d3.loss_dice: 0.9195, decode.d4.loss_cls: 0.5616, decode.d4.loss_mask: 0.6263, decode.d4.loss_dice: 0.9175, decode.d5.loss_cls: 0.5482, decode.d5.loss_mask: 0.6279, decode.d5.loss_dice: 0.9152, decode.d6.loss_cls: 0.5459, decode.d6.loss_mask: 0.6228, decode.d6.loss_dice: 0.9143, decode.d7.loss_cls: 0.5467, decode.d7.loss_mask: 0.6223, decode.d7.loss_dice: 0.9153, decode.d8.loss_cls: 0.5436, decode.d8.loss_mask: 0.6234, decode.d8.loss_dice: 0.9146, loss: 29.5395
2022-11-30 04:41:21,174 - mmseg - INFO - Iter [6750/40000]	lr: 1.106e-07, eta: 1 day, 16:16:26, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5395, decode.loss_mask: 0.6284, decode.loss_dice: 0.8919, decode.d0.loss_cls: 8.7834, decode.d0.loss_mask: 0.5960, decode.d0.loss_dice: 0.9747, decode.d1.loss_cls: 0.6933, decode.d1.loss_mask: 0.6472, decode.d1.loss_dice: 0.9614, decode.d2.loss_cls: 0.6132, decode.d2.loss_mask: 0.6326, decode.d2.loss_dice: 0.9150, decode.d3.loss_cls: 0.5704, decode.d3.loss_mask: 0.6305, decode.d3.loss_dice: 0.8985, decode.d4.loss_cls: 0.5619, decode.d4.loss_mask: 0.6275, decode.d4.loss_dice: 0.8916, decode.d5.loss_cls: 0.5438, decode.d5.loss_mask: 0.6274, decode.d5.loss_dice: 0.8924, decode.d6.loss_cls: 0.5415, decode.d6.loss_mask: 0.6282, decode.d6.loss_dice: 0.8873, decode.d7.loss_cls: 0.5413, decode.d7.loss_mask: 0.6272, decode.d7.loss_dice: 0.8933, decode.d8.loss_cls: 0.5386, decode.d8.loss_mask: 0.6269, decode.d8.loss_dice: 0.8934, loss: 29.2982
2022-11-30 04:44:46,517 - mmseg - INFO - Iter [6800/40000]	lr: 1.104e-07, eta: 1 day, 16:11:46, time: 4.107, data_time: 0.020, memory: 51902, decode.loss_cls: 0.5439, decode.loss_mask: 0.6080, decode.loss_dice: 0.9049, decode.d0.loss_cls: 8.7747, decode.d0.loss_mask: 0.5824, decode.d0.loss_dice: 0.9837, decode.d1.loss_cls: 0.6970, decode.d1.loss_mask: 0.6315, decode.d1.loss_dice: 0.9668, decode.d2.loss_cls: 0.6101, decode.d2.loss_mask: 0.6202, decode.d2.loss_dice: 0.9260, decode.d3.loss_cls: 0.5742, decode.d3.loss_mask: 0.6106, decode.d3.loss_dice: 0.9130, decode.d4.loss_cls: 0.5661, decode.d4.loss_mask: 0.6084, decode.d4.loss_dice: 0.9084, decode.d5.loss_cls: 0.5515, decode.d5.loss_mask: 0.6064, decode.d5.loss_dice: 0.9074, decode.d6.loss_cls: 0.5496, decode.d6.loss_mask: 0.6078, decode.d6.loss_dice: 0.9032, decode.d7.loss_cls: 0.5443, decode.d7.loss_mask: 0.6091, decode.d7.loss_dice: 0.9056, decode.d8.loss_cls: 0.5423, decode.d8.loss_mask: 0.6079, decode.d8.loss_dice: 0.9048, loss: 29.2696
2022-11-30 04:48:12,323 - mmseg - INFO - Iter [6850/40000]	lr: 1.103e-07, eta: 1 day, 16:07:10, time: 4.116, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5273, decode.loss_mask: 0.6308, decode.loss_dice: 0.8852, decode.d0.loss_cls: 8.7624, decode.d0.loss_mask: 0.5950, decode.d0.loss_dice: 0.9539, decode.d1.loss_cls: 0.6721, decode.d1.loss_mask: 0.6433, decode.d1.loss_dice: 0.9408, decode.d2.loss_cls: 0.5951, decode.d2.loss_mask: 0.6396, decode.d2.loss_dice: 0.9026, decode.d3.loss_cls: 0.5571, decode.d3.loss_mask: 0.6345, decode.d3.loss_dice: 0.8903, decode.d4.loss_cls: 0.5449, decode.d4.loss_mask: 0.6331, decode.d4.loss_dice: 0.8947, decode.d5.loss_cls: 0.5348, decode.d5.loss_mask: 0.6305, decode.d5.loss_dice: 0.8880, decode.d6.loss_cls: 0.5312, decode.d6.loss_mask: 0.6305, decode.d6.loss_dice: 0.8859, decode.d7.loss_cls: 0.5238, decode.d7.loss_mask: 0.6331, decode.d7.loss_dice: 0.8899, decode.d8.loss_cls: 0.5243, decode.d8.loss_mask: 0.6325, decode.d8.loss_dice: 0.8859, loss: 29.0933
2022-11-30 04:51:37,869 - mmseg - INFO - Iter [6900/40000]	lr: 1.101e-07, eta: 1 day, 16:02:33, time: 4.111, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5192, decode.loss_mask: 0.6045, decode.loss_dice: 0.8909, decode.d0.loss_cls: 8.7447, decode.d0.loss_mask: 0.5785, decode.d0.loss_dice: 0.9597, decode.d1.loss_cls: 0.6732, decode.d1.loss_mask: 0.6232, decode.d1.loss_dice: 0.9420, decode.d2.loss_cls: 0.5918, decode.d2.loss_mask: 0.6120, decode.d2.loss_dice: 0.9052, decode.d3.loss_cls: 0.5499, decode.d3.loss_mask: 0.6060, decode.d3.loss_dice: 0.8965, decode.d4.loss_cls: 0.5375, decode.d4.loss_mask: 0.6049, decode.d4.loss_dice: 0.8951, decode.d5.loss_cls: 0.5267, decode.d5.loss_mask: 0.6063, decode.d5.loss_dice: 0.8888, decode.d6.loss_cls: 0.5216, decode.d6.loss_mask: 0.6038, decode.d6.loss_dice: 0.8908, decode.d7.loss_cls: 0.5182, decode.d7.loss_mask: 0.6034, decode.d7.loss_dice: 0.8915, decode.d8.loss_cls: 0.5198, decode.d8.loss_mask: 0.6027, decode.d8.loss_dice: 0.8924, loss: 28.8009
2022-11-30 04:55:03,316 - mmseg - INFO - Iter [6950/40000]	lr: 1.099e-07, eta: 1 day, 15:57:57, time: 4.109, data_time: 0.018, memory: 51902, decode.loss_cls: 0.5467, decode.loss_mask: 0.6276, decode.loss_dice: 0.9069, decode.d0.loss_cls: 8.7370, decode.d0.loss_mask: 0.6004, decode.d0.loss_dice: 0.9898, decode.d1.loss_cls: 0.7064, decode.d1.loss_mask: 0.6494, decode.d1.loss_dice: 0.9783, decode.d2.loss_cls: 0.6159, decode.d2.loss_mask: 0.6335, decode.d2.loss_dice: 0.9320, decode.d3.loss_cls: 0.5787, decode.d3.loss_mask: 0.6287, decode.d3.loss_dice: 0.9127, decode.d4.loss_cls: 0.5635, decode.d4.loss_mask: 0.6274, decode.d4.loss_dice: 0.9107, decode.d5.loss_cls: 0.5528, decode.d5.loss_mask: 0.6226, decode.d5.loss_dice: 0.9078, decode.d6.loss_cls: 0.5508, decode.d6.loss_mask: 0.6231, decode.d6.loss_dice: 0.9069, decode.d7.loss_cls: 0.5470, decode.d7.loss_mask: 0.6252, decode.d7.loss_dice: 0.9042, decode.d8.loss_cls: 0.5463, decode.d8.loss_mask: 0.6252, decode.d8.loss_dice: 0.9051, loss: 29.4627
2022-11-30 04:58:31,345 - mmseg - INFO - Saving checkpoint at 7000 iterations
2022-11-30 04:59:14,278 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 04:59:14,278 - mmseg - INFO - Iter [7000/40000]	lr: 1.098e-07, eta: 1 day, 15:56:56, time: 5.019, data_time: 0.064, memory: 51902, decode.loss_cls: 0.5240, decode.loss_mask: 0.5911, decode.loss_dice: 0.8903, decode.d0.loss_cls: 8.7352, decode.d0.loss_mask: 0.5666, decode.d0.loss_dice: 0.9676, decode.d1.loss_cls: 0.6904, decode.d1.loss_mask: 0.6162, decode.d1.loss_dice: 0.9560, decode.d2.loss_cls: 0.5998, decode.d2.loss_mask: 0.6009, decode.d2.loss_dice: 0.9118, decode.d3.loss_cls: 0.5563, decode.d3.loss_mask: 0.5955, decode.d3.loss_dice: 0.8966, decode.d4.loss_cls: 0.5465, decode.d4.loss_mask: 0.5906, decode.d4.loss_dice: 0.8954, decode.d5.loss_cls: 0.5312, decode.d5.loss_mask: 0.5906, decode.d5.loss_dice: 0.8936, decode.d6.loss_cls: 0.5253, decode.d6.loss_mask: 0.5928, decode.d6.loss_dice: 0.8898, decode.d7.loss_cls: 0.5196, decode.d7.loss_mask: 0.5946, decode.d7.loss_dice: 0.8943, decode.d8.loss_cls: 0.5200, decode.d8.loss_mask: 0.5908, decode.d8.loss_dice: 0.8904, loss: 28.7637
2022-11-30 05:02:12,278 - mmseg - INFO - per class results:
2022-11-30 05:02:12,283 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 82.73 | 89.99 |
|       building      | 85.02 | 91.12 |
|         sky         | 95.16 | 97.17 |
|        floor        | 85.35 |  91.1 |
|         tree        | 78.63 | 90.13 |
|       ceiling       | 86.99 | 92.31 |
|         road        | 87.33 | 92.61 |
|         bed         | 93.12 | 96.86 |
|      windowpane     | 67.82 | 82.72 |
|        grass        | 66.49 | 80.82 |
|       cabinet       | 62.33 | 75.86 |
|       sidewalk      | 71.78 | 85.62 |
|        person       | 88.03 | 93.26 |
|        earth        | 37.31 | 46.18 |
|         door        | 61.54 | 79.42 |
|        table        | 71.79 | 80.81 |
|       mountain      | 64.08 | 77.26 |
|        plant        |  56.8 | 71.81 |
|       curtain       | 80.12 | 91.54 |
|        chair        |  66.3 | 74.95 |
|         car         | 88.46 | 95.64 |
|        water        | 56.47 | 77.01 |
|       painting      | 81.72 | 91.28 |
|         sofa        | 86.61 | 92.21 |
|        shelf        |  44.0 |  54.4 |
|        house        | 45.36 | 57.21 |
|         sea         | 63.76 | 77.08 |
|        mirror       | 81.16 | 91.21 |
|         rug         |  70.2 | 82.36 |
|        field        | 32.39 | 71.69 |
|       armchair      | 61.16 | 87.85 |
|         seat        | 68.84 | 90.56 |
|        fence        | 55.63 |  81.0 |
|         desk        | 57.38 | 82.04 |
|         rock        | 63.98 | 77.66 |
|       wardrobe      | 51.71 | 78.71 |
|         lamp        | 79.08 | 89.26 |
|       bathtub       | 91.52 | 93.02 |
|       railing       | 44.26 | 64.98 |
|       cushion       | 75.93 | 89.11 |
|         base        | 40.75 |  74.7 |
|         box         | 40.57 | 53.58 |
|        column       | 60.83 | 73.84 |
|      signboard      | 45.07 | 68.11 |
|   chest of drawers  | 46.92 |  69.3 |
|       counter       | 54.73 | 65.21 |
|         sand        | 62.84 | 83.44 |
|         sink        | 81.01 | 85.91 |
|      skyscraper     | 39.72 | 49.03 |
|      fireplace      | 79.44 | 96.37 |
|     refrigerator    | 84.37 | 95.87 |
|      grandstand     | 39.85 | 75.97 |
|         path        | 21.03 | 24.54 |
|        stairs       | 31.45 | 37.35 |
|        runway       | 73.84 | 96.54 |
|         case        | 71.89 | 83.01 |
|      pool table     |  95.3 | 98.63 |
|        pillow       | 70.64 | 81.18 |
|     screen door     | 81.88 | 84.43 |
|       stairway      | 52.68 | 72.16 |
|        river        | 26.88 | 40.36 |
|        bridge       | 82.89 | 89.33 |
|       bookcase      | 29.49 | 58.87 |
|        blind        |  41.8 |  46.8 |
|     coffee table    | 71.28 | 89.04 |
|        toilet       | 91.23 | 96.68 |
|        flower       | 42.86 | 69.79 |
|         book        | 56.98 | 79.54 |
|         hill        | 16.46 | 24.12 |
|        bench        | 75.54 | 85.09 |
|      countertop     | 71.83 | 85.57 |
|        stove        | 84.91 | 89.14 |
|         palm        | 56.23 | 82.59 |
|    kitchen island   | 39.39 | 82.95 |
|       computer      | 81.67 | 90.45 |
|     swivel chair    | 53.39 | 74.89 |
|         boat        | 57.51 | 89.05 |
|         bar         | 57.03 | 61.38 |
|    arcade machine   | 90.22 | 98.66 |
|        hovel        |  40.3 |  78.8 |
|         bus         | 93.14 | 95.49 |
|        towel        | 79.44 | 94.26 |
|        light        | 64.19 | 78.13 |
|        truck        | 50.37 | 73.15 |
|        tower        | 30.82 | 58.69 |
|      chandelier     | 76.71 | 87.52 |
|        awning       | 30.53 | 50.76 |
|     streetlight     | 43.56 | 62.11 |
|        booth        | 37.55 | 38.04 |
| television receiver | 70.97 | 91.66 |
|       airplane      | 88.35 | 96.13 |
|      dirt track     | 18.66 | 21.37 |
|       apparel       | 49.13 |  92.7 |
|         pole        | 36.36 | 62.47 |
|         land        |  0.81 |  0.94 |
|      bannister      | 13.53 | 19.45 |
|      escalator      | 64.04 | 80.44 |
|       ottoman       | 57.22 | 80.84 |
|        bottle       | 55.27 | 76.76 |
|        buffet       | 11.59 | 12.26 |
|        poster       | 41.47 | 70.02 |
|        stage        | 35.13 | 58.36 |
|         van         | 45.76 | 57.99 |
|         ship        |  3.96 |  4.12 |
|       fountain      | 29.63 |  30.4 |
|    conveyer belt    | 87.39 | 97.67 |
|        canopy       | 41.77 | 54.99 |
|        washer       | 91.35 | 94.49 |
|      plaything      | 35.21 | 54.56 |
|    swimming pool    | 42.49 | 74.69 |
|        stool        | 55.95 | 84.61 |
|        barrel       | 53.24 | 64.79 |
|        basket       | 44.89 |  72.6 |
|      waterfall      | 53.13 | 57.11 |
|         tent        | 93.62 | 97.79 |
|         bag         |  39.0 | 56.97 |
|       minibike      | 80.66 | 93.55 |
|        cradle       | 91.23 | 97.09 |
|         oven        | 64.93 | 83.92 |
|         ball        | 71.21 | 91.38 |
|         food        | 67.09 | 81.79 |
|         step        | 24.28 | 43.57 |
|         tank        | 42.37 |  43.4 |
|      trade name     | 30.87 |  42.7 |
|      microwave      | 88.96 | 94.47 |
|         pot         | 55.56 |  67.4 |
|        animal       | 86.46 | 90.75 |
|       bicycle       | 60.55 | 83.69 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 64.73 | 91.64 |
|        screen       | 62.38 | 92.89 |
|       blanket       | 35.14 | 46.52 |
|      sculpture      | 66.42 | 93.56 |
|         hood        | 70.52 | 81.09 |
|        sconce       | 60.76 | 83.21 |
|         vase        | 58.24 |  82.2 |
|    traffic light    | 50.52 | 73.16 |
|         tray        | 28.42 |  41.6 |
|        ashcan       | 49.89 |  76.1 |
|         fan         | 73.41 | 85.25 |
|         pier        | 38.25 | 39.34 |
|      crt screen     |  5.41 | 14.52 |
|        plate        | 70.49 | 84.88 |
|       monitor       |  4.54 |  5.34 |
|    bulletin board   | 70.75 | 78.05 |
|        shower       | 23.93 | 30.21 |
|       radiator      | 72.36 | 88.22 |
|        glass        | 29.01 | 32.44 |
|        clock        | 60.02 | 73.06 |
|         flag        | 68.59 | 86.48 |
+---------------------+-------+-------+
2022-11-30 05:02:12,283 - mmseg - INFO - Summary:
2022-11-30 05:02:12,283 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 86.25 | 58.17 | 72.57 |
+-------+-------+-------+
2022-11-30 05:02:12,286 - mmseg - INFO - The previous best checkpoint /mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune/lr1.0_lrd0.9/best_mIoU_iter_6000.pth was removed
2022-11-30 05:02:54,533 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_7000.pth.
2022-11-30 05:02:54,533 - mmseg - INFO - Best mIoU is 0.5817 at 7000 iter.
2022-11-30 05:02:54,545 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 05:02:54,545 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8625, mIoU: 0.5817, mAcc: 0.7257, IoU.wall: 0.8273, IoU.building: 0.8502, IoU.sky: 0.9516, IoU.floor: 0.8535, IoU.tree: 0.7863, IoU.ceiling: 0.8699, IoU.road: 0.8733, IoU.bed : 0.9312, IoU.windowpane: 0.6782, IoU.grass: 0.6649, IoU.cabinet: 0.6233, IoU.sidewalk: 0.7178, IoU.person: 0.8803, IoU.earth: 0.3731, IoU.door: 0.6154, IoU.table: 0.7179, IoU.mountain: 0.6408, IoU.plant: 0.5680, IoU.curtain: 0.8012, IoU.chair: 0.6630, IoU.car: 0.8846, IoU.water: 0.5647, IoU.painting: 0.8172, IoU.sofa: 0.8661, IoU.shelf: 0.4400, IoU.house: 0.4536, IoU.sea: 0.6376, IoU.mirror: 0.8116, IoU.rug: 0.7020, IoU.field: 0.3239, IoU.armchair: 0.6116, IoU.seat: 0.6884, IoU.fence: 0.5563, IoU.desk: 0.5738, IoU.rock: 0.6398, IoU.wardrobe: 0.5171, IoU.lamp: 0.7908, IoU.bathtub: 0.9152, IoU.railing: 0.4426, IoU.cushion: 0.7593, IoU.base: 0.4075, IoU.box: 0.4057, IoU.column: 0.6083, IoU.signboard: 0.4507, IoU.chest of drawers: 0.4692, IoU.counter: 0.5473, IoU.sand: 0.6284, IoU.sink: 0.8101, IoU.skyscraper: 0.3972, IoU.fireplace: 0.7944, IoU.refrigerator: 0.8437, IoU.grandstand: 0.3985, IoU.path: 0.2103, IoU.stairs: 0.3145, IoU.runway: 0.7384, IoU.case: 0.7189, IoU.pool table: 0.9530, IoU.pillow: 0.7064, IoU.screen door: 0.8188, IoU.stairway: 0.5268, IoU.river: 0.2688, IoU.bridge: 0.8289, IoU.bookcase: 0.2949, IoU.blind: 0.4180, IoU.coffee table: 0.7128, IoU.toilet: 0.9123, IoU.flower: 0.4286, IoU.book: 0.5698, IoU.hill: 0.1646, IoU.bench: 0.7554, IoU.countertop: 0.7183, IoU.stove: 0.8491, IoU.palm: 0.5623, IoU.kitchen island: 0.3939, IoU.computer: 0.8167, IoU.swivel chair: 0.5339, IoU.boat: 0.5751, IoU.bar: 0.5703, IoU.arcade machine: 0.9022, IoU.hovel: 0.4030, IoU.bus: 0.9314, IoU.towel: 0.7944, IoU.light: 0.6419, IoU.truck: 0.5037, IoU.tower: 0.3082, IoU.chandelier: 0.7671, IoU.awning: 0.3053, IoU.streetlight: 0.4356, IoU.booth: 0.3755, IoU.television receiver: 0.7097, IoU.airplane: 0.8835, IoU.dirt track: 0.1866, IoU.apparel: 0.4913, IoU.pole: 0.3636, IoU.land: 0.0081, IoU.bannister: 0.1353, IoU.escalator: 0.6404, IoU.ottoman: 0.5722, IoU.bottle: 0.5527, IoU.buffet: 0.1159, IoU.poster: 0.4147, IoU.stage: 0.3513, IoU.van: 0.4576, IoU.ship: 0.0396, IoU.fountain: 0.2963, IoU.conveyer belt: 0.8739, IoU.canopy: 0.4177, IoU.washer: 0.9135, IoU.plaything: 0.3521, IoU.swimming pool: 0.4249, IoU.stool: 0.5595, IoU.barrel: 0.5324, IoU.basket: 0.4489, IoU.waterfall: 0.5313, IoU.tent: 0.9362, IoU.bag: 0.3900, IoU.minibike: 0.8066, IoU.cradle: 0.9123, IoU.oven: 0.6493, IoU.ball: 0.7121, IoU.food: 0.6709, IoU.step: 0.2428, IoU.tank: 0.4237, IoU.trade name: 0.3087, IoU.microwave: 0.8896, IoU.pot: 0.5556, IoU.animal: 0.8646, IoU.bicycle: 0.6055, IoU.lake: 0.0000, IoU.dishwasher: 0.6473, IoU.screen: 0.6238, IoU.blanket: 0.3514, IoU.sculpture: 0.6642, IoU.hood: 0.7052, IoU.sconce: 0.6076, IoU.vase: 0.5824, IoU.traffic light: 0.5052, IoU.tray: 0.2842, IoU.ashcan: 0.4989, IoU.fan: 0.7341, IoU.pier: 0.3825, IoU.crt screen: 0.0541, IoU.plate: 0.7049, IoU.monitor: 0.0454, IoU.bulletin board: 0.7075, IoU.shower: 0.2393, IoU.radiator: 0.7236, IoU.glass: 0.2901, IoU.clock: 0.6002, IoU.flag: 0.6859, Acc.wall: 0.8999, Acc.building: 0.9112, Acc.sky: 0.9717, Acc.floor: 0.9110, Acc.tree: 0.9013, Acc.ceiling: 0.9231, Acc.road: 0.9261, Acc.bed : 0.9686, Acc.windowpane: 0.8272, Acc.grass: 0.8082, Acc.cabinet: 0.7586, Acc.sidewalk: 0.8562, Acc.person: 0.9326, Acc.earth: 0.4618, Acc.door: 0.7942, Acc.table: 0.8081, Acc.mountain: 0.7726, Acc.plant: 0.7181, Acc.curtain: 0.9154, Acc.chair: 0.7495, Acc.car: 0.9564, Acc.water: 0.7701, Acc.painting: 0.9128, Acc.sofa: 0.9221, Acc.shelf: 0.5440, Acc.house: 0.5721, Acc.sea: 0.7708, Acc.mirror: 0.9121, Acc.rug: 0.8236, Acc.field: 0.7169, Acc.armchair: 0.8785, Acc.seat: 0.9056, Acc.fence: 0.8100, Acc.desk: 0.8204, Acc.rock: 0.7766, Acc.wardrobe: 0.7871, Acc.lamp: 0.8926, Acc.bathtub: 0.9302, Acc.railing: 0.6498, Acc.cushion: 0.8911, Acc.base: 0.7470, Acc.box: 0.5358, Acc.column: 0.7384, Acc.signboard: 0.6811, Acc.chest of drawers: 0.6930, Acc.counter: 0.6521, Acc.sand: 0.8344, Acc.sink: 0.8591, Acc.skyscraper: 0.4903, Acc.fireplace: 0.9637, Acc.refrigerator: 0.9587, Acc.grandstand: 0.7597, Acc.path: 0.2454, Acc.stairs: 0.3735, Acc.runway: 0.9654, Acc.case: 0.8301, Acc.pool table: 0.9863, Acc.pillow: 0.8118, Acc.screen door: 0.8443, Acc.stairway: 0.7216, Acc.river: 0.4036, Acc.bridge: 0.8933, Acc.bookcase: 0.5887, Acc.blind: 0.4680, Acc.coffee table: 0.8904, Acc.toilet: 0.9668, Acc.flower: 0.6979, Acc.book: 0.7954, Acc.hill: 0.2412, Acc.bench: 0.8509, Acc.countertop: 0.8557, Acc.stove: 0.8914, Acc.palm: 0.8259, Acc.kitchen island: 0.8295, Acc.computer: 0.9045, Acc.swivel chair: 0.7489, Acc.boat: 0.8905, Acc.bar: 0.6138, Acc.arcade machine: 0.9866, Acc.hovel: 0.7880, Acc.bus: 0.9549, Acc.towel: 0.9426, Acc.light: 0.7813, Acc.truck: 0.7315, Acc.tower: 0.5869, Acc.chandelier: 0.8752, Acc.awning: 0.5076, Acc.streetlight: 0.6211, Acc.booth: 0.3804, Acc.television receiver: 0.9166, Acc.airplane: 0.9613, Acc.dirt track: 0.2137, Acc.apparel: 0.9270, Acc.pole: 0.6247, Acc.land: 0.0094, Acc.bannister: 0.1945, Acc.escalator: 0.8044, Acc.ottoman: 0.8084, Acc.bottle: 0.7676, Acc.buffet: 0.1226, Acc.poster: 0.7002, Acc.stage: 0.5836, Acc.van: 0.5799, Acc.ship: 0.0412, Acc.fountain: 0.3040, Acc.conveyer belt: 0.9767, Acc.canopy: 0.5499, Acc.washer: 0.9449, Acc.plaything: 0.5456, Acc.swimming pool: 0.7469, Acc.stool: 0.8461, Acc.barrel: 0.6479, Acc.basket: 0.7260, Acc.waterfall: 0.5711, Acc.tent: 0.9779, Acc.bag: 0.5697, Acc.minibike: 0.9355, Acc.cradle: 0.9709, Acc.oven: 0.8392, Acc.ball: 0.9138, Acc.food: 0.8179, Acc.step: 0.4357, Acc.tank: 0.4340, Acc.trade name: 0.4270, Acc.microwave: 0.9447, Acc.pot: 0.6740, Acc.animal: 0.9075, Acc.bicycle: 0.8369, Acc.lake: 0.0000, Acc.dishwasher: 0.9164, Acc.screen: 0.9289, Acc.blanket: 0.4652, Acc.sculpture: 0.9356, Acc.hood: 0.8109, Acc.sconce: 0.8321, Acc.vase: 0.8220, Acc.traffic light: 0.7316, Acc.tray: 0.4160, Acc.ashcan: 0.7610, Acc.fan: 0.8525, Acc.pier: 0.3934, Acc.crt screen: 0.1452, Acc.plate: 0.8488, Acc.monitor: 0.0534, Acc.bulletin board: 0.7805, Acc.shower: 0.3021, Acc.radiator: 0.8822, Acc.glass: 0.3244, Acc.clock: 0.7306, Acc.flag: 0.8648
2022-11-30 05:06:20,714 - mmseg - INFO - Iter [7050/40000]	lr: 1.096e-07, eta: 1 day, 16:09:33, time: 8.529, data_time: 4.425, memory: 51902, decode.loss_cls: 0.5265, decode.loss_mask: 0.6216, decode.loss_dice: 0.9009, decode.d0.loss_cls: 8.7148, decode.d0.loss_mask: 0.5878, decode.d0.loss_dice: 0.9700, decode.d1.loss_cls: 0.6877, decode.d1.loss_mask: 0.6348, decode.d1.loss_dice: 0.9538, decode.d2.loss_cls: 0.5979, decode.d2.loss_mask: 0.6250, decode.d2.loss_dice: 0.9166, decode.d3.loss_cls: 0.5608, decode.d3.loss_mask: 0.6195, decode.d3.loss_dice: 0.9008, decode.d4.loss_cls: 0.5491, decode.d4.loss_mask: 0.6180, decode.d4.loss_dice: 0.9013, decode.d5.loss_cls: 0.5395, decode.d5.loss_mask: 0.6182, decode.d5.loss_dice: 0.8993, decode.d6.loss_cls: 0.5306, decode.d6.loss_mask: 0.6197, decode.d6.loss_dice: 0.8993, decode.d7.loss_cls: 0.5292, decode.d7.loss_mask: 0.6211, decode.d7.loss_dice: 0.9040, decode.d8.loss_cls: 0.5246, decode.d8.loss_mask: 0.6210, decode.d8.loss_dice: 0.8996, loss: 29.0929
2022-11-30 05:09:46,179 - mmseg - INFO - Iter [7100/40000]	lr: 1.094e-07, eta: 1 day, 16:04:49, time: 4.109, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5250, decode.loss_mask: 0.6231, decode.loss_dice: 0.9016, decode.d0.loss_cls: 8.7037, decode.d0.loss_mask: 0.5989, decode.d0.loss_dice: 0.9767, decode.d1.loss_cls: 0.6928, decode.d1.loss_mask: 0.6423, decode.d1.loss_dice: 0.9586, decode.d2.loss_cls: 0.6102, decode.d2.loss_mask: 0.6291, decode.d2.loss_dice: 0.9215, decode.d3.loss_cls: 0.5670, decode.d3.loss_mask: 0.6242, decode.d3.loss_dice: 0.9051, decode.d4.loss_cls: 0.5507, decode.d4.loss_mask: 0.6241, decode.d4.loss_dice: 0.9017, decode.d5.loss_cls: 0.5344, decode.d5.loss_mask: 0.6229, decode.d5.loss_dice: 0.9016, decode.d6.loss_cls: 0.5311, decode.d6.loss_mask: 0.6208, decode.d6.loss_dice: 0.8961, decode.d7.loss_cls: 0.5254, decode.d7.loss_mask: 0.6226, decode.d7.loss_dice: 0.9007, decode.d8.loss_cls: 0.5232, decode.d8.loss_mask: 0.6227, decode.d8.loss_dice: 0.8985, loss: 29.1565
2022-11-30 05:13:11,793 - mmseg - INFO - Iter [7150/40000]	lr: 1.093e-07, eta: 1 day, 16:00:07, time: 4.112, data_time: 0.018, memory: 51902, decode.loss_cls: 0.5203, decode.loss_mask: 0.5979, decode.loss_dice: 0.8903, decode.d0.loss_cls: 8.6983, decode.d0.loss_mask: 0.5721, decode.d0.loss_dice: 0.9723, decode.d1.loss_cls: 0.6840, decode.d1.loss_mask: 0.6167, decode.d1.loss_dice: 0.9575, decode.d2.loss_cls: 0.5994, decode.d2.loss_mask: 0.6041, decode.d2.loss_dice: 0.9114, decode.d3.loss_cls: 0.5582, decode.d3.loss_mask: 0.5964, decode.d3.loss_dice: 0.8989, decode.d4.loss_cls: 0.5442, decode.d4.loss_mask: 0.5973, decode.d4.loss_dice: 0.8995, decode.d5.loss_cls: 0.5319, decode.d5.loss_mask: 0.5942, decode.d5.loss_dice: 0.8948, decode.d6.loss_cls: 0.5280, decode.d6.loss_mask: 0.5951, decode.d6.loss_dice: 0.8906, decode.d7.loss_cls: 0.5279, decode.d7.loss_mask: 0.5962, decode.d7.loss_dice: 0.8911, decode.d8.loss_cls: 0.5215, decode.d8.loss_mask: 0.5972, decode.d8.loss_dice: 0.8899, loss: 28.7772
2022-11-30 05:16:37,567 - mmseg - INFO - Iter [7200/40000]	lr: 1.091e-07, eta: 1 day, 15:55:27, time: 4.115, data_time: 0.018, memory: 51902, decode.loss_cls: 0.5329, decode.loss_mask: 0.6312, decode.loss_dice: 0.9056, decode.d0.loss_cls: 8.6839, decode.d0.loss_mask: 0.6007, decode.d0.loss_dice: 0.9781, decode.d1.loss_cls: 0.6863, decode.d1.loss_mask: 0.6550, decode.d1.loss_dice: 0.9661, decode.d2.loss_cls: 0.6014, decode.d2.loss_mask: 0.6390, decode.d2.loss_dice: 0.9229, decode.d3.loss_cls: 0.5535, decode.d3.loss_mask: 0.6380, decode.d3.loss_dice: 0.9082, decode.d4.loss_cls: 0.5499, decode.d4.loss_mask: 0.6341, decode.d4.loss_dice: 0.9067, decode.d5.loss_cls: 0.5408, decode.d5.loss_mask: 0.6308, decode.d5.loss_dice: 0.9049, decode.d6.loss_cls: 0.5370, decode.d6.loss_mask: 0.6303, decode.d6.loss_dice: 0.9011, decode.d7.loss_cls: 0.5329, decode.d7.loss_mask: 0.6294, decode.d7.loss_dice: 0.9003, decode.d8.loss_cls: 0.5321, decode.d8.loss_mask: 0.6289, decode.d8.loss_dice: 0.8994, loss: 29.2612
2022-11-30 05:20:02,868 - mmseg - INFO - Iter [7250/40000]	lr: 1.089e-07, eta: 1 day, 15:50:45, time: 4.106, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5083, decode.loss_mask: 0.6209, decode.loss_dice: 0.8849, decode.d0.loss_cls: 8.6515, decode.d0.loss_mask: 0.5918, decode.d0.loss_dice: 0.9571, decode.d1.loss_cls: 0.6517, decode.d1.loss_mask: 0.6396, decode.d1.loss_dice: 0.9508, decode.d2.loss_cls: 0.5716, decode.d2.loss_mask: 0.6288, decode.d2.loss_dice: 0.9025, decode.d3.loss_cls: 0.5340, decode.d3.loss_mask: 0.6245, decode.d3.loss_dice: 0.8940, decode.d4.loss_cls: 0.5258, decode.d4.loss_mask: 0.6252, decode.d4.loss_dice: 0.8892, decode.d5.loss_cls: 0.5159, decode.d5.loss_mask: 0.6204, decode.d5.loss_dice: 0.8858, decode.d6.loss_cls: 0.5137, decode.d6.loss_mask: 0.6177, decode.d6.loss_dice: 0.8817, decode.d7.loss_cls: 0.5095, decode.d7.loss_mask: 0.6208, decode.d7.loss_dice: 0.8869, decode.d8.loss_cls: 0.5110, decode.d8.loss_mask: 0.6213, decode.d8.loss_dice: 0.8860, loss: 28.7228
2022-11-30 05:23:28,571 - mmseg - INFO - Iter [7300/40000]	lr: 1.088e-07, eta: 1 day, 15:46:07, time: 4.114, data_time: 0.018, memory: 51902, decode.loss_cls: 0.5187, decode.loss_mask: 0.6276, decode.loss_dice: 0.8993, decode.d0.loss_cls: 8.6508, decode.d0.loss_mask: 0.5971, decode.d0.loss_dice: 0.9692, decode.d1.loss_cls: 0.6679, decode.d1.loss_mask: 0.6464, decode.d1.loss_dice: 0.9588, decode.d2.loss_cls: 0.5864, decode.d2.loss_mask: 0.6323, decode.d2.loss_dice: 0.9208, decode.d3.loss_cls: 0.5527, decode.d3.loss_mask: 0.6290, decode.d3.loss_dice: 0.9040, decode.d4.loss_cls: 0.5397, decode.d4.loss_mask: 0.6262, decode.d4.loss_dice: 0.9026, decode.d5.loss_cls: 0.5318, decode.d5.loss_mask: 0.6235, decode.d5.loss_dice: 0.9033, decode.d6.loss_cls: 0.5224, decode.d6.loss_mask: 0.6241, decode.d6.loss_dice: 0.8931, decode.d7.loss_cls: 0.5194, decode.d7.loss_mask: 0.6273, decode.d7.loss_dice: 0.8988, decode.d8.loss_cls: 0.5167, decode.d8.loss_mask: 0.6282, decode.d8.loss_dice: 0.9004, loss: 29.0184
2022-11-30 05:26:54,095 - mmseg - INFO - Iter [7350/40000]	lr: 1.086e-07, eta: 1 day, 15:41:28, time: 4.110, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5189, decode.loss_mask: 0.5989, decode.loss_dice: 0.8927, decode.d0.loss_cls: 8.6458, decode.d0.loss_mask: 0.5707, decode.d0.loss_dice: 0.9633, decode.d1.loss_cls: 0.6711, decode.d1.loss_mask: 0.6213, decode.d1.loss_dice: 0.9503, decode.d2.loss_cls: 0.5895, decode.d2.loss_mask: 0.6092, decode.d2.loss_dice: 0.9091, decode.d3.loss_cls: 0.5490, decode.d3.loss_mask: 0.6036, decode.d3.loss_dice: 0.8950, decode.d4.loss_cls: 0.5382, decode.d4.loss_mask: 0.5987, decode.d4.loss_dice: 0.8912, decode.d5.loss_cls: 0.5260, decode.d5.loss_mask: 0.5990, decode.d5.loss_dice: 0.8897, decode.d6.loss_cls: 0.5212, decode.d6.loss_mask: 0.5995, decode.d6.loss_dice: 0.8855, decode.d7.loss_cls: 0.5183, decode.d7.loss_mask: 0.5977, decode.d7.loss_dice: 0.8921, decode.d8.loss_cls: 0.5194, decode.d8.loss_mask: 0.5975, decode.d8.loss_dice: 0.8898, loss: 28.6521
2022-11-30 05:30:19,718 - mmseg - INFO - Iter [7400/40000]	lr: 1.084e-07, eta: 1 day, 15:36:51, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5273, decode.loss_mask: 0.6200, decode.loss_dice: 0.8865, decode.d0.loss_cls: 8.6294, decode.d0.loss_mask: 0.5898, decode.d0.loss_dice: 0.9704, decode.d1.loss_cls: 0.6659, decode.d1.loss_mask: 0.6399, decode.d1.loss_dice: 0.9540, decode.d2.loss_cls: 0.5898, decode.d2.loss_mask: 0.6245, decode.d2.loss_dice: 0.9072, decode.d3.loss_cls: 0.5576, decode.d3.loss_mask: 0.6201, decode.d3.loss_dice: 0.8951, decode.d4.loss_cls: 0.5477, decode.d4.loss_mask: 0.6157, decode.d4.loss_dice: 0.8914, decode.d5.loss_cls: 0.5347, decode.d5.loss_mask: 0.6152, decode.d5.loss_dice: 0.8870, decode.d6.loss_cls: 0.5318, decode.d6.loss_mask: 0.6162, decode.d6.loss_dice: 0.8809, decode.d7.loss_cls: 0.5260, decode.d7.loss_mask: 0.6184, decode.d7.loss_dice: 0.8868, decode.d8.loss_cls: 0.5291, decode.d8.loss_mask: 0.6190, decode.d8.loss_dice: 0.8853, loss: 28.8627
2022-11-30 05:33:45,363 - mmseg - INFO - Iter [7450/40000]	lr: 1.083e-07, eta: 1 day, 15:32:15, time: 4.113, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5456, decode.loss_mask: 0.6318, decode.loss_dice: 0.9175, decode.d0.loss_cls: 8.6152, decode.d0.loss_mask: 0.5997, decode.d0.loss_dice: 0.9947, decode.d1.loss_cls: 0.6985, decode.d1.loss_mask: 0.6467, decode.d1.loss_dice: 0.9768, decode.d2.loss_cls: 0.6167, decode.d2.loss_mask: 0.6347, decode.d2.loss_dice: 0.9349, decode.d3.loss_cls: 0.5718, decode.d3.loss_mask: 0.6337, decode.d3.loss_dice: 0.9226, decode.d4.loss_cls: 0.5648, decode.d4.loss_mask: 0.6324, decode.d4.loss_dice: 0.9223, decode.d5.loss_cls: 0.5530, decode.d5.loss_mask: 0.6298, decode.d5.loss_dice: 0.9208, decode.d6.loss_cls: 0.5453, decode.d6.loss_mask: 0.6271, decode.d6.loss_dice: 0.9130, decode.d7.loss_cls: 0.5476, decode.d7.loss_mask: 0.6273, decode.d7.loss_dice: 0.9165, decode.d8.loss_cls: 0.5461, decode.d8.loss_mask: 0.6283, decode.d8.loss_dice: 0.9173, loss: 29.4329
2022-11-30 05:37:10,814 - mmseg - INFO - Iter [7500/40000]	lr: 1.081e-07, eta: 1 day, 15:27:39, time: 4.109, data_time: 0.018, memory: 51902, decode.loss_cls: 0.5162, decode.loss_mask: 0.6252, decode.loss_dice: 0.8932, decode.d0.loss_cls: 8.6091, decode.d0.loss_mask: 0.5981, decode.d0.loss_dice: 0.9700, decode.d1.loss_cls: 0.6595, decode.d1.loss_mask: 0.6452, decode.d1.loss_dice: 0.9558, decode.d2.loss_cls: 0.5812, decode.d2.loss_mask: 0.6374, decode.d2.loss_dice: 0.9175, decode.d3.loss_cls: 0.5447, decode.d3.loss_mask: 0.6283, decode.d3.loss_dice: 0.9008, decode.d4.loss_cls: 0.5348, decode.d4.loss_mask: 0.6279, decode.d4.loss_dice: 0.9009, decode.d5.loss_cls: 0.5195, decode.d5.loss_mask: 0.6274, decode.d5.loss_dice: 0.8974, decode.d6.loss_cls: 0.5192, decode.d6.loss_mask: 0.6260, decode.d6.loss_dice: 0.8937, decode.d7.loss_cls: 0.5132, decode.d7.loss_mask: 0.6286, decode.d7.loss_dice: 0.8968, decode.d8.loss_cls: 0.5180, decode.d8.loss_mask: 0.6288, decode.d8.loss_dice: 0.8950, loss: 28.9095
2022-11-30 05:40:36,725 - mmseg - INFO - Iter [7550/40000]	lr: 1.079e-07, eta: 1 day, 15:23:07, time: 4.118, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5234, decode.loss_mask: 0.6200, decode.loss_dice: 0.8953, decode.d0.loss_cls: 8.5938, decode.d0.loss_mask: 0.5888, decode.d0.loss_dice: 0.9805, decode.d1.loss_cls: 0.6789, decode.d1.loss_mask: 0.6368, decode.d1.loss_dice: 0.9575, decode.d2.loss_cls: 0.6002, decode.d2.loss_mask: 0.6242, decode.d2.loss_dice: 0.9115, decode.d3.loss_cls: 0.5524, decode.d3.loss_mask: 0.6217, decode.d3.loss_dice: 0.9034, decode.d4.loss_cls: 0.5473, decode.d4.loss_mask: 0.6174, decode.d4.loss_dice: 0.9023, decode.d5.loss_cls: 0.5304, decode.d5.loss_mask: 0.6182, decode.d5.loss_dice: 0.8957, decode.d6.loss_cls: 0.5287, decode.d6.loss_mask: 0.6190, decode.d6.loss_dice: 0.8930, decode.d7.loss_cls: 0.5287, decode.d7.loss_mask: 0.6201, decode.d7.loss_dice: 0.8949, decode.d8.loss_cls: 0.5276, decode.d8.loss_mask: 0.6185, decode.d8.loss_dice: 0.8943, loss: 28.9241
2022-11-30 05:44:04,488 - mmseg - INFO - Iter [7600/40000]	lr: 1.078e-07, eta: 1 day, 15:18:42, time: 4.155, data_time: 0.064, memory: 51902, decode.loss_cls: 0.5144, decode.loss_mask: 0.6243, decode.loss_dice: 0.9068, decode.d0.loss_cls: 8.5772, decode.d0.loss_mask: 0.5969, decode.d0.loss_dice: 0.9885, decode.d1.loss_cls: 0.6575, decode.d1.loss_mask: 0.6448, decode.d1.loss_dice: 0.9708, decode.d2.loss_cls: 0.5789, decode.d2.loss_mask: 0.6366, decode.d2.loss_dice: 0.9341, decode.d3.loss_cls: 0.5460, decode.d3.loss_mask: 0.6261, decode.d3.loss_dice: 0.9114, decode.d4.loss_cls: 0.5323, decode.d4.loss_mask: 0.6215, decode.d4.loss_dice: 0.9075, decode.d5.loss_cls: 0.5223, decode.d5.loss_mask: 0.6233, decode.d5.loss_dice: 0.9086, decode.d6.loss_cls: 0.5172, decode.d6.loss_mask: 0.6234, decode.d6.loss_dice: 0.9036, decode.d7.loss_cls: 0.5142, decode.d7.loss_mask: 0.6235, decode.d7.loss_dice: 0.9028, decode.d8.loss_cls: 0.5153, decode.d8.loss_mask: 0.6204, decode.d8.loss_dice: 0.9036, loss: 28.9540
2022-11-30 05:47:30,104 - mmseg - INFO - Iter [7650/40000]	lr: 1.076e-07, eta: 1 day, 15:14:10, time: 4.112, data_time: 0.018, memory: 51902, decode.loss_cls: 0.5121, decode.loss_mask: 0.6085, decode.loss_dice: 0.8800, decode.d0.loss_cls: 8.5649, decode.d0.loss_mask: 0.5884, decode.d0.loss_dice: 0.9539, decode.d1.loss_cls: 0.6640, decode.d1.loss_mask: 0.6250, decode.d1.loss_dice: 0.9364, decode.d2.loss_cls: 0.5834, decode.d2.loss_mask: 0.6145, decode.d2.loss_dice: 0.9043, decode.d3.loss_cls: 0.5420, decode.d3.loss_mask: 0.6120, decode.d3.loss_dice: 0.8897, decode.d4.loss_cls: 0.5336, decode.d4.loss_mask: 0.6119, decode.d4.loss_dice: 0.8894, decode.d5.loss_cls: 0.5213, decode.d5.loss_mask: 0.6098, decode.d5.loss_dice: 0.8868, decode.d6.loss_cls: 0.5171, decode.d6.loss_mask: 0.6067, decode.d6.loss_dice: 0.8835, decode.d7.loss_cls: 0.5091, decode.d7.loss_mask: 0.6082, decode.d7.loss_dice: 0.8862, decode.d8.loss_cls: 0.5108, decode.d8.loss_mask: 0.6094, decode.d8.loss_dice: 0.8821, loss: 28.5449
2022-11-30 05:50:55,581 - mmseg - INFO - Iter [7700/40000]	lr: 1.074e-07, eta: 1 day, 15:09:38, time: 4.110, data_time: 0.018, memory: 51902, decode.loss_cls: 0.5121, decode.loss_mask: 0.6173, decode.loss_dice: 0.8949, decode.d0.loss_cls: 8.5499, decode.d0.loss_mask: 0.5900, decode.d0.loss_dice: 0.9611, decode.d1.loss_cls: 0.6553, decode.d1.loss_mask: 0.6377, decode.d1.loss_dice: 0.9397, decode.d2.loss_cls: 0.5735, decode.d2.loss_mask: 0.6223, decode.d2.loss_dice: 0.9109, decode.d3.loss_cls: 0.5342, decode.d3.loss_mask: 0.6193, decode.d3.loss_dice: 0.8961, decode.d4.loss_cls: 0.5212, decode.d4.loss_mask: 0.6201, decode.d4.loss_dice: 0.8942, decode.d5.loss_cls: 0.5158, decode.d5.loss_mask: 0.6163, decode.d5.loss_dice: 0.8929, decode.d6.loss_cls: 0.5113, decode.d6.loss_mask: 0.6173, decode.d6.loss_dice: 0.8916, decode.d7.loss_cls: 0.5088, decode.d7.loss_mask: 0.6160, decode.d7.loss_dice: 0.8977, decode.d8.loss_cls: 0.5092, decode.d8.loss_mask: 0.6179, decode.d8.loss_dice: 0.8966, loss: 28.6413
2022-11-30 05:54:21,201 - mmseg - INFO - Iter [7750/40000]	lr: 1.073e-07, eta: 1 day, 15:05:07, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5423, decode.loss_mask: 0.6175, decode.loss_dice: 0.8855, decode.d0.loss_cls: 8.5542, decode.d0.loss_mask: 0.5856, decode.d0.loss_dice: 0.9719, decode.d1.loss_cls: 0.6974, decode.d1.loss_mask: 0.6337, decode.d1.loss_dice: 0.9542, decode.d2.loss_cls: 0.6100, decode.d2.loss_mask: 0.6193, decode.d2.loss_dice: 0.9070, decode.d3.loss_cls: 0.5693, decode.d3.loss_mask: 0.6158, decode.d3.loss_dice: 0.8906, decode.d4.loss_cls: 0.5598, decode.d4.loss_mask: 0.6159, decode.d4.loss_dice: 0.8919, decode.d5.loss_cls: 0.5471, decode.d5.loss_mask: 0.6144, decode.d5.loss_dice: 0.8871, decode.d6.loss_cls: 0.5441, decode.d6.loss_mask: 0.6174, decode.d6.loss_dice: 0.8869, decode.d7.loss_cls: 0.5422, decode.d7.loss_mask: 0.6204, decode.d7.loss_dice: 0.8899, decode.d8.loss_cls: 0.5420, decode.d8.loss_mask: 0.6177, decode.d8.loss_dice: 0.8842, loss: 28.9156
2022-11-30 05:57:46,790 - mmseg - INFO - Iter [7800/40000]	lr: 1.071e-07, eta: 1 day, 15:00:37, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5130, decode.loss_mask: 0.6202, decode.loss_dice: 0.8873, decode.d0.loss_cls: 8.5420, decode.d0.loss_mask: 0.5914, decode.d0.loss_dice: 0.9650, decode.d1.loss_cls: 0.6694, decode.d1.loss_mask: 0.6400, decode.d1.loss_dice: 0.9479, decode.d2.loss_cls: 0.5823, decode.d2.loss_mask: 0.6281, decode.d2.loss_dice: 0.9087, decode.d3.loss_cls: 0.5391, decode.d3.loss_mask: 0.6217, decode.d3.loss_dice: 0.8901, decode.d4.loss_cls: 0.5299, decode.d4.loss_mask: 0.6228, decode.d4.loss_dice: 0.8909, decode.d5.loss_cls: 0.5220, decode.d5.loss_mask: 0.6202, decode.d5.loss_dice: 0.8936, decode.d6.loss_cls: 0.5168, decode.d6.loss_mask: 0.6193, decode.d6.loss_dice: 0.8848, decode.d7.loss_cls: 0.5126, decode.d7.loss_mask: 0.6194, decode.d7.loss_dice: 0.8904, decode.d8.loss_cls: 0.5106, decode.d8.loss_mask: 0.6204, decode.d8.loss_dice: 0.8869, loss: 28.6868
2022-11-30 06:01:12,489 - mmseg - INFO - Iter [7850/40000]	lr: 1.069e-07, eta: 1 day, 14:56:08, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5209, decode.loss_mask: 0.6168, decode.loss_dice: 0.8940, decode.d0.loss_cls: 8.5278, decode.d0.loss_mask: 0.5844, decode.d0.loss_dice: 0.9640, decode.d1.loss_cls: 0.6710, decode.d1.loss_mask: 0.6354, decode.d1.loss_dice: 0.9602, decode.d2.loss_cls: 0.5851, decode.d2.loss_mask: 0.6239, decode.d2.loss_dice: 0.9224, decode.d3.loss_cls: 0.5457, decode.d3.loss_mask: 0.6194, decode.d3.loss_dice: 0.9010, decode.d4.loss_cls: 0.5393, decode.d4.loss_mask: 0.6189, decode.d4.loss_dice: 0.9012, decode.d5.loss_cls: 0.5258, decode.d5.loss_mask: 0.6176, decode.d5.loss_dice: 0.8995, decode.d6.loss_cls: 0.5223, decode.d6.loss_mask: 0.6146, decode.d6.loss_dice: 0.8938, decode.d7.loss_cls: 0.5203, decode.d7.loss_mask: 0.6165, decode.d7.loss_dice: 0.8983, decode.d8.loss_cls: 0.5220, decode.d8.loss_mask: 0.6158, decode.d8.loss_dice: 0.8957, loss: 28.7735
2022-11-30 06:04:37,663 - mmseg - INFO - Iter [7900/40000]	lr: 1.068e-07, eta: 1 day, 14:51:38, time: 4.103, data_time: 0.020, memory: 51902, decode.loss_cls: 0.5011, decode.loss_mask: 0.6056, decode.loss_dice: 0.8916, decode.d0.loss_cls: 8.5153, decode.d0.loss_mask: 0.5781, decode.d0.loss_dice: 0.9645, decode.d1.loss_cls: 0.6590, decode.d1.loss_mask: 0.6284, decode.d1.loss_dice: 0.9554, decode.d2.loss_cls: 0.5747, decode.d2.loss_mask: 0.6156, decode.d2.loss_dice: 0.9123, decode.d3.loss_cls: 0.5335, decode.d3.loss_mask: 0.6097, decode.d3.loss_dice: 0.8999, decode.d4.loss_cls: 0.5178, decode.d4.loss_mask: 0.6074, decode.d4.loss_dice: 0.8995, decode.d5.loss_cls: 0.5130, decode.d5.loss_mask: 0.6075, decode.d5.loss_dice: 0.8986, decode.d6.loss_cls: 0.5053, decode.d6.loss_mask: 0.6054, decode.d6.loss_dice: 0.8927, decode.d7.loss_cls: 0.5017, decode.d7.loss_mask: 0.6078, decode.d7.loss_dice: 0.8930, decode.d8.loss_cls: 0.5011, decode.d8.loss_mask: 0.6073, decode.d8.loss_dice: 0.8903, loss: 28.4933
2022-11-30 06:08:03,756 - mmseg - INFO - Iter [7950/40000]	lr: 1.066e-07, eta: 1 day, 14:47:13, time: 4.122, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5229, decode.loss_mask: 0.6080, decode.loss_dice: 0.8850, decode.d0.loss_cls: 8.4947, decode.d0.loss_mask: 0.5817, decode.d0.loss_dice: 0.9701, decode.d1.loss_cls: 0.6660, decode.d1.loss_mask: 0.6325, decode.d1.loss_dice: 0.9507, decode.d2.loss_cls: 0.5932, decode.d2.loss_mask: 0.6141, decode.d2.loss_dice: 0.9058, decode.d3.loss_cls: 0.5561, decode.d3.loss_mask: 0.6099, decode.d3.loss_dice: 0.8909, decode.d4.loss_cls: 0.5442, decode.d4.loss_mask: 0.6071, decode.d4.loss_dice: 0.8886, decode.d5.loss_cls: 0.5327, decode.d5.loss_mask: 0.6053, decode.d5.loss_dice: 0.8877, decode.d6.loss_cls: 0.5299, decode.d6.loss_mask: 0.6030, decode.d6.loss_dice: 0.8849, decode.d7.loss_cls: 0.5280, decode.d7.loss_mask: 0.6024, decode.d7.loss_dice: 0.8879, decode.d8.loss_cls: 0.5244, decode.d8.loss_mask: 0.6061, decode.d8.loss_dice: 0.8906, loss: 28.6043
2022-11-30 06:11:29,439 - mmseg - INFO - Saving checkpoint at 8000 iterations
2022-11-30 06:12:12,159 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 06:12:12,160 - mmseg - INFO - Iter [8000/40000]	lr: 1.064e-07, eta: 1 day, 14:45:37, time: 4.968, data_time: 0.018, memory: 51902, decode.loss_cls: 0.5161, decode.loss_mask: 0.6134, decode.loss_dice: 0.8916, decode.d0.loss_cls: 8.4911, decode.d0.loss_mask: 0.5782, decode.d0.loss_dice: 0.9619, decode.d1.loss_cls: 0.6501, decode.d1.loss_mask: 0.6339, decode.d1.loss_dice: 0.9523, decode.d2.loss_cls: 0.5717, decode.d2.loss_mask: 0.6254, decode.d2.loss_dice: 0.9115, decode.d3.loss_cls: 0.5415, decode.d3.loss_mask: 0.6168, decode.d3.loss_dice: 0.8943, decode.d4.loss_cls: 0.5306, decode.d4.loss_mask: 0.6123, decode.d4.loss_dice: 0.8952, decode.d5.loss_cls: 0.5180, decode.d5.loss_mask: 0.6117, decode.d5.loss_dice: 0.8938, decode.d6.loss_cls: 0.5141, decode.d6.loss_mask: 0.6125, decode.d6.loss_dice: 0.8875, decode.d7.loss_cls: 0.5104, decode.d7.loss_mask: 0.6148, decode.d7.loss_dice: 0.8897, decode.d8.loss_cls: 0.5160, decode.d8.loss_mask: 0.6129, decode.d8.loss_dice: 0.8923, loss: 28.5614
2022-11-30 06:15:10,188 - mmseg - INFO - per class results:
2022-11-30 06:15:10,193 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        |  83.1 | 90.67 |
|       building      | 85.11 | 91.62 |
|         sky         | 95.18 | 97.27 |
|        floor        | 85.36 | 89.85 |
|         tree        | 78.65 | 89.43 |
|       ceiling       | 87.29 | 91.61 |
|         road        | 87.17 | 92.41 |
|         bed         | 92.84 | 96.71 |
|      windowpane     | 67.81 | 80.45 |
|        grass        | 69.16 | 84.67 |
|       cabinet       | 63.66 | 78.37 |
|       sidewalk      | 72.99 | 85.59 |
|        person       | 88.21 |  93.8 |
|        earth        | 41.82 |  53.9 |
|         door        |  61.6 | 80.99 |
|        table        | 71.32 | 81.58 |
|       mountain      | 63.85 | 73.17 |
|        plant        | 57.63 | 70.96 |
|       curtain       | 82.44 | 91.34 |
|        chair        | 65.76 | 73.58 |
|         car         | 89.15 | 94.77 |
|        water        | 60.84 |  79.0 |
|       painting      | 83.08 | 92.12 |
|         sofa        | 83.57 | 92.91 |
|        shelf        | 45.39 | 55.72 |
|        house        |  52.7 | 63.68 |
|         sea         | 72.03 | 89.49 |
|        mirror       | 80.98 | 90.43 |
|         rug         | 73.32 |  90.7 |
|        field        | 32.78 | 67.79 |
|       armchair      | 57.78 | 79.13 |
|         seat        | 69.39 | 92.17 |
|        fence        | 57.81 | 80.57 |
|         desk        | 54.39 | 85.55 |
|         rock        | 59.33 |  71.7 |
|       wardrobe      | 55.83 | 77.88 |
|         lamp        | 79.66 | 89.07 |
|       bathtub       | 90.21 | 93.22 |
|       railing       | 49.89 | 75.44 |
|       cushion       | 76.61 | 88.55 |
|         base        | 40.16 | 76.78 |
|         box         |  41.4 | 56.03 |
|        column       | 59.39 | 70.47 |
|      signboard      | 44.26 | 64.89 |
|   chest of drawers  | 42.15 | 61.91 |
|       counter       | 49.22 |  55.8 |
|         sand        | 64.74 | 87.11 |
|         sink        | 82.64 | 87.11 |
|      skyscraper     | 38.48 | 49.25 |
|      fireplace      | 81.98 | 94.85 |
|     refrigerator    | 86.94 | 95.83 |
|      grandstand     | 40.17 | 75.21 |
|         path        | 25.32 | 31.28 |
|        stairs       | 32.26 | 38.55 |
|        runway       |  75.1 | 94.71 |
|         case        | 71.72 | 81.17 |
|      pool table     | 94.56 | 98.91 |
|        pillow       | 71.41 | 83.67 |
|     screen door     | 85.29 | 88.22 |
|       stairway      | 52.97 |  77.1 |
|        river        | 18.64 | 20.56 |
|        bridge       | 77.31 | 90.97 |
|       bookcase      | 31.03 | 51.09 |
|        blind        | 48.27 | 61.32 |
|     coffee table    | 80.05 |  92.3 |
|        toilet       | 92.65 | 96.84 |
|        flower       | 43.93 | 63.46 |
|         book        |  55.3 | 80.91 |
|         hill        | 13.13 |  29.0 |
|        bench        | 76.76 | 84.97 |
|      countertop     | 70.18 | 84.62 |
|        stove        | 84.76 | 89.62 |
|         palm        | 55.22 |  82.9 |
|    kitchen island   | 25.59 |  49.9 |
|       computer      | 80.64 | 89.45 |
|     swivel chair    |  54.4 | 84.63 |
|         boat        | 74.74 |  87.4 |
|         bar         | 60.81 | 69.33 |
|    arcade machine   | 89.43 | 96.14 |
|        hovel        | 51.33 | 72.84 |
|         bus         | 92.49 | 94.79 |
|        towel        | 79.87 | 94.37 |
|        light        | 64.71 | 82.02 |
|        truck        | 50.66 | 75.44 |
|        tower        | 33.18 | 64.81 |
|      chandelier     | 76.73 | 86.53 |
|        awning       | 32.76 |  48.5 |
|     streetlight     | 42.52 | 63.98 |
|        booth        | 34.63 | 34.85 |
| television receiver | 72.67 | 91.73 |
|       airplane      | 89.86 | 96.64 |
|      dirt track     |  3.15 |  3.49 |
|       apparel       | 49.23 |  94.1 |
|         pole        | 38.29 | 64.08 |
|         land        |  0.0  |  0.0  |
|      bannister      |  14.1 | 19.61 |
|      escalator      | 65.61 | 82.81 |
|       ottoman       | 54.97 | 81.34 |
|        bottle       | 53.26 | 77.71 |
|        buffet       | 11.24 | 11.88 |
|        poster       | 30.68 | 44.21 |
|        stage        | 24.76 | 51.91 |
|         van         | 54.57 | 75.33 |
|         ship        |  3.94 |  4.11 |
|       fountain      | 43.43 | 45.08 |
|    conveyer belt    | 82.72 | 97.64 |
|        canopy       | 43.72 | 55.06 |
|        washer       | 90.21 | 90.79 |
|      plaything      | 38.04 | 64.47 |
|    swimming pool    | 43.71 | 75.97 |
|        stool        | 50.37 | 84.83 |
|        barrel       | 57.03 | 64.64 |
|        basket       | 39.94 | 67.34 |
|      waterfall      | 50.65 | 55.66 |
|         tent        | 95.25 | 97.87 |
|         bag         |  32.7 | 50.29 |
|       minibike      | 80.48 | 94.02 |
|        cradle       |  91.2 | 97.18 |
|         oven        | 65.06 | 81.89 |
|         ball        | 72.07 | 89.27 |
|         food        | 68.95 | 83.52 |
|         step        | 30.85 | 40.68 |
|         tank        | 40.93 | 41.99 |
|      trade name     | 29.46 | 41.55 |
|      microwave      | 89.63 | 94.64 |
|         pot         | 55.68 | 69.49 |
|        animal       | 84.57 | 88.21 |
|       bicycle       | 59.89 | 86.54 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 79.43 | 94.64 |
|        screen       | 60.24 | 89.87 |
|       blanket       | 31.55 | 43.13 |
|      sculpture      | 73.33 | 91.96 |
|         hood        | 72.92 | 78.92 |
|        sconce       | 64.01 | 82.35 |
|         vase        | 58.94 | 80.22 |
|    traffic light    | 50.89 | 71.56 |
|         tray        | 27.99 | 48.74 |
|        ashcan       | 46.42 | 73.18 |
|         fan         | 73.37 | 86.73 |
|         pier        | 75.18 |  83.4 |
|      crt screen     |  6.78 | 17.91 |
|        plate        |  67.6 | 86.51 |
|       monitor       |  5.56 |  6.73 |
|    bulletin board   | 64.77 | 86.14 |
|        shower       | 24.78 | 28.84 |
|       radiator      | 64.21 | 78.58 |
|        glass        | 29.18 | 33.52 |
|        clock        | 63.08 |  73.9 |
|         flag        | 70.55 | 87.78 |
+---------------------+-------+-------+
2022-11-30 06:15:10,193 - mmseg - INFO - Summary:
2022-11-30 06:15:10,193 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 86.58 | 58.74 | 72.75 |
+-------+-------+-------+
2022-11-30 06:15:10,196 - mmseg - INFO - The previous best checkpoint /mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune/lr1.0_lrd0.9/best_mIoU_iter_7000.pth was removed
2022-11-30 06:15:52,579 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_8000.pth.
2022-11-30 06:15:52,580 - mmseg - INFO - Best mIoU is 0.5874 at 8000 iter.
2022-11-30 06:15:52,589 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 06:15:52,589 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8658, mIoU: 0.5874, mAcc: 0.7275, IoU.wall: 0.8310, IoU.building: 0.8511, IoU.sky: 0.9518, IoU.floor: 0.8536, IoU.tree: 0.7865, IoU.ceiling: 0.8729, IoU.road: 0.8717, IoU.bed : 0.9284, IoU.windowpane: 0.6781, IoU.grass: 0.6916, IoU.cabinet: 0.6366, IoU.sidewalk: 0.7299, IoU.person: 0.8821, IoU.earth: 0.4182, IoU.door: 0.6160, IoU.table: 0.7132, IoU.mountain: 0.6385, IoU.plant: 0.5763, IoU.curtain: 0.8244, IoU.chair: 0.6576, IoU.car: 0.8915, IoU.water: 0.6084, IoU.painting: 0.8308, IoU.sofa: 0.8357, IoU.shelf: 0.4539, IoU.house: 0.5270, IoU.sea: 0.7203, IoU.mirror: 0.8098, IoU.rug: 0.7332, IoU.field: 0.3278, IoU.armchair: 0.5778, IoU.seat: 0.6939, IoU.fence: 0.5781, IoU.desk: 0.5439, IoU.rock: 0.5933, IoU.wardrobe: 0.5583, IoU.lamp: 0.7966, IoU.bathtub: 0.9021, IoU.railing: 0.4989, IoU.cushion: 0.7661, IoU.base: 0.4016, IoU.box: 0.4140, IoU.column: 0.5939, IoU.signboard: 0.4426, IoU.chest of drawers: 0.4215, IoU.counter: 0.4922, IoU.sand: 0.6474, IoU.sink: 0.8264, IoU.skyscraper: 0.3848, IoU.fireplace: 0.8198, IoU.refrigerator: 0.8694, IoU.grandstand: 0.4017, IoU.path: 0.2532, IoU.stairs: 0.3226, IoU.runway: 0.7510, IoU.case: 0.7172, IoU.pool table: 0.9456, IoU.pillow: 0.7141, IoU.screen door: 0.8529, IoU.stairway: 0.5297, IoU.river: 0.1864, IoU.bridge: 0.7731, IoU.bookcase: 0.3103, IoU.blind: 0.4827, IoU.coffee table: 0.8005, IoU.toilet: 0.9265, IoU.flower: 0.4393, IoU.book: 0.5530, IoU.hill: 0.1313, IoU.bench: 0.7676, IoU.countertop: 0.7018, IoU.stove: 0.8476, IoU.palm: 0.5522, IoU.kitchen island: 0.2559, IoU.computer: 0.8064, IoU.swivel chair: 0.5440, IoU.boat: 0.7474, IoU.bar: 0.6081, IoU.arcade machine: 0.8943, IoU.hovel: 0.5133, IoU.bus: 0.9249, IoU.towel: 0.7987, IoU.light: 0.6471, IoU.truck: 0.5066, IoU.tower: 0.3318, IoU.chandelier: 0.7673, IoU.awning: 0.3276, IoU.streetlight: 0.4252, IoU.booth: 0.3463, IoU.television receiver: 0.7267, IoU.airplane: 0.8986, IoU.dirt track: 0.0315, IoU.apparel: 0.4923, IoU.pole: 0.3829, IoU.land: 0.0000, IoU.bannister: 0.1410, IoU.escalator: 0.6561, IoU.ottoman: 0.5497, IoU.bottle: 0.5326, IoU.buffet: 0.1124, IoU.poster: 0.3068, IoU.stage: 0.2476, IoU.van: 0.5457, IoU.ship: 0.0394, IoU.fountain: 0.4343, IoU.conveyer belt: 0.8272, IoU.canopy: 0.4372, IoU.washer: 0.9021, IoU.plaything: 0.3804, IoU.swimming pool: 0.4371, IoU.stool: 0.5037, IoU.barrel: 0.5703, IoU.basket: 0.3994, IoU.waterfall: 0.5065, IoU.tent: 0.9525, IoU.bag: 0.3270, IoU.minibike: 0.8048, IoU.cradle: 0.9120, IoU.oven: 0.6506, IoU.ball: 0.7207, IoU.food: 0.6895, IoU.step: 0.3085, IoU.tank: 0.4093, IoU.trade name: 0.2946, IoU.microwave: 0.8963, IoU.pot: 0.5568, IoU.animal: 0.8457, IoU.bicycle: 0.5989, IoU.lake: 0.0000, IoU.dishwasher: 0.7943, IoU.screen: 0.6024, IoU.blanket: 0.3155, IoU.sculpture: 0.7333, IoU.hood: 0.7292, IoU.sconce: 0.6401, IoU.vase: 0.5894, IoU.traffic light: 0.5089, IoU.tray: 0.2799, IoU.ashcan: 0.4642, IoU.fan: 0.7337, IoU.pier: 0.7518, IoU.crt screen: 0.0678, IoU.plate: 0.6760, IoU.monitor: 0.0556, IoU.bulletin board: 0.6477, IoU.shower: 0.2478, IoU.radiator: 0.6421, IoU.glass: 0.2918, IoU.clock: 0.6308, IoU.flag: 0.7055, Acc.wall: 0.9067, Acc.building: 0.9162, Acc.sky: 0.9727, Acc.floor: 0.8985, Acc.tree: 0.8943, Acc.ceiling: 0.9161, Acc.road: 0.9241, Acc.bed : 0.9671, Acc.windowpane: 0.8045, Acc.grass: 0.8467, Acc.cabinet: 0.7837, Acc.sidewalk: 0.8559, Acc.person: 0.9380, Acc.earth: 0.5390, Acc.door: 0.8099, Acc.table: 0.8158, Acc.mountain: 0.7317, Acc.plant: 0.7096, Acc.curtain: 0.9134, Acc.chair: 0.7358, Acc.car: 0.9477, Acc.water: 0.7900, Acc.painting: 0.9212, Acc.sofa: 0.9291, Acc.shelf: 0.5572, Acc.house: 0.6368, Acc.sea: 0.8949, Acc.mirror: 0.9043, Acc.rug: 0.9070, Acc.field: 0.6779, Acc.armchair: 0.7913, Acc.seat: 0.9217, Acc.fence: 0.8057, Acc.desk: 0.8555, Acc.rock: 0.7170, Acc.wardrobe: 0.7788, Acc.lamp: 0.8907, Acc.bathtub: 0.9322, Acc.railing: 0.7544, Acc.cushion: 0.8855, Acc.base: 0.7678, Acc.box: 0.5603, Acc.column: 0.7047, Acc.signboard: 0.6489, Acc.chest of drawers: 0.6191, Acc.counter: 0.5580, Acc.sand: 0.8711, Acc.sink: 0.8711, Acc.skyscraper: 0.4925, Acc.fireplace: 0.9485, Acc.refrigerator: 0.9583, Acc.grandstand: 0.7521, Acc.path: 0.3128, Acc.stairs: 0.3855, Acc.runway: 0.9471, Acc.case: 0.8117, Acc.pool table: 0.9891, Acc.pillow: 0.8367, Acc.screen door: 0.8822, Acc.stairway: 0.7710, Acc.river: 0.2056, Acc.bridge: 0.9097, Acc.bookcase: 0.5109, Acc.blind: 0.6132, Acc.coffee table: 0.9230, Acc.toilet: 0.9684, Acc.flower: 0.6346, Acc.book: 0.8091, Acc.hill: 0.2900, Acc.bench: 0.8497, Acc.countertop: 0.8462, Acc.stove: 0.8962, Acc.palm: 0.8290, Acc.kitchen island: 0.4990, Acc.computer: 0.8945, Acc.swivel chair: 0.8463, Acc.boat: 0.8740, Acc.bar: 0.6933, Acc.arcade machine: 0.9614, Acc.hovel: 0.7284, Acc.bus: 0.9479, Acc.towel: 0.9437, Acc.light: 0.8202, Acc.truck: 0.7544, Acc.tower: 0.6481, Acc.chandelier: 0.8653, Acc.awning: 0.4850, Acc.streetlight: 0.6398, Acc.booth: 0.3485, Acc.television receiver: 0.9173, Acc.airplane: 0.9664, Acc.dirt track: 0.0349, Acc.apparel: 0.9410, Acc.pole: 0.6408, Acc.land: 0.0000, Acc.bannister: 0.1961, Acc.escalator: 0.8281, Acc.ottoman: 0.8134, Acc.bottle: 0.7771, Acc.buffet: 0.1188, Acc.poster: 0.4421, Acc.stage: 0.5191, Acc.van: 0.7533, Acc.ship: 0.0411, Acc.fountain: 0.4508, Acc.conveyer belt: 0.9764, Acc.canopy: 0.5506, Acc.washer: 0.9079, Acc.plaything: 0.6447, Acc.swimming pool: 0.7597, Acc.stool: 0.8483, Acc.barrel: 0.6464, Acc.basket: 0.6734, Acc.waterfall: 0.5566, Acc.tent: 0.9787, Acc.bag: 0.5029, Acc.minibike: 0.9402, Acc.cradle: 0.9718, Acc.oven: 0.8189, Acc.ball: 0.8927, Acc.food: 0.8352, Acc.step: 0.4068, Acc.tank: 0.4199, Acc.trade name: 0.4155, Acc.microwave: 0.9464, Acc.pot: 0.6949, Acc.animal: 0.8821, Acc.bicycle: 0.8654, Acc.lake: 0.0000, Acc.dishwasher: 0.9464, Acc.screen: 0.8987, Acc.blanket: 0.4313, Acc.sculpture: 0.9196, Acc.hood: 0.7892, Acc.sconce: 0.8235, Acc.vase: 0.8022, Acc.traffic light: 0.7156, Acc.tray: 0.4874, Acc.ashcan: 0.7318, Acc.fan: 0.8673, Acc.pier: 0.8340, Acc.crt screen: 0.1791, Acc.plate: 0.8651, Acc.monitor: 0.0673, Acc.bulletin board: 0.8614, Acc.shower: 0.2884, Acc.radiator: 0.7858, Acc.glass: 0.3352, Acc.clock: 0.7390, Acc.flag: 0.8778
2022-11-30 06:19:17,990 - mmseg - INFO - Iter [8050/40000]	lr: 1.063e-07, eta: 1 day, 14:55:44, time: 8.517, data_time: 4.428, memory: 51902, decode.loss_cls: 0.4990, decode.loss_mask: 0.6032, decode.loss_dice: 0.8794, decode.d0.loss_cls: 8.4757, decode.d0.loss_mask: 0.5805, decode.d0.loss_dice: 0.9571, decode.d1.loss_cls: 0.6399, decode.d1.loss_mask: 0.6276, decode.d1.loss_dice: 0.9484, decode.d2.loss_cls: 0.5645, decode.d2.loss_mask: 0.6167, decode.d2.loss_dice: 0.9089, decode.d3.loss_cls: 0.5309, decode.d3.loss_mask: 0.6074, decode.d3.loss_dice: 0.8916, decode.d4.loss_cls: 0.5206, decode.d4.loss_mask: 0.6073, decode.d4.loss_dice: 0.8931, decode.d5.loss_cls: 0.5054, decode.d5.loss_mask: 0.6034, decode.d5.loss_dice: 0.8849, decode.d6.loss_cls: 0.4983, decode.d6.loss_mask: 0.6051, decode.d6.loss_dice: 0.8843, decode.d7.loss_cls: 0.4962, decode.d7.loss_mask: 0.6067, decode.d7.loss_dice: 0.8824, decode.d8.loss_cls: 0.4942, decode.d8.loss_mask: 0.6055, decode.d8.loss_dice: 0.8831, loss: 28.3011
2022-11-30 06:22:44,080 - mmseg - INFO - Iter [8100/40000]	lr: 1.061e-07, eta: 1 day, 14:51:12, time: 4.122, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4946, decode.loss_mask: 0.6111, decode.loss_dice: 0.8842, decode.d0.loss_cls: 8.4698, decode.d0.loss_mask: 0.5805, decode.d0.loss_dice: 0.9507, decode.d1.loss_cls: 0.6416, decode.d1.loss_mask: 0.6323, decode.d1.loss_dice: 0.9440, decode.d2.loss_cls: 0.5656, decode.d2.loss_mask: 0.6158, decode.d2.loss_dice: 0.8969, decode.d3.loss_cls: 0.5282, decode.d3.loss_mask: 0.6114, decode.d3.loss_dice: 0.8855, decode.d4.loss_cls: 0.5197, decode.d4.loss_mask: 0.6094, decode.d4.loss_dice: 0.8840, decode.d5.loss_cls: 0.5041, decode.d5.loss_mask: 0.6089, decode.d5.loss_dice: 0.8870, decode.d6.loss_cls: 0.4995, decode.d6.loss_mask: 0.6097, decode.d6.loss_dice: 0.8825, decode.d7.loss_cls: 0.4974, decode.d7.loss_mask: 0.6105, decode.d7.loss_dice: 0.8849, decode.d8.loss_cls: 0.4937, decode.d8.loss_mask: 0.6097, decode.d8.loss_dice: 0.8810, loss: 28.2945
2022-11-30 06:26:09,984 - mmseg - INFO - Iter [8150/40000]	lr: 1.059e-07, eta: 1 day, 14:46:41, time: 4.118, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5170, decode.loss_mask: 0.6156, decode.loss_dice: 0.8805, decode.d0.loss_cls: 8.4491, decode.d0.loss_mask: 0.5883, decode.d0.loss_dice: 0.9599, decode.d1.loss_cls: 0.6595, decode.d1.loss_mask: 0.6384, decode.d1.loss_dice: 0.9405, decode.d2.loss_cls: 0.5836, decode.d2.loss_mask: 0.6236, decode.d2.loss_dice: 0.9039, decode.d3.loss_cls: 0.5453, decode.d3.loss_mask: 0.6192, decode.d3.loss_dice: 0.8905, decode.d4.loss_cls: 0.5387, decode.d4.loss_mask: 0.6173, decode.d4.loss_dice: 0.8878, decode.d5.loss_cls: 0.5232, decode.d5.loss_mask: 0.6160, decode.d5.loss_dice: 0.8891, decode.d6.loss_cls: 0.5226, decode.d6.loss_mask: 0.6167, decode.d6.loss_dice: 0.8854, decode.d7.loss_cls: 0.5181, decode.d7.loss_mask: 0.6169, decode.d7.loss_dice: 0.8827, decode.d8.loss_cls: 0.5180, decode.d8.loss_mask: 0.6161, decode.d8.loss_dice: 0.8827, loss: 28.5461
2022-11-30 06:29:35,578 - mmseg - INFO - Iter [8200/40000]	lr: 1.058e-07, eta: 1 day, 14:42:09, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 0.5196, decode.loss_mask: 0.6230, decode.loss_dice: 0.8936, decode.d0.loss_cls: 8.4485, decode.d0.loss_mask: 0.5963, decode.d0.loss_dice: 0.9718, decode.d1.loss_cls: 0.6640, decode.d1.loss_mask: 0.6433, decode.d1.loss_dice: 0.9499, decode.d2.loss_cls: 0.5922, decode.d2.loss_mask: 0.6314, decode.d2.loss_dice: 0.9110, decode.d3.loss_cls: 0.5540, decode.d3.loss_mask: 0.6240, decode.d3.loss_dice: 0.8984, decode.d4.loss_cls: 0.5433, decode.d4.loss_mask: 0.6258, decode.d4.loss_dice: 0.8922, decode.d5.loss_cls: 0.5300, decode.d5.loss_mask: 0.6253, decode.d5.loss_dice: 0.8962, decode.d6.loss_cls: 0.5274, decode.d6.loss_mask: 0.6247, decode.d6.loss_dice: 0.8902, decode.d7.loss_cls: 0.5226, decode.d7.loss_mask: 0.6237, decode.d7.loss_dice: 0.8894, decode.d8.loss_cls: 0.5216, decode.d8.loss_mask: 0.6220, decode.d8.loss_dice: 0.8914, loss: 28.7466
2022-11-30 06:33:03,513 - mmseg - INFO - Iter [8250/40000]	lr: 1.056e-07, eta: 1 day, 14:37:47, time: 4.159, data_time: 0.064, memory: 51902, decode.loss_cls: 0.5268, decode.loss_mask: 0.6023, decode.loss_dice: 0.8880, decode.d0.loss_cls: 8.4320, decode.d0.loss_mask: 0.5754, decode.d0.loss_dice: 0.9656, decode.d1.loss_cls: 0.6801, decode.d1.loss_mask: 0.6231, decode.d1.loss_dice: 0.9495, decode.d2.loss_cls: 0.5951, decode.d2.loss_mask: 0.6115, decode.d2.loss_dice: 0.9148, decode.d3.loss_cls: 0.5614, decode.d3.loss_mask: 0.6047, decode.d3.loss_dice: 0.8984, decode.d4.loss_cls: 0.5539, decode.d4.loss_mask: 0.6004, decode.d4.loss_dice: 0.8951, decode.d5.loss_cls: 0.5380, decode.d5.loss_mask: 0.5998, decode.d5.loss_dice: 0.8952, decode.d6.loss_cls: 0.5329, decode.d6.loss_mask: 0.6006, decode.d6.loss_dice: 0.8885, decode.d7.loss_cls: 0.5280, decode.d7.loss_mask: 0.6002, decode.d7.loss_dice: 0.8935, decode.d8.loss_cls: 0.5277, decode.d8.loss_mask: 0.5994, decode.d8.loss_dice: 0.8865, loss: 28.5683
2022-11-30 06:36:29,369 - mmseg - INFO - Iter [8300/40000]	lr: 1.054e-07, eta: 1 day, 14:33:18, time: 4.117, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4901, decode.loss_mask: 0.5953, decode.loss_dice: 0.8784, decode.d0.loss_cls: 8.4239, decode.d0.loss_mask: 0.5702, decode.d0.loss_dice: 0.9499, decode.d1.loss_cls: 0.6407, decode.d1.loss_mask: 0.6120, decode.d1.loss_dice: 0.9363, decode.d2.loss_cls: 0.5651, decode.d2.loss_mask: 0.5993, decode.d2.loss_dice: 0.8958, decode.d3.loss_cls: 0.5265, decode.d3.loss_mask: 0.5951, decode.d3.loss_dice: 0.8777, decode.d4.loss_cls: 0.5086, decode.d4.loss_mask: 0.5947, decode.d4.loss_dice: 0.8817, decode.d5.loss_cls: 0.4989, decode.d5.loss_mask: 0.5959, decode.d5.loss_dice: 0.8830, decode.d6.loss_cls: 0.4922, decode.d6.loss_mask: 0.5944, decode.d6.loss_dice: 0.8734, decode.d7.loss_cls: 0.4901, decode.d7.loss_mask: 0.5928, decode.d7.loss_dice: 0.8749, decode.d8.loss_cls: 0.4899, decode.d8.loss_mask: 0.5944, decode.d8.loss_dice: 0.8777, loss: 27.9988
2022-11-30 06:39:54,629 - mmseg - INFO - Iter [8350/40000]	lr: 1.053e-07, eta: 1 day, 14:28:48, time: 4.105, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4960, decode.loss_mask: 0.6206, decode.loss_dice: 0.8781, decode.d0.loss_cls: 8.4049, decode.d0.loss_mask: 0.5893, decode.d0.loss_dice: 0.9448, decode.d1.loss_cls: 0.6416, decode.d1.loss_mask: 0.6419, decode.d1.loss_dice: 0.9392, decode.d2.loss_cls: 0.5646, decode.d2.loss_mask: 0.6274, decode.d2.loss_dice: 0.8969, decode.d3.loss_cls: 0.5320, decode.d3.loss_mask: 0.6212, decode.d3.loss_dice: 0.8801, decode.d4.loss_cls: 0.5214, decode.d4.loss_mask: 0.6215, decode.d4.loss_dice: 0.8844, decode.d5.loss_cls: 0.5088, decode.d5.loss_mask: 0.6211, decode.d5.loss_dice: 0.8831, decode.d6.loss_cls: 0.5020, decode.d6.loss_mask: 0.6179, decode.d6.loss_dice: 0.8796, decode.d7.loss_cls: 0.4974, decode.d7.loss_mask: 0.6203, decode.d7.loss_dice: 0.8807, decode.d8.loss_cls: 0.4987, decode.d8.loss_mask: 0.6200, decode.d8.loss_dice: 0.8768, loss: 28.3123
2022-11-30 06:43:20,285 - mmseg - INFO - Iter [8400/40000]	lr: 1.051e-07, eta: 1 day, 14:24:19, time: 4.113, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5167, decode.loss_mask: 0.6070, decode.loss_dice: 0.8962, decode.d0.loss_cls: 8.3952, decode.d0.loss_mask: 0.5796, decode.d0.loss_dice: 0.9871, decode.d1.loss_cls: 0.6580, decode.d1.loss_mask: 0.6266, decode.d1.loss_dice: 0.9681, decode.d2.loss_cls: 0.5757, decode.d2.loss_mask: 0.6116, decode.d2.loss_dice: 0.9224, decode.d3.loss_cls: 0.5477, decode.d3.loss_mask: 0.6040, decode.d3.loss_dice: 0.9068, decode.d4.loss_cls: 0.5332, decode.d4.loss_mask: 0.6029, decode.d4.loss_dice: 0.9054, decode.d5.loss_cls: 0.5229, decode.d5.loss_mask: 0.6053, decode.d5.loss_dice: 0.9005, decode.d6.loss_cls: 0.5211, decode.d6.loss_mask: 0.6049, decode.d6.loss_dice: 0.8977, decode.d7.loss_cls: 0.5183, decode.d7.loss_mask: 0.6040, decode.d7.loss_dice: 0.8992, decode.d8.loss_cls: 0.5171, decode.d8.loss_mask: 0.6063, decode.d8.loss_dice: 0.8950, loss: 28.5365
2022-11-30 06:46:45,887 - mmseg - INFO - Iter [8450/40000]	lr: 1.049e-07, eta: 1 day, 14:19:51, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5103, decode.loss_mask: 0.6298, decode.loss_dice: 0.9006, decode.d0.loss_cls: 8.3809, decode.d0.loss_mask: 0.6017, decode.d0.loss_dice: 0.9743, decode.d1.loss_cls: 0.6431, decode.d1.loss_mask: 0.6519, decode.d1.loss_dice: 0.9639, decode.d2.loss_cls: 0.5810, decode.d2.loss_mask: 0.6365, decode.d2.loss_dice: 0.9211, decode.d3.loss_cls: 0.5426, decode.d3.loss_mask: 0.6309, decode.d3.loss_dice: 0.9012, decode.d4.loss_cls: 0.5316, decode.d4.loss_mask: 0.6297, decode.d4.loss_dice: 0.9019, decode.d5.loss_cls: 0.5201, decode.d5.loss_mask: 0.6322, decode.d5.loss_dice: 0.9010, decode.d6.loss_cls: 0.5125, decode.d6.loss_mask: 0.6330, decode.d6.loss_dice: 0.8997, decode.d7.loss_cls: 0.5094, decode.d7.loss_mask: 0.6316, decode.d7.loss_dice: 0.8981, decode.d8.loss_cls: 0.5089, decode.d8.loss_mask: 0.6299, decode.d8.loss_dice: 0.8996, loss: 28.7088
2022-11-30 06:50:11,659 - mmseg - INFO - Iter [8500/40000]	lr: 1.048e-07, eta: 1 day, 14:15:25, time: 4.115, data_time: 0.018, memory: 51902, decode.loss_cls: 0.5164, decode.loss_mask: 0.6012, decode.loss_dice: 0.8889, decode.d0.loss_cls: 8.3835, decode.d0.loss_mask: 0.5738, decode.d0.loss_dice: 0.9740, decode.d1.loss_cls: 0.6689, decode.d1.loss_mask: 0.6224, decode.d1.loss_dice: 0.9536, decode.d2.loss_cls: 0.5817, decode.d2.loss_mask: 0.6098, decode.d2.loss_dice: 0.9134, decode.d3.loss_cls: 0.5507, decode.d3.loss_mask: 0.6032, decode.d3.loss_dice: 0.8951, decode.d4.loss_cls: 0.5354, decode.d4.loss_mask: 0.6043, decode.d4.loss_dice: 0.8982, decode.d5.loss_cls: 0.5236, decode.d5.loss_mask: 0.6021, decode.d5.loss_dice: 0.8964, decode.d6.loss_cls: 0.5171, decode.d6.loss_mask: 0.6022, decode.d6.loss_dice: 0.8902, decode.d7.loss_cls: 0.5181, decode.d7.loss_mask: 0.6012, decode.d7.loss_dice: 0.8893, decode.d8.loss_cls: 0.5151, decode.d8.loss_mask: 0.6042, decode.d8.loss_dice: 0.8933, loss: 28.4273
2022-11-30 06:53:37,104 - mmseg - INFO - Iter [8550/40000]	lr: 1.046e-07, eta: 1 day, 14:10:58, time: 4.109, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4884, decode.loss_mask: 0.6037, decode.loss_dice: 0.8720, decode.d0.loss_cls: 8.3562, decode.d0.loss_mask: 0.5760, decode.d0.loss_dice: 0.9474, decode.d1.loss_cls: 0.6250, decode.d1.loss_mask: 0.6220, decode.d1.loss_dice: 0.9276, decode.d2.loss_cls: 0.5516, decode.d2.loss_mask: 0.6078, decode.d2.loss_dice: 0.8902, decode.d3.loss_cls: 0.5141, decode.d3.loss_mask: 0.6058, decode.d3.loss_dice: 0.8753, decode.d4.loss_cls: 0.5050, decode.d4.loss_mask: 0.6055, decode.d4.loss_dice: 0.8791, decode.d5.loss_cls: 0.4930, decode.d5.loss_mask: 0.6024, decode.d5.loss_dice: 0.8779, decode.d6.loss_cls: 0.4879, decode.d6.loss_mask: 0.6008, decode.d6.loss_dice: 0.8723, decode.d7.loss_cls: 0.4830, decode.d7.loss_mask: 0.6043, decode.d7.loss_dice: 0.8731, decode.d8.loss_cls: 0.4832, decode.d8.loss_mask: 0.6046, decode.d8.loss_dice: 0.8723, loss: 27.9074
2022-11-30 06:57:02,900 - mmseg - INFO - Iter [8600/40000]	lr: 1.044e-07, eta: 1 day, 14:06:33, time: 4.116, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4967, decode.loss_mask: 0.6138, decode.loss_dice: 0.8825, decode.d0.loss_cls: 8.3468, decode.d0.loss_mask: 0.5899, decode.d0.loss_dice: 0.9506, decode.d1.loss_cls: 0.6381, decode.d1.loss_mask: 0.6378, decode.d1.loss_dice: 0.9454, decode.d2.loss_cls: 0.5591, decode.d2.loss_mask: 0.6281, decode.d2.loss_dice: 0.9097, decode.d3.loss_cls: 0.5254, decode.d3.loss_mask: 0.6186, decode.d3.loss_dice: 0.8900, decode.d4.loss_cls: 0.5094, decode.d4.loss_mask: 0.6192, decode.d4.loss_dice: 0.8899, decode.d5.loss_cls: 0.5053, decode.d5.loss_mask: 0.6148, decode.d5.loss_dice: 0.8788, decode.d6.loss_cls: 0.4961, decode.d6.loss_mask: 0.6153, decode.d6.loss_dice: 0.8807, decode.d7.loss_cls: 0.4952, decode.d7.loss_mask: 0.6176, decode.d7.loss_dice: 0.8778, decode.d8.loss_cls: 0.4964, decode.d8.loss_mask: 0.6139, decode.d8.loss_dice: 0.8789, loss: 28.2218
2022-11-30 07:00:28,315 - mmseg - INFO - Iter [8650/40000]	lr: 1.043e-07, eta: 1 day, 14:02:07, time: 4.108, data_time: 0.020, memory: 51902, decode.loss_cls: 0.5103, decode.loss_mask: 0.6116, decode.loss_dice: 0.8812, decode.d0.loss_cls: 8.3486, decode.d0.loss_mask: 0.5831, decode.d0.loss_dice: 0.9491, decode.d1.loss_cls: 0.6557, decode.d1.loss_mask: 0.6306, decode.d1.loss_dice: 0.9400, decode.d2.loss_cls: 0.5748, decode.d2.loss_mask: 0.6191, decode.d2.loss_dice: 0.9013, decode.d3.loss_cls: 0.5370, decode.d3.loss_mask: 0.6135, decode.d3.loss_dice: 0.8815, decode.d4.loss_cls: 0.5291, decode.d4.loss_mask: 0.6117, decode.d4.loss_dice: 0.8807, decode.d5.loss_cls: 0.5187, decode.d5.loss_mask: 0.6113, decode.d5.loss_dice: 0.8819, decode.d6.loss_cls: 0.5126, decode.d6.loss_mask: 0.6090, decode.d6.loss_dice: 0.8789, decode.d7.loss_cls: 0.5091, decode.d7.loss_mask: 0.6130, decode.d7.loss_dice: 0.8787, decode.d8.loss_cls: 0.5109, decode.d8.loss_mask: 0.6123, decode.d8.loss_dice: 0.8799, loss: 28.2751
2022-11-30 07:03:53,934 - mmseg - INFO - Iter [8700/40000]	lr: 1.041e-07, eta: 1 day, 13:57:42, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 0.5034, decode.loss_mask: 0.6272, decode.loss_dice: 0.9084, decode.d0.loss_cls: 8.3219, decode.d0.loss_mask: 0.5935, decode.d0.loss_dice: 0.9894, decode.d1.loss_cls: 0.6420, decode.d1.loss_mask: 0.6469, decode.d1.loss_dice: 0.9746, decode.d2.loss_cls: 0.5665, decode.d2.loss_mask: 0.6352, decode.d2.loss_dice: 0.9283, decode.d3.loss_cls: 0.5292, decode.d3.loss_mask: 0.6325, decode.d3.loss_dice: 0.9147, decode.d4.loss_cls: 0.5187, decode.d4.loss_mask: 0.6306, decode.d4.loss_dice: 0.9112, decode.d5.loss_cls: 0.5078, decode.d5.loss_mask: 0.6259, decode.d5.loss_dice: 0.9104, decode.d6.loss_cls: 0.5055, decode.d6.loss_mask: 0.6273, decode.d6.loss_dice: 0.9062, decode.d7.loss_cls: 0.5043, decode.d7.loss_mask: 0.6261, decode.d7.loss_dice: 0.9054, decode.d8.loss_cls: 0.5016, decode.d8.loss_mask: 0.6270, decode.d8.loss_dice: 0.9066, loss: 28.6283
2022-11-30 07:07:19,482 - mmseg - INFO - Iter [8750/40000]	lr: 1.039e-07, eta: 1 day, 13:53:19, time: 4.111, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4972, decode.loss_mask: 0.6111, decode.loss_dice: 0.9023, decode.d0.loss_cls: 8.3184, decode.d0.loss_mask: 0.5821, decode.d0.loss_dice: 0.9787, decode.d1.loss_cls: 0.6449, decode.d1.loss_mask: 0.6331, decode.d1.loss_dice: 0.9608, decode.d2.loss_cls: 0.5683, decode.d2.loss_mask: 0.6208, decode.d2.loss_dice: 0.9261, decode.d3.loss_cls: 0.5322, decode.d3.loss_mask: 0.6148, decode.d3.loss_dice: 0.9075, decode.d4.loss_cls: 0.5178, decode.d4.loss_mask: 0.6113, decode.d4.loss_dice: 0.9039, decode.d5.loss_cls: 0.5061, decode.d5.loss_mask: 0.6122, decode.d5.loss_dice: 0.9023, decode.d6.loss_cls: 0.5020, decode.d6.loss_mask: 0.6101, decode.d6.loss_dice: 0.8979, decode.d7.loss_cls: 0.4981, decode.d7.loss_mask: 0.6115, decode.d7.loss_dice: 0.9027, decode.d8.loss_cls: 0.4989, decode.d8.loss_mask: 0.6081, decode.d8.loss_dice: 0.9025, loss: 28.3835
2022-11-30 07:10:45,116 - mmseg - INFO - Iter [8800/40000]	lr: 1.038e-07, eta: 1 day, 13:48:56, time: 4.113, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4816, decode.loss_mask: 0.6003, decode.loss_dice: 0.8625, decode.d0.loss_cls: 8.3009, decode.d0.loss_mask: 0.5677, decode.d0.loss_dice: 0.9320, decode.d1.loss_cls: 0.6211, decode.d1.loss_mask: 0.6203, decode.d1.loss_dice: 0.9234, decode.d2.loss_cls: 0.5478, decode.d2.loss_mask: 0.6051, decode.d2.loss_dice: 0.8874, decode.d3.loss_cls: 0.5126, decode.d3.loss_mask: 0.6019, decode.d3.loss_dice: 0.8685, decode.d4.loss_cls: 0.5056, decode.d4.loss_mask: 0.5969, decode.d4.loss_dice: 0.8642, decode.d5.loss_cls: 0.4897, decode.d5.loss_mask: 0.5982, decode.d5.loss_dice: 0.8671, decode.d6.loss_cls: 0.4883, decode.d6.loss_mask: 0.5965, decode.d6.loss_dice: 0.8596, decode.d7.loss_cls: 0.4850, decode.d7.loss_mask: 0.5984, decode.d7.loss_dice: 0.8598, decode.d8.loss_cls: 0.4842, decode.d8.loss_mask: 0.5983, decode.d8.loss_dice: 0.8625, loss: 27.6877
2022-11-30 07:14:12,955 - mmseg - INFO - Iter [8850/40000]	lr: 1.036e-07, eta: 1 day, 13:44:41, time: 4.157, data_time: 0.063, memory: 51902, decode.loss_cls: 0.4891, decode.loss_mask: 0.5926, decode.loss_dice: 0.8723, decode.d0.loss_cls: 8.2988, decode.d0.loss_mask: 0.5654, decode.d0.loss_dice: 0.9512, decode.d1.loss_cls: 0.6427, decode.d1.loss_mask: 0.6094, decode.d1.loss_dice: 0.9315, decode.d2.loss_cls: 0.5570, decode.d2.loss_mask: 0.5995, decode.d2.loss_dice: 0.8903, decode.d3.loss_cls: 0.5235, decode.d3.loss_mask: 0.5940, decode.d3.loss_dice: 0.8745, decode.d4.loss_cls: 0.5111, decode.d4.loss_mask: 0.5919, decode.d4.loss_dice: 0.8777, decode.d5.loss_cls: 0.4982, decode.d5.loss_mask: 0.5905, decode.d5.loss_dice: 0.8731, decode.d6.loss_cls: 0.4910, decode.d6.loss_mask: 0.5908, decode.d6.loss_dice: 0.8713, decode.d7.loss_cls: 0.4924, decode.d7.loss_mask: 0.5924, decode.d7.loss_dice: 0.8716, decode.d8.loss_cls: 0.4958, decode.d8.loss_mask: 0.5911, decode.d8.loss_dice: 0.8725, loss: 27.8031
2022-11-30 07:17:38,626 - mmseg - INFO - Iter [8900/40000]	lr: 1.034e-07, eta: 1 day, 13:40:20, time: 4.113, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4817, decode.loss_mask: 0.5959, decode.loss_dice: 0.8819, decode.d0.loss_cls: 8.2807, decode.d0.loss_mask: 0.5662, decode.d0.loss_dice: 0.9463, decode.d1.loss_cls: 0.6325, decode.d1.loss_mask: 0.6178, decode.d1.loss_dice: 0.9294, decode.d2.loss_cls: 0.5540, decode.d2.loss_mask: 0.6081, decode.d2.loss_dice: 0.8984, decode.d3.loss_cls: 0.5184, decode.d3.loss_mask: 0.6012, decode.d3.loss_dice: 0.8883, decode.d4.loss_cls: 0.5019, decode.d4.loss_mask: 0.5986, decode.d4.loss_dice: 0.8857, decode.d5.loss_cls: 0.4934, decode.d5.loss_mask: 0.5970, decode.d5.loss_dice: 0.8851, decode.d6.loss_cls: 0.4854, decode.d6.loss_mask: 0.5959, decode.d6.loss_dice: 0.8788, decode.d7.loss_cls: 0.4824, decode.d7.loss_mask: 0.5978, decode.d7.loss_dice: 0.8806, decode.d8.loss_cls: 0.4787, decode.d8.loss_mask: 0.5987, decode.d8.loss_dice: 0.8820, loss: 27.8427
2022-11-30 07:21:04,268 - mmseg - INFO - Iter [8950/40000]	lr: 1.033e-07, eta: 1 day, 13:35:58, time: 4.113, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4887, decode.loss_mask: 0.6174, decode.loss_dice: 0.8807, decode.d0.loss_cls: 8.2687, decode.d0.loss_mask: 0.5889, decode.d0.loss_dice: 0.9612, decode.d1.loss_cls: 0.6298, decode.d1.loss_mask: 0.6403, decode.d1.loss_dice: 0.9510, decode.d2.loss_cls: 0.5559, decode.d2.loss_mask: 0.6243, decode.d2.loss_dice: 0.9093, decode.d3.loss_cls: 0.5149, decode.d3.loss_mask: 0.6212, decode.d3.loss_dice: 0.8936, decode.d4.loss_cls: 0.5040, decode.d4.loss_mask: 0.6163, decode.d4.loss_dice: 0.8906, decode.d5.loss_cls: 0.4940, decode.d5.loss_mask: 0.6147, decode.d5.loss_dice: 0.8845, decode.d6.loss_cls: 0.4920, decode.d6.loss_mask: 0.6148, decode.d6.loss_dice: 0.8838, decode.d7.loss_cls: 0.4835, decode.d7.loss_mask: 0.6150, decode.d7.loss_dice: 0.8825, decode.d8.loss_cls: 0.4867, decode.d8.loss_mask: 0.6171, decode.d8.loss_dice: 0.8877, loss: 28.1131
2022-11-30 07:24:29,406 - mmseg - INFO - Saving checkpoint at 9000 iterations
2022-11-30 07:25:13,365 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 07:25:13,366 - mmseg - INFO - Iter [9000/40000]	lr: 1.031e-07, eta: 1 day, 13:34:08, time: 4.982, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4987, decode.loss_mask: 0.5838, decode.loss_dice: 0.8567, decode.d0.loss_cls: 8.2654, decode.d0.loss_mask: 0.5585, decode.d0.loss_dice: 0.9313, decode.d1.loss_cls: 0.6375, decode.d1.loss_mask: 0.5985, decode.d1.loss_dice: 0.9209, decode.d2.loss_cls: 0.5626, decode.d2.loss_mask: 0.5864, decode.d2.loss_dice: 0.8856, decode.d3.loss_cls: 0.5303, decode.d3.loss_mask: 0.5806, decode.d3.loss_dice: 0.8652, decode.d4.loss_cls: 0.5171, decode.d4.loss_mask: 0.5789, decode.d4.loss_dice: 0.8601, decode.d5.loss_cls: 0.5042, decode.d5.loss_mask: 0.5772, decode.d5.loss_dice: 0.8599, decode.d6.loss_cls: 0.4982, decode.d6.loss_mask: 0.5791, decode.d6.loss_dice: 0.8559, decode.d7.loss_cls: 0.4985, decode.d7.loss_mask: 0.5807, decode.d7.loss_dice: 0.8571, decode.d8.loss_cls: 0.4984, decode.d8.loss_mask: 0.5818, decode.d8.loss_dice: 0.8566, loss: 27.5657
2022-11-30 07:28:11,399 - mmseg - INFO - per class results:
2022-11-30 07:28:11,403 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 82.35 | 87.98 |
|       building      |  84.6 | 91.75 |
|         sky         | 95.15 | 97.16 |
|        floor        | 84.96 | 90.55 |
|         tree        | 78.37 | 89.79 |
|       ceiling       | 87.34 | 94.63 |
|         road        | 86.67 | 91.26 |
|         bed         | 93.34 | 96.81 |
|      windowpane     | 66.62 | 82.96 |
|        grass        | 72.81 | 83.38 |
|       cabinet       | 61.37 | 74.64 |
|       sidewalk      | 71.34 | 85.67 |
|        person       | 88.57 | 94.15 |
|        earth        | 43.06 | 57.93 |
|         door        | 60.02 | 84.38 |
|        table        | 72.67 | 82.18 |
|       mountain      | 61.42 | 75.81 |
|        plant        | 56.44 | 69.27 |
|       curtain       | 82.19 | 90.54 |
|        chair        | 64.94 | 72.63 |
|         car         | 88.83 | 94.45 |
|        water        | 56.57 | 74.92 |
|       painting      | 82.05 | 92.26 |
|         sofa        | 83.59 | 92.44 |
|        shelf        | 48.94 |  63.0 |
|        house        | 51.38 | 65.35 |
|         sea         | 69.12 | 82.71 |
|        mirror       | 81.71 | 92.34 |
|         rug         | 70.87 | 83.31 |
|        field        | 34.88 | 67.53 |
|       armchair      | 60.48 | 85.29 |
|         seat        | 65.45 | 87.13 |
|        fence        | 58.61 | 79.12 |
|         desk        | 58.96 | 85.12 |
|         rock        | 52.44 | 65.35 |
|       wardrobe      | 51.44 | 76.73 |
|         lamp        | 80.42 | 90.07 |
|       bathtub       | 91.55 | 92.86 |
|       railing       | 46.25 |  72.4 |
|       cushion       | 76.22 | 87.22 |
|         base        | 41.88 | 76.01 |
|         box         | 37.88 | 55.89 |
|        column       | 61.73 | 78.25 |
|      signboard      | 46.18 | 63.55 |
|   chest of drawers  | 43.12 | 68.95 |
|       counter       | 52.47 | 65.67 |
|         sand        |  61.9 | 88.39 |
|         sink        | 83.08 | 86.08 |
|      skyscraper     | 35.57 |  44.4 |
|      fireplace      | 75.78 | 96.67 |
|     refrigerator    | 88.29 | 95.34 |
|      grandstand     | 45.44 | 77.34 |
|         path        |  25.8 |  32.2 |
|        stairs       | 32.04 | 38.58 |
|        runway       | 74.63 | 94.52 |
|         case        | 67.42 | 81.78 |
|      pool table     | 95.62 | 98.47 |
|        pillow       |  72.1 | 83.91 |
|     screen door     | 73.42 | 75.88 |
|       stairway      | 47.07 | 73.71 |
|        river        | 30.83 | 36.38 |
|        bridge       | 76.68 | 90.33 |
|       bookcase      | 30.37 | 45.39 |
|        blind        | 40.18 | 45.68 |
|     coffee table    | 74.47 | 92.29 |
|        toilet       | 92.84 | 96.73 |
|        flower       | 42.46 |  70.1 |
|         book        | 57.63 | 82.26 |
|         hill        | 10.57 | 23.72 |
|        bench        | 76.13 | 85.15 |
|      countertop     |  68.4 | 85.46 |
|        stove        | 84.78 |  89.8 |
|         palm        | 54.03 | 82.88 |
|    kitchen island   | 36.11 | 64.65 |
|       computer      |  80.9 | 91.79 |
|     swivel chair    | 49.83 | 86.49 |
|         boat        | 55.02 |  86.9 |
|         bar         | 56.89 | 60.67 |
|    arcade machine   | 92.08 | 98.45 |
|        hovel        | 28.54 | 42.85 |
|         bus         | 93.57 | 95.81 |
|        towel        | 81.88 |  92.9 |
|        light        | 62.64 | 81.88 |
|        truck        | 51.27 | 71.06 |
|        tower        | 23.83 |  46.1 |
|      chandelier     | 74.81 |  84.7 |
|        awning       | 37.22 |  49.5 |
|     streetlight     | 44.46 | 66.22 |
|        booth        | 38.17 | 38.54 |
| television receiver | 70.22 | 87.57 |
|       airplane      | 88.94 | 95.86 |
|      dirt track     | 12.43 | 20.53 |
|       apparel       | 56.59 | 93.44 |
|         pole        |  37.6 | 57.43 |
|         land        |  0.15 |  0.18 |
|      bannister      | 18.13 | 30.95 |
|      escalator      | 66.09 | 85.44 |
|       ottoman       | 60.52 | 83.12 |
|        bottle       | 52.72 | 81.15 |
|        buffet       | 11.06 |  13.2 |
|        poster       |  33.8 | 61.49 |
|        stage        | 13.19 | 25.65 |
|         van         | 49.49 | 76.37 |
|         ship        |  9.47 |  9.91 |
|       fountain      | 42.68 | 43.96 |
|    conveyer belt    | 82.14 | 98.06 |
|        canopy       | 42.39 | 54.81 |
|        washer       | 86.43 | 88.64 |
|      plaything      | 37.01 | 54.77 |
|    swimming pool    | 41.36 | 72.82 |
|        stool        | 61.53 | 85.42 |
|        barrel       | 57.59 | 64.52 |
|        basket       | 41.11 | 69.67 |
|      waterfall      |  45.0 | 54.45 |
|         tent        | 94.48 | 97.86 |
|         bag         | 36.04 | 48.71 |
|       minibike      | 80.95 | 92.99 |
|        cradle       |  91.3 | 97.35 |
|         oven        | 66.27 | 82.81 |
|         ball        | 61.54 | 73.51 |
|         food        | 64.77 | 73.53 |
|         step        |  20.2 | 28.38 |
|         tank        | 47.96 |  49.5 |
|      trade name     | 39.83 | 68.47 |
|      microwave      | 90.32 | 94.88 |
|         pot         | 55.28 | 69.08 |
|        animal       | 82.28 |  84.3 |
|       bicycle       | 60.26 | 83.47 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 79.59 | 89.86 |
|        screen       | 58.61 |  94.6 |
|       blanket       | 35.46 | 49.92 |
|      sculpture      | 74.33 | 91.48 |
|         hood        | 76.05 | 82.48 |
|        sconce       | 63.99 | 83.11 |
|         vase        | 57.77 |  81.4 |
|    traffic light    | 51.19 | 72.16 |
|         tray        | 26.47 | 43.14 |
|        ashcan       | 48.09 | 70.22 |
|         fan         | 72.73 | 83.93 |
|         pier        | 35.15 | 40.75 |
|      crt screen     |  1.86 |  4.68 |
|        plate        | 69.24 | 84.84 |
|       monitor       |  3.51 |  4.16 |
|    bulletin board   | 65.81 | 80.98 |
|        shower       | 22.75 | 25.26 |
|       radiator      | 71.64 | 92.54 |
|        glass        |  29.1 | 31.99 |
|        clock        | 62.99 | 77.86 |
|         flag        | 69.42 | 84.55 |
+---------------------+-------+-------+
2022-11-30 07:28:11,404 - mmseg - INFO - Summary:
2022-11-30 07:28:11,404 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 86.19 | 57.98 | 72.05 |
+-------+-------+-------+
2022-11-30 07:28:11,409 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 07:28:11,409 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8619, mIoU: 0.5798, mAcc: 0.7205, IoU.wall: 0.8235, IoU.building: 0.8460, IoU.sky: 0.9515, IoU.floor: 0.8496, IoU.tree: 0.7837, IoU.ceiling: 0.8734, IoU.road: 0.8667, IoU.bed : 0.9334, IoU.windowpane: 0.6662, IoU.grass: 0.7281, IoU.cabinet: 0.6137, IoU.sidewalk: 0.7134, IoU.person: 0.8857, IoU.earth: 0.4306, IoU.door: 0.6002, IoU.table: 0.7267, IoU.mountain: 0.6142, IoU.plant: 0.5644, IoU.curtain: 0.8219, IoU.chair: 0.6494, IoU.car: 0.8883, IoU.water: 0.5657, IoU.painting: 0.8205, IoU.sofa: 0.8359, IoU.shelf: 0.4894, IoU.house: 0.5138, IoU.sea: 0.6912, IoU.mirror: 0.8171, IoU.rug: 0.7087, IoU.field: 0.3488, IoU.armchair: 0.6048, IoU.seat: 0.6545, IoU.fence: 0.5861, IoU.desk: 0.5896, IoU.rock: 0.5244, IoU.wardrobe: 0.5144, IoU.lamp: 0.8042, IoU.bathtub: 0.9155, IoU.railing: 0.4625, IoU.cushion: 0.7622, IoU.base: 0.4188, IoU.box: 0.3788, IoU.column: 0.6173, IoU.signboard: 0.4618, IoU.chest of drawers: 0.4312, IoU.counter: 0.5247, IoU.sand: 0.6190, IoU.sink: 0.8308, IoU.skyscraper: 0.3557, IoU.fireplace: 0.7578, IoU.refrigerator: 0.8829, IoU.grandstand: 0.4544, IoU.path: 0.2580, IoU.stairs: 0.3204, IoU.runway: 0.7463, IoU.case: 0.6742, IoU.pool table: 0.9562, IoU.pillow: 0.7210, IoU.screen door: 0.7342, IoU.stairway: 0.4707, IoU.river: 0.3083, IoU.bridge: 0.7668, IoU.bookcase: 0.3037, IoU.blind: 0.4018, IoU.coffee table: 0.7447, IoU.toilet: 0.9284, IoU.flower: 0.4246, IoU.book: 0.5763, IoU.hill: 0.1057, IoU.bench: 0.7613, IoU.countertop: 0.6840, IoU.stove: 0.8478, IoU.palm: 0.5403, IoU.kitchen island: 0.3611, IoU.computer: 0.8090, IoU.swivel chair: 0.4983, IoU.boat: 0.5502, IoU.bar: 0.5689, IoU.arcade machine: 0.9208, IoU.hovel: 0.2854, IoU.bus: 0.9357, IoU.towel: 0.8188, IoU.light: 0.6264, IoU.truck: 0.5127, IoU.tower: 0.2383, IoU.chandelier: 0.7481, IoU.awning: 0.3722, IoU.streetlight: 0.4446, IoU.booth: 0.3817, IoU.television receiver: 0.7022, IoU.airplane: 0.8894, IoU.dirt track: 0.1243, IoU.apparel: 0.5659, IoU.pole: 0.3760, IoU.land: 0.0015, IoU.bannister: 0.1813, IoU.escalator: 0.6609, IoU.ottoman: 0.6052, IoU.bottle: 0.5272, IoU.buffet: 0.1106, IoU.poster: 0.3380, IoU.stage: 0.1319, IoU.van: 0.4949, IoU.ship: 0.0947, IoU.fountain: 0.4268, IoU.conveyer belt: 0.8214, IoU.canopy: 0.4239, IoU.washer: 0.8643, IoU.plaything: 0.3701, IoU.swimming pool: 0.4136, IoU.stool: 0.6153, IoU.barrel: 0.5759, IoU.basket: 0.4111, IoU.waterfall: 0.4500, IoU.tent: 0.9448, IoU.bag: 0.3604, IoU.minibike: 0.8095, IoU.cradle: 0.9130, IoU.oven: 0.6627, IoU.ball: 0.6154, IoU.food: 0.6477, IoU.step: 0.2020, IoU.tank: 0.4796, IoU.trade name: 0.3983, IoU.microwave: 0.9032, IoU.pot: 0.5528, IoU.animal: 0.8228, IoU.bicycle: 0.6026, IoU.lake: 0.0000, IoU.dishwasher: 0.7959, IoU.screen: 0.5861, IoU.blanket: 0.3546, IoU.sculpture: 0.7433, IoU.hood: 0.7605, IoU.sconce: 0.6399, IoU.vase: 0.5777, IoU.traffic light: 0.5119, IoU.tray: 0.2647, IoU.ashcan: 0.4809, IoU.fan: 0.7273, IoU.pier: 0.3515, IoU.crt screen: 0.0186, IoU.plate: 0.6924, IoU.monitor: 0.0351, IoU.bulletin board: 0.6581, IoU.shower: 0.2275, IoU.radiator: 0.7164, IoU.glass: 0.2910, IoU.clock: 0.6299, IoU.flag: 0.6942, Acc.wall: 0.8798, Acc.building: 0.9175, Acc.sky: 0.9716, Acc.floor: 0.9055, Acc.tree: 0.8979, Acc.ceiling: 0.9463, Acc.road: 0.9126, Acc.bed : 0.9681, Acc.windowpane: 0.8296, Acc.grass: 0.8338, Acc.cabinet: 0.7464, Acc.sidewalk: 0.8567, Acc.person: 0.9415, Acc.earth: 0.5793, Acc.door: 0.8438, Acc.table: 0.8218, Acc.mountain: 0.7581, Acc.plant: 0.6927, Acc.curtain: 0.9054, Acc.chair: 0.7263, Acc.car: 0.9445, Acc.water: 0.7492, Acc.painting: 0.9226, Acc.sofa: 0.9244, Acc.shelf: 0.6300, Acc.house: 0.6535, Acc.sea: 0.8271, Acc.mirror: 0.9234, Acc.rug: 0.8331, Acc.field: 0.6753, Acc.armchair: 0.8529, Acc.seat: 0.8713, Acc.fence: 0.7912, Acc.desk: 0.8512, Acc.rock: 0.6535, Acc.wardrobe: 0.7673, Acc.lamp: 0.9007, Acc.bathtub: 0.9286, Acc.railing: 0.7240, Acc.cushion: 0.8722, Acc.base: 0.7601, Acc.box: 0.5589, Acc.column: 0.7825, Acc.signboard: 0.6355, Acc.chest of drawers: 0.6895, Acc.counter: 0.6567, Acc.sand: 0.8839, Acc.sink: 0.8608, Acc.skyscraper: 0.4440, Acc.fireplace: 0.9667, Acc.refrigerator: 0.9534, Acc.grandstand: 0.7734, Acc.path: 0.3220, Acc.stairs: 0.3858, Acc.runway: 0.9452, Acc.case: 0.8178, Acc.pool table: 0.9847, Acc.pillow: 0.8391, Acc.screen door: 0.7588, Acc.stairway: 0.7371, Acc.river: 0.3638, Acc.bridge: 0.9033, Acc.bookcase: 0.4539, Acc.blind: 0.4568, Acc.coffee table: 0.9229, Acc.toilet: 0.9673, Acc.flower: 0.7010, Acc.book: 0.8226, Acc.hill: 0.2372, Acc.bench: 0.8515, Acc.countertop: 0.8546, Acc.stove: 0.8980, Acc.palm: 0.8288, Acc.kitchen island: 0.6465, Acc.computer: 0.9179, Acc.swivel chair: 0.8649, Acc.boat: 0.8690, Acc.bar: 0.6067, Acc.arcade machine: 0.9845, Acc.hovel: 0.4285, Acc.bus: 0.9581, Acc.towel: 0.9290, Acc.light: 0.8188, Acc.truck: 0.7106, Acc.tower: 0.4610, Acc.chandelier: 0.8470, Acc.awning: 0.4950, Acc.streetlight: 0.6622, Acc.booth: 0.3854, Acc.television receiver: 0.8757, Acc.airplane: 0.9586, Acc.dirt track: 0.2053, Acc.apparel: 0.9344, Acc.pole: 0.5743, Acc.land: 0.0018, Acc.bannister: 0.3095, Acc.escalator: 0.8544, Acc.ottoman: 0.8312, Acc.bottle: 0.8115, Acc.buffet: 0.1320, Acc.poster: 0.6149, Acc.stage: 0.2565, Acc.van: 0.7637, Acc.ship: 0.0991, Acc.fountain: 0.4396, Acc.conveyer belt: 0.9806, Acc.canopy: 0.5481, Acc.washer: 0.8864, Acc.plaything: 0.5477, Acc.swimming pool: 0.7282, Acc.stool: 0.8542, Acc.barrel: 0.6452, Acc.basket: 0.6967, Acc.waterfall: 0.5445, Acc.tent: 0.9786, Acc.bag: 0.4871, Acc.minibike: 0.9299, Acc.cradle: 0.9735, Acc.oven: 0.8281, Acc.ball: 0.7351, Acc.food: 0.7353, Acc.step: 0.2838, Acc.tank: 0.4950, Acc.trade name: 0.6847, Acc.microwave: 0.9488, Acc.pot: 0.6908, Acc.animal: 0.8430, Acc.bicycle: 0.8347, Acc.lake: 0.0000, Acc.dishwasher: 0.8986, Acc.screen: 0.9460, Acc.blanket: 0.4992, Acc.sculpture: 0.9148, Acc.hood: 0.8248, Acc.sconce: 0.8311, Acc.vase: 0.8140, Acc.traffic light: 0.7216, Acc.tray: 0.4314, Acc.ashcan: 0.7022, Acc.fan: 0.8393, Acc.pier: 0.4075, Acc.crt screen: 0.0468, Acc.plate: 0.8484, Acc.monitor: 0.0416, Acc.bulletin board: 0.8098, Acc.shower: 0.2526, Acc.radiator: 0.9254, Acc.glass: 0.3199, Acc.clock: 0.7786, Acc.flag: 0.8455
2022-11-30 07:31:37,586 - mmseg - INFO - Iter [9050/40000]	lr: 1.029e-07, eta: 1 day, 13:39:58, time: 7.684, data_time: 3.579, memory: 51902, decode.loss_cls: 0.4918, decode.loss_mask: 0.6017, decode.loss_dice: 0.8874, decode.d0.loss_cls: 8.2529, decode.d0.loss_mask: 0.5740, decode.d0.loss_dice: 0.9644, decode.d1.loss_cls: 0.6350, decode.d1.loss_mask: 0.6207, decode.d1.loss_dice: 0.9490, decode.d2.loss_cls: 0.5564, decode.d2.loss_mask: 0.6079, decode.d2.loss_dice: 0.9088, decode.d3.loss_cls: 0.5158, decode.d3.loss_mask: 0.6052, decode.d3.loss_dice: 0.8976, decode.d4.loss_cls: 0.5032, decode.d4.loss_mask: 0.6022, decode.d4.loss_dice: 0.8931, decode.d5.loss_cls: 0.4955, decode.d5.loss_mask: 0.6023, decode.d5.loss_dice: 0.8920, decode.d6.loss_cls: 0.4918, decode.d6.loss_mask: 0.6010, decode.d6.loss_dice: 0.8910, decode.d7.loss_cls: 0.4942, decode.d7.loss_mask: 0.6013, decode.d7.loss_dice: 0.8883, decode.d8.loss_cls: 0.4909, decode.d8.loss_mask: 0.6028, decode.d8.loss_dice: 0.8896, loss: 28.0076
2022-11-30 07:35:03,158 - mmseg - INFO - Iter [9100/40000]	lr: 1.028e-07, eta: 1 day, 13:35:33, time: 4.111, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4923, decode.loss_mask: 0.6083, decode.loss_dice: 0.8791, decode.d0.loss_cls: 8.2219, decode.d0.loss_mask: 0.5803, decode.d0.loss_dice: 0.9468, decode.d1.loss_cls: 0.6279, decode.d1.loss_mask: 0.6339, decode.d1.loss_dice: 0.9378, decode.d2.loss_cls: 0.5516, decode.d2.loss_mask: 0.6205, decode.d2.loss_dice: 0.8997, decode.d3.loss_cls: 0.5170, decode.d3.loss_mask: 0.6135, decode.d3.loss_dice: 0.8860, decode.d4.loss_cls: 0.5079, decode.d4.loss_mask: 0.6107, decode.d4.loss_dice: 0.8789, decode.d5.loss_cls: 0.4999, decode.d5.loss_mask: 0.6098, decode.d5.loss_dice: 0.8799, decode.d6.loss_cls: 0.4921, decode.d6.loss_mask: 0.6100, decode.d6.loss_dice: 0.8795, decode.d7.loss_cls: 0.4953, decode.d7.loss_mask: 0.6095, decode.d7.loss_dice: 0.8807, decode.d8.loss_cls: 0.4916, decode.d8.loss_mask: 0.6071, decode.d8.loss_dice: 0.8785, loss: 27.9480
2022-11-30 07:38:28,745 - mmseg - INFO - Iter [9150/40000]	lr: 1.026e-07, eta: 1 day, 13:31:09, time: 4.112, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4848, decode.loss_mask: 0.6293, decode.loss_dice: 0.8767, decode.d0.loss_cls: 8.2052, decode.d0.loss_mask: 0.5948, decode.d0.loss_dice: 0.9505, decode.d1.loss_cls: 0.6218, decode.d1.loss_mask: 0.6477, decode.d1.loss_dice: 0.9374, decode.d2.loss_cls: 0.5511, decode.d2.loss_mask: 0.6356, decode.d2.loss_dice: 0.8996, decode.d3.loss_cls: 0.5170, decode.d3.loss_mask: 0.6291, decode.d3.loss_dice: 0.8822, decode.d4.loss_cls: 0.5032, decode.d4.loss_mask: 0.6297, decode.d4.loss_dice: 0.8832, decode.d5.loss_cls: 0.4941, decode.d5.loss_mask: 0.6286, decode.d5.loss_dice: 0.8833, decode.d6.loss_cls: 0.4900, decode.d6.loss_mask: 0.6273, decode.d6.loss_dice: 0.8797, decode.d7.loss_cls: 0.4888, decode.d7.loss_mask: 0.6264, decode.d7.loss_dice: 0.8800, decode.d8.loss_cls: 0.4860, decode.d8.loss_mask: 0.6280, decode.d8.loss_dice: 0.8831, loss: 28.0742
2022-11-30 07:41:54,184 - mmseg - INFO - Iter [9200/40000]	lr: 1.024e-07, eta: 1 day, 13:26:45, time: 4.109, data_time: 0.019, memory: 51902, decode.loss_cls: 0.5000, decode.loss_mask: 0.6001, decode.loss_dice: 0.8865, decode.d0.loss_cls: 8.2102, decode.d0.loss_mask: 0.5755, decode.d0.loss_dice: 0.9552, decode.d1.loss_cls: 0.6368, decode.d1.loss_mask: 0.6238, decode.d1.loss_dice: 0.9522, decode.d2.loss_cls: 0.5600, decode.d2.loss_mask: 0.6111, decode.d2.loss_dice: 0.9095, decode.d3.loss_cls: 0.5263, decode.d3.loss_mask: 0.6065, decode.d3.loss_dice: 0.8896, decode.d4.loss_cls: 0.5133, decode.d4.loss_mask: 0.6045, decode.d4.loss_dice: 0.8913, decode.d5.loss_cls: 0.4997, decode.d5.loss_mask: 0.6023, decode.d5.loss_dice: 0.8898, decode.d6.loss_cls: 0.5017, decode.d6.loss_mask: 0.5984, decode.d6.loss_dice: 0.8805, decode.d7.loss_cls: 0.4992, decode.d7.loss_mask: 0.6003, decode.d7.loss_dice: 0.8823, decode.d8.loss_cls: 0.4989, decode.d8.loss_mask: 0.6001, decode.d8.loss_dice: 0.8840, loss: 27.9895
2022-11-30 07:45:20,028 - mmseg - INFO - Iter [9250/40000]	lr: 1.023e-07, eta: 1 day, 13:22:22, time: 4.117, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4902, decode.loss_mask: 0.6035, decode.loss_dice: 0.8733, decode.d0.loss_cls: 8.2034, decode.d0.loss_mask: 0.5768, decode.d0.loss_dice: 0.9475, decode.d1.loss_cls: 0.6284, decode.d1.loss_mask: 0.6264, decode.d1.loss_dice: 0.9402, decode.d2.loss_cls: 0.5482, decode.d2.loss_mask: 0.6175, decode.d2.loss_dice: 0.8994, decode.d3.loss_cls: 0.5145, decode.d3.loss_mask: 0.6095, decode.d3.loss_dice: 0.8849, decode.d4.loss_cls: 0.5062, decode.d4.loss_mask: 0.6093, decode.d4.loss_dice: 0.8812, decode.d5.loss_cls: 0.4939, decode.d5.loss_mask: 0.6089, decode.d5.loss_dice: 0.8762, decode.d6.loss_cls: 0.4929, decode.d6.loss_mask: 0.6069, decode.d6.loss_dice: 0.8744, decode.d7.loss_cls: 0.4887, decode.d7.loss_mask: 0.6050, decode.d7.loss_dice: 0.8787, decode.d8.loss_cls: 0.4893, decode.d8.loss_mask: 0.6078, decode.d8.loss_dice: 0.8730, loss: 27.8560
2022-11-30 07:48:45,481 - mmseg - INFO - Iter [9300/40000]	lr: 1.021e-07, eta: 1 day, 13:18:00, time: 4.109, data_time: 0.020, memory: 51902, decode.loss_cls: 0.5122, decode.loss_mask: 0.6029, decode.loss_dice: 0.8764, decode.d0.loss_cls: 8.1947, decode.d0.loss_mask: 0.5748, decode.d0.loss_dice: 0.9575, decode.d1.loss_cls: 0.6365, decode.d1.loss_mask: 0.6222, decode.d1.loss_dice: 0.9464, decode.d2.loss_cls: 0.5729, decode.d2.loss_mask: 0.6107, decode.d2.loss_dice: 0.9018, decode.d3.loss_cls: 0.5413, decode.d3.loss_mask: 0.6032, decode.d3.loss_dice: 0.8880, decode.d4.loss_cls: 0.5331, decode.d4.loss_mask: 0.6018, decode.d4.loss_dice: 0.8812, decode.d5.loss_cls: 0.5208, decode.d5.loss_mask: 0.6020, decode.d5.loss_dice: 0.8826, decode.d6.loss_cls: 0.5166, decode.d6.loss_mask: 0.5984, decode.d6.loss_dice: 0.8768, decode.d7.loss_cls: 0.5157, decode.d7.loss_mask: 0.5999, decode.d7.loss_dice: 0.8784, decode.d8.loss_cls: 0.5141, decode.d8.loss_mask: 0.6018, decode.d8.loss_dice: 0.8789, loss: 28.0438
2022-11-30 07:52:11,086 - mmseg - INFO - Iter [9350/40000]	lr: 1.019e-07, eta: 1 day, 13:13:38, time: 4.112, data_time: 0.018, memory: 51902, decode.loss_cls: 0.5009, decode.loss_mask: 0.6004, decode.loss_dice: 0.8944, decode.d0.loss_cls: 8.1797, decode.d0.loss_mask: 0.5734, decode.d0.loss_dice: 0.9713, decode.d1.loss_cls: 0.6349, decode.d1.loss_mask: 0.6215, decode.d1.loss_dice: 0.9534, decode.d2.loss_cls: 0.5582, decode.d2.loss_mask: 0.6119, decode.d2.loss_dice: 0.9095, decode.d3.loss_cls: 0.5233, decode.d3.loss_mask: 0.6044, decode.d3.loss_dice: 0.9000, decode.d4.loss_cls: 0.5129, decode.d4.loss_mask: 0.6023, decode.d4.loss_dice: 0.8987, decode.d5.loss_cls: 0.5081, decode.d5.loss_mask: 0.6006, decode.d5.loss_dice: 0.8949, decode.d6.loss_cls: 0.5018, decode.d6.loss_mask: 0.6019, decode.d6.loss_dice: 0.8938, decode.d7.loss_cls: 0.4983, decode.d7.loss_mask: 0.6002, decode.d7.loss_dice: 0.8952, decode.d8.loss_cls: 0.5002, decode.d8.loss_mask: 0.6007, decode.d8.loss_dice: 0.8929, loss: 28.0397
2022-11-30 07:55:36,797 - mmseg - INFO - Iter [9400/40000]	lr: 1.018e-07, eta: 1 day, 13:09:17, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4976, decode.loss_mask: 0.6124, decode.loss_dice: 0.8927, decode.d0.loss_cls: 8.1670, decode.d0.loss_mask: 0.5839, decode.d0.loss_dice: 0.9657, decode.d1.loss_cls: 0.6365, decode.d1.loss_mask: 0.6300, decode.d1.loss_dice: 0.9531, decode.d2.loss_cls: 0.5675, decode.d2.loss_mask: 0.6195, decode.d2.loss_dice: 0.9120, decode.d3.loss_cls: 0.5290, decode.d3.loss_mask: 0.6150, decode.d3.loss_dice: 0.8990, decode.d4.loss_cls: 0.5217, decode.d4.loss_mask: 0.6157, decode.d4.loss_dice: 0.8919, decode.d5.loss_cls: 0.5095, decode.d5.loss_mask: 0.6111, decode.d5.loss_dice: 0.8910, decode.d6.loss_cls: 0.5028, decode.d6.loss_mask: 0.6101, decode.d6.loss_dice: 0.8828, decode.d7.loss_cls: 0.4966, decode.d7.loss_mask: 0.6124, decode.d7.loss_dice: 0.8902, decode.d8.loss_cls: 0.5014, decode.d8.loss_mask: 0.6117, decode.d8.loss_dice: 0.8852, loss: 28.1152
2022-11-30 07:59:02,474 - mmseg - INFO - Iter [9450/40000]	lr: 1.016e-07, eta: 1 day, 13:04:57, time: 4.114, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4890, decode.loss_mask: 0.6221, decode.loss_dice: 0.8874, decode.d0.loss_cls: 8.1631, decode.d0.loss_mask: 0.5890, decode.d0.loss_dice: 0.9563, decode.d1.loss_cls: 0.6278, decode.d1.loss_mask: 0.6439, decode.d1.loss_dice: 0.9528, decode.d2.loss_cls: 0.5517, decode.d2.loss_mask: 0.6318, decode.d2.loss_dice: 0.9130, decode.d3.loss_cls: 0.5163, decode.d3.loss_mask: 0.6280, decode.d3.loss_dice: 0.8975, decode.d4.loss_cls: 0.5051, decode.d4.loss_mask: 0.6247, decode.d4.loss_dice: 0.8998, decode.d5.loss_cls: 0.5012, decode.d5.loss_mask: 0.6194, decode.d5.loss_dice: 0.8958, decode.d6.loss_cls: 0.4923, decode.d6.loss_mask: 0.6227, decode.d6.loss_dice: 0.8905, decode.d7.loss_cls: 0.4940, decode.d7.loss_mask: 0.6201, decode.d7.loss_dice: 0.8945, decode.d8.loss_cls: 0.4907, decode.d8.loss_mask: 0.6209, decode.d8.loss_dice: 0.8859, loss: 28.1273
2022-11-30 08:02:30,263 - mmseg - INFO - Iter [9500/40000]	lr: 1.014e-07, eta: 1 day, 13:00:44, time: 4.156, data_time: 0.064, memory: 51902, decode.loss_cls: 0.4892, decode.loss_mask: 0.6047, decode.loss_dice: 0.8777, decode.d0.loss_cls: 8.1425, decode.d0.loss_mask: 0.5820, decode.d0.loss_dice: 0.9523, decode.d1.loss_cls: 0.6263, decode.d1.loss_mask: 0.6280, decode.d1.loss_dice: 0.9437, decode.d2.loss_cls: 0.5540, decode.d2.loss_mask: 0.6139, decode.d2.loss_dice: 0.9025, decode.d3.loss_cls: 0.5105, decode.d3.loss_mask: 0.6118, decode.d3.loss_dice: 0.8876, decode.d4.loss_cls: 0.5040, decode.d4.loss_mask: 0.6084, decode.d4.loss_dice: 0.8862, decode.d5.loss_cls: 0.4948, decode.d5.loss_mask: 0.6074, decode.d5.loss_dice: 0.8850, decode.d6.loss_cls: 0.4966, decode.d6.loss_mask: 0.6042, decode.d6.loss_dice: 0.8751, decode.d7.loss_cls: 0.4895, decode.d7.loss_mask: 0.6056, decode.d7.loss_dice: 0.8780, decode.d8.loss_cls: 0.4867, decode.d8.loss_mask: 0.6058, decode.d8.loss_dice: 0.8813, loss: 27.8353
2022-11-30 08:05:55,986 - mmseg - INFO - Iter [9550/40000]	lr: 1.013e-07, eta: 1 day, 12:56:25, time: 4.114, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4830, decode.loss_mask: 0.5914, decode.loss_dice: 0.8673, decode.d0.loss_cls: 8.1332, decode.d0.loss_mask: 0.5694, decode.d0.loss_dice: 0.9377, decode.d1.loss_cls: 0.6230, decode.d1.loss_mask: 0.6155, decode.d1.loss_dice: 0.9293, decode.d2.loss_cls: 0.5494, decode.d2.loss_mask: 0.6025, decode.d2.loss_dice: 0.8860, decode.d3.loss_cls: 0.5067, decode.d3.loss_mask: 0.5947, decode.d3.loss_dice: 0.8754, decode.d4.loss_cls: 0.4962, decode.d4.loss_mask: 0.5937, decode.d4.loss_dice: 0.8724, decode.d5.loss_cls: 0.4897, decode.d5.loss_mask: 0.5927, decode.d5.loss_dice: 0.8697, decode.d6.loss_cls: 0.4861, decode.d6.loss_mask: 0.5914, decode.d6.loss_dice: 0.8651, decode.d7.loss_cls: 0.4851, decode.d7.loss_mask: 0.5929, decode.d7.loss_dice: 0.8675, decode.d8.loss_cls: 0.4824, decode.d8.loss_mask: 0.5925, decode.d8.loss_dice: 0.8671, loss: 27.5089
2022-11-30 08:09:21,571 - mmseg - INFO - Iter [9600/40000]	lr: 1.011e-07, eta: 1 day, 12:52:07, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4920, decode.loss_mask: 0.6038, decode.loss_dice: 0.8833, decode.d0.loss_cls: 8.1302, decode.d0.loss_mask: 0.5717, decode.d0.loss_dice: 0.9589, decode.d1.loss_cls: 0.6429, decode.d1.loss_mask: 0.6329, decode.d1.loss_dice: 0.9458, decode.d2.loss_cls: 0.5663, decode.d2.loss_mask: 0.6137, decode.d2.loss_dice: 0.9031, decode.d3.loss_cls: 0.5208, decode.d3.loss_mask: 0.6078, decode.d3.loss_dice: 0.8933, decode.d4.loss_cls: 0.5105, decode.d4.loss_mask: 0.6085, decode.d4.loss_dice: 0.8946, decode.d5.loss_cls: 0.5002, decode.d5.loss_mask: 0.6047, decode.d5.loss_dice: 0.8850, decode.d6.loss_cls: 0.4946, decode.d6.loss_mask: 0.6049, decode.d6.loss_dice: 0.8807, decode.d7.loss_cls: 0.4894, decode.d7.loss_mask: 0.6049, decode.d7.loss_dice: 0.8827, decode.d8.loss_cls: 0.4901, decode.d8.loss_mask: 0.6031, decode.d8.loss_dice: 0.8819, loss: 27.9024
2022-11-30 08:12:47,469 - mmseg - INFO - Iter [9650/40000]	lr: 1.009e-07, eta: 1 day, 12:47:49, time: 4.118, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4876, decode.loss_mask: 0.6095, decode.loss_dice: 0.8874, decode.d0.loss_cls: 8.1140, decode.d0.loss_mask: 0.5846, decode.d0.loss_dice: 0.9611, decode.d1.loss_cls: 0.6234, decode.d1.loss_mask: 0.6295, decode.d1.loss_dice: 0.9511, decode.d2.loss_cls: 0.5499, decode.d2.loss_mask: 0.6177, decode.d2.loss_dice: 0.9104, decode.d3.loss_cls: 0.5137, decode.d3.loss_mask: 0.6144, decode.d3.loss_dice: 0.8978, decode.d4.loss_cls: 0.5076, decode.d4.loss_mask: 0.6119, decode.d4.loss_dice: 0.8947, decode.d5.loss_cls: 0.4951, decode.d5.loss_mask: 0.6106, decode.d5.loss_dice: 0.8885, decode.d6.loss_cls: 0.4927, decode.d6.loss_mask: 0.6077, decode.d6.loss_dice: 0.8822, decode.d7.loss_cls: 0.4916, decode.d7.loss_mask: 0.6081, decode.d7.loss_dice: 0.8880, decode.d8.loss_cls: 0.4908, decode.d8.loss_mask: 0.6080, decode.d8.loss_dice: 0.8881, loss: 27.9181
2022-11-30 08:16:13,144 - mmseg - INFO - Iter [9700/40000]	lr: 1.008e-07, eta: 1 day, 12:43:32, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4942, decode.loss_mask: 0.5944, decode.loss_dice: 0.8826, decode.d0.loss_cls: 8.0962, decode.d0.loss_mask: 0.5697, decode.d0.loss_dice: 0.9595, decode.d1.loss_cls: 0.6335, decode.d1.loss_mask: 0.6188, decode.d1.loss_dice: 0.9513, decode.d2.loss_cls: 0.5545, decode.d2.loss_mask: 0.6060, decode.d2.loss_dice: 0.9110, decode.d3.loss_cls: 0.5213, decode.d3.loss_mask: 0.6002, decode.d3.loss_dice: 0.8970, decode.d4.loss_cls: 0.5090, decode.d4.loss_mask: 0.5968, decode.d4.loss_dice: 0.8987, decode.d5.loss_cls: 0.5000, decode.d5.loss_mask: 0.5943, decode.d5.loss_dice: 0.8870, decode.d6.loss_cls: 0.5011, decode.d6.loss_mask: 0.5922, decode.d6.loss_dice: 0.8859, decode.d7.loss_cls: 0.4963, decode.d7.loss_mask: 0.5925, decode.d7.loss_dice: 0.8830, decode.d8.loss_cls: 0.4979, decode.d8.loss_mask: 0.5919, decode.d8.loss_dice: 0.8833, loss: 27.8000
2022-11-30 08:19:38,499 - mmseg - INFO - Iter [9750/40000]	lr: 1.006e-07, eta: 1 day, 12:39:14, time: 4.107, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4813, decode.loss_mask: 0.6017, decode.loss_dice: 0.8808, decode.d0.loss_cls: 8.0823, decode.d0.loss_mask: 0.5753, decode.d0.loss_dice: 0.9499, decode.d1.loss_cls: 0.6108, decode.d1.loss_mask: 0.6173, decode.d1.loss_dice: 0.9420, decode.d2.loss_cls: 0.5466, decode.d2.loss_mask: 0.6070, decode.d2.loss_dice: 0.9009, decode.d3.loss_cls: 0.5110, decode.d3.loss_mask: 0.6036, decode.d3.loss_dice: 0.8888, decode.d4.loss_cls: 0.5037, decode.d4.loss_mask: 0.6024, decode.d4.loss_dice: 0.8845, decode.d5.loss_cls: 0.4923, decode.d5.loss_mask: 0.6028, decode.d5.loss_dice: 0.8808, decode.d6.loss_cls: 0.4876, decode.d6.loss_mask: 0.6003, decode.d6.loss_dice: 0.8798, decode.d7.loss_cls: 0.4825, decode.d7.loss_mask: 0.5996, decode.d7.loss_dice: 0.8804, decode.d8.loss_cls: 0.4845, decode.d8.loss_mask: 0.5987, decode.d8.loss_dice: 0.8809, loss: 27.6600
2022-11-30 08:23:04,443 - mmseg - INFO - Iter [9800/40000]	lr: 1.004e-07, eta: 1 day, 12:34:58, time: 4.119, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4915, decode.loss_mask: 0.6043, decode.loss_dice: 0.8510, decode.d0.loss_cls: 8.0730, decode.d0.loss_mask: 0.5834, decode.d0.loss_dice: 0.9280, decode.d1.loss_cls: 0.6188, decode.d1.loss_mask: 0.6300, decode.d1.loss_dice: 0.9155, decode.d2.loss_cls: 0.5511, decode.d2.loss_mask: 0.6180, decode.d2.loss_dice: 0.8765, decode.d3.loss_cls: 0.5159, decode.d3.loss_mask: 0.6100, decode.d3.loss_dice: 0.8603, decode.d4.loss_cls: 0.5080, decode.d4.loss_mask: 0.6065, decode.d4.loss_dice: 0.8588, decode.d5.loss_cls: 0.4978, decode.d5.loss_mask: 0.6043, decode.d5.loss_dice: 0.8565, decode.d6.loss_cls: 0.4919, decode.d6.loss_mask: 0.6016, decode.d6.loss_dice: 0.8543, decode.d7.loss_cls: 0.4934, decode.d7.loss_mask: 0.6031, decode.d7.loss_dice: 0.8526, decode.d8.loss_cls: 0.4887, decode.d8.loss_mask: 0.6044, decode.d8.loss_dice: 0.8541, loss: 27.5032
2022-11-30 08:26:30,195 - mmseg - INFO - Iter [9850/40000]	lr: 1.003e-07, eta: 1 day, 12:30:43, time: 4.115, data_time: 0.017, memory: 51902, decode.loss_cls: 0.4779, decode.loss_mask: 0.5955, decode.loss_dice: 0.8780, decode.d0.loss_cls: 8.0649, decode.d0.loss_mask: 0.5692, decode.d0.loss_dice: 0.9387, decode.d1.loss_cls: 0.6092, decode.d1.loss_mask: 0.6209, decode.d1.loss_dice: 0.9289, decode.d2.loss_cls: 0.5390, decode.d2.loss_mask: 0.6071, decode.d2.loss_dice: 0.9000, decode.d3.loss_cls: 0.5003, decode.d3.loss_mask: 0.6010, decode.d3.loss_dice: 0.8881, decode.d4.loss_cls: 0.4937, decode.d4.loss_mask: 0.5979, decode.d4.loss_dice: 0.8834, decode.d5.loss_cls: 0.4825, decode.d5.loss_mask: 0.5985, decode.d5.loss_dice: 0.8796, decode.d6.loss_cls: 0.4750, decode.d6.loss_mask: 0.5940, decode.d6.loss_dice: 0.8787, decode.d7.loss_cls: 0.4743, decode.d7.loss_mask: 0.5967, decode.d7.loss_dice: 0.8779, decode.d8.loss_cls: 0.4748, decode.d8.loss_mask: 0.5962, decode.d8.loss_dice: 0.8767, loss: 27.4986
2022-11-30 08:29:55,703 - mmseg - INFO - Iter [9900/40000]	lr: 1.001e-07, eta: 1 day, 12:26:27, time: 4.110, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4934, decode.loss_mask: 0.6014, decode.loss_dice: 0.8782, decode.d0.loss_cls: 8.0608, decode.d0.loss_mask: 0.5785, decode.d0.loss_dice: 0.9527, decode.d1.loss_cls: 0.6256, decode.d1.loss_mask: 0.6232, decode.d1.loss_dice: 0.9432, decode.d2.loss_cls: 0.5574, decode.d2.loss_mask: 0.6106, decode.d2.loss_dice: 0.9034, decode.d3.loss_cls: 0.5198, decode.d3.loss_mask: 0.6075, decode.d3.loss_dice: 0.8891, decode.d4.loss_cls: 0.5142, decode.d4.loss_mask: 0.6018, decode.d4.loss_dice: 0.8837, decode.d5.loss_cls: 0.5017, decode.d5.loss_mask: 0.5999, decode.d5.loss_dice: 0.8772, decode.d6.loss_cls: 0.4991, decode.d6.loss_mask: 0.5993, decode.d6.loss_dice: 0.8746, decode.d7.loss_cls: 0.4921, decode.d7.loss_mask: 0.6004, decode.d7.loss_dice: 0.8808, decode.d8.loss_cls: 0.4929, decode.d8.loss_mask: 0.6019, decode.d8.loss_dice: 0.8780, loss: 27.7424
2022-11-30 08:33:21,375 - mmseg - INFO - Iter [9950/40000]	lr: 9.994e-08, eta: 1 day, 12:22:12, time: 4.113, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4923, decode.loss_mask: 0.6010, decode.loss_dice: 0.8769, decode.d0.loss_cls: 8.0455, decode.d0.loss_mask: 0.5733, decode.d0.loss_dice: 0.9536, decode.d1.loss_cls: 0.6263, decode.d1.loss_mask: 0.6263, decode.d1.loss_dice: 0.9431, decode.d2.loss_cls: 0.5524, decode.d2.loss_mask: 0.6109, decode.d2.loss_dice: 0.9002, decode.d3.loss_cls: 0.5121, decode.d3.loss_mask: 0.6069, decode.d3.loss_dice: 0.8842, decode.d4.loss_cls: 0.5069, decode.d4.loss_mask: 0.6012, decode.d4.loss_dice: 0.8798, decode.d5.loss_cls: 0.4953, decode.d5.loss_mask: 0.6036, decode.d5.loss_dice: 0.8788, decode.d6.loss_cls: 0.4918, decode.d6.loss_mask: 0.6030, decode.d6.loss_dice: 0.8762, decode.d7.loss_cls: 0.4927, decode.d7.loss_mask: 0.6003, decode.d7.loss_dice: 0.8771, decode.d8.loss_cls: 0.4924, decode.d8.loss_mask: 0.6006, decode.d8.loss_dice: 0.8760, loss: 27.6806
2022-11-30 08:36:47,452 - mmseg - INFO - Saving checkpoint at 10000 iterations
2022-11-30 08:37:34,878 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 08:37:34,878 - mmseg - INFO - Iter [10000/40000]	lr: 9.977e-08, eta: 1 day, 12:20:21, time: 5.070, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4965, decode.loss_mask: 0.6003, decode.loss_dice: 0.8816, decode.d0.loss_cls: 8.0460, decode.d0.loss_mask: 0.5775, decode.d0.loss_dice: 0.9530, decode.d1.loss_cls: 0.6452, decode.d1.loss_mask: 0.6213, decode.d1.loss_dice: 0.9341, decode.d2.loss_cls: 0.5631, decode.d2.loss_mask: 0.6103, decode.d2.loss_dice: 0.9033, decode.d3.loss_cls: 0.5223, decode.d3.loss_mask: 0.6070, decode.d3.loss_dice: 0.8883, decode.d4.loss_cls: 0.5136, decode.d4.loss_mask: 0.6032, decode.d4.loss_dice: 0.8852, decode.d5.loss_cls: 0.4998, decode.d5.loss_mask: 0.6027, decode.d5.loss_dice: 0.8863, decode.d6.loss_cls: 0.4986, decode.d6.loss_mask: 0.5987, decode.d6.loss_dice: 0.8825, decode.d7.loss_cls: 0.4972, decode.d7.loss_mask: 0.5984, decode.d7.loss_dice: 0.8827, decode.d8.loss_cls: 0.4918, decode.d8.loss_mask: 0.6011, decode.d8.loss_dice: 0.8826, loss: 27.7741
2022-11-30 08:40:33,030 - mmseg - INFO - per class results:
2022-11-30 08:40:33,035 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        |  83.0 | 89.48 |
|       building      | 85.03 | 92.33 |
|         sky         | 95.04 | 97.44 |
|        floor        | 85.14 |  90.9 |
|         tree        |  78.5 | 89.43 |
|       ceiling       | 87.09 | 92.86 |
|         road        |  87.4 | 91.97 |
|         bed         | 93.15 | 96.46 |
|      windowpane     | 66.88 | 82.62 |
|        grass        | 70.24 | 84.69 |
|       cabinet       | 62.94 | 73.46 |
|       sidewalk      | 71.15 | 87.51 |
|        person       | 88.27 | 93.77 |
|        earth        | 41.42 | 53.03 |
|         door        | 63.14 | 80.89 |
|        table        | 71.72 | 81.41 |
|       mountain      |  65.9 |  73.7 |
|        plant        | 57.24 | 70.76 |
|       curtain       | 81.91 | 90.71 |
|        chair        | 68.96 | 78.81 |
|         car         | 89.47 | 95.24 |
|        water        | 59.83 |  77.0 |
|       painting      | 82.42 | 92.85 |
|         sofa        | 85.03 | 92.46 |
|        shelf        | 46.08 | 58.79 |
|        house        | 51.44 | 63.96 |
|         sea         | 71.65 | 88.84 |
|        mirror       | 80.24 | 91.74 |
|         rug         | 71.58 |  84.0 |
|        field        | 37.63 | 69.16 |
|       armchair      | 62.77 | 79.01 |
|         seat        | 68.69 | 90.37 |
|        fence        | 58.97 | 74.85 |
|         desk        | 60.57 | 84.92 |
|         rock        | 61.24 | 81.16 |
|       wardrobe      | 52.27 |  78.6 |
|         lamp        | 79.54 | 90.43 |
|       bathtub       | 91.57 | 93.06 |
|       railing       | 47.33 | 68.16 |
|       cushion       | 77.23 | 88.74 |
|         base        | 46.31 | 71.05 |
|         box         | 43.88 | 57.43 |
|        column       | 61.74 | 72.24 |
|      signboard      | 45.59 |  63.3 |
|   chest of drawers  | 46.41 | 65.38 |
|       counter       | 51.48 | 69.44 |
|         sand        | 63.78 | 90.27 |
|         sink        | 82.83 | 87.51 |
|      skyscraper     | 33.67 | 39.77 |
|      fireplace      | 75.85 | 97.26 |
|     refrigerator    | 84.58 | 95.85 |
|      grandstand     | 42.67 | 75.89 |
|         path        | 25.14 | 32.06 |
|        stairs       | 33.29 | 42.38 |
|        runway       |  73.8 |  96.1 |
|         case        | 73.65 | 86.86 |
|      pool table     | 95.31 | 98.31 |
|        pillow       | 72.72 |  85.9 |
|     screen door     | 87.94 | 91.82 |
|       stairway      | 51.94 | 75.14 |
|        river        | 30.73 | 41.97 |
|        bridge       | 77.14 | 89.71 |
|       bookcase      |  29.7 | 57.61 |
|        blind        | 39.91 | 47.92 |
|     coffee table    | 70.91 | 88.72 |
|        toilet       | 92.91 | 96.21 |
|        flower       | 44.17 | 70.05 |
|         book        | 59.32 | 82.99 |
|         hill        | 15.54 | 25.42 |
|        bench        | 75.89 | 81.82 |
|      countertop     | 69.85 | 83.47 |
|        stove        | 85.62 | 89.87 |
|         palm        | 55.27 | 81.38 |
|    kitchen island   | 35.45 | 89.15 |
|       computer      | 81.61 | 89.57 |
|     swivel chair    | 55.13 | 82.81 |
|         boat        | 51.14 | 88.59 |
|         bar         | 64.75 | 69.63 |
|    arcade machine   |  91.8 | 98.28 |
|        hovel        | 49.85 | 70.01 |
|         bus         | 94.63 | 96.82 |
|        towel        | 79.53 | 93.55 |
|        light        |  64.3 | 80.78 |
|        truck        | 52.53 | 70.27 |
|        tower        |  33.1 | 62.29 |
|      chandelier     | 76.86 | 87.74 |
|        awning       | 32.36 | 51.32 |
|     streetlight     | 44.01 | 69.34 |
|        booth        | 36.89 | 38.87 |
| television receiver | 73.51 | 90.22 |
|       airplane      | 89.72 |  96.3 |
|      dirt track     |  0.0  |  0.0  |
|       apparel       |  51.5 | 92.45 |
|         pole        | 36.38 | 50.82 |
|         land        |  0.68 |  1.02 |
|      bannister      | 21.91 | 31.61 |
|      escalator      | 64.07 | 83.39 |
|       ottoman       | 54.85 | 85.96 |
|        bottle       | 52.98 | 80.32 |
|        buffet       | 16.66 | 21.32 |
|        poster       | 32.89 | 51.65 |
|        stage        | 26.48 |  62.8 |
|         van         | 56.11 | 80.77 |
|         ship        | 11.29 | 11.79 |
|       fountain      | 34.09 | 34.85 |
|    conveyer belt    | 73.02 | 97.69 |
|        canopy       | 53.08 | 58.22 |
|        washer       |  90.9 |  93.6 |
|      plaything      | 38.24 | 63.47 |
|    swimming pool    | 44.39 | 72.73 |
|        stool        | 60.45 | 85.08 |
|        barrel       | 58.78 | 64.42 |
|        basket       | 41.23 | 68.93 |
|      waterfall      | 58.61 | 72.32 |
|         tent        | 95.79 |  97.4 |
|         bag         | 35.33 | 55.13 |
|       minibike      | 81.11 | 93.59 |
|        cradle       | 91.26 | 97.17 |
|         oven        | 68.67 | 83.81 |
|         ball        | 66.04 | 80.11 |
|         food        | 69.32 | 84.03 |
|         step        | 26.02 | 38.84 |
|         tank        | 47.42 | 51.38 |
|      trade name     | 34.16 | 46.48 |
|      microwave      | 91.75 | 97.92 |
|         pot         | 57.41 | 68.71 |
|        animal       | 84.12 | 87.47 |
|       bicycle       | 60.31 | 84.26 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 78.86 | 91.06 |
|        screen       | 58.97 | 94.46 |
|       blanket       | 36.01 | 46.97 |
|      sculpture      | 71.49 | 90.54 |
|         hood        | 79.93 | 95.11 |
|        sconce       | 64.54 | 81.82 |
|         vase        | 59.24 | 79.84 |
|    traffic light    | 49.38 | 74.53 |
|         tray        | 30.02 | 50.85 |
|        ashcan       | 49.85 | 73.15 |
|         fan         |  72.4 | 86.43 |
|         pier        | 37.39 |  41.5 |
|      crt screen     |  2.35 |  6.14 |
|        plate        | 69.42 | 87.26 |
|       monitor       |  4.46 |  6.1  |
|    bulletin board   | 62.11 | 92.28 |
|        shower       | 24.19 | 29.53 |
|       radiator      | 71.91 | 92.66 |
|        glass        | 28.98 | 31.92 |
|        clock        | 61.41 |  75.6 |
|         flag        | 70.19 | 83.88 |
+---------------------+-------+-------+
2022-11-30 08:40:33,035 - mmseg - INFO - Summary:
2022-11-30 08:40:33,035 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 86.66 | 59.05 | 73.57 |
+-------+-------+-------+
2022-11-30 08:40:33,038 - mmseg - INFO - The previous best checkpoint /mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune/lr1.0_lrd0.9/best_mIoU_iter_8000.pth was removed
2022-11-30 08:41:21,334 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_10000.pth.
2022-11-30 08:41:21,334 - mmseg - INFO - Best mIoU is 0.5905 at 10000 iter.
2022-11-30 08:41:21,347 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 08:41:21,347 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8666, mIoU: 0.5905, mAcc: 0.7357, IoU.wall: 0.8300, IoU.building: 0.8503, IoU.sky: 0.9504, IoU.floor: 0.8514, IoU.tree: 0.7850, IoU.ceiling: 0.8709, IoU.road: 0.8740, IoU.bed : 0.9315, IoU.windowpane: 0.6688, IoU.grass: 0.7024, IoU.cabinet: 0.6294, IoU.sidewalk: 0.7115, IoU.person: 0.8827, IoU.earth: 0.4142, IoU.door: 0.6314, IoU.table: 0.7172, IoU.mountain: 0.6590, IoU.plant: 0.5724, IoU.curtain: 0.8191, IoU.chair: 0.6896, IoU.car: 0.8947, IoU.water: 0.5983, IoU.painting: 0.8242, IoU.sofa: 0.8503, IoU.shelf: 0.4608, IoU.house: 0.5144, IoU.sea: 0.7165, IoU.mirror: 0.8024, IoU.rug: 0.7158, IoU.field: 0.3763, IoU.armchair: 0.6277, IoU.seat: 0.6869, IoU.fence: 0.5897, IoU.desk: 0.6057, IoU.rock: 0.6124, IoU.wardrobe: 0.5227, IoU.lamp: 0.7954, IoU.bathtub: 0.9157, IoU.railing: 0.4733, IoU.cushion: 0.7723, IoU.base: 0.4631, IoU.box: 0.4388, IoU.column: 0.6174, IoU.signboard: 0.4559, IoU.chest of drawers: 0.4641, IoU.counter: 0.5148, IoU.sand: 0.6378, IoU.sink: 0.8283, IoU.skyscraper: 0.3367, IoU.fireplace: 0.7585, IoU.refrigerator: 0.8458, IoU.grandstand: 0.4267, IoU.path: 0.2514, IoU.stairs: 0.3329, IoU.runway: 0.7380, IoU.case: 0.7365, IoU.pool table: 0.9531, IoU.pillow: 0.7272, IoU.screen door: 0.8794, IoU.stairway: 0.5194, IoU.river: 0.3073, IoU.bridge: 0.7714, IoU.bookcase: 0.2970, IoU.blind: 0.3991, IoU.coffee table: 0.7091, IoU.toilet: 0.9291, IoU.flower: 0.4417, IoU.book: 0.5932, IoU.hill: 0.1554, IoU.bench: 0.7589, IoU.countertop: 0.6985, IoU.stove: 0.8562, IoU.palm: 0.5527, IoU.kitchen island: 0.3545, IoU.computer: 0.8161, IoU.swivel chair: 0.5513, IoU.boat: 0.5114, IoU.bar: 0.6475, IoU.arcade machine: 0.9180, IoU.hovel: 0.4985, IoU.bus: 0.9463, IoU.towel: 0.7953, IoU.light: 0.6430, IoU.truck: 0.5253, IoU.tower: 0.3310, IoU.chandelier: 0.7686, IoU.awning: 0.3236, IoU.streetlight: 0.4401, IoU.booth: 0.3689, IoU.television receiver: 0.7351, IoU.airplane: 0.8972, IoU.dirt track: 0.0000, IoU.apparel: 0.5150, IoU.pole: 0.3638, IoU.land: 0.0068, IoU.bannister: 0.2191, IoU.escalator: 0.6407, IoU.ottoman: 0.5485, IoU.bottle: 0.5298, IoU.buffet: 0.1666, IoU.poster: 0.3289, IoU.stage: 0.2648, IoU.van: 0.5611, IoU.ship: 0.1129, IoU.fountain: 0.3409, IoU.conveyer belt: 0.7302, IoU.canopy: 0.5308, IoU.washer: 0.9090, IoU.plaything: 0.3824, IoU.swimming pool: 0.4439, IoU.stool: 0.6045, IoU.barrel: 0.5878, IoU.basket: 0.4123, IoU.waterfall: 0.5861, IoU.tent: 0.9579, IoU.bag: 0.3533, IoU.minibike: 0.8111, IoU.cradle: 0.9126, IoU.oven: 0.6867, IoU.ball: 0.6604, IoU.food: 0.6932, IoU.step: 0.2602, IoU.tank: 0.4742, IoU.trade name: 0.3416, IoU.microwave: 0.9175, IoU.pot: 0.5741, IoU.animal: 0.8412, IoU.bicycle: 0.6031, IoU.lake: 0.0000, IoU.dishwasher: 0.7886, IoU.screen: 0.5897, IoU.blanket: 0.3601, IoU.sculpture: 0.7149, IoU.hood: 0.7993, IoU.sconce: 0.6454, IoU.vase: 0.5924, IoU.traffic light: 0.4938, IoU.tray: 0.3002, IoU.ashcan: 0.4985, IoU.fan: 0.7240, IoU.pier: 0.3739, IoU.crt screen: 0.0235, IoU.plate: 0.6942, IoU.monitor: 0.0446, IoU.bulletin board: 0.6211, IoU.shower: 0.2419, IoU.radiator: 0.7191, IoU.glass: 0.2898, IoU.clock: 0.6141, IoU.flag: 0.7019, Acc.wall: 0.8948, Acc.building: 0.9233, Acc.sky: 0.9744, Acc.floor: 0.9090, Acc.tree: 0.8943, Acc.ceiling: 0.9286, Acc.road: 0.9197, Acc.bed : 0.9646, Acc.windowpane: 0.8262, Acc.grass: 0.8469, Acc.cabinet: 0.7346, Acc.sidewalk: 0.8751, Acc.person: 0.9377, Acc.earth: 0.5303, Acc.door: 0.8089, Acc.table: 0.8141, Acc.mountain: 0.7370, Acc.plant: 0.7076, Acc.curtain: 0.9071, Acc.chair: 0.7881, Acc.car: 0.9524, Acc.water: 0.7700, Acc.painting: 0.9285, Acc.sofa: 0.9246, Acc.shelf: 0.5879, Acc.house: 0.6396, Acc.sea: 0.8884, Acc.mirror: 0.9174, Acc.rug: 0.8400, Acc.field: 0.6916, Acc.armchair: 0.7901, Acc.seat: 0.9037, Acc.fence: 0.7485, Acc.desk: 0.8492, Acc.rock: 0.8116, Acc.wardrobe: 0.7860, Acc.lamp: 0.9043, Acc.bathtub: 0.9306, Acc.railing: 0.6816, Acc.cushion: 0.8874, Acc.base: 0.7105, Acc.box: 0.5743, Acc.column: 0.7224, Acc.signboard: 0.6330, Acc.chest of drawers: 0.6538, Acc.counter: 0.6944, Acc.sand: 0.9027, Acc.sink: 0.8751, Acc.skyscraper: 0.3977, Acc.fireplace: 0.9726, Acc.refrigerator: 0.9585, Acc.grandstand: 0.7589, Acc.path: 0.3206, Acc.stairs: 0.4238, Acc.runway: 0.9610, Acc.case: 0.8686, Acc.pool table: 0.9831, Acc.pillow: 0.8590, Acc.screen door: 0.9182, Acc.stairway: 0.7514, Acc.river: 0.4197, Acc.bridge: 0.8971, Acc.bookcase: 0.5761, Acc.blind: 0.4792, Acc.coffee table: 0.8872, Acc.toilet: 0.9621, Acc.flower: 0.7005, Acc.book: 0.8299, Acc.hill: 0.2542, Acc.bench: 0.8182, Acc.countertop: 0.8347, Acc.stove: 0.8987, Acc.palm: 0.8138, Acc.kitchen island: 0.8915, Acc.computer: 0.8957, Acc.swivel chair: 0.8281, Acc.boat: 0.8859, Acc.bar: 0.6963, Acc.arcade machine: 0.9828, Acc.hovel: 0.7001, Acc.bus: 0.9682, Acc.towel: 0.9355, Acc.light: 0.8078, Acc.truck: 0.7027, Acc.tower: 0.6229, Acc.chandelier: 0.8774, Acc.awning: 0.5132, Acc.streetlight: 0.6934, Acc.booth: 0.3887, Acc.television receiver: 0.9022, Acc.airplane: 0.9630, Acc.dirt track: 0.0000, Acc.apparel: 0.9245, Acc.pole: 0.5082, Acc.land: 0.0102, Acc.bannister: 0.3161, Acc.escalator: 0.8339, Acc.ottoman: 0.8596, Acc.bottle: 0.8032, Acc.buffet: 0.2132, Acc.poster: 0.5165, Acc.stage: 0.6280, Acc.van: 0.8077, Acc.ship: 0.1179, Acc.fountain: 0.3485, Acc.conveyer belt: 0.9769, Acc.canopy: 0.5822, Acc.washer: 0.9360, Acc.plaything: 0.6347, Acc.swimming pool: 0.7273, Acc.stool: 0.8508, Acc.barrel: 0.6442, Acc.basket: 0.6893, Acc.waterfall: 0.7232, Acc.tent: 0.9740, Acc.bag: 0.5513, Acc.minibike: 0.9359, Acc.cradle: 0.9717, Acc.oven: 0.8381, Acc.ball: 0.8011, Acc.food: 0.8403, Acc.step: 0.3884, Acc.tank: 0.5138, Acc.trade name: 0.4648, Acc.microwave: 0.9792, Acc.pot: 0.6871, Acc.animal: 0.8747, Acc.bicycle: 0.8426, Acc.lake: 0.0000, Acc.dishwasher: 0.9106, Acc.screen: 0.9446, Acc.blanket: 0.4697, Acc.sculpture: 0.9054, Acc.hood: 0.9511, Acc.sconce: 0.8182, Acc.vase: 0.7984, Acc.traffic light: 0.7453, Acc.tray: 0.5085, Acc.ashcan: 0.7315, Acc.fan: 0.8643, Acc.pier: 0.4150, Acc.crt screen: 0.0614, Acc.plate: 0.8726, Acc.monitor: 0.0610, Acc.bulletin board: 0.9228, Acc.shower: 0.2953, Acc.radiator: 0.9266, Acc.glass: 0.3192, Acc.clock: 0.7560, Acc.flag: 0.8388
2022-11-30 08:44:46,905 - mmseg - INFO - Iter [10050/40000]	lr: 9.961e-08, eta: 1 day, 12:27:21, time: 8.641, data_time: 4.547, memory: 51902, decode.loss_cls: 0.4818, decode.loss_mask: 0.6054, decode.loss_dice: 0.8872, decode.d0.loss_cls: 8.0127, decode.d0.loss_mask: 0.5765, decode.d0.loss_dice: 0.9513, decode.d1.loss_cls: 0.6082, decode.d1.loss_mask: 0.6266, decode.d1.loss_dice: 0.9497, decode.d2.loss_cls: 0.5405, decode.d2.loss_mask: 0.6138, decode.d2.loss_dice: 0.9097, decode.d3.loss_cls: 0.5065, decode.d3.loss_mask: 0.6076, decode.d3.loss_dice: 0.8931, decode.d4.loss_cls: 0.4986, decode.d4.loss_mask: 0.6042, decode.d4.loss_dice: 0.8902, decode.d5.loss_cls: 0.4901, decode.d5.loss_mask: 0.6033, decode.d5.loss_dice: 0.8883, decode.d6.loss_cls: 0.4821, decode.d6.loss_mask: 0.6034, decode.d6.loss_dice: 0.8896, decode.d7.loss_cls: 0.4810, decode.d7.loss_mask: 0.6075, decode.d7.loss_dice: 0.8892, decode.d8.loss_cls: 0.4804, decode.d8.loss_mask: 0.6052, decode.d8.loss_dice: 0.8870, loss: 27.6707
2022-11-30 08:48:12,658 - mmseg - INFO - Iter [10100/40000]	lr: 9.944e-08, eta: 1 day, 12:23:02, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4846, decode.loss_mask: 0.6106, decode.loss_dice: 0.8821, decode.d0.loss_cls: 8.0146, decode.d0.loss_mask: 0.5826, decode.d0.loss_dice: 0.9554, decode.d1.loss_cls: 0.6145, decode.d1.loss_mask: 0.6326, decode.d1.loss_dice: 0.9390, decode.d2.loss_cls: 0.5479, decode.d2.loss_mask: 0.6171, decode.d2.loss_dice: 0.9044, decode.d3.loss_cls: 0.5118, decode.d3.loss_mask: 0.6130, decode.d3.loss_dice: 0.8882, decode.d4.loss_cls: 0.5019, decode.d4.loss_mask: 0.6082, decode.d4.loss_dice: 0.8854, decode.d5.loss_cls: 0.4940, decode.d5.loss_mask: 0.6106, decode.d5.loss_dice: 0.8854, decode.d6.loss_cls: 0.4902, decode.d6.loss_mask: 0.6086, decode.d6.loss_dice: 0.8796, decode.d7.loss_cls: 0.4856, decode.d7.loss_mask: 0.6109, decode.d7.loss_dice: 0.8829, decode.d8.loss_cls: 0.4865, decode.d8.loss_mask: 0.6089, decode.d8.loss_dice: 0.8805, loss: 27.7174
2022-11-30 08:51:40,565 - mmseg - INFO - Iter [10150/40000]	lr: 9.928e-08, eta: 1 day, 12:18:50, time: 4.158, data_time: 0.065, memory: 51902, decode.loss_cls: 0.4771, decode.loss_mask: 0.5958, decode.loss_dice: 0.8754, decode.d0.loss_cls: 7.9993, decode.d0.loss_mask: 0.5693, decode.d0.loss_dice: 0.9456, decode.d1.loss_cls: 0.6100, decode.d1.loss_mask: 0.6176, decode.d1.loss_dice: 0.9410, decode.d2.loss_cls: 0.5397, decode.d2.loss_mask: 0.6059, decode.d2.loss_dice: 0.8974, decode.d3.loss_cls: 0.5040, decode.d3.loss_mask: 0.6007, decode.d3.loss_dice: 0.8794, decode.d4.loss_cls: 0.4958, decode.d4.loss_mask: 0.5962, decode.d4.loss_dice: 0.8774, decode.d5.loss_cls: 0.4844, decode.d5.loss_mask: 0.5970, decode.d5.loss_dice: 0.8759, decode.d6.loss_cls: 0.4786, decode.d6.loss_mask: 0.5966, decode.d6.loss_dice: 0.8702, decode.d7.loss_cls: 0.4726, decode.d7.loss_mask: 0.5965, decode.d7.loss_dice: 0.8756, decode.d8.loss_cls: 0.4718, decode.d8.loss_mask: 0.5961, decode.d8.loss_dice: 0.8741, loss: 27.4169
2022-11-30 08:55:06,216 - mmseg - INFO - Iter [10200/40000]	lr: 9.911e-08, eta: 1 day, 12:14:32, time: 4.113, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4689, decode.loss_mask: 0.6072, decode.loss_dice: 0.8761, decode.d0.loss_cls: 7.9867, decode.d0.loss_mask: 0.5765, decode.d0.loss_dice: 0.9517, decode.d1.loss_cls: 0.5977, decode.d1.loss_mask: 0.6279, decode.d1.loss_dice: 0.9373, decode.d2.loss_cls: 0.5305, decode.d2.loss_mask: 0.6152, decode.d2.loss_dice: 0.8988, decode.d3.loss_cls: 0.4969, decode.d3.loss_mask: 0.6075, decode.d3.loss_dice: 0.8810, decode.d4.loss_cls: 0.4843, decode.d4.loss_mask: 0.6076, decode.d4.loss_dice: 0.8808, decode.d5.loss_cls: 0.4775, decode.d5.loss_mask: 0.6050, decode.d5.loss_dice: 0.8770, decode.d6.loss_cls: 0.4718, decode.d6.loss_mask: 0.6056, decode.d6.loss_dice: 0.8744, decode.d7.loss_cls: 0.4725, decode.d7.loss_mask: 0.6035, decode.d7.loss_dice: 0.8770, decode.d8.loss_cls: 0.4711, decode.d8.loss_mask: 0.6026, decode.d8.loss_dice: 0.8758, loss: 27.4468
2022-11-30 08:58:31,750 - mmseg - INFO - Iter [10250/40000]	lr: 9.894e-08, eta: 1 day, 12:10:15, time: 4.111, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4719, decode.loss_mask: 0.6000, decode.loss_dice: 0.8672, decode.d0.loss_cls: 7.9733, decode.d0.loss_mask: 0.5713, decode.d0.loss_dice: 0.9295, decode.d1.loss_cls: 0.6107, decode.d1.loss_mask: 0.6157, decode.d1.loss_dice: 0.9340, decode.d2.loss_cls: 0.5367, decode.d2.loss_mask: 0.6082, decode.d2.loss_dice: 0.8896, decode.d3.loss_cls: 0.5030, decode.d3.loss_mask: 0.6046, decode.d3.loss_dice: 0.8740, decode.d4.loss_cls: 0.4894, decode.d4.loss_mask: 0.6001, decode.d4.loss_dice: 0.8700, decode.d5.loss_cls: 0.4780, decode.d5.loss_mask: 0.6011, decode.d5.loss_dice: 0.8700, decode.d6.loss_cls: 0.4753, decode.d6.loss_mask: 0.5990, decode.d6.loss_dice: 0.8657, decode.d7.loss_cls: 0.4737, decode.d7.loss_mask: 0.6014, decode.d7.loss_dice: 0.8632, decode.d8.loss_cls: 0.4705, decode.d8.loss_mask: 0.6006, decode.d8.loss_dice: 0.8669, loss: 27.3145
2022-11-30 09:01:57,459 - mmseg - INFO - Iter [10300/40000]	lr: 9.878e-08, eta: 1 day, 12:05:58, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4855, decode.loss_mask: 0.6037, decode.loss_dice: 0.8798, decode.d0.loss_cls: 7.9691, decode.d0.loss_mask: 0.5769, decode.d0.loss_dice: 0.9487, decode.d1.loss_cls: 0.6087, decode.d1.loss_mask: 0.6252, decode.d1.loss_dice: 0.9415, decode.d2.loss_cls: 0.5413, decode.d2.loss_mask: 0.6119, decode.d2.loss_dice: 0.9020, decode.d3.loss_cls: 0.5073, decode.d3.loss_mask: 0.6078, decode.d3.loss_dice: 0.8884, decode.d4.loss_cls: 0.5000, decode.d4.loss_mask: 0.6024, decode.d4.loss_dice: 0.8879, decode.d5.loss_cls: 0.4909, decode.d5.loss_mask: 0.6029, decode.d5.loss_dice: 0.8828, decode.d6.loss_cls: 0.4828, decode.d6.loss_mask: 0.6053, decode.d6.loss_dice: 0.8793, decode.d7.loss_cls: 0.4836, decode.d7.loss_mask: 0.6030, decode.d7.loss_dice: 0.8845, decode.d8.loss_cls: 0.4765, decode.d8.loss_mask: 0.6061, decode.d8.loss_dice: 0.8837, loss: 27.5693
2022-11-30 09:05:22,785 - mmseg - INFO - Iter [10350/40000]	lr: 9.861e-08, eta: 1 day, 12:01:40, time: 4.107, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4705, decode.loss_mask: 0.6052, decode.loss_dice: 0.8761, decode.d0.loss_cls: 7.9600, decode.d0.loss_mask: 0.5784, decode.d0.loss_dice: 0.9479, decode.d1.loss_cls: 0.6047, decode.d1.loss_mask: 0.6249, decode.d1.loss_dice: 0.9461, decode.d2.loss_cls: 0.5343, decode.d2.loss_mask: 0.6158, decode.d2.loss_dice: 0.9079, decode.d3.loss_cls: 0.5017, decode.d3.loss_mask: 0.6067, decode.d3.loss_dice: 0.8929, decode.d4.loss_cls: 0.4884, decode.d4.loss_mask: 0.6063, decode.d4.loss_dice: 0.8839, decode.d5.loss_cls: 0.4820, decode.d5.loss_mask: 0.6046, decode.d5.loss_dice: 0.8784, decode.d6.loss_cls: 0.4715, decode.d6.loss_mask: 0.6033, decode.d6.loss_dice: 0.8797, decode.d7.loss_cls: 0.4694, decode.d7.loss_mask: 0.6023, decode.d7.loss_dice: 0.8786, decode.d8.loss_cls: 0.4707, decode.d8.loss_mask: 0.6064, decode.d8.loss_dice: 0.8776, loss: 27.4763
2022-11-30 09:08:48,272 - mmseg - INFO - Iter [10400/40000]	lr: 9.844e-08, eta: 1 day, 11:57:24, time: 4.110, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4768, decode.loss_mask: 0.5967, decode.loss_dice: 0.8538, decode.d0.loss_cls: 7.9493, decode.d0.loss_mask: 0.5731, decode.d0.loss_dice: 0.9272, decode.d1.loss_cls: 0.6073, decode.d1.loss_mask: 0.6197, decode.d1.loss_dice: 0.9157, decode.d2.loss_cls: 0.5466, decode.d2.loss_mask: 0.6046, decode.d2.loss_dice: 0.8808, decode.d3.loss_cls: 0.5065, decode.d3.loss_mask: 0.6011, decode.d3.loss_dice: 0.8680, decode.d4.loss_cls: 0.4949, decode.d4.loss_mask: 0.6006, decode.d4.loss_dice: 0.8622, decode.d5.loss_cls: 0.4859, decode.d5.loss_mask: 0.5980, decode.d5.loss_dice: 0.8598, decode.d6.loss_cls: 0.4815, decode.d6.loss_mask: 0.5958, decode.d6.loss_dice: 0.8572, decode.d7.loss_cls: 0.4802, decode.d7.loss_mask: 0.5965, decode.d7.loss_dice: 0.8566, decode.d8.loss_cls: 0.4751, decode.d8.loss_mask: 0.5960, decode.d8.loss_dice: 0.8584, loss: 27.2260
2022-11-30 09:12:13,865 - mmseg - INFO - Iter [10450/40000]	lr: 9.828e-08, eta: 1 day, 11:53:08, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4665, decode.loss_mask: 0.5871, decode.loss_dice: 0.8705, decode.d0.loss_cls: 7.9405, decode.d0.loss_mask: 0.5607, decode.d0.loss_dice: 0.9471, decode.d1.loss_cls: 0.6156, decode.d1.loss_mask: 0.6045, decode.d1.loss_dice: 0.9299, decode.d2.loss_cls: 0.5438, decode.d2.loss_mask: 0.5889, decode.d2.loss_dice: 0.8899, decode.d3.loss_cls: 0.5031, decode.d3.loss_mask: 0.5858, decode.d3.loss_dice: 0.8806, decode.d4.loss_cls: 0.4930, decode.d4.loss_mask: 0.5848, decode.d4.loss_dice: 0.8757, decode.d5.loss_cls: 0.4803, decode.d5.loss_mask: 0.5831, decode.d5.loss_dice: 0.8736, decode.d6.loss_cls: 0.4762, decode.d6.loss_mask: 0.5839, decode.d6.loss_dice: 0.8653, decode.d7.loss_cls: 0.4683, decode.d7.loss_mask: 0.5841, decode.d7.loss_dice: 0.8692, decode.d8.loss_cls: 0.4697, decode.d8.loss_mask: 0.5857, decode.d8.loss_dice: 0.8677, loss: 27.1748
2022-11-30 09:15:39,314 - mmseg - INFO - Iter [10500/40000]	lr: 9.811e-08, eta: 1 day, 11:48:53, time: 4.109, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4724, decode.loss_mask: 0.6043, decode.loss_dice: 0.8834, decode.d0.loss_cls: 7.9276, decode.d0.loss_mask: 0.5758, decode.d0.loss_dice: 0.9537, decode.d1.loss_cls: 0.6099, decode.d1.loss_mask: 0.6223, decode.d1.loss_dice: 0.9442, decode.d2.loss_cls: 0.5396, decode.d2.loss_mask: 0.6130, decode.d2.loss_dice: 0.9093, decode.d3.loss_cls: 0.5017, decode.d3.loss_mask: 0.6076, decode.d3.loss_dice: 0.8907, decode.d4.loss_cls: 0.4927, decode.d4.loss_mask: 0.6048, decode.d4.loss_dice: 0.8914, decode.d5.loss_cls: 0.4769, decode.d5.loss_mask: 0.6035, decode.d5.loss_dice: 0.8922, decode.d6.loss_cls: 0.4745, decode.d6.loss_mask: 0.6030, decode.d6.loss_dice: 0.8878, decode.d7.loss_cls: 0.4746, decode.d7.loss_mask: 0.6032, decode.d7.loss_dice: 0.8882, decode.d8.loss_cls: 0.4717, decode.d8.loss_mask: 0.6023, decode.d8.loss_dice: 0.8859, loss: 27.5085
2022-11-30 09:19:04,719 - mmseg - INFO - Iter [10550/40000]	lr: 9.795e-08, eta: 1 day, 11:44:38, time: 4.108, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4755, decode.loss_mask: 0.6018, decode.loss_dice: 0.8790, decode.d0.loss_cls: 7.9208, decode.d0.loss_mask: 0.5735, decode.d0.loss_dice: 0.9505, decode.d1.loss_cls: 0.6044, decode.d1.loss_mask: 0.6243, decode.d1.loss_dice: 0.9401, decode.d2.loss_cls: 0.5385, decode.d2.loss_mask: 0.6124, decode.d2.loss_dice: 0.9025, decode.d3.loss_cls: 0.5055, decode.d3.loss_mask: 0.6055, decode.d3.loss_dice: 0.8836, decode.d4.loss_cls: 0.4943, decode.d4.loss_mask: 0.6038, decode.d4.loss_dice: 0.8816, decode.d5.loss_cls: 0.4812, decode.d5.loss_mask: 0.6025, decode.d5.loss_dice: 0.8805, decode.d6.loss_cls: 0.4811, decode.d6.loss_mask: 0.6001, decode.d6.loss_dice: 0.8779, decode.d7.loss_cls: 0.4794, decode.d7.loss_mask: 0.6020, decode.d7.loss_dice: 0.8791, decode.d8.loss_cls: 0.4729, decode.d8.loss_mask: 0.6027, decode.d8.loss_dice: 0.8802, loss: 27.4373
2022-11-30 09:22:30,361 - mmseg - INFO - Iter [10600/40000]	lr: 9.778e-08, eta: 1 day, 11:40:24, time: 4.113, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4784, decode.loss_mask: 0.5873, decode.loss_dice: 0.8591, decode.d0.loss_cls: 7.9117, decode.d0.loss_mask: 0.5586, decode.d0.loss_dice: 0.9358, decode.d1.loss_cls: 0.6156, decode.d1.loss_mask: 0.6066, decode.d1.loss_dice: 0.9206, decode.d2.loss_cls: 0.5474, decode.d2.loss_mask: 0.5935, decode.d2.loss_dice: 0.8775, decode.d3.loss_cls: 0.5125, decode.d3.loss_mask: 0.5887, decode.d3.loss_dice: 0.8630, decode.d4.loss_cls: 0.5021, decode.d4.loss_mask: 0.5899, decode.d4.loss_dice: 0.8628, decode.d5.loss_cls: 0.4878, decode.d5.loss_mask: 0.5882, decode.d5.loss_dice: 0.8595, decode.d6.loss_cls: 0.4823, decode.d6.loss_mask: 0.5879, decode.d6.loss_dice: 0.8526, decode.d7.loss_cls: 0.4814, decode.d7.loss_mask: 0.5878, decode.d7.loss_dice: 0.8569, decode.d8.loss_cls: 0.4786, decode.d8.loss_mask: 0.5870, decode.d8.loss_dice: 0.8542, loss: 27.1154
2022-11-30 09:25:55,919 - mmseg - INFO - Iter [10650/40000]	lr: 9.761e-08, eta: 1 day, 11:36:10, time: 4.111, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4809, decode.loss_mask: 0.6113, decode.loss_dice: 0.8751, decode.d0.loss_cls: 7.8858, decode.d0.loss_mask: 0.5856, decode.d0.loss_dice: 0.9453, decode.d1.loss_cls: 0.6109, decode.d1.loss_mask: 0.6323, decode.d1.loss_dice: 0.9355, decode.d2.loss_cls: 0.5528, decode.d2.loss_mask: 0.6221, decode.d2.loss_dice: 0.8944, decode.d3.loss_cls: 0.5114, decode.d3.loss_mask: 0.6169, decode.d3.loss_dice: 0.8827, decode.d4.loss_cls: 0.5032, decode.d4.loss_mask: 0.6153, decode.d4.loss_dice: 0.8823, decode.d5.loss_cls: 0.4923, decode.d5.loss_mask: 0.6086, decode.d5.loss_dice: 0.8747, decode.d6.loss_cls: 0.4834, decode.d6.loss_mask: 0.6105, decode.d6.loss_dice: 0.8735, decode.d7.loss_cls: 0.4834, decode.d7.loss_mask: 0.6116, decode.d7.loss_dice: 0.8748, decode.d8.loss_cls: 0.4837, decode.d8.loss_mask: 0.6124, decode.d8.loss_dice: 0.8737, loss: 27.5266
2022-11-30 09:29:21,070 - mmseg - INFO - Iter [10700/40000]	lr: 9.745e-08, eta: 1 day, 11:31:55, time: 4.103, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4597, decode.loss_mask: 0.6015, decode.loss_dice: 0.8722, decode.d0.loss_cls: 7.8771, decode.d0.loss_mask: 0.5744, decode.d0.loss_dice: 0.9445, decode.d1.loss_cls: 0.5979, decode.d1.loss_mask: 0.6235, decode.d1.loss_dice: 0.9384, decode.d2.loss_cls: 0.5210, decode.d2.loss_mask: 0.6127, decode.d2.loss_dice: 0.8921, decode.d3.loss_cls: 0.4844, decode.d3.loss_mask: 0.6073, decode.d3.loss_dice: 0.8791, decode.d4.loss_cls: 0.4766, decode.d4.loss_mask: 0.6054, decode.d4.loss_dice: 0.8779, decode.d5.loss_cls: 0.4690, decode.d5.loss_mask: 0.6037, decode.d5.loss_dice: 0.8724, decode.d6.loss_cls: 0.4661, decode.d6.loss_mask: 0.6010, decode.d6.loss_dice: 0.8704, decode.d7.loss_cls: 0.4611, decode.d7.loss_mask: 0.6036, decode.d7.loss_dice: 0.8729, decode.d8.loss_cls: 0.4586, decode.d8.loss_mask: 0.6011, decode.d8.loss_dice: 0.8733, loss: 27.1991
2022-11-30 09:32:49,312 - mmseg - INFO - Iter [10750/40000]	lr: 9.728e-08, eta: 1 day, 11:27:50, time: 4.165, data_time: 0.064, memory: 51902, decode.loss_cls: 0.4760, decode.loss_mask: 0.6067, decode.loss_dice: 0.8719, decode.d0.loss_cls: 7.8698, decode.d0.loss_mask: 0.5774, decode.d0.loss_dice: 0.9442, decode.d1.loss_cls: 0.5987, decode.d1.loss_mask: 0.6292, decode.d1.loss_dice: 0.9401, decode.d2.loss_cls: 0.5289, decode.d2.loss_mask: 0.6142, decode.d2.loss_dice: 0.9001, decode.d3.loss_cls: 0.4970, decode.d3.loss_mask: 0.6073, decode.d3.loss_dice: 0.8846, decode.d4.loss_cls: 0.4912, decode.d4.loss_mask: 0.6021, decode.d4.loss_dice: 0.8799, decode.d5.loss_cls: 0.4832, decode.d5.loss_mask: 0.6037, decode.d5.loss_dice: 0.8721, decode.d6.loss_cls: 0.4779, decode.d6.loss_mask: 0.6032, decode.d6.loss_dice: 0.8710, decode.d7.loss_cls: 0.4781, decode.d7.loss_mask: 0.6022, decode.d7.loss_dice: 0.8722, decode.d8.loss_cls: 0.4729, decode.d8.loss_mask: 0.6044, decode.d8.loss_dice: 0.8727, loss: 27.3331
2022-11-30 09:36:14,842 - mmseg - INFO - Iter [10800/40000]	lr: 9.711e-08, eta: 1 day, 11:23:37, time: 4.111, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4763, decode.loss_mask: 0.5770, decode.loss_dice: 0.8644, decode.d0.loss_cls: 7.8874, decode.d0.loss_mask: 0.5493, decode.d0.loss_dice: 0.9321, decode.d1.loss_cls: 0.6236, decode.d1.loss_mask: 0.5945, decode.d1.loss_dice: 0.9239, decode.d2.loss_cls: 0.5425, decode.d2.loss_mask: 0.5859, decode.d2.loss_dice: 0.8848, decode.d3.loss_cls: 0.5082, decode.d3.loss_mask: 0.5797, decode.d3.loss_dice: 0.8710, decode.d4.loss_cls: 0.4983, decode.d4.loss_mask: 0.5753, decode.d4.loss_dice: 0.8704, decode.d5.loss_cls: 0.4884, decode.d5.loss_mask: 0.5753, decode.d5.loss_dice: 0.8671, decode.d6.loss_cls: 0.4822, decode.d6.loss_mask: 0.5750, decode.d6.loss_dice: 0.8606, decode.d7.loss_cls: 0.4777, decode.d7.loss_mask: 0.5755, decode.d7.loss_dice: 0.8670, decode.d8.loss_cls: 0.4795, decode.d8.loss_mask: 0.5775, decode.d8.loss_dice: 0.8666, loss: 27.0371
2022-11-30 09:39:40,293 - mmseg - INFO - Iter [10850/40000]	lr: 9.695e-08, eta: 1 day, 11:19:25, time: 4.109, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4515, decode.loss_mask: 0.5952, decode.loss_dice: 0.8519, decode.d0.loss_cls: 7.8492, decode.d0.loss_mask: 0.5742, decode.d0.loss_dice: 0.9256, decode.d1.loss_cls: 0.6002, decode.d1.loss_mask: 0.6161, decode.d1.loss_dice: 0.9101, decode.d2.loss_cls: 0.5245, decode.d2.loss_mask: 0.6020, decode.d2.loss_dice: 0.8730, decode.d3.loss_cls: 0.4892, decode.d3.loss_mask: 0.5959, decode.d3.loss_dice: 0.8605, decode.d4.loss_cls: 0.4762, decode.d4.loss_mask: 0.5954, decode.d4.loss_dice: 0.8573, decode.d5.loss_cls: 0.4625, decode.d5.loss_mask: 0.5964, decode.d5.loss_dice: 0.8533, decode.d6.loss_cls: 0.4595, decode.d6.loss_mask: 0.5916, decode.d6.loss_dice: 0.8483, decode.d7.loss_cls: 0.4542, decode.d7.loss_mask: 0.5929, decode.d7.loss_dice: 0.8509, decode.d8.loss_cls: 0.4537, decode.d8.loss_mask: 0.5938, decode.d8.loss_dice: 0.8521, loss: 26.8572
2022-11-30 09:43:05,699 - mmseg - INFO - Iter [10900/40000]	lr: 9.678e-08, eta: 1 day, 11:15:13, time: 4.108, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4793, decode.loss_mask: 0.5970, decode.loss_dice: 0.8694, decode.d0.loss_cls: 7.8420, decode.d0.loss_mask: 0.5731, decode.d0.loss_dice: 0.9512, decode.d1.loss_cls: 0.6268, decode.d1.loss_mask: 0.6181, decode.d1.loss_dice: 0.9270, decode.d2.loss_cls: 0.5472, decode.d2.loss_mask: 0.6088, decode.d2.loss_dice: 0.8862, decode.d3.loss_cls: 0.5104, decode.d3.loss_mask: 0.6003, decode.d3.loss_dice: 0.8698, decode.d4.loss_cls: 0.4993, decode.d4.loss_mask: 0.6009, decode.d4.loss_dice: 0.8732, decode.d5.loss_cls: 0.4915, decode.d5.loss_mask: 0.5980, decode.d5.loss_dice: 0.8689, decode.d6.loss_cls: 0.4869, decode.d6.loss_mask: 0.5946, decode.d6.loss_dice: 0.8580, decode.d7.loss_cls: 0.4788, decode.d7.loss_mask: 0.5967, decode.d7.loss_dice: 0.8623, decode.d8.loss_cls: 0.4816, decode.d8.loss_mask: 0.5959, decode.d8.loss_dice: 0.8665, loss: 27.2598
2022-11-30 09:46:31,475 - mmseg - INFO - Iter [10950/40000]	lr: 9.661e-08, eta: 1 day, 11:11:02, time: 4.116, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4658, decode.loss_mask: 0.5913, decode.loss_dice: 0.8607, decode.d0.loss_cls: 7.8206, decode.d0.loss_mask: 0.5653, decode.d0.loss_dice: 0.9317, decode.d1.loss_cls: 0.5941, decode.d1.loss_mask: 0.6142, decode.d1.loss_dice: 0.9262, decode.d2.loss_cls: 0.5244, decode.d2.loss_mask: 0.6018, decode.d2.loss_dice: 0.8848, decode.d3.loss_cls: 0.4931, decode.d3.loss_mask: 0.5972, decode.d3.loss_dice: 0.8663, decode.d4.loss_cls: 0.4863, decode.d4.loss_mask: 0.5900, decode.d4.loss_dice: 0.8711, decode.d5.loss_cls: 0.4716, decode.d5.loss_mask: 0.5906, decode.d5.loss_dice: 0.8656, decode.d6.loss_cls: 0.4660, decode.d6.loss_mask: 0.5929, decode.d6.loss_dice: 0.8607, decode.d7.loss_cls: 0.4643, decode.d7.loss_mask: 0.5906, decode.d7.loss_dice: 0.8632, decode.d8.loss_cls: 0.4632, decode.d8.loss_mask: 0.5925, decode.d8.loss_dice: 0.8630, loss: 26.9689
2022-11-30 09:49:56,735 - mmseg - INFO - Saving checkpoint at 11000 iterations
2022-11-30 09:50:46,061 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 09:50:46,061 - mmseg - INFO - Iter [11000/40000]	lr: 9.645e-08, eta: 1 day, 11:09:00, time: 5.092, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4781, decode.loss_mask: 0.5856, decode.loss_dice: 0.8520, decode.d0.loss_cls: 7.8164, decode.d0.loss_mask: 0.5579, decode.d0.loss_dice: 0.9305, decode.d1.loss_cls: 0.6066, decode.d1.loss_mask: 0.6065, decode.d1.loss_dice: 0.9123, decode.d2.loss_cls: 0.5394, decode.d2.loss_mask: 0.5931, decode.d2.loss_dice: 0.8752, decode.d3.loss_cls: 0.4982, decode.d3.loss_mask: 0.5896, decode.d3.loss_dice: 0.8604, decode.d4.loss_cls: 0.4932, decode.d4.loss_mask: 0.5841, decode.d4.loss_dice: 0.8579, decode.d5.loss_cls: 0.4841, decode.d5.loss_mask: 0.5850, decode.d5.loss_dice: 0.8517, decode.d6.loss_cls: 0.4794, decode.d6.loss_mask: 0.5861, decode.d6.loss_dice: 0.8498, decode.d7.loss_cls: 0.4758, decode.d7.loss_mask: 0.5848, decode.d7.loss_dice: 0.8502, decode.d8.loss_cls: 0.4773, decode.d8.loss_mask: 0.5845, decode.d8.loss_dice: 0.8483, loss: 26.8939
2022-11-30 09:53:44,050 - mmseg - INFO - per class results:
2022-11-30 09:53:44,055 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 83.27 | 90.04 |
|       building      | 85.14 | 91.04 |
|         sky         |  95.0 | 96.86 |
|        floor        | 84.87 | 89.93 |
|         tree        | 78.25 | 91.15 |
|       ceiling       | 87.57 | 92.74 |
|         road        | 88.27 | 91.46 |
|         bed         |  93.1 | 96.29 |
|      windowpane     | 65.96 | 85.15 |
|        grass        | 71.11 | 82.88 |
|       cabinet       | 63.67 | 74.91 |
|       sidewalk      | 72.78 | 86.93 |
|        person       | 88.31 | 93.89 |
|        earth        | 47.21 | 66.18 |
|         door        | 62.26 | 77.75 |
|        table        |  72.7 | 82.24 |
|       mountain      | 61.42 | 79.52 |
|        plant        | 57.46 | 68.32 |
|       curtain       | 82.46 | 90.78 |
|        chair        | 69.06 | 79.03 |
|         car         | 88.89 | 95.58 |
|        water        | 63.29 | 81.82 |
|       painting      | 81.21 | 92.24 |
|         sofa        | 85.54 | 91.21 |
|        shelf        | 45.24 |  54.7 |
|        house        | 48.54 | 63.96 |
|         sea         | 72.75 | 87.83 |
|        mirror       | 81.36 |  92.1 |
|         rug         |  72.2 | 86.73 |
|        field        | 36.32 | 66.98 |
|       armchair      | 63.38 | 83.88 |
|         seat        | 67.61 | 89.03 |
|        fence        |  57.1 | 79.36 |
|         desk        | 61.56 | 83.55 |
|         rock        | 52.88 | 57.61 |
|       wardrobe      | 52.38 | 78.77 |
|         lamp        | 80.05 | 90.01 |
|       bathtub       | 91.34 |  93.1 |
|       railing       | 47.37 | 74.93 |
|       cushion       | 76.12 | 90.23 |
|         base        | 43.39 | 72.08 |
|         box         | 42.48 | 60.33 |
|        column       | 58.96 |  73.7 |
|      signboard      | 45.89 | 67.14 |
|   chest of drawers  | 45.08 | 67.97 |
|       counter       | 54.73 | 71.88 |
|         sand        | 64.33 | 83.54 |
|         sink        | 80.65 | 86.31 |
|      skyscraper     |  40.2 | 53.95 |
|      fireplace      | 83.18 | 93.07 |
|     refrigerator    | 86.32 | 95.88 |
|      grandstand     | 45.59 | 77.19 |
|         path        | 30.11 |  42.8 |
|        stairs       | 29.18 | 36.23 |
|        runway       |  74.8 | 95.53 |
|         case        | 75.66 | 85.31 |
|      pool table     | 94.94 | 98.56 |
|        pillow       | 72.54 | 82.84 |
|     screen door     | 77.87 | 82.99 |
|       stairway      |  50.4 | 73.55 |
|        river        | 23.38 | 25.68 |
|        bridge       | 80.53 | 90.18 |
|       bookcase      | 33.91 | 64.28 |
|        blind        | 31.23 | 33.36 |
|     coffee table    | 71.02 | 90.67 |
|        toilet       | 92.72 | 96.13 |
|        flower       | 43.96 |  63.1 |
|         book        |  60.1 | 78.85 |
|         hill        |  7.41 | 11.16 |
|        bench        | 77.03 | 85.12 |
|      countertop     | 68.89 | 81.49 |
|        stove        | 83.87 | 86.89 |
|         palm        | 54.96 | 80.33 |
|    kitchen island   | 36.63 | 80.83 |
|       computer      |  79.8 | 83.97 |
|     swivel chair    | 55.83 | 81.92 |
|         boat        | 53.46 | 86.05 |
|         bar         | 58.39 | 62.25 |
|    arcade machine   | 89.69 | 96.75 |
|        hovel        | 29.12 | 40.81 |
|         bus         |  94.9 | 96.64 |
|        towel        | 79.14 | 94.45 |
|        light        | 65.67 | 80.29 |
|        truck        | 54.86 | 72.27 |
|        tower        | 31.13 |  60.1 |
|      chandelier     | 76.27 |  88.4 |
|        awning       | 33.03 | 50.21 |
|     streetlight     | 48.32 | 69.36 |
|        booth        | 38.78 | 40.99 |
| television receiver | 75.14 | 91.98 |
|       airplane      | 89.14 | 95.91 |
|      dirt track     |  0.01 |  0.01 |
|       apparel       | 53.82 | 89.62 |
|         pole        | 42.35 | 56.44 |
|         land        |  0.0  |  0.0  |
|      bannister      | 14.88 | 20.01 |
|      escalator      | 63.77 | 82.46 |
|       ottoman       | 53.01 | 81.14 |
|        bottle       | 54.11 |  81.7 |
|        buffet       | 37.58 | 50.35 |
|        poster       | 32.74 | 49.91 |
|        stage        | 24.71 | 55.58 |
|         van         | 48.69 | 62.22 |
|         ship        | 25.26 | 26.38 |
|       fountain      | 42.94 | 44.07 |
|    conveyer belt    | 69.71 | 98.06 |
|        canopy       | 41.05 | 55.03 |
|        washer       | 90.55 | 93.34 |
|      plaything      | 39.16 | 58.65 |
|    swimming pool    | 44.21 |  74.1 |
|        stool        | 62.86 | 81.27 |
|        barrel       | 58.34 | 64.49 |
|        basket       | 42.92 | 72.23 |
|      waterfall      | 47.38 | 58.09 |
|         tent        | 93.84 | 97.44 |
|         bag         | 35.59 |  50.8 |
|       minibike      | 79.85 |  93.5 |
|        cradle       | 91.34 | 97.51 |
|         oven        | 61.79 | 83.97 |
|         ball        | 63.23 | 76.07 |
|         food        |  67.7 | 83.13 |
|         step        | 33.45 | 52.37 |
|         tank        | 48.37 | 49.77 |
|      trade name     | 35.02 | 51.52 |
|      microwave      | 89.04 | 94.75 |
|         pot         | 58.03 | 69.57 |
|        animal       | 85.13 | 88.37 |
|       bicycle       | 58.13 | 83.96 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 80.04 | 90.27 |
|        screen       | 61.57 | 92.73 |
|       blanket       | 33.58 | 48.41 |
|      sculpture      | 73.13 | 89.66 |
|         hood        | 69.22 | 74.74 |
|        sconce       | 65.98 | 82.95 |
|         vase        |  57.3 | 80.74 |
|    traffic light    | 48.45 | 70.99 |
|         tray        | 29.46 | 41.07 |
|        ashcan       | 51.46 | 73.94 |
|         fan         | 71.42 | 86.03 |
|         pier        | 37.41 | 40.57 |
|      crt screen     |  0.0  |  0.0  |
|        plate        | 68.35 | 87.12 |
|       monitor       |  20.3 | 33.74 |
|    bulletin board   | 65.03 | 84.22 |
|        shower       | 23.91 | 26.72 |
|       radiator      |  73.9 | 91.75 |
|        glass        | 28.77 | 32.06 |
|        clock        | 62.38 | 74.86 |
|         flag        | 69.29 | 83.18 |
+---------------------+-------+-------+
2022-11-30 09:53:44,055 - mmseg - INFO - Summary:
2022-11-30 09:53:44,055 - mmseg - INFO - 
+------+-------+-------+
| aAcc |  mIoU |  mAcc |
+------+-------+-------+
| 86.7 | 58.87 | 72.77 |
+------+-------+-------+
2022-11-30 09:53:44,060 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 09:53:44,060 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8670, mIoU: 0.5887, mAcc: 0.7277, IoU.wall: 0.8327, IoU.building: 0.8514, IoU.sky: 0.9500, IoU.floor: 0.8487, IoU.tree: 0.7825, IoU.ceiling: 0.8757, IoU.road: 0.8827, IoU.bed : 0.9310, IoU.windowpane: 0.6596, IoU.grass: 0.7111, IoU.cabinet: 0.6367, IoU.sidewalk: 0.7278, IoU.person: 0.8831, IoU.earth: 0.4721, IoU.door: 0.6226, IoU.table: 0.7270, IoU.mountain: 0.6142, IoU.plant: 0.5746, IoU.curtain: 0.8246, IoU.chair: 0.6906, IoU.car: 0.8889, IoU.water: 0.6329, IoU.painting: 0.8121, IoU.sofa: 0.8554, IoU.shelf: 0.4524, IoU.house: 0.4854, IoU.sea: 0.7275, IoU.mirror: 0.8136, IoU.rug: 0.7220, IoU.field: 0.3632, IoU.armchair: 0.6338, IoU.seat: 0.6761, IoU.fence: 0.5710, IoU.desk: 0.6156, IoU.rock: 0.5288, IoU.wardrobe: 0.5238, IoU.lamp: 0.8005, IoU.bathtub: 0.9134, IoU.railing: 0.4737, IoU.cushion: 0.7612, IoU.base: 0.4339, IoU.box: 0.4248, IoU.column: 0.5896, IoU.signboard: 0.4589, IoU.chest of drawers: 0.4508, IoU.counter: 0.5473, IoU.sand: 0.6433, IoU.sink: 0.8065, IoU.skyscraper: 0.4020, IoU.fireplace: 0.8318, IoU.refrigerator: 0.8632, IoU.grandstand: 0.4559, IoU.path: 0.3011, IoU.stairs: 0.2918, IoU.runway: 0.7480, IoU.case: 0.7566, IoU.pool table: 0.9494, IoU.pillow: 0.7254, IoU.screen door: 0.7787, IoU.stairway: 0.5040, IoU.river: 0.2338, IoU.bridge: 0.8053, IoU.bookcase: 0.3391, IoU.blind: 0.3123, IoU.coffee table: 0.7102, IoU.toilet: 0.9272, IoU.flower: 0.4396, IoU.book: 0.6010, IoU.hill: 0.0741, IoU.bench: 0.7703, IoU.countertop: 0.6889, IoU.stove: 0.8387, IoU.palm: 0.5496, IoU.kitchen island: 0.3663, IoU.computer: 0.7980, IoU.swivel chair: 0.5583, IoU.boat: 0.5346, IoU.bar: 0.5839, IoU.arcade machine: 0.8969, IoU.hovel: 0.2912, IoU.bus: 0.9490, IoU.towel: 0.7914, IoU.light: 0.6567, IoU.truck: 0.5486, IoU.tower: 0.3113, IoU.chandelier: 0.7627, IoU.awning: 0.3303, IoU.streetlight: 0.4832, IoU.booth: 0.3878, IoU.television receiver: 0.7514, IoU.airplane: 0.8914, IoU.dirt track: 0.0001, IoU.apparel: 0.5382, IoU.pole: 0.4235, IoU.land: 0.0000, IoU.bannister: 0.1488, IoU.escalator: 0.6377, IoU.ottoman: 0.5301, IoU.bottle: 0.5411, IoU.buffet: 0.3758, IoU.poster: 0.3274, IoU.stage: 0.2471, IoU.van: 0.4869, IoU.ship: 0.2526, IoU.fountain: 0.4294, IoU.conveyer belt: 0.6971, IoU.canopy: 0.4105, IoU.washer: 0.9055, IoU.plaything: 0.3916, IoU.swimming pool: 0.4421, IoU.stool: 0.6286, IoU.barrel: 0.5834, IoU.basket: 0.4292, IoU.waterfall: 0.4738, IoU.tent: 0.9384, IoU.bag: 0.3559, IoU.minibike: 0.7985, IoU.cradle: 0.9134, IoU.oven: 0.6179, IoU.ball: 0.6323, IoU.food: 0.6770, IoU.step: 0.3345, IoU.tank: 0.4837, IoU.trade name: 0.3502, IoU.microwave: 0.8904, IoU.pot: 0.5803, IoU.animal: 0.8513, IoU.bicycle: 0.5813, IoU.lake: 0.0000, IoU.dishwasher: 0.8004, IoU.screen: 0.6157, IoU.blanket: 0.3358, IoU.sculpture: 0.7313, IoU.hood: 0.6922, IoU.sconce: 0.6598, IoU.vase: 0.5730, IoU.traffic light: 0.4845, IoU.tray: 0.2946, IoU.ashcan: 0.5146, IoU.fan: 0.7142, IoU.pier: 0.3741, IoU.crt screen: 0.0000, IoU.plate: 0.6835, IoU.monitor: 0.2030, IoU.bulletin board: 0.6503, IoU.shower: 0.2391, IoU.radiator: 0.7390, IoU.glass: 0.2877, IoU.clock: 0.6238, IoU.flag: 0.6929, Acc.wall: 0.9004, Acc.building: 0.9104, Acc.sky: 0.9686, Acc.floor: 0.8993, Acc.tree: 0.9115, Acc.ceiling: 0.9274, Acc.road: 0.9146, Acc.bed : 0.9629, Acc.windowpane: 0.8515, Acc.grass: 0.8288, Acc.cabinet: 0.7491, Acc.sidewalk: 0.8693, Acc.person: 0.9389, Acc.earth: 0.6618, Acc.door: 0.7775, Acc.table: 0.8224, Acc.mountain: 0.7952, Acc.plant: 0.6832, Acc.curtain: 0.9078, Acc.chair: 0.7903, Acc.car: 0.9558, Acc.water: 0.8182, Acc.painting: 0.9224, Acc.sofa: 0.9121, Acc.shelf: 0.5470, Acc.house: 0.6396, Acc.sea: 0.8783, Acc.mirror: 0.9210, Acc.rug: 0.8673, Acc.field: 0.6698, Acc.armchair: 0.8388, Acc.seat: 0.8903, Acc.fence: 0.7936, Acc.desk: 0.8355, Acc.rock: 0.5761, Acc.wardrobe: 0.7877, Acc.lamp: 0.9001, Acc.bathtub: 0.9310, Acc.railing: 0.7493, Acc.cushion: 0.9023, Acc.base: 0.7208, Acc.box: 0.6033, Acc.column: 0.7370, Acc.signboard: 0.6714, Acc.chest of drawers: 0.6797, Acc.counter: 0.7188, Acc.sand: 0.8354, Acc.sink: 0.8631, Acc.skyscraper: 0.5395, Acc.fireplace: 0.9307, Acc.refrigerator: 0.9588, Acc.grandstand: 0.7719, Acc.path: 0.4280, Acc.stairs: 0.3623, Acc.runway: 0.9553, Acc.case: 0.8531, Acc.pool table: 0.9856, Acc.pillow: 0.8284, Acc.screen door: 0.8299, Acc.stairway: 0.7355, Acc.river: 0.2568, Acc.bridge: 0.9018, Acc.bookcase: 0.6428, Acc.blind: 0.3336, Acc.coffee table: 0.9067, Acc.toilet: 0.9613, Acc.flower: 0.6310, Acc.book: 0.7885, Acc.hill: 0.1116, Acc.bench: 0.8512, Acc.countertop: 0.8149, Acc.stove: 0.8689, Acc.palm: 0.8033, Acc.kitchen island: 0.8083, Acc.computer: 0.8397, Acc.swivel chair: 0.8192, Acc.boat: 0.8605, Acc.bar: 0.6225, Acc.arcade machine: 0.9675, Acc.hovel: 0.4081, Acc.bus: 0.9664, Acc.towel: 0.9445, Acc.light: 0.8029, Acc.truck: 0.7227, Acc.tower: 0.6010, Acc.chandelier: 0.8840, Acc.awning: 0.5021, Acc.streetlight: 0.6936, Acc.booth: 0.4099, Acc.television receiver: 0.9198, Acc.airplane: 0.9591, Acc.dirt track: 0.0001, Acc.apparel: 0.8962, Acc.pole: 0.5644, Acc.land: 0.0000, Acc.bannister: 0.2001, Acc.escalator: 0.8246, Acc.ottoman: 0.8114, Acc.bottle: 0.8170, Acc.buffet: 0.5035, Acc.poster: 0.4991, Acc.stage: 0.5558, Acc.van: 0.6222, Acc.ship: 0.2638, Acc.fountain: 0.4407, Acc.conveyer belt: 0.9806, Acc.canopy: 0.5503, Acc.washer: 0.9334, Acc.plaything: 0.5865, Acc.swimming pool: 0.7410, Acc.stool: 0.8127, Acc.barrel: 0.6449, Acc.basket: 0.7223, Acc.waterfall: 0.5809, Acc.tent: 0.9744, Acc.bag: 0.5080, Acc.minibike: 0.9350, Acc.cradle: 0.9751, Acc.oven: 0.8397, Acc.ball: 0.7607, Acc.food: 0.8313, Acc.step: 0.5237, Acc.tank: 0.4977, Acc.trade name: 0.5152, Acc.microwave: 0.9475, Acc.pot: 0.6957, Acc.animal: 0.8837, Acc.bicycle: 0.8396, Acc.lake: 0.0000, Acc.dishwasher: 0.9027, Acc.screen: 0.9273, Acc.blanket: 0.4841, Acc.sculpture: 0.8966, Acc.hood: 0.7474, Acc.sconce: 0.8295, Acc.vase: 0.8074, Acc.traffic light: 0.7099, Acc.tray: 0.4107, Acc.ashcan: 0.7394, Acc.fan: 0.8603, Acc.pier: 0.4057, Acc.crt screen: 0.0000, Acc.plate: 0.8712, Acc.monitor: 0.3374, Acc.bulletin board: 0.8422, Acc.shower: 0.2672, Acc.radiator: 0.9175, Acc.glass: 0.3206, Acc.clock: 0.7486, Acc.flag: 0.8318
2022-11-30 09:57:09,854 - mmseg - INFO - Iter [11050/40000]	lr: 9.628e-08, eta: 1 day, 11:12:36, time: 7.676, data_time: 3.578, memory: 51902, decode.loss_cls: 0.4774, decode.loss_mask: 0.6001, decode.loss_dice: 0.8699, decode.d0.loss_cls: 7.7970, decode.d0.loss_mask: 0.5762, decode.d0.loss_dice: 0.9443, decode.d1.loss_cls: 0.6049, decode.d1.loss_mask: 0.6221, decode.d1.loss_dice: 0.9336, decode.d2.loss_cls: 0.5399, decode.d2.loss_mask: 0.6116, decode.d2.loss_dice: 0.8896, decode.d3.loss_cls: 0.5042, decode.d3.loss_mask: 0.6045, decode.d3.loss_dice: 0.8788, decode.d4.loss_cls: 0.4928, decode.d4.loss_mask: 0.6038, decode.d4.loss_dice: 0.8812, decode.d5.loss_cls: 0.4850, decode.d5.loss_mask: 0.6000, decode.d5.loss_dice: 0.8769, decode.d6.loss_cls: 0.4836, decode.d6.loss_mask: 0.5999, decode.d6.loss_dice: 0.8735, decode.d7.loss_cls: 0.4822, decode.d7.loss_mask: 0.5978, decode.d7.loss_dice: 0.8698, decode.d8.loss_cls: 0.4795, decode.d8.loss_mask: 0.5988, decode.d8.loss_dice: 0.8724, loss: 27.2510
2022-11-30 10:00:35,689 - mmseg - INFO - Iter [11100/40000]	lr: 9.612e-08, eta: 1 day, 11:08:23, time: 4.117, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4695, decode.loss_mask: 0.5892, decode.loss_dice: 0.8707, decode.d0.loss_cls: 7.7994, decode.d0.loss_mask: 0.5565, decode.d0.loss_dice: 0.9406, decode.d1.loss_cls: 0.6041, decode.d1.loss_mask: 0.6148, decode.d1.loss_dice: 0.9252, decode.d2.loss_cls: 0.5322, decode.d2.loss_mask: 0.6015, decode.d2.loss_dice: 0.8928, decode.d3.loss_cls: 0.4969, decode.d3.loss_mask: 0.5943, decode.d3.loss_dice: 0.8789, decode.d4.loss_cls: 0.4916, decode.d4.loss_mask: 0.5914, decode.d4.loss_dice: 0.8773, decode.d5.loss_cls: 0.4813, decode.d5.loss_mask: 0.5929, decode.d5.loss_dice: 0.8722, decode.d6.loss_cls: 0.4776, decode.d6.loss_mask: 0.5886, decode.d6.loss_dice: 0.8695, decode.d7.loss_cls: 0.4744, decode.d7.loss_mask: 0.5901, decode.d7.loss_dice: 0.8706, decode.d8.loss_cls: 0.4731, decode.d8.loss_mask: 0.5906, decode.d8.loss_dice: 0.8683, loss: 27.0760
2022-11-30 10:04:01,140 - mmseg - INFO - Iter [11150/40000]	lr: 9.595e-08, eta: 1 day, 11:04:10, time: 4.109, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4735, decode.loss_mask: 0.5943, decode.loss_dice: 0.8804, decode.d0.loss_cls: 7.7934, decode.d0.loss_mask: 0.5682, decode.d0.loss_dice: 0.9434, decode.d1.loss_cls: 0.5971, decode.d1.loss_mask: 0.6162, decode.d1.loss_dice: 0.9405, decode.d2.loss_cls: 0.5281, decode.d2.loss_mask: 0.6030, decode.d2.loss_dice: 0.9053, decode.d3.loss_cls: 0.4919, decode.d3.loss_mask: 0.5987, decode.d3.loss_dice: 0.8908, decode.d4.loss_cls: 0.4838, decode.d4.loss_mask: 0.5974, decode.d4.loss_dice: 0.8899, decode.d5.loss_cls: 0.4766, decode.d5.loss_mask: 0.5930, decode.d5.loss_dice: 0.8825, decode.d6.loss_cls: 0.4753, decode.d6.loss_mask: 0.5954, decode.d6.loss_dice: 0.8828, decode.d7.loss_cls: 0.4735, decode.d7.loss_mask: 0.5938, decode.d7.loss_dice: 0.8821, decode.d8.loss_cls: 0.4705, decode.d8.loss_mask: 0.5920, decode.d8.loss_dice: 0.8814, loss: 27.1949
2022-11-30 10:07:26,825 - mmseg - INFO - Iter [11200/40000]	lr: 9.578e-08, eta: 1 day, 10:59:57, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4736, decode.loss_mask: 0.6151, decode.loss_dice: 0.8814, decode.d0.loss_cls: 7.7762, decode.d0.loss_mask: 0.5855, decode.d0.loss_dice: 0.9524, decode.d1.loss_cls: 0.6144, decode.d1.loss_mask: 0.6391, decode.d1.loss_dice: 0.9503, decode.d2.loss_cls: 0.5361, decode.d2.loss_mask: 0.6269, decode.d2.loss_dice: 0.9051, decode.d3.loss_cls: 0.5016, decode.d3.loss_mask: 0.6186, decode.d3.loss_dice: 0.8909, decode.d4.loss_cls: 0.4905, decode.d4.loss_mask: 0.6215, decode.d4.loss_dice: 0.8888, decode.d5.loss_cls: 0.4793, decode.d5.loss_mask: 0.6171, decode.d5.loss_dice: 0.8841, decode.d6.loss_cls: 0.4767, decode.d6.loss_mask: 0.6159, decode.d6.loss_dice: 0.8798, decode.d7.loss_cls: 0.4757, decode.d7.loss_mask: 0.6142, decode.d7.loss_dice: 0.8798, decode.d8.loss_cls: 0.4706, decode.d8.loss_mask: 0.6148, decode.d8.loss_dice: 0.8818, loss: 27.4579
2022-11-30 10:10:52,423 - mmseg - INFO - Iter [11250/40000]	lr: 9.562e-08, eta: 1 day, 10:55:45, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4646, decode.loss_mask: 0.5903, decode.loss_dice: 0.8806, decode.d0.loss_cls: 7.7507, decode.d0.loss_mask: 0.5624, decode.d0.loss_dice: 0.9458, decode.d1.loss_cls: 0.5919, decode.d1.loss_mask: 0.6103, decode.d1.loss_dice: 0.9334, decode.d2.loss_cls: 0.5301, decode.d2.loss_mask: 0.5961, decode.d2.loss_dice: 0.8924, decode.d3.loss_cls: 0.4929, decode.d3.loss_mask: 0.5924, decode.d3.loss_dice: 0.8762, decode.d4.loss_cls: 0.4832, decode.d4.loss_mask: 0.5927, decode.d4.loss_dice: 0.8786, decode.d5.loss_cls: 0.4725, decode.d5.loss_mask: 0.5903, decode.d5.loss_dice: 0.8730, decode.d6.loss_cls: 0.4693, decode.d6.loss_mask: 0.5891, decode.d6.loss_dice: 0.8750, decode.d7.loss_cls: 0.4690, decode.d7.loss_mask: 0.5868, decode.d7.loss_dice: 0.8742, decode.d8.loss_cls: 0.4637, decode.d8.loss_mask: 0.5872, decode.d8.loss_dice: 0.8784, loss: 26.9930
2022-11-30 10:14:17,963 - mmseg - INFO - Iter [11300/40000]	lr: 9.545e-08, eta: 1 day, 10:51:33, time: 4.111, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4674, decode.loss_mask: 0.5935, decode.loss_dice: 0.8732, decode.d0.loss_cls: 7.7589, decode.d0.loss_mask: 0.5670, decode.d0.loss_dice: 0.9454, decode.d1.loss_cls: 0.5904, decode.d1.loss_mask: 0.6197, decode.d1.loss_dice: 0.9271, decode.d2.loss_cls: 0.5228, decode.d2.loss_mask: 0.6057, decode.d2.loss_dice: 0.8895, decode.d3.loss_cls: 0.4892, decode.d3.loss_mask: 0.5988, decode.d3.loss_dice: 0.8799, decode.d4.loss_cls: 0.4780, decode.d4.loss_mask: 0.5965, decode.d4.loss_dice: 0.8800, decode.d5.loss_cls: 0.4701, decode.d5.loss_mask: 0.5947, decode.d5.loss_dice: 0.8774, decode.d6.loss_cls: 0.4656, decode.d6.loss_mask: 0.5973, decode.d6.loss_dice: 0.8714, decode.d7.loss_cls: 0.4633, decode.d7.loss_mask: 0.5956, decode.d7.loss_dice: 0.8748, decode.d8.loss_cls: 0.4635, decode.d8.loss_mask: 0.5942, decode.d8.loss_dice: 0.8723, loss: 27.0233
2022-11-30 10:17:43,701 - mmseg - INFO - Iter [11350/40000]	lr: 9.528e-08, eta: 1 day, 10:47:21, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4653, decode.loss_mask: 0.5943, decode.loss_dice: 0.8672, decode.d0.loss_cls: 7.7269, decode.d0.loss_mask: 0.5685, decode.d0.loss_dice: 0.9324, decode.d1.loss_cls: 0.5954, decode.d1.loss_mask: 0.6111, decode.d1.loss_dice: 0.9273, decode.d2.loss_cls: 0.5296, decode.d2.loss_mask: 0.6006, decode.d2.loss_dice: 0.8893, decode.d3.loss_cls: 0.4935, decode.d3.loss_mask: 0.5956, decode.d3.loss_dice: 0.8768, decode.d4.loss_cls: 0.4846, decode.d4.loss_mask: 0.5937, decode.d4.loss_dice: 0.8743, decode.d5.loss_cls: 0.4720, decode.d5.loss_mask: 0.5955, decode.d5.loss_dice: 0.8738, decode.d6.loss_cls: 0.4711, decode.d6.loss_mask: 0.5939, decode.d6.loss_dice: 0.8681, decode.d7.loss_cls: 0.4666, decode.d7.loss_mask: 0.5932, decode.d7.loss_dice: 0.8674, decode.d8.loss_cls: 0.4667, decode.d8.loss_mask: 0.5940, decode.d8.loss_dice: 0.8670, loss: 26.9555
2022-11-30 10:21:11,632 - mmseg - INFO - Iter [11400/40000]	lr: 9.512e-08, eta: 1 day, 10:43:16, time: 4.159, data_time: 0.065, memory: 51902, decode.loss_cls: 0.4642, decode.loss_mask: 0.5879, decode.loss_dice: 0.8755, decode.d0.loss_cls: 7.7402, decode.d0.loss_mask: 0.5592, decode.d0.loss_dice: 0.9364, decode.d1.loss_cls: 0.5989, decode.d1.loss_mask: 0.6051, decode.d1.loss_dice: 0.9385, decode.d2.loss_cls: 0.5244, decode.d2.loss_mask: 0.5997, decode.d2.loss_dice: 0.8925, decode.d3.loss_cls: 0.4904, decode.d3.loss_mask: 0.5917, decode.d3.loss_dice: 0.8865, decode.d4.loss_cls: 0.4826, decode.d4.loss_mask: 0.5925, decode.d4.loss_dice: 0.8838, decode.d5.loss_cls: 0.4717, decode.d5.loss_mask: 0.5898, decode.d5.loss_dice: 0.8807, decode.d6.loss_cls: 0.4666, decode.d6.loss_mask: 0.5885, decode.d6.loss_dice: 0.8785, decode.d7.loss_cls: 0.4652, decode.d7.loss_mask: 0.5877, decode.d7.loss_dice: 0.8771, decode.d8.loss_cls: 0.4653, decode.d8.loss_mask: 0.5865, decode.d8.loss_dice: 0.8778, loss: 26.9855
2022-11-30 10:24:37,232 - mmseg - INFO - Iter [11450/40000]	lr: 9.495e-08, eta: 1 day, 10:39:05, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4758, decode.loss_mask: 0.6100, decode.loss_dice: 0.8824, decode.d0.loss_cls: 7.7246, decode.d0.loss_mask: 0.5848, decode.d0.loss_dice: 0.9576, decode.d1.loss_cls: 0.6121, decode.d1.loss_mask: 0.6280, decode.d1.loss_dice: 0.9428, decode.d2.loss_cls: 0.5379, decode.d2.loss_mask: 0.6185, decode.d2.loss_dice: 0.9106, decode.d3.loss_cls: 0.5027, decode.d3.loss_mask: 0.6140, decode.d3.loss_dice: 0.8915, decode.d4.loss_cls: 0.4929, decode.d4.loss_mask: 0.6116, decode.d4.loss_dice: 0.8937, decode.d5.loss_cls: 0.4835, decode.d5.loss_mask: 0.6087, decode.d5.loss_dice: 0.8880, decode.d6.loss_cls: 0.4784, decode.d6.loss_mask: 0.6082, decode.d6.loss_dice: 0.8800, decode.d7.loss_cls: 0.4733, decode.d7.loss_mask: 0.6084, decode.d7.loss_dice: 0.8838, decode.d8.loss_cls: 0.4744, decode.d8.loss_mask: 0.6098, decode.d8.loss_dice: 0.8857, loss: 27.3738
2022-11-30 10:28:03,252 - mmseg - INFO - Iter [11500/40000]	lr: 9.479e-08, eta: 1 day, 10:34:56, time: 4.120, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4471, decode.loss_mask: 0.5835, decode.loss_dice: 0.8508, decode.d0.loss_cls: 7.7079, decode.d0.loss_mask: 0.5586, decode.d0.loss_dice: 0.9229, decode.d1.loss_cls: 0.5736, decode.d1.loss_mask: 0.6061, decode.d1.loss_dice: 0.9122, decode.d2.loss_cls: 0.5076, decode.d2.loss_mask: 0.5937, decode.d2.loss_dice: 0.8772, decode.d3.loss_cls: 0.4710, decode.d3.loss_mask: 0.5911, decode.d3.loss_dice: 0.8629, decode.d4.loss_cls: 0.4618, decode.d4.loss_mask: 0.5871, decode.d4.loss_dice: 0.8563, decode.d5.loss_cls: 0.4563, decode.d5.loss_mask: 0.5861, decode.d5.loss_dice: 0.8552, decode.d6.loss_cls: 0.4537, decode.d6.loss_mask: 0.5835, decode.d6.loss_dice: 0.8482, decode.d7.loss_cls: 0.4471, decode.d7.loss_mask: 0.5843, decode.d7.loss_dice: 0.8536, decode.d8.loss_cls: 0.4461, decode.d8.loss_mask: 0.5842, decode.d8.loss_dice: 0.8518, loss: 26.5213
2022-11-30 10:31:29,218 - mmseg - INFO - Iter [11550/40000]	lr: 9.462e-08, eta: 1 day, 10:30:47, time: 4.119, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4584, decode.loss_mask: 0.5984, decode.loss_dice: 0.8601, decode.d0.loss_cls: 7.6984, decode.d0.loss_mask: 0.5653, decode.d0.loss_dice: 0.9221, decode.d1.loss_cls: 0.5903, decode.d1.loss_mask: 0.6122, decode.d1.loss_dice: 0.9233, decode.d2.loss_cls: 0.5215, decode.d2.loss_mask: 0.6027, decode.d2.loss_dice: 0.8861, decode.d3.loss_cls: 0.4890, decode.d3.loss_mask: 0.5986, decode.d3.loss_dice: 0.8728, decode.d4.loss_cls: 0.4763, decode.d4.loss_mask: 0.5992, decode.d4.loss_dice: 0.8716, decode.d5.loss_cls: 0.4666, decode.d5.loss_mask: 0.5965, decode.d5.loss_dice: 0.8671, decode.d6.loss_cls: 0.4610, decode.d6.loss_mask: 0.5951, decode.d6.loss_dice: 0.8611, decode.d7.loss_cls: 0.4613, decode.d7.loss_mask: 0.5963, decode.d7.loss_dice: 0.8645, decode.d8.loss_cls: 0.4571, decode.d8.loss_mask: 0.5950, decode.d8.loss_dice: 0.8649, loss: 26.8328
2022-11-30 10:34:54,910 - mmseg - INFO - Iter [11600/40000]	lr: 9.445e-08, eta: 1 day, 10:26:38, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4677, decode.loss_mask: 0.5888, decode.loss_dice: 0.8692, decode.d0.loss_cls: 7.6950, decode.d0.loss_mask: 0.5669, decode.d0.loss_dice: 0.9380, decode.d1.loss_cls: 0.5930, decode.d1.loss_mask: 0.6111, decode.d1.loss_dice: 0.9334, decode.d2.loss_cls: 0.5277, decode.d2.loss_mask: 0.5999, decode.d2.loss_dice: 0.8952, decode.d3.loss_cls: 0.4878, decode.d3.loss_mask: 0.5934, decode.d3.loss_dice: 0.8818, decode.d4.loss_cls: 0.4803, decode.d4.loss_mask: 0.5927, decode.d4.loss_dice: 0.8797, decode.d5.loss_cls: 0.4701, decode.d5.loss_mask: 0.5893, decode.d5.loss_dice: 0.8796, decode.d6.loss_cls: 0.4694, decode.d6.loss_mask: 0.5878, decode.d6.loss_dice: 0.8720, decode.d7.loss_cls: 0.4614, decode.d7.loss_mask: 0.5875, decode.d7.loss_dice: 0.8711, decode.d8.loss_cls: 0.4658, decode.d8.loss_mask: 0.5891, decode.d8.loss_dice: 0.8675, loss: 26.9121
2022-11-30 10:38:20,670 - mmseg - INFO - Iter [11650/40000]	lr: 9.429e-08, eta: 1 day, 10:22:29, time: 4.115, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4650, decode.loss_mask: 0.5911, decode.loss_dice: 0.8695, decode.d0.loss_cls: 7.6848, decode.d0.loss_mask: 0.5656, decode.d0.loss_dice: 0.9354, decode.d1.loss_cls: 0.5973, decode.d1.loss_mask: 0.6074, decode.d1.loss_dice: 0.9247, decode.d2.loss_cls: 0.5269, decode.d2.loss_mask: 0.6000, decode.d2.loss_dice: 0.8880, decode.d3.loss_cls: 0.4877, decode.d3.loss_mask: 0.5954, decode.d3.loss_dice: 0.8780, decode.d4.loss_cls: 0.4748, decode.d4.loss_mask: 0.5966, decode.d4.loss_dice: 0.8768, decode.d5.loss_cls: 0.4699, decode.d5.loss_mask: 0.5909, decode.d5.loss_dice: 0.8717, decode.d6.loss_cls: 0.4628, decode.d6.loss_mask: 0.5921, decode.d6.loss_dice: 0.8652, decode.d7.loss_cls: 0.4657, decode.d7.loss_mask: 0.5928, decode.d7.loss_dice: 0.8650, decode.d8.loss_cls: 0.4617, decode.d8.loss_mask: 0.5933, decode.d8.loss_dice: 0.8684, loss: 26.8644
2022-11-30 10:41:46,872 - mmseg - INFO - Iter [11700/40000]	lr: 9.412e-08, eta: 1 day, 10:18:21, time: 4.124, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4485, decode.loss_mask: 0.5886, decode.loss_dice: 0.8553, decode.d0.loss_cls: 7.6684, decode.d0.loss_mask: 0.5629, decode.d0.loss_dice: 0.9216, decode.d1.loss_cls: 0.5717, decode.d1.loss_mask: 0.6102, decode.d1.loss_dice: 0.9192, decode.d2.loss_cls: 0.5105, decode.d2.loss_mask: 0.5964, decode.d2.loss_dice: 0.8755, decode.d3.loss_cls: 0.4745, decode.d3.loss_mask: 0.5912, decode.d3.loss_dice: 0.8608, decode.d4.loss_cls: 0.4662, decode.d4.loss_mask: 0.5904, decode.d4.loss_dice: 0.8608, decode.d5.loss_cls: 0.4572, decode.d5.loss_mask: 0.5882, decode.d5.loss_dice: 0.8578, decode.d6.loss_cls: 0.4503, decode.d6.loss_mask: 0.5882, decode.d6.loss_dice: 0.8533, decode.d7.loss_cls: 0.4468, decode.d7.loss_mask: 0.5914, decode.d7.loss_dice: 0.8605, decode.d8.loss_cls: 0.4454, decode.d8.loss_mask: 0.5869, decode.d8.loss_dice: 0.8578, loss: 26.5564
2022-11-30 10:45:12,523 - mmseg - INFO - Iter [11750/40000]	lr: 9.395e-08, eta: 1 day, 10:14:13, time: 4.113, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4743, decode.loss_mask: 0.5938, decode.loss_dice: 0.8664, decode.d0.loss_cls: 7.6633, decode.d0.loss_mask: 0.5707, decode.d0.loss_dice: 0.9377, decode.d1.loss_cls: 0.6007, decode.d1.loss_mask: 0.6192, decode.d1.loss_dice: 0.9240, decode.d2.loss_cls: 0.5349, decode.d2.loss_mask: 0.6039, decode.d2.loss_dice: 0.8910, decode.d3.loss_cls: 0.5011, decode.d3.loss_mask: 0.5985, decode.d3.loss_dice: 0.8713, decode.d4.loss_cls: 0.4890, decode.d4.loss_mask: 0.5949, decode.d4.loss_dice: 0.8725, decode.d5.loss_cls: 0.4774, decode.d5.loss_mask: 0.5953, decode.d5.loss_dice: 0.8672, decode.d6.loss_cls: 0.4726, decode.d6.loss_mask: 0.5952, decode.d6.loss_dice: 0.8651, decode.d7.loss_cls: 0.4668, decode.d7.loss_mask: 0.5977, decode.d7.loss_dice: 0.8715, decode.d8.loss_cls: 0.4681, decode.d8.loss_mask: 0.5965, decode.d8.loss_dice: 0.8675, loss: 26.9482
2022-11-30 10:48:38,311 - mmseg - INFO - Iter [11800/40000]	lr: 9.379e-08, eta: 1 day, 10:10:05, time: 4.116, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4797, decode.loss_mask: 0.5906, decode.loss_dice: 0.8762, decode.d0.loss_cls: 7.6430, decode.d0.loss_mask: 0.5697, decode.d0.loss_dice: 0.9432, decode.d1.loss_cls: 0.5969, decode.d1.loss_mask: 0.6136, decode.d1.loss_dice: 0.9323, decode.d2.loss_cls: 0.5346, decode.d2.loss_mask: 0.6043, decode.d2.loss_dice: 0.9017, decode.d3.loss_cls: 0.5051, decode.d3.loss_mask: 0.5980, decode.d3.loss_dice: 0.8810, decode.d4.loss_cls: 0.4955, decode.d4.loss_mask: 0.5966, decode.d4.loss_dice: 0.8785, decode.d5.loss_cls: 0.4845, decode.d5.loss_mask: 0.5932, decode.d5.loss_dice: 0.8768, decode.d6.loss_cls: 0.4834, decode.d6.loss_mask: 0.5924, decode.d6.loss_dice: 0.8734, decode.d7.loss_cls: 0.4801, decode.d7.loss_mask: 0.5932, decode.d7.loss_dice: 0.8767, decode.d8.loss_cls: 0.4822, decode.d8.loss_mask: 0.5924, decode.d8.loss_dice: 0.8752, loss: 27.0441
2022-11-30 10:52:04,095 - mmseg - INFO - Iter [11850/40000]	lr: 9.362e-08, eta: 1 day, 10:05:58, time: 4.116, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4676, decode.loss_mask: 0.5962, decode.loss_dice: 0.8644, decode.d0.loss_cls: 7.6355, decode.d0.loss_mask: 0.5719, decode.d0.loss_dice: 0.9358, decode.d1.loss_cls: 0.5964, decode.d1.loss_mask: 0.6176, decode.d1.loss_dice: 0.9344, decode.d2.loss_cls: 0.5340, decode.d2.loss_mask: 0.6048, decode.d2.loss_dice: 0.8897, decode.d3.loss_cls: 0.5025, decode.d3.loss_mask: 0.5950, decode.d3.loss_dice: 0.8698, decode.d4.loss_cls: 0.4906, decode.d4.loss_mask: 0.5930, decode.d4.loss_dice: 0.8705, decode.d5.loss_cls: 0.4799, decode.d5.loss_mask: 0.5957, decode.d5.loss_dice: 0.8678, decode.d6.loss_cls: 0.4749, decode.d6.loss_mask: 0.5970, decode.d6.loss_dice: 0.8682, decode.d7.loss_cls: 0.4724, decode.d7.loss_mask: 0.5960, decode.d7.loss_dice: 0.8669, decode.d8.loss_cls: 0.4723, decode.d8.loss_mask: 0.5939, decode.d8.loss_dice: 0.8692, loss: 26.9241
2022-11-30 10:55:30,254 - mmseg - INFO - Iter [11900/40000]	lr: 9.346e-08, eta: 1 day, 10:01:52, time: 4.123, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4547, decode.loss_mask: 0.5967, decode.loss_dice: 0.8558, decode.d0.loss_cls: 7.6084, decode.d0.loss_mask: 0.5643, decode.d0.loss_dice: 0.9196, decode.d1.loss_cls: 0.5794, decode.d1.loss_mask: 0.6155, decode.d1.loss_dice: 0.9124, decode.d2.loss_cls: 0.5140, decode.d2.loss_mask: 0.6046, decode.d2.loss_dice: 0.8828, decode.d3.loss_cls: 0.4799, decode.d3.loss_mask: 0.5987, decode.d3.loss_dice: 0.8636, decode.d4.loss_cls: 0.4692, decode.d4.loss_mask: 0.6006, decode.d4.loss_dice: 0.8632, decode.d5.loss_cls: 0.4622, decode.d5.loss_mask: 0.5960, decode.d5.loss_dice: 0.8598, decode.d6.loss_cls: 0.4547, decode.d6.loss_mask: 0.5967, decode.d6.loss_dice: 0.8588, decode.d7.loss_cls: 0.4486, decode.d7.loss_mask: 0.5996, decode.d7.loss_dice: 0.8576, decode.d8.loss_cls: 0.4517, decode.d8.loss_mask: 0.6003, decode.d8.loss_dice: 0.8582, loss: 26.6278
2022-11-30 10:58:55,776 - mmseg - INFO - Iter [11950/40000]	lr: 9.329e-08, eta: 1 day, 9:57:45, time: 4.110, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4583, decode.loss_mask: 0.6043, decode.loss_dice: 0.8632, decode.d0.loss_cls: 7.6124, decode.d0.loss_mask: 0.5785, decode.d0.loss_dice: 0.9291, decode.d1.loss_cls: 0.5803, decode.d1.loss_mask: 0.6283, decode.d1.loss_dice: 0.9257, decode.d2.loss_cls: 0.5170, decode.d2.loss_mask: 0.6147, decode.d2.loss_dice: 0.8851, decode.d3.loss_cls: 0.4854, decode.d3.loss_mask: 0.6072, decode.d3.loss_dice: 0.8676, decode.d4.loss_cls: 0.4741, decode.d4.loss_mask: 0.6052, decode.d4.loss_dice: 0.8702, decode.d5.loss_cls: 0.4638, decode.d5.loss_mask: 0.6043, decode.d5.loss_dice: 0.8660, decode.d6.loss_cls: 0.4566, decode.d6.loss_mask: 0.6035, decode.d6.loss_dice: 0.8651, decode.d7.loss_cls: 0.4588, decode.d7.loss_mask: 0.6037, decode.d7.loss_dice: 0.8637, decode.d8.loss_cls: 0.4549, decode.d8.loss_mask: 0.6031, decode.d8.loss_dice: 0.8615, loss: 26.8118
2022-11-30 11:02:21,588 - mmseg - INFO - Saving checkpoint at 12000 iterations
2022-11-30 11:03:10,826 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 11:03:10,826 - mmseg - INFO - Iter [12000/40000]	lr: 9.312e-08, eta: 1 day, 9:55:33, time: 5.101, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4656, decode.loss_mask: 0.5849, decode.loss_dice: 0.8545, decode.d0.loss_cls: 7.6101, decode.d0.loss_mask: 0.5645, decode.d0.loss_dice: 0.9319, decode.d1.loss_cls: 0.5898, decode.d1.loss_mask: 0.6085, decode.d1.loss_dice: 0.9235, decode.d2.loss_cls: 0.5299, decode.d2.loss_mask: 0.5965, decode.d2.loss_dice: 0.8771, decode.d3.loss_cls: 0.4894, decode.d3.loss_mask: 0.5913, decode.d3.loss_dice: 0.8632, decode.d4.loss_cls: 0.4818, decode.d4.loss_mask: 0.5903, decode.d4.loss_dice: 0.8626, decode.d5.loss_cls: 0.4708, decode.d5.loss_mask: 0.5895, decode.d5.loss_dice: 0.8567, decode.d6.loss_cls: 0.4663, decode.d6.loss_mask: 0.5890, decode.d6.loss_dice: 0.8572, decode.d7.loss_cls: 0.4623, decode.d7.loss_mask: 0.5863, decode.d7.loss_dice: 0.8620, decode.d8.loss_cls: 0.4624, decode.d8.loss_mask: 0.5858, decode.d8.loss_dice: 0.8592, loss: 26.6630
2022-11-30 11:06:08,879 - mmseg - INFO - per class results:
2022-11-30 11:06:08,884 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 82.47 | 89.25 |
|       building      | 84.52 | 91.86 |
|         sky         |  95.1 | 97.29 |
|        floor        | 86.24 | 91.26 |
|         tree        | 79.14 | 89.69 |
|       ceiling       | 87.21 |  93.0 |
|         road        | 87.97 | 91.76 |
|         bed         | 93.39 |  96.7 |
|      windowpane     | 66.24 | 82.68 |
|        grass        | 70.12 | 82.35 |
|       cabinet       | 62.66 | 76.05 |
|       sidewalk      | 73.17 | 87.29 |
|        person       |  88.3 |  93.4 |
|        earth        | 42.07 | 53.78 |
|         door        | 60.68 | 79.49 |
|        table        | 72.23 | 84.74 |
|       mountain      | 61.78 | 68.28 |
|        plant        |  58.8 | 70.98 |
|       curtain       | 82.47 |  91.5 |
|        chair        | 68.18 |  78.1 |
|         car         | 89.86 | 94.97 |
|        water        | 62.07 | 80.63 |
|       painting      | 82.61 | 92.02 |
|         sofa        | 85.46 | 90.42 |
|        shelf        |  51.3 | 66.15 |
|        house        |  50.2 | 68.81 |
|         sea         | 70.37 | 82.09 |
|        mirror       | 80.97 | 92.62 |
|         rug         | 72.06 | 84.58 |
|        field        | 37.97 | 77.62 |
|       armchair      | 64.46 | 83.36 |
|         seat        |  66.7 | 90.28 |
|        fence        | 57.75 | 77.84 |
|         desk        | 60.06 | 78.54 |
|         rock        | 65.36 | 81.66 |
|       wardrobe      | 52.05 | 83.78 |
|         lamp        | 79.97 | 89.35 |
|       bathtub       | 91.76 | 93.75 |
|       railing       | 44.52 |  64.2 |
|       cushion       | 77.05 | 90.19 |
|         base        | 49.39 | 70.44 |
|         box         | 41.64 | 57.65 |
|        column       | 57.37 | 70.96 |
|      signboard      | 47.43 | 63.65 |
|   chest of drawers  | 45.39 | 60.97 |
|       counter       | 54.98 | 71.08 |
|         sand        | 61.96 | 88.15 |
|         sink        | 81.46 | 86.84 |
|      skyscraper     | 29.92 | 31.93 |
|      fireplace      | 79.77 | 97.52 |
|     refrigerator    | 83.37 | 95.63 |
|      grandstand     | 42.32 |  77.7 |
|         path        | 28.77 | 42.06 |
|        stairs       | 25.73 | 31.48 |
|        runway       | 73.73 | 95.27 |
|         case        |  72.1 |  89.5 |
|      pool table     | 95.58 | 98.08 |
|        pillow       | 72.88 | 83.89 |
|     screen door     | 86.58 | 96.12 |
|       stairway      |  51.2 | 79.92 |
|        river        | 21.41 | 28.88 |
|        bridge       | 78.13 | 89.96 |
|       bookcase      | 33.45 |  58.3 |
|        blind        | 37.87 | 42.65 |
|     coffee table    | 71.38 | 83.62 |
|        toilet       | 93.25 | 96.68 |
|        flower       | 45.35 | 67.64 |
|         book        | 59.18 | 78.82 |
|         hill        |  9.51 | 25.12 |
|        bench        | 75.39 | 80.93 |
|      countertop     | 72.05 | 81.74 |
|        stove        | 84.73 | 88.19 |
|         palm        |  55.0 | 82.49 |
|    kitchen island   | 49.08 | 81.28 |
|       computer      | 82.09 | 91.05 |
|     swivel chair    | 56.13 | 83.28 |
|         boat        | 51.06 | 87.79 |
|         bar         |  67.3 | 75.02 |
|    arcade machine   | 90.97 |  98.7 |
|        hovel        | 50.86 | 74.71 |
|         bus         | 92.72 | 94.68 |
|        towel        | 80.14 | 94.56 |
|        light        | 66.18 | 80.65 |
|        truck        | 52.83 | 73.73 |
|        tower        | 33.05 | 62.15 |
|      chandelier     | 76.14 | 89.21 |
|        awning       | 34.13 | 55.36 |
|     streetlight     |  46.3 |  69.0 |
|        booth        | 38.81 | 39.17 |
| television receiver | 75.81 | 89.73 |
|       airplane      | 87.36 | 95.61 |
|      dirt track     | 18.89 | 20.98 |
|       apparel       | 55.74 | 91.56 |
|         pole        | 40.48 |  57.7 |
|         land        |  1.38 |  1.82 |
|      bannister      | 18.87 | 34.67 |
|      escalator      | 64.15 | 85.81 |
|       ottoman       | 51.91 | 82.31 |
|        bottle       | 54.61 |  72.8 |
|        buffet       | 13.25 |  16.2 |
|        poster       | 28.97 | 43.78 |
|        stage        | 35.04 | 82.29 |
|         van         | 55.09 |  76.6 |
|         ship        | 87.61 | 91.91 |
|       fountain      | 42.52 | 43.82 |
|    conveyer belt    |  81.1 | 97.89 |
|        canopy       | 45.92 | 60.27 |
|        washer       | 90.56 | 93.52 |
|      plaything      | 38.31 | 56.62 |
|    swimming pool    | 44.56 | 74.23 |
|        stool        | 53.67 | 82.85 |
|        barrel       | 58.94 | 65.17 |
|        basket       | 41.73 | 65.61 |
|      waterfall      | 66.64 | 82.91 |
|         tent        | 95.12 |  97.8 |
|         bag         | 33.98 | 45.04 |
|       minibike      | 80.91 | 93.53 |
|        cradle       | 91.27 | 97.13 |
|         oven        | 61.41 | 83.64 |
|         ball        | 45.08 | 51.37 |
|         food        | 63.24 | 73.17 |
|         step        | 33.14 | 42.17 |
|         tank        | 46.62 | 50.18 |
|      trade name     | 32.07 | 42.17 |
|      microwave      | 89.38 | 94.64 |
|         pot         | 58.19 | 70.93 |
|        animal       | 84.11 | 86.96 |
|       bicycle       | 60.78 | 83.95 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 77.11 | 90.25 |
|        screen       | 61.25 | 91.14 |
|       blanket       | 37.63 | 48.89 |
|      sculpture      | 71.49 | 90.42 |
|         hood        |  70.0 | 79.14 |
|        sconce       | 64.99 | 83.33 |
|         vase        | 57.66 | 80.24 |
|    traffic light    | 52.42 | 71.74 |
|         tray        | 28.82 | 44.37 |
|        ashcan       | 53.55 |  69.4 |
|         fan         | 73.97 | 85.16 |
|         pier        | 37.59 | 41.06 |
|      crt screen     | 11.22 | 32.15 |
|        plate        | 69.71 | 84.82 |
|       monitor       |  2.09 |  2.37 |
|    bulletin board   | 66.25 | 91.98 |
|        shower       |  22.6 | 28.75 |
|       radiator      | 71.41 |  93.1 |
|        glass        | 28.69 | 31.45 |
|        clock        | 64.75 | 76.76 |
|         flag        | 70.54 | 84.25 |
+---------------------+-------+-------+
2022-11-30 11:06:08,884 - mmseg - INFO - Summary:
2022-11-30 11:06:08,884 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 86.65 | 59.69 | 73.84 |
+-------+-------+-------+
2022-11-30 11:06:08,887 - mmseg - INFO - The previous best checkpoint /mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune/lr1.0_lrd0.9/best_mIoU_iter_10000.pth was removed
2022-11-30 11:06:57,718 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_12000.pth.
2022-11-30 11:06:57,719 - mmseg - INFO - Best mIoU is 0.5969 at 12000 iter.
2022-11-30 11:06:57,727 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 11:06:57,727 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8665, mIoU: 0.5969, mAcc: 0.7384, IoU.wall: 0.8247, IoU.building: 0.8452, IoU.sky: 0.9510, IoU.floor: 0.8624, IoU.tree: 0.7914, IoU.ceiling: 0.8721, IoU.road: 0.8797, IoU.bed : 0.9339, IoU.windowpane: 0.6624, IoU.grass: 0.7012, IoU.cabinet: 0.6266, IoU.sidewalk: 0.7317, IoU.person: 0.8830, IoU.earth: 0.4207, IoU.door: 0.6068, IoU.table: 0.7223, IoU.mountain: 0.6178, IoU.plant: 0.5880, IoU.curtain: 0.8247, IoU.chair: 0.6818, IoU.car: 0.8986, IoU.water: 0.6207, IoU.painting: 0.8261, IoU.sofa: 0.8546, IoU.shelf: 0.5130, IoU.house: 0.5020, IoU.sea: 0.7037, IoU.mirror: 0.8097, IoU.rug: 0.7206, IoU.field: 0.3797, IoU.armchair: 0.6446, IoU.seat: 0.6670, IoU.fence: 0.5775, IoU.desk: 0.6006, IoU.rock: 0.6536, IoU.wardrobe: 0.5205, IoU.lamp: 0.7997, IoU.bathtub: 0.9176, IoU.railing: 0.4452, IoU.cushion: 0.7705, IoU.base: 0.4939, IoU.box: 0.4164, IoU.column: 0.5737, IoU.signboard: 0.4743, IoU.chest of drawers: 0.4539, IoU.counter: 0.5498, IoU.sand: 0.6196, IoU.sink: 0.8146, IoU.skyscraper: 0.2992, IoU.fireplace: 0.7977, IoU.refrigerator: 0.8337, IoU.grandstand: 0.4232, IoU.path: 0.2877, IoU.stairs: 0.2573, IoU.runway: 0.7373, IoU.case: 0.7210, IoU.pool table: 0.9558, IoU.pillow: 0.7288, IoU.screen door: 0.8658, IoU.stairway: 0.5120, IoU.river: 0.2141, IoU.bridge: 0.7813, IoU.bookcase: 0.3345, IoU.blind: 0.3787, IoU.coffee table: 0.7138, IoU.toilet: 0.9325, IoU.flower: 0.4535, IoU.book: 0.5918, IoU.hill: 0.0951, IoU.bench: 0.7539, IoU.countertop: 0.7205, IoU.stove: 0.8473, IoU.palm: 0.5500, IoU.kitchen island: 0.4908, IoU.computer: 0.8209, IoU.swivel chair: 0.5613, IoU.boat: 0.5106, IoU.bar: 0.6730, IoU.arcade machine: 0.9097, IoU.hovel: 0.5086, IoU.bus: 0.9272, IoU.towel: 0.8014, IoU.light: 0.6618, IoU.truck: 0.5283, IoU.tower: 0.3305, IoU.chandelier: 0.7614, IoU.awning: 0.3413, IoU.streetlight: 0.4630, IoU.booth: 0.3881, IoU.television receiver: 0.7581, IoU.airplane: 0.8736, IoU.dirt track: 0.1889, IoU.apparel: 0.5574, IoU.pole: 0.4048, IoU.land: 0.0138, IoU.bannister: 0.1887, IoU.escalator: 0.6415, IoU.ottoman: 0.5191, IoU.bottle: 0.5461, IoU.buffet: 0.1325, IoU.poster: 0.2897, IoU.stage: 0.3504, IoU.van: 0.5509, IoU.ship: 0.8761, IoU.fountain: 0.4252, IoU.conveyer belt: 0.8110, IoU.canopy: 0.4592, IoU.washer: 0.9056, IoU.plaything: 0.3831, IoU.swimming pool: 0.4456, IoU.stool: 0.5367, IoU.barrel: 0.5894, IoU.basket: 0.4173, IoU.waterfall: 0.6664, IoU.tent: 0.9512, IoU.bag: 0.3398, IoU.minibike: 0.8091, IoU.cradle: 0.9127, IoU.oven: 0.6141, IoU.ball: 0.4508, IoU.food: 0.6324, IoU.step: 0.3314, IoU.tank: 0.4662, IoU.trade name: 0.3207, IoU.microwave: 0.8938, IoU.pot: 0.5819, IoU.animal: 0.8411, IoU.bicycle: 0.6078, IoU.lake: 0.0000, IoU.dishwasher: 0.7711, IoU.screen: 0.6125, IoU.blanket: 0.3763, IoU.sculpture: 0.7149, IoU.hood: 0.7000, IoU.sconce: 0.6499, IoU.vase: 0.5766, IoU.traffic light: 0.5242, IoU.tray: 0.2882, IoU.ashcan: 0.5355, IoU.fan: 0.7397, IoU.pier: 0.3759, IoU.crt screen: 0.1122, IoU.plate: 0.6971, IoU.monitor: 0.0209, IoU.bulletin board: 0.6625, IoU.shower: 0.2260, IoU.radiator: 0.7141, IoU.glass: 0.2869, IoU.clock: 0.6475, IoU.flag: 0.7054, Acc.wall: 0.8925, Acc.building: 0.9186, Acc.sky: 0.9729, Acc.floor: 0.9126, Acc.tree: 0.8969, Acc.ceiling: 0.9300, Acc.road: 0.9176, Acc.bed : 0.9670, Acc.windowpane: 0.8268, Acc.grass: 0.8235, Acc.cabinet: 0.7605, Acc.sidewalk: 0.8729, Acc.person: 0.9340, Acc.earth: 0.5378, Acc.door: 0.7949, Acc.table: 0.8474, Acc.mountain: 0.6828, Acc.plant: 0.7098, Acc.curtain: 0.9150, Acc.chair: 0.7810, Acc.car: 0.9497, Acc.water: 0.8063, Acc.painting: 0.9202, Acc.sofa: 0.9042, Acc.shelf: 0.6615, Acc.house: 0.6881, Acc.sea: 0.8209, Acc.mirror: 0.9262, Acc.rug: 0.8458, Acc.field: 0.7762, Acc.armchair: 0.8336, Acc.seat: 0.9028, Acc.fence: 0.7784, Acc.desk: 0.7854, Acc.rock: 0.8166, Acc.wardrobe: 0.8378, Acc.lamp: 0.8935, Acc.bathtub: 0.9375, Acc.railing: 0.6420, Acc.cushion: 0.9019, Acc.base: 0.7044, Acc.box: 0.5765, Acc.column: 0.7096, Acc.signboard: 0.6365, Acc.chest of drawers: 0.6097, Acc.counter: 0.7108, Acc.sand: 0.8815, Acc.sink: 0.8684, Acc.skyscraper: 0.3193, Acc.fireplace: 0.9752, Acc.refrigerator: 0.9563, Acc.grandstand: 0.7770, Acc.path: 0.4206, Acc.stairs: 0.3148, Acc.runway: 0.9527, Acc.case: 0.8950, Acc.pool table: 0.9808, Acc.pillow: 0.8389, Acc.screen door: 0.9612, Acc.stairway: 0.7992, Acc.river: 0.2888, Acc.bridge: 0.8996, Acc.bookcase: 0.5830, Acc.blind: 0.4265, Acc.coffee table: 0.8362, Acc.toilet: 0.9668, Acc.flower: 0.6764, Acc.book: 0.7882, Acc.hill: 0.2512, Acc.bench: 0.8093, Acc.countertop: 0.8174, Acc.stove: 0.8819, Acc.palm: 0.8249, Acc.kitchen island: 0.8128, Acc.computer: 0.9105, Acc.swivel chair: 0.8328, Acc.boat: 0.8779, Acc.bar: 0.7502, Acc.arcade machine: 0.9870, Acc.hovel: 0.7471, Acc.bus: 0.9468, Acc.towel: 0.9456, Acc.light: 0.8065, Acc.truck: 0.7373, Acc.tower: 0.6215, Acc.chandelier: 0.8921, Acc.awning: 0.5536, Acc.streetlight: 0.6900, Acc.booth: 0.3917, Acc.television receiver: 0.8973, Acc.airplane: 0.9561, Acc.dirt track: 0.2098, Acc.apparel: 0.9156, Acc.pole: 0.5770, Acc.land: 0.0182, Acc.bannister: 0.3467, Acc.escalator: 0.8581, Acc.ottoman: 0.8231, Acc.bottle: 0.7280, Acc.buffet: 0.1620, Acc.poster: 0.4378, Acc.stage: 0.8229, Acc.van: 0.7660, Acc.ship: 0.9191, Acc.fountain: 0.4382, Acc.conveyer belt: 0.9789, Acc.canopy: 0.6027, Acc.washer: 0.9352, Acc.plaything: 0.5662, Acc.swimming pool: 0.7423, Acc.stool: 0.8285, Acc.barrel: 0.6517, Acc.basket: 0.6561, Acc.waterfall: 0.8291, Acc.tent: 0.9780, Acc.bag: 0.4504, Acc.minibike: 0.9353, Acc.cradle: 0.9713, Acc.oven: 0.8364, Acc.ball: 0.5137, Acc.food: 0.7317, Acc.step: 0.4217, Acc.tank: 0.5018, Acc.trade name: 0.4217, Acc.microwave: 0.9464, Acc.pot: 0.7093, Acc.animal: 0.8696, Acc.bicycle: 0.8395, Acc.lake: 0.0000, Acc.dishwasher: 0.9025, Acc.screen: 0.9114, Acc.blanket: 0.4889, Acc.sculpture: 0.9042, Acc.hood: 0.7914, Acc.sconce: 0.8333, Acc.vase: 0.8024, Acc.traffic light: 0.7174, Acc.tray: 0.4437, Acc.ashcan: 0.6940, Acc.fan: 0.8516, Acc.pier: 0.4106, Acc.crt screen: 0.3215, Acc.plate: 0.8482, Acc.monitor: 0.0237, Acc.bulletin board: 0.9198, Acc.shower: 0.2875, Acc.radiator: 0.9310, Acc.glass: 0.3145, Acc.clock: 0.7676, Acc.flag: 0.8425
2022-11-30 11:10:26,148 - mmseg - INFO - Iter [12050/40000]	lr: 9.296e-08, eta: 1 day, 10:00:19, time: 8.706, data_time: 4.601, memory: 51902, decode.loss_cls: 0.4470, decode.loss_mask: 0.5901, decode.loss_dice: 0.8550, decode.d0.loss_cls: 7.5849, decode.d0.loss_mask: 0.5541, decode.d0.loss_dice: 0.9137, decode.d1.loss_cls: 0.5790, decode.d1.loss_mask: 0.6079, decode.d1.loss_dice: 0.9137, decode.d2.loss_cls: 0.5108, decode.d2.loss_mask: 0.5958, decode.d2.loss_dice: 0.8765, decode.d3.loss_cls: 0.4748, decode.d3.loss_mask: 0.5906, decode.d3.loss_dice: 0.8629, decode.d4.loss_cls: 0.4698, decode.d4.loss_mask: 0.5904, decode.d4.loss_dice: 0.8559, decode.d5.loss_cls: 0.4588, decode.d5.loss_mask: 0.5892, decode.d5.loss_dice: 0.8542, decode.d6.loss_cls: 0.4517, decode.d6.loss_mask: 0.5880, decode.d6.loss_dice: 0.8542, decode.d7.loss_cls: 0.4480, decode.d7.loss_mask: 0.5867, decode.d7.loss_dice: 0.8549, decode.d8.loss_cls: 0.4521, decode.d8.loss_mask: 0.5889, decode.d8.loss_dice: 0.8538, loss: 26.4534
2022-11-30 11:13:51,879 - mmseg - INFO - Iter [12100/40000]	lr: 9.279e-08, eta: 1 day, 9:56:09, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4588, decode.loss_mask: 0.5879, decode.loss_dice: 0.8514, decode.d0.loss_cls: 7.5844, decode.d0.loss_mask: 0.5631, decode.d0.loss_dice: 0.9223, decode.d1.loss_cls: 0.5855, decode.d1.loss_mask: 0.6051, decode.d1.loss_dice: 0.9124, decode.d2.loss_cls: 0.5180, decode.d2.loss_mask: 0.5940, decode.d2.loss_dice: 0.8691, decode.d3.loss_cls: 0.4830, decode.d3.loss_mask: 0.5894, decode.d3.loss_dice: 0.8570, decode.d4.loss_cls: 0.4776, decode.d4.loss_mask: 0.5880, decode.d4.loss_dice: 0.8550, decode.d5.loss_cls: 0.4650, decode.d5.loss_mask: 0.5880, decode.d5.loss_dice: 0.8546, decode.d6.loss_cls: 0.4596, decode.d6.loss_mask: 0.5883, decode.d6.loss_dice: 0.8511, decode.d7.loss_cls: 0.4565, decode.d7.loss_mask: 0.5883, decode.d7.loss_dice: 0.8543, decode.d8.loss_cls: 0.4593, decode.d8.loss_mask: 0.5878, decode.d8.loss_dice: 0.8520, loss: 26.5069
2022-11-30 11:17:17,968 - mmseg - INFO - Iter [12150/40000]	lr: 9.262e-08, eta: 1 day, 9:52:01, time: 4.122, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4543, decode.loss_mask: 0.5856, decode.loss_dice: 0.8617, decode.d0.loss_cls: 7.5867, decode.d0.loss_mask: 0.5645, decode.d0.loss_dice: 0.9279, decode.d1.loss_cls: 0.5883, decode.d1.loss_mask: 0.6078, decode.d1.loss_dice: 0.9206, decode.d2.loss_cls: 0.5124, decode.d2.loss_mask: 0.5954, decode.d2.loss_dice: 0.8852, decode.d3.loss_cls: 0.4780, decode.d3.loss_mask: 0.5915, decode.d3.loss_dice: 0.8670, decode.d4.loss_cls: 0.4748, decode.d4.loss_mask: 0.5879, decode.d4.loss_dice: 0.8645, decode.d5.loss_cls: 0.4650, decode.d5.loss_mask: 0.5864, decode.d5.loss_dice: 0.8613, decode.d6.loss_cls: 0.4581, decode.d6.loss_mask: 0.5871, decode.d6.loss_dice: 0.8596, decode.d7.loss_cls: 0.4559, decode.d7.loss_mask: 0.5878, decode.d7.loss_dice: 0.8606, decode.d8.loss_cls: 0.4568, decode.d8.loss_mask: 0.5849, decode.d8.loss_dice: 0.8616, loss: 26.5795
2022-11-30 11:20:43,964 - mmseg - INFO - Iter [12200/40000]	lr: 9.246e-08, eta: 1 day, 9:47:53, time: 4.119, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4589, decode.loss_mask: 0.6004, decode.loss_dice: 0.8629, decode.d0.loss_cls: 7.5685, decode.d0.loss_mask: 0.5783, decode.d0.loss_dice: 0.9329, decode.d1.loss_cls: 0.5849, decode.d1.loss_mask: 0.6238, decode.d1.loss_dice: 0.9223, decode.d2.loss_cls: 0.5182, decode.d2.loss_mask: 0.6110, decode.d2.loss_dice: 0.8781, decode.d3.loss_cls: 0.4866, decode.d3.loss_mask: 0.6032, decode.d3.loss_dice: 0.8648, decode.d4.loss_cls: 0.4767, decode.d4.loss_mask: 0.6029, decode.d4.loss_dice: 0.8628, decode.d5.loss_cls: 0.4702, decode.d5.loss_mask: 0.6008, decode.d5.loss_dice: 0.8561, decode.d6.loss_cls: 0.4620, decode.d6.loss_mask: 0.6009, decode.d6.loss_dice: 0.8611, decode.d7.loss_cls: 0.4593, decode.d7.loss_mask: 0.6031, decode.d7.loss_dice: 0.8592, decode.d8.loss_cls: 0.4592, decode.d8.loss_mask: 0.6016, decode.d8.loss_dice: 0.8624, loss: 26.7330
2022-11-30 11:24:09,410 - mmseg - INFO - Iter [12250/40000]	lr: 9.229e-08, eta: 1 day, 9:43:44, time: 4.110, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4569, decode.loss_mask: 0.5863, decode.loss_dice: 0.8609, decode.d0.loss_cls: 7.5537, decode.d0.loss_mask: 0.5616, decode.d0.loss_dice: 0.9326, decode.d1.loss_cls: 0.5865, decode.d1.loss_mask: 0.6038, decode.d1.loss_dice: 0.9173, decode.d2.loss_cls: 0.5217, decode.d2.loss_mask: 0.5954, decode.d2.loss_dice: 0.8794, decode.d3.loss_cls: 0.4831, decode.d3.loss_mask: 0.5883, decode.d3.loss_dice: 0.8635, decode.d4.loss_cls: 0.4737, decode.d4.loss_mask: 0.5862, decode.d4.loss_dice: 0.8633, decode.d5.loss_cls: 0.4626, decode.d5.loss_mask: 0.5837, decode.d5.loss_dice: 0.8628, decode.d6.loss_cls: 0.4591, decode.d6.loss_mask: 0.5816, decode.d6.loss_dice: 0.8584, decode.d7.loss_cls: 0.4574, decode.d7.loss_mask: 0.5823, decode.d7.loss_dice: 0.8603, decode.d8.loss_cls: 0.4544, decode.d8.loss_mask: 0.5830, decode.d8.loss_dice: 0.8623, loss: 26.5219
2022-11-30 11:27:35,226 - mmseg - INFO - Iter [12300/40000]	lr: 9.213e-08, eta: 1 day, 9:39:36, time: 4.116, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4571, decode.loss_mask: 0.5880, decode.loss_dice: 0.8729, decode.d0.loss_cls: 7.5398, decode.d0.loss_mask: 0.5658, decode.d0.loss_dice: 0.9468, decode.d1.loss_cls: 0.5857, decode.d1.loss_mask: 0.6105, decode.d1.loss_dice: 0.9371, decode.d2.loss_cls: 0.5175, decode.d2.loss_mask: 0.5934, decode.d2.loss_dice: 0.8983, decode.d3.loss_cls: 0.4818, decode.d3.loss_mask: 0.5912, decode.d3.loss_dice: 0.8825, decode.d4.loss_cls: 0.4752, decode.d4.loss_mask: 0.5916, decode.d4.loss_dice: 0.8767, decode.d5.loss_cls: 0.4605, decode.d5.loss_mask: 0.5897, decode.d5.loss_dice: 0.8752, decode.d6.loss_cls: 0.4555, decode.d6.loss_mask: 0.5895, decode.d6.loss_dice: 0.8748, decode.d7.loss_cls: 0.4565, decode.d7.loss_mask: 0.5899, decode.d7.loss_dice: 0.8787, decode.d8.loss_cls: 0.4509, decode.d8.loss_mask: 0.5901, decode.d8.loss_dice: 0.8770, loss: 26.7000
2022-11-30 11:31:01,028 - mmseg - INFO - Iter [12350/40000]	lr: 9.196e-08, eta: 1 day, 9:35:28, time: 4.116, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4451, decode.loss_mask: 0.5904, decode.loss_dice: 0.8542, decode.d0.loss_cls: 7.5344, decode.d0.loss_mask: 0.5701, decode.d0.loss_dice: 0.9330, decode.d1.loss_cls: 0.5816, decode.d1.loss_mask: 0.6148, decode.d1.loss_dice: 0.9160, decode.d2.loss_cls: 0.5068, decode.d2.loss_mask: 0.6046, decode.d2.loss_dice: 0.8809, decode.d3.loss_cls: 0.4704, decode.d3.loss_mask: 0.5973, decode.d3.loss_dice: 0.8653, decode.d4.loss_cls: 0.4626, decode.d4.loss_mask: 0.5943, decode.d4.loss_dice: 0.8571, decode.d5.loss_cls: 0.4561, decode.d5.loss_mask: 0.5931, decode.d5.loss_dice: 0.8567, decode.d6.loss_cls: 0.4479, decode.d6.loss_mask: 0.5908, decode.d6.loss_dice: 0.8541, decode.d7.loss_cls: 0.4453, decode.d7.loss_mask: 0.5911, decode.d7.loss_dice: 0.8563, decode.d8.loss_cls: 0.4434, decode.d8.loss_mask: 0.5907, decode.d8.loss_dice: 0.8533, loss: 26.4578
2022-11-30 11:34:26,283 - mmseg - INFO - Iter [12400/40000]	lr: 9.179e-08, eta: 1 day, 9:31:19, time: 4.105, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4468, decode.loss_mask: 0.5966, decode.loss_dice: 0.8594, decode.d0.loss_cls: 7.5256, decode.d0.loss_mask: 0.5700, decode.d0.loss_dice: 0.9268, decode.d1.loss_cls: 0.5747, decode.d1.loss_mask: 0.6178, decode.d1.loss_dice: 0.9141, decode.d2.loss_cls: 0.5097, decode.d2.loss_mask: 0.6028, decode.d2.loss_dice: 0.8794, decode.d3.loss_cls: 0.4754, decode.d3.loss_mask: 0.5980, decode.d3.loss_dice: 0.8615, decode.d4.loss_cls: 0.4671, decode.d4.loss_mask: 0.5962, decode.d4.loss_dice: 0.8623, decode.d5.loss_cls: 0.4613, decode.d5.loss_mask: 0.5943, decode.d5.loss_dice: 0.8582, decode.d6.loss_cls: 0.4529, decode.d6.loss_mask: 0.5946, decode.d6.loss_dice: 0.8578, decode.d7.loss_cls: 0.4493, decode.d7.loss_mask: 0.5954, decode.d7.loss_dice: 0.8593, decode.d8.loss_cls: 0.4489, decode.d8.loss_mask: 0.5948, decode.d8.loss_dice: 0.8610, loss: 26.5118
2022-11-30 11:37:52,599 - mmseg - INFO - Iter [12450/40000]	lr: 9.163e-08, eta: 1 day, 9:27:14, time: 4.126, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4701, decode.loss_mask: 0.5907, decode.loss_dice: 0.8657, decode.d0.loss_cls: 7.5259, decode.d0.loss_mask: 0.5719, decode.d0.loss_dice: 0.9427, decode.d1.loss_cls: 0.5857, decode.d1.loss_mask: 0.6204, decode.d1.loss_dice: 0.9333, decode.d2.loss_cls: 0.5241, decode.d2.loss_mask: 0.6016, decode.d2.loss_dice: 0.8924, decode.d3.loss_cls: 0.4891, decode.d3.loss_mask: 0.5964, decode.d3.loss_dice: 0.8749, decode.d4.loss_cls: 0.4831, decode.d4.loss_mask: 0.5941, decode.d4.loss_dice: 0.8741, decode.d5.loss_cls: 0.4789, decode.d5.loss_mask: 0.5943, decode.d5.loss_dice: 0.8736, decode.d6.loss_cls: 0.4708, decode.d6.loss_mask: 0.5913, decode.d6.loss_dice: 0.8675, decode.d7.loss_cls: 0.4711, decode.d7.loss_mask: 0.5922, decode.d7.loss_dice: 0.8645, decode.d8.loss_cls: 0.4686, decode.d8.loss_mask: 0.5935, decode.d8.loss_dice: 0.8653, loss: 26.7677
2022-11-30 11:41:18,254 - mmseg - INFO - Iter [12500/40000]	lr: 9.146e-08, eta: 1 day, 9:23:07, time: 4.113, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4500, decode.loss_mask: 0.5942, decode.loss_dice: 0.8694, decode.d0.loss_cls: 7.5111, decode.d0.loss_mask: 0.5618, decode.d0.loss_dice: 0.9336, decode.d1.loss_cls: 0.5900, decode.d1.loss_mask: 0.6095, decode.d1.loss_dice: 0.9260, decode.d2.loss_cls: 0.5180, decode.d2.loss_mask: 0.5992, decode.d2.loss_dice: 0.8910, decode.d3.loss_cls: 0.4783, decode.d3.loss_mask: 0.5965, decode.d3.loss_dice: 0.8719, decode.d4.loss_cls: 0.4679, decode.d4.loss_mask: 0.5969, decode.d4.loss_dice: 0.8693, decode.d5.loss_cls: 0.4587, decode.d5.loss_mask: 0.5927, decode.d5.loss_dice: 0.8670, decode.d6.loss_cls: 0.4543, decode.d6.loss_mask: 0.5929, decode.d6.loss_dice: 0.8664, decode.d7.loss_cls: 0.4504, decode.d7.loss_mask: 0.5957, decode.d7.loss_dice: 0.8676, decode.d8.loss_cls: 0.4504, decode.d8.loss_mask: 0.5932, decode.d8.loss_dice: 0.8677, loss: 26.5916
2022-11-30 11:44:43,888 - mmseg - INFO - Iter [12550/40000]	lr: 9.129e-08, eta: 1 day, 9:19:00, time: 4.113, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4570, decode.loss_mask: 0.5850, decode.loss_dice: 0.8565, decode.d0.loss_cls: 7.4889, decode.d0.loss_mask: 0.5537, decode.d0.loss_dice: 0.9167, decode.d1.loss_cls: 0.5908, decode.d1.loss_mask: 0.6077, decode.d1.loss_dice: 0.9094, decode.d2.loss_cls: 0.5279, decode.d2.loss_mask: 0.5952, decode.d2.loss_dice: 0.8765, decode.d3.loss_cls: 0.4887, decode.d3.loss_mask: 0.5900, decode.d3.loss_dice: 0.8633, decode.d4.loss_cls: 0.4772, decode.d4.loss_mask: 0.5878, decode.d4.loss_dice: 0.8581, decode.d5.loss_cls: 0.4674, decode.d5.loss_mask: 0.5855, decode.d5.loss_dice: 0.8519, decode.d6.loss_cls: 0.4628, decode.d6.loss_mask: 0.5853, decode.d6.loss_dice: 0.8516, decode.d7.loss_cls: 0.4584, decode.d7.loss_mask: 0.5867, decode.d7.loss_dice: 0.8540, decode.d8.loss_cls: 0.4567, decode.d8.loss_mask: 0.5853, decode.d8.loss_dice: 0.8559, loss: 26.4317
2022-11-30 11:48:09,654 - mmseg - INFO - Iter [12600/40000]	lr: 9.113e-08, eta: 1 day, 9:14:54, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4704, decode.loss_mask: 0.5848, decode.loss_dice: 0.8584, decode.d0.loss_cls: 7.4907, decode.d0.loss_mask: 0.5546, decode.d0.loss_dice: 0.9265, decode.d1.loss_cls: 0.5914, decode.d1.loss_mask: 0.6042, decode.d1.loss_dice: 0.9199, decode.d2.loss_cls: 0.5288, decode.d2.loss_mask: 0.5938, decode.d2.loss_dice: 0.8815, decode.d3.loss_cls: 0.4924, decode.d3.loss_mask: 0.5891, decode.d3.loss_dice: 0.8683, decode.d4.loss_cls: 0.4840, decode.d4.loss_mask: 0.5860, decode.d4.loss_dice: 0.8677, decode.d5.loss_cls: 0.4765, decode.d5.loss_mask: 0.5843, decode.d5.loss_dice: 0.8608, decode.d6.loss_cls: 0.4729, decode.d6.loss_mask: 0.5834, decode.d6.loss_dice: 0.8564, decode.d7.loss_cls: 0.4696, decode.d7.loss_mask: 0.5842, decode.d7.loss_dice: 0.8588, decode.d8.loss_cls: 0.4693, decode.d8.loss_mask: 0.5849, decode.d8.loss_dice: 0.8588, loss: 26.5523
2022-11-30 11:51:38,011 - mmseg - INFO - Iter [12650/40000]	lr: 9.096e-08, eta: 1 day, 9:10:54, time: 4.167, data_time: 0.064, memory: 51902, decode.loss_cls: 0.4527, decode.loss_mask: 0.5969, decode.loss_dice: 0.8659, decode.d0.loss_cls: 7.4847, decode.d0.loss_mask: 0.5735, decode.d0.loss_dice: 0.9296, decode.d1.loss_cls: 0.5793, decode.d1.loss_mask: 0.6171, decode.d1.loss_dice: 0.9245, decode.d2.loss_cls: 0.5151, decode.d2.loss_mask: 0.6075, decode.d2.loss_dice: 0.8848, decode.d3.loss_cls: 0.4847, decode.d3.loss_mask: 0.6007, decode.d3.loss_dice: 0.8714, decode.d4.loss_cls: 0.4781, decode.d4.loss_mask: 0.5970, decode.d4.loss_dice: 0.8690, decode.d5.loss_cls: 0.4636, decode.d5.loss_mask: 0.5962, decode.d5.loss_dice: 0.8641, decode.d6.loss_cls: 0.4593, decode.d6.loss_mask: 0.5976, decode.d6.loss_dice: 0.8654, decode.d7.loss_cls: 0.4548, decode.d7.loss_mask: 0.5974, decode.d7.loss_dice: 0.8662, decode.d8.loss_cls: 0.4538, decode.d8.loss_mask: 0.5980, decode.d8.loss_dice: 0.8618, loss: 26.6107
2022-11-30 11:55:03,628 - mmseg - INFO - Iter [12700/40000]	lr: 9.079e-08, eta: 1 day, 9:06:48, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4529, decode.loss_mask: 0.5986, decode.loss_dice: 0.8721, decode.d0.loss_cls: 7.4661, decode.d0.loss_mask: 0.5762, decode.d0.loss_dice: 0.9371, decode.d1.loss_cls: 0.5806, decode.d1.loss_mask: 0.6227, decode.d1.loss_dice: 0.9365, decode.d2.loss_cls: 0.5106, decode.d2.loss_mask: 0.6083, decode.d2.loss_dice: 0.8988, decode.d3.loss_cls: 0.4772, decode.d3.loss_mask: 0.6057, decode.d3.loss_dice: 0.8801, decode.d4.loss_cls: 0.4695, decode.d4.loss_mask: 0.6020, decode.d4.loss_dice: 0.8817, decode.d5.loss_cls: 0.4567, decode.d5.loss_mask: 0.6004, decode.d5.loss_dice: 0.8749, decode.d6.loss_cls: 0.4499, decode.d6.loss_mask: 0.6001, decode.d6.loss_dice: 0.8738, decode.d7.loss_cls: 0.4501, decode.d7.loss_mask: 0.5994, decode.d7.loss_dice: 0.8708, decode.d8.loss_cls: 0.4511, decode.d8.loss_mask: 0.5986, decode.d8.loss_dice: 0.8708, loss: 26.6730
2022-11-30 11:58:29,316 - mmseg - INFO - Iter [12750/40000]	lr: 9.063e-08, eta: 1 day, 9:02:42, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4413, decode.loss_mask: 0.5887, decode.loss_dice: 0.8450, decode.d0.loss_cls: 7.4474, decode.d0.loss_mask: 0.5639, decode.d0.loss_dice: 0.9163, decode.d1.loss_cls: 0.5645, decode.d1.loss_mask: 0.6120, decode.d1.loss_dice: 0.9094, decode.d2.loss_cls: 0.5027, decode.d2.loss_mask: 0.5986, decode.d2.loss_dice: 0.8761, decode.d3.loss_cls: 0.4666, decode.d3.loss_mask: 0.5918, decode.d3.loss_dice: 0.8589, decode.d4.loss_cls: 0.4578, decode.d4.loss_mask: 0.5910, decode.d4.loss_dice: 0.8572, decode.d5.loss_cls: 0.4483, decode.d5.loss_mask: 0.5901, decode.d5.loss_dice: 0.8522, decode.d6.loss_cls: 0.4467, decode.d6.loss_mask: 0.5879, decode.d6.loss_dice: 0.8474, decode.d7.loss_cls: 0.4444, decode.d7.loss_mask: 0.5885, decode.d7.loss_dice: 0.8461, decode.d8.loss_cls: 0.4433, decode.d8.loss_mask: 0.5885, decode.d8.loss_dice: 0.8480, loss: 26.2204
2022-11-30 12:01:55,882 - mmseg - INFO - Iter [12800/40000]	lr: 9.046e-08, eta: 1 day, 8:58:39, time: 4.131, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4467, decode.loss_mask: 0.5738, decode.loss_dice: 0.8461, decode.d0.loss_cls: 7.4500, decode.d0.loss_mask: 0.5503, decode.d0.loss_dice: 0.9168, decode.d1.loss_cls: 0.5675, decode.d1.loss_mask: 0.5968, decode.d1.loss_dice: 0.9052, decode.d2.loss_cls: 0.5055, decode.d2.loss_mask: 0.5838, decode.d2.loss_dice: 0.8671, decode.d3.loss_cls: 0.4740, decode.d3.loss_mask: 0.5765, decode.d3.loss_dice: 0.8553, decode.d4.loss_cls: 0.4635, decode.d4.loss_mask: 0.5749, decode.d4.loss_dice: 0.8518, decode.d5.loss_cls: 0.4537, decode.d5.loss_mask: 0.5744, decode.d5.loss_dice: 0.8493, decode.d6.loss_cls: 0.4475, decode.d6.loss_mask: 0.5724, decode.d6.loss_dice: 0.8454, decode.d7.loss_cls: 0.4432, decode.d7.loss_mask: 0.5753, decode.d7.loss_dice: 0.8464, decode.d8.loss_cls: 0.4448, decode.d8.loss_mask: 0.5757, decode.d8.loss_dice: 0.8471, loss: 26.0807
2022-11-30 12:05:21,667 - mmseg - INFO - Iter [12850/40000]	lr: 9.030e-08, eta: 1 day, 8:54:35, time: 4.116, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4502, decode.loss_mask: 0.5816, decode.loss_dice: 0.8637, decode.d0.loss_cls: 7.4339, decode.d0.loss_mask: 0.5558, decode.d0.loss_dice: 0.9292, decode.d1.loss_cls: 0.5922, decode.d1.loss_mask: 0.5982, decode.d1.loss_dice: 0.9206, decode.d2.loss_cls: 0.5174, decode.d2.loss_mask: 0.5869, decode.d2.loss_dice: 0.8862, decode.d3.loss_cls: 0.4772, decode.d3.loss_mask: 0.5811, decode.d3.loss_dice: 0.8738, decode.d4.loss_cls: 0.4626, decode.d4.loss_mask: 0.5811, decode.d4.loss_dice: 0.8728, decode.d5.loss_cls: 0.4569, decode.d5.loss_mask: 0.5795, decode.d5.loss_dice: 0.8691, decode.d6.loss_cls: 0.4519, decode.d6.loss_mask: 0.5772, decode.d6.loss_dice: 0.8641, decode.d7.loss_cls: 0.4517, decode.d7.loss_mask: 0.5776, decode.d7.loss_dice: 0.8655, decode.d8.loss_cls: 0.4495, decode.d8.loss_mask: 0.5799, decode.d8.loss_dice: 0.8670, loss: 26.3543
2022-11-30 12:08:47,697 - mmseg - INFO - Iter [12900/40000]	lr: 9.013e-08, eta: 1 day, 8:50:31, time: 4.121, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4429, decode.loss_mask: 0.5803, decode.loss_dice: 0.8476, decode.d0.loss_cls: 7.4341, decode.d0.loss_mask: 0.5550, decode.d0.loss_dice: 0.9049, decode.d1.loss_cls: 0.5651, decode.d1.loss_mask: 0.6004, decode.d1.loss_dice: 0.9021, decode.d2.loss_cls: 0.4982, decode.d2.loss_mask: 0.5869, decode.d2.loss_dice: 0.8636, decode.d3.loss_cls: 0.4662, decode.d3.loss_mask: 0.5838, decode.d3.loss_dice: 0.8523, decode.d4.loss_cls: 0.4573, decode.d4.loss_mask: 0.5812, decode.d4.loss_dice: 0.8486, decode.d5.loss_cls: 0.4501, decode.d5.loss_mask: 0.5801, decode.d5.loss_dice: 0.8438, decode.d6.loss_cls: 0.4447, decode.d6.loss_mask: 0.5787, decode.d6.loss_dice: 0.8380, decode.d7.loss_cls: 0.4431, decode.d7.loss_mask: 0.5795, decode.d7.loss_dice: 0.8454, decode.d8.loss_cls: 0.4437, decode.d8.loss_mask: 0.5813, decode.d8.loss_dice: 0.8459, loss: 26.0451
2022-11-30 12:12:13,395 - mmseg - INFO - Iter [12950/40000]	lr: 8.996e-08, eta: 1 day, 8:46:27, time: 4.114, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4466, decode.loss_mask: 0.6090, decode.loss_dice: 0.8728, decode.d0.loss_cls: 7.4041, decode.d0.loss_mask: 0.5762, decode.d0.loss_dice: 0.9319, decode.d1.loss_cls: 0.5720, decode.d1.loss_mask: 0.6282, decode.d1.loss_dice: 0.9321, decode.d2.loss_cls: 0.5083, decode.d2.loss_mask: 0.6172, decode.d2.loss_dice: 0.8966, decode.d3.loss_cls: 0.4766, decode.d3.loss_mask: 0.6085, decode.d3.loss_dice: 0.8755, decode.d4.loss_cls: 0.4696, decode.d4.loss_mask: 0.6087, decode.d4.loss_dice: 0.8753, decode.d5.loss_cls: 0.4539, decode.d5.loss_mask: 0.6066, decode.d5.loss_dice: 0.8783, decode.d6.loss_cls: 0.4521, decode.d6.loss_mask: 0.6060, decode.d6.loss_dice: 0.8714, decode.d7.loss_cls: 0.4489, decode.d7.loss_mask: 0.6062, decode.d7.loss_dice: 0.8728, decode.d8.loss_cls: 0.4471, decode.d8.loss_mask: 0.6062, decode.d8.loss_dice: 0.8740, loss: 26.6329
2022-11-30 12:15:39,454 - mmseg - INFO - Saving checkpoint at 13000 iterations
2022-11-30 12:16:28,104 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 12:16:28,104 - mmseg - INFO - Iter [13000/40000]	lr: 8.980e-08, eta: 1 day, 8:44:05, time: 5.094, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4351, decode.loss_mask: 0.5895, decode.loss_dice: 0.8590, decode.d0.loss_cls: 7.3967, decode.d0.loss_mask: 0.5666, decode.d0.loss_dice: 0.9209, decode.d1.loss_cls: 0.5592, decode.d1.loss_mask: 0.6076, decode.d1.loss_dice: 0.9092, decode.d2.loss_cls: 0.4946, decode.d2.loss_mask: 0.5998, decode.d2.loss_dice: 0.8783, decode.d3.loss_cls: 0.4589, decode.d3.loss_mask: 0.5942, decode.d3.loss_dice: 0.8635, decode.d4.loss_cls: 0.4513, decode.d4.loss_mask: 0.5932, decode.d4.loss_dice: 0.8621, decode.d5.loss_cls: 0.4389, decode.d5.loss_mask: 0.5915, decode.d5.loss_dice: 0.8572, decode.d6.loss_cls: 0.4349, decode.d6.loss_mask: 0.5902, decode.d6.loss_dice: 0.8529, decode.d7.loss_cls: 0.4382, decode.d7.loss_mask: 0.5894, decode.d7.loss_dice: 0.8532, decode.d8.loss_cls: 0.4343, decode.d8.loss_mask: 0.5907, decode.d8.loss_dice: 0.8567, loss: 26.1676
2022-11-30 12:19:26,187 - mmseg - INFO - per class results:
2022-11-30 12:19:26,192 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 82.75 |  89.3 |
|       building      | 84.49 | 92.34 |
|         sky         | 95.02 | 97.41 |
|        floor        |  85.2 | 88.83 |
|         tree        | 78.75 | 89.18 |
|       ceiling       | 86.64 | 90.76 |
|         road        | 87.42 | 91.56 |
|         bed         | 93.18 | 96.43 |
|      windowpane     | 66.56 |  85.6 |
|        grass        | 70.97 | 85.61 |
|       cabinet       | 61.57 |  72.4 |
|       sidewalk      | 71.21 |  84.5 |
|        person       | 88.32 | 94.01 |
|        earth        | 43.42 | 59.89 |
|         door        | 64.31 | 80.71 |
|        table        | 72.48 | 81.83 |
|       mountain      | 64.68 | 76.79 |
|        plant        |  57.7 | 73.15 |
|       curtain       | 82.31 | 90.24 |
|        chair        | 67.45 | 76.67 |
|         car         | 89.72 | 95.22 |
|        water        | 60.88 | 74.99 |
|       painting      | 81.98 | 91.63 |
|         sofa        | 87.13 | 92.83 |
|        shelf        | 48.08 | 64.36 |
|        house        | 49.33 | 62.71 |
|         sea         | 71.18 | 89.07 |
|        mirror       | 81.29 | 91.71 |
|         rug         | 71.39 | 86.11 |
|        field        | 40.04 | 65.34 |
|       armchair      | 62.39 | 84.33 |
|         seat        | 67.45 | 90.68 |
|        fence        | 55.06 | 80.12 |
|         desk        | 60.12 | 84.65 |
|         rock        |  60.8 | 77.65 |
|       wardrobe      | 54.12 | 77.92 |
|         lamp        | 79.72 | 88.66 |
|       bathtub       | 92.26 | 93.79 |
|       railing       | 47.69 | 68.27 |
|       cushion       | 76.86 | 88.57 |
|         base        | 44.72 | 79.99 |
|         box         | 40.74 | 55.87 |
|        column       | 56.42 | 70.95 |
|      signboard      | 45.16 | 63.52 |
|   chest of drawers  | 44.01 |  70.0 |
|       counter       | 56.22 | 68.55 |
|         sand        | 64.18 | 88.58 |
|         sink        | 82.12 | 86.98 |
|      skyscraper     | 24.46 | 27.15 |
|      fireplace      | 76.26 |  94.4 |
|     refrigerator    | 85.32 | 95.72 |
|      grandstand     | 47.59 | 82.16 |
|         path        | 28.94 | 41.43 |
|        stairs       | 29.61 | 35.85 |
|        runway       | 73.96 | 95.05 |
|         case        | 72.43 | 89.95 |
|      pool table     | 95.66 | 98.44 |
|        pillow       | 71.94 | 84.57 |
|     screen door     | 83.04 | 90.36 |
|       stairway      | 52.56 | 74.88 |
|        river        | 22.87 | 29.28 |
|        bridge       | 76.94 | 90.11 |
|       bookcase      | 31.93 | 50.83 |
|        blind        | 36.32 | 41.51 |
|     coffee table    |  73.0 | 90.76 |
|        toilet       | 92.05 |  95.2 |
|        flower       |  40.9 | 65.26 |
|         book        | 56.39 | 72.66 |
|         hill        |  8.46 | 14.49 |
|        bench        | 75.39 | 81.94 |
|      countertop     | 70.36 | 92.92 |
|        stove        | 85.84 | 90.02 |
|         palm        | 55.11 |  82.4 |
|    kitchen island   | 36.65 | 95.02 |
|       computer      | 81.27 | 89.53 |
|     swivel chair    | 54.55 |  84.4 |
|         boat        | 49.76 | 88.02 |
|         bar         | 61.89 | 66.58 |
|    arcade machine   | 90.72 | 99.06 |
|        hovel        | 28.85 |  39.8 |
|         bus         | 94.76 | 96.99 |
|        towel        | 79.01 | 95.42 |
|        light        | 65.73 |  78.9 |
|        truck        |  53.1 |  73.2 |
|        tower        | 32.67 | 59.49 |
|      chandelier     | 75.79 | 87.41 |
|        awning       | 34.03 | 54.37 |
|     streetlight     | 44.78 | 66.08 |
|        booth        | 49.57 | 63.91 |
| television receiver | 73.82 | 89.42 |
|       airplane      | 88.42 | 96.12 |
|      dirt track     |  1.82 |  1.82 |
|       apparel       |  51.1 | 94.28 |
|         pole        | 39.58 | 55.19 |
|         land        |  0.99 |  1.28 |
|      bannister      | 21.66 | 28.62 |
|      escalator      | 64.14 | 83.58 |
|       ottoman       | 53.79 | 78.37 |
|        bottle       | 53.71 | 81.86 |
|        buffet       | 25.77 |  32.9 |
|        poster       |  35.6 | 59.15 |
|        stage        |  27.7 | 77.72 |
|         van         | 53.21 | 73.23 |
|         ship        | 83.94 |  88.5 |
|       fountain      | 41.74 | 50.21 |
|    conveyer belt    | 78.33 | 97.22 |
|        canopy       | 51.43 | 60.54 |
|        washer       | 91.35 | 94.12 |
|      plaything      | 40.54 | 62.39 |
|    swimming pool    | 45.57 | 74.53 |
|        stool        | 56.73 | 86.62 |
|        barrel       | 57.71 | 64.76 |
|        basket       | 45.72 | 70.21 |
|      waterfall      | 68.76 |  88.7 |
|         tent        | 94.39 | 97.87 |
|         bag         | 34.25 | 47.41 |
|       minibike      | 81.14 | 92.97 |
|        cradle       | 91.24 | 97.05 |
|         oven        | 64.76 | 83.08 |
|         ball        | 50.88 | 58.35 |
|         food        | 64.15 | 74.95 |
|         step        | 18.29 | 32.41 |
|         tank        | 50.22 | 55.58 |
|      trade name     | 33.43 | 44.07 |
|      microwave      | 88.83 |  94.7 |
|         pot         | 61.32 | 74.47 |
|        animal       | 84.86 | 87.92 |
|       bicycle       | 60.75 | 81.38 |
|         lake        |  3.48 |  5.66 |
|      dishwasher     | 64.13 | 90.56 |
|        screen       | 60.11 | 95.71 |
|       blanket       | 37.55 | 48.37 |
|      sculpture      | 68.89 | 90.83 |
|         hood        | 79.97 |  95.2 |
|        sconce       | 65.69 | 80.28 |
|         vase        | 60.41 | 79.74 |
|    traffic light    | 50.35 | 72.87 |
|         tray        | 26.49 |  38.2 |
|        ashcan       | 54.23 |  71.4 |
|         fan         | 71.76 | 85.08 |
|         pier        | 36.61 | 41.45 |
|      crt screen     |  6.97 | 19.84 |
|        plate        | 67.54 | 86.49 |
|       monitor       |  4.31 |  5.56 |
|    bulletin board   | 57.06 | 88.91 |
|        shower       | 23.29 | 30.32 |
|       radiator      | 72.64 | 93.19 |
|        glass        | 28.59 | 31.24 |
|        clock        | 63.06 | 75.25 |
|         flag        | 71.23 | 85.65 |
+---------------------+-------+-------+
2022-11-30 12:19:26,192 - mmseg - INFO - Summary:
2022-11-30 12:19:26,192 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 86.53 | 59.21 | 74.01 |
+-------+-------+-------+
2022-11-30 12:19:26,198 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 12:19:26,198 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8653, mIoU: 0.5921, mAcc: 0.7401, IoU.wall: 0.8275, IoU.building: 0.8449, IoU.sky: 0.9502, IoU.floor: 0.8520, IoU.tree: 0.7875, IoU.ceiling: 0.8664, IoU.road: 0.8742, IoU.bed : 0.9318, IoU.windowpane: 0.6656, IoU.grass: 0.7097, IoU.cabinet: 0.6157, IoU.sidewalk: 0.7121, IoU.person: 0.8832, IoU.earth: 0.4342, IoU.door: 0.6431, IoU.table: 0.7248, IoU.mountain: 0.6468, IoU.plant: 0.5770, IoU.curtain: 0.8231, IoU.chair: 0.6745, IoU.car: 0.8972, IoU.water: 0.6088, IoU.painting: 0.8198, IoU.sofa: 0.8713, IoU.shelf: 0.4808, IoU.house: 0.4933, IoU.sea: 0.7118, IoU.mirror: 0.8129, IoU.rug: 0.7139, IoU.field: 0.4004, IoU.armchair: 0.6239, IoU.seat: 0.6745, IoU.fence: 0.5506, IoU.desk: 0.6012, IoU.rock: 0.6080, IoU.wardrobe: 0.5412, IoU.lamp: 0.7972, IoU.bathtub: 0.9226, IoU.railing: 0.4769, IoU.cushion: 0.7686, IoU.base: 0.4472, IoU.box: 0.4074, IoU.column: 0.5642, IoU.signboard: 0.4516, IoU.chest of drawers: 0.4401, IoU.counter: 0.5622, IoU.sand: 0.6418, IoU.sink: 0.8212, IoU.skyscraper: 0.2446, IoU.fireplace: 0.7626, IoU.refrigerator: 0.8532, IoU.grandstand: 0.4759, IoU.path: 0.2894, IoU.stairs: 0.2961, IoU.runway: 0.7396, IoU.case: 0.7243, IoU.pool table: 0.9566, IoU.pillow: 0.7194, IoU.screen door: 0.8304, IoU.stairway: 0.5256, IoU.river: 0.2287, IoU.bridge: 0.7694, IoU.bookcase: 0.3193, IoU.blind: 0.3632, IoU.coffee table: 0.7300, IoU.toilet: 0.9205, IoU.flower: 0.4090, IoU.book: 0.5639, IoU.hill: 0.0846, IoU.bench: 0.7539, IoU.countertop: 0.7036, IoU.stove: 0.8584, IoU.palm: 0.5511, IoU.kitchen island: 0.3665, IoU.computer: 0.8127, IoU.swivel chair: 0.5455, IoU.boat: 0.4976, IoU.bar: 0.6189, IoU.arcade machine: 0.9072, IoU.hovel: 0.2885, IoU.bus: 0.9476, IoU.towel: 0.7901, IoU.light: 0.6573, IoU.truck: 0.5310, IoU.tower: 0.3267, IoU.chandelier: 0.7579, IoU.awning: 0.3403, IoU.streetlight: 0.4478, IoU.booth: 0.4957, IoU.television receiver: 0.7382, IoU.airplane: 0.8842, IoU.dirt track: 0.0182, IoU.apparel: 0.5110, IoU.pole: 0.3958, IoU.land: 0.0099, IoU.bannister: 0.2166, IoU.escalator: 0.6414, IoU.ottoman: 0.5379, IoU.bottle: 0.5371, IoU.buffet: 0.2577, IoU.poster: 0.3560, IoU.stage: 0.2770, IoU.van: 0.5321, IoU.ship: 0.8394, IoU.fountain: 0.4174, IoU.conveyer belt: 0.7833, IoU.canopy: 0.5143, IoU.washer: 0.9135, IoU.plaything: 0.4054, IoU.swimming pool: 0.4557, IoU.stool: 0.5673, IoU.barrel: 0.5771, IoU.basket: 0.4572, IoU.waterfall: 0.6876, IoU.tent: 0.9439, IoU.bag: 0.3425, IoU.minibike: 0.8114, IoU.cradle: 0.9124, IoU.oven: 0.6476, IoU.ball: 0.5088, IoU.food: 0.6415, IoU.step: 0.1829, IoU.tank: 0.5022, IoU.trade name: 0.3343, IoU.microwave: 0.8883, IoU.pot: 0.6132, IoU.animal: 0.8486, IoU.bicycle: 0.6075, IoU.lake: 0.0348, IoU.dishwasher: 0.6413, IoU.screen: 0.6011, IoU.blanket: 0.3755, IoU.sculpture: 0.6889, IoU.hood: 0.7997, IoU.sconce: 0.6569, IoU.vase: 0.6041, IoU.traffic light: 0.5035, IoU.tray: 0.2649, IoU.ashcan: 0.5423, IoU.fan: 0.7176, IoU.pier: 0.3661, IoU.crt screen: 0.0697, IoU.plate: 0.6754, IoU.monitor: 0.0431, IoU.bulletin board: 0.5706, IoU.shower: 0.2329, IoU.radiator: 0.7264, IoU.glass: 0.2859, IoU.clock: 0.6306, IoU.flag: 0.7123, Acc.wall: 0.8930, Acc.building: 0.9234, Acc.sky: 0.9741, Acc.floor: 0.8883, Acc.tree: 0.8918, Acc.ceiling: 0.9076, Acc.road: 0.9156, Acc.bed : 0.9643, Acc.windowpane: 0.8560, Acc.grass: 0.8561, Acc.cabinet: 0.7240, Acc.sidewalk: 0.8450, Acc.person: 0.9401, Acc.earth: 0.5989, Acc.door: 0.8071, Acc.table: 0.8183, Acc.mountain: 0.7679, Acc.plant: 0.7315, Acc.curtain: 0.9024, Acc.chair: 0.7667, Acc.car: 0.9522, Acc.water: 0.7499, Acc.painting: 0.9163, Acc.sofa: 0.9283, Acc.shelf: 0.6436, Acc.house: 0.6271, Acc.sea: 0.8907, Acc.mirror: 0.9171, Acc.rug: 0.8611, Acc.field: 0.6534, Acc.armchair: 0.8433, Acc.seat: 0.9068, Acc.fence: 0.8012, Acc.desk: 0.8465, Acc.rock: 0.7765, Acc.wardrobe: 0.7792, Acc.lamp: 0.8866, Acc.bathtub: 0.9379, Acc.railing: 0.6827, Acc.cushion: 0.8857, Acc.base: 0.7999, Acc.box: 0.5587, Acc.column: 0.7095, Acc.signboard: 0.6352, Acc.chest of drawers: 0.7000, Acc.counter: 0.6855, Acc.sand: 0.8858, Acc.sink: 0.8698, Acc.skyscraper: 0.2715, Acc.fireplace: 0.9440, Acc.refrigerator: 0.9572, Acc.grandstand: 0.8216, Acc.path: 0.4143, Acc.stairs: 0.3585, Acc.runway: 0.9505, Acc.case: 0.8995, Acc.pool table: 0.9844, Acc.pillow: 0.8457, Acc.screen door: 0.9036, Acc.stairway: 0.7488, Acc.river: 0.2928, Acc.bridge: 0.9011, Acc.bookcase: 0.5083, Acc.blind: 0.4151, Acc.coffee table: 0.9076, Acc.toilet: 0.9520, Acc.flower: 0.6526, Acc.book: 0.7266, Acc.hill: 0.1449, Acc.bench: 0.8194, Acc.countertop: 0.9292, Acc.stove: 0.9002, Acc.palm: 0.8240, Acc.kitchen island: 0.9502, Acc.computer: 0.8953, Acc.swivel chair: 0.8440, Acc.boat: 0.8802, Acc.bar: 0.6658, Acc.arcade machine: 0.9906, Acc.hovel: 0.3980, Acc.bus: 0.9699, Acc.towel: 0.9542, Acc.light: 0.7890, Acc.truck: 0.7320, Acc.tower: 0.5949, Acc.chandelier: 0.8741, Acc.awning: 0.5437, Acc.streetlight: 0.6608, Acc.booth: 0.6391, Acc.television receiver: 0.8942, Acc.airplane: 0.9612, Acc.dirt track: 0.0182, Acc.apparel: 0.9428, Acc.pole: 0.5519, Acc.land: 0.0128, Acc.bannister: 0.2862, Acc.escalator: 0.8358, Acc.ottoman: 0.7837, Acc.bottle: 0.8186, Acc.buffet: 0.3290, Acc.poster: 0.5915, Acc.stage: 0.7772, Acc.van: 0.7323, Acc.ship: 0.8850, Acc.fountain: 0.5021, Acc.conveyer belt: 0.9722, Acc.canopy: 0.6054, Acc.washer: 0.9412, Acc.plaything: 0.6239, Acc.swimming pool: 0.7453, Acc.stool: 0.8662, Acc.barrel: 0.6476, Acc.basket: 0.7021, Acc.waterfall: 0.8870, Acc.tent: 0.9787, Acc.bag: 0.4741, Acc.minibike: 0.9297, Acc.cradle: 0.9705, Acc.oven: 0.8308, Acc.ball: 0.5835, Acc.food: 0.7495, Acc.step: 0.3241, Acc.tank: 0.5558, Acc.trade name: 0.4407, Acc.microwave: 0.9470, Acc.pot: 0.7447, Acc.animal: 0.8792, Acc.bicycle: 0.8138, Acc.lake: 0.0566, Acc.dishwasher: 0.9056, Acc.screen: 0.9571, Acc.blanket: 0.4837, Acc.sculpture: 0.9083, Acc.hood: 0.9520, Acc.sconce: 0.8028, Acc.vase: 0.7974, Acc.traffic light: 0.7287, Acc.tray: 0.3820, Acc.ashcan: 0.7140, Acc.fan: 0.8508, Acc.pier: 0.4145, Acc.crt screen: 0.1984, Acc.plate: 0.8649, Acc.monitor: 0.0556, Acc.bulletin board: 0.8891, Acc.shower: 0.3032, Acc.radiator: 0.9319, Acc.glass: 0.3124, Acc.clock: 0.7525, Acc.flag: 0.8565
2022-11-30 12:22:52,204 - mmseg - INFO - Iter [13050/40000]	lr: 8.963e-08, eta: 1 day, 8:46:09, time: 7.682, data_time: 3.582, memory: 51902, decode.loss_cls: 0.4471, decode.loss_mask: 0.5987, decode.loss_dice: 0.8731, decode.d0.loss_cls: 7.3996, decode.d0.loss_mask: 0.5643, decode.d0.loss_dice: 0.9391, decode.d1.loss_cls: 0.5705, decode.d1.loss_mask: 0.6177, decode.d1.loss_dice: 0.9274, decode.d2.loss_cls: 0.5055, decode.d2.loss_mask: 0.6076, decode.d2.loss_dice: 0.8905, decode.d3.loss_cls: 0.4734, decode.d3.loss_mask: 0.6022, decode.d3.loss_dice: 0.8786, decode.d4.loss_cls: 0.4630, decode.d4.loss_mask: 0.6009, decode.d4.loss_dice: 0.8757, decode.d5.loss_cls: 0.4518, decode.d5.loss_mask: 0.5987, decode.d5.loss_dice: 0.8764, decode.d6.loss_cls: 0.4498, decode.d6.loss_mask: 0.5998, decode.d6.loss_dice: 0.8716, decode.d7.loss_cls: 0.4488, decode.d7.loss_mask: 0.5993, decode.d7.loss_dice: 0.8757, decode.d8.loss_cls: 0.4443, decode.d8.loss_mask: 0.6004, decode.d8.loss_dice: 0.8740, loss: 26.5253
2022-11-30 12:26:18,382 - mmseg - INFO - Iter [13100/40000]	lr: 8.946e-08, eta: 1 day, 8:42:04, time: 4.124, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4384, decode.loss_mask: 0.5879, decode.loss_dice: 0.8469, decode.d0.loss_cls: 7.3876, decode.d0.loss_mask: 0.5646, decode.d0.loss_dice: 0.9108, decode.d1.loss_cls: 0.5597, decode.d1.loss_mask: 0.6096, decode.d1.loss_dice: 0.9097, decode.d2.loss_cls: 0.4980, decode.d2.loss_mask: 0.5977, decode.d2.loss_dice: 0.8658, decode.d3.loss_cls: 0.4621, decode.d3.loss_mask: 0.5952, decode.d3.loss_dice: 0.8604, decode.d4.loss_cls: 0.4600, decode.d4.loss_mask: 0.5909, decode.d4.loss_dice: 0.8536, decode.d5.loss_cls: 0.4464, decode.d5.loss_mask: 0.5906, decode.d5.loss_dice: 0.8506, decode.d6.loss_cls: 0.4383, decode.d6.loss_mask: 0.5906, decode.d6.loss_dice: 0.8469, decode.d7.loss_cls: 0.4415, decode.d7.loss_mask: 0.5897, decode.d7.loss_dice: 0.8475, decode.d8.loss_cls: 0.4383, decode.d8.loss_mask: 0.5880, decode.d8.loss_dice: 0.8479, loss: 26.1152
2022-11-30 12:29:44,088 - mmseg - INFO - Iter [13150/40000]	lr: 8.930e-08, eta: 1 day, 8:37:59, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4545, decode.loss_mask: 0.5774, decode.loss_dice: 0.8430, decode.d0.loss_cls: 7.3799, decode.d0.loss_mask: 0.5515, decode.d0.loss_dice: 0.9061, decode.d1.loss_cls: 0.5699, decode.d1.loss_mask: 0.6026, decode.d1.loss_dice: 0.9035, decode.d2.loss_cls: 0.5148, decode.d2.loss_mask: 0.5861, decode.d2.loss_dice: 0.8664, decode.d3.loss_cls: 0.4832, decode.d3.loss_mask: 0.5803, decode.d3.loss_dice: 0.8472, decode.d4.loss_cls: 0.4718, decode.d4.loss_mask: 0.5808, decode.d4.loss_dice: 0.8521, decode.d5.loss_cls: 0.4630, decode.d5.loss_mask: 0.5762, decode.d5.loss_dice: 0.8482, decode.d6.loss_cls: 0.4564, decode.d6.loss_mask: 0.5784, decode.d6.loss_dice: 0.8438, decode.d7.loss_cls: 0.4589, decode.d7.loss_mask: 0.5771, decode.d7.loss_dice: 0.8399, decode.d8.loss_cls: 0.4578, decode.d8.loss_mask: 0.5762, decode.d8.loss_dice: 0.8443, loss: 26.0914
2022-11-30 12:33:10,450 - mmseg - INFO - Iter [13200/40000]	lr: 8.913e-08, eta: 1 day, 8:33:55, time: 4.127, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4642, decode.loss_mask: 0.5934, decode.loss_dice: 0.8619, decode.d0.loss_cls: 7.3614, decode.d0.loss_mask: 0.5722, decode.d0.loss_dice: 0.9407, decode.d1.loss_cls: 0.5865, decode.d1.loss_mask: 0.6143, decode.d1.loss_dice: 0.9286, decode.d2.loss_cls: 0.5229, decode.d2.loss_mask: 0.6027, decode.d2.loss_dice: 0.8909, decode.d3.loss_cls: 0.4905, decode.d3.loss_mask: 0.5938, decode.d3.loss_dice: 0.8721, decode.d4.loss_cls: 0.4803, decode.d4.loss_mask: 0.5929, decode.d4.loss_dice: 0.8714, decode.d5.loss_cls: 0.4720, decode.d5.loss_mask: 0.5911, decode.d5.loss_dice: 0.8669, decode.d6.loss_cls: 0.4719, decode.d6.loss_mask: 0.5920, decode.d6.loss_dice: 0.8632, decode.d7.loss_cls: 0.4622, decode.d7.loss_mask: 0.5935, decode.d7.loss_dice: 0.8650, decode.d8.loss_cls: 0.4622, decode.d8.loss_mask: 0.5922, decode.d8.loss_dice: 0.8645, loss: 26.5376
2022-11-30 12:36:36,709 - mmseg - INFO - Iter [13250/40000]	lr: 8.897e-08, eta: 1 day, 8:29:51, time: 4.125, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4516, decode.loss_mask: 0.6006, decode.loss_dice: 0.8681, decode.d0.loss_cls: 7.3614, decode.d0.loss_mask: 0.5725, decode.d0.loss_dice: 0.9368, decode.d1.loss_cls: 0.5736, decode.d1.loss_mask: 0.6195, decode.d1.loss_dice: 0.9259, decode.d2.loss_cls: 0.5124, decode.d2.loss_mask: 0.6096, decode.d2.loss_dice: 0.8844, decode.d3.loss_cls: 0.4799, decode.d3.loss_mask: 0.6013, decode.d3.loss_dice: 0.8729, decode.d4.loss_cls: 0.4702, decode.d4.loss_mask: 0.5990, decode.d4.loss_dice: 0.8709, decode.d5.loss_cls: 0.4603, decode.d5.loss_mask: 0.5991, decode.d5.loss_dice: 0.8685, decode.d6.loss_cls: 0.4522, decode.d6.loss_mask: 0.5996, decode.d6.loss_dice: 0.8662, decode.d7.loss_cls: 0.4524, decode.d7.loss_mask: 0.5988, decode.d7.loss_dice: 0.8699, decode.d8.loss_cls: 0.4531, decode.d8.loss_mask: 0.5990, decode.d8.loss_dice: 0.8656, loss: 26.4954
2022-11-30 12:40:04,515 - mmseg - INFO - Iter [13300/40000]	lr: 8.880e-08, eta: 1 day, 8:25:50, time: 4.156, data_time: 0.065, memory: 51902, decode.loss_cls: 0.4183, decode.loss_mask: 0.5953, decode.loss_dice: 0.8479, decode.d0.loss_cls: 7.3381, decode.d0.loss_mask: 0.5715, decode.d0.loss_dice: 0.9113, decode.d1.loss_cls: 0.5432, decode.d1.loss_mask: 0.6191, decode.d1.loss_dice: 0.9078, decode.d2.loss_cls: 0.4824, decode.d2.loss_mask: 0.6024, decode.d2.loss_dice: 0.8660, decode.d3.loss_cls: 0.4473, decode.d3.loss_mask: 0.5980, decode.d3.loss_dice: 0.8548, decode.d4.loss_cls: 0.4378, decode.d4.loss_mask: 0.5942, decode.d4.loss_dice: 0.8497, decode.d5.loss_cls: 0.4251, decode.d5.loss_mask: 0.5945, decode.d5.loss_dice: 0.8497, decode.d6.loss_cls: 0.4267, decode.d6.loss_mask: 0.5959, decode.d6.loss_dice: 0.8462, decode.d7.loss_cls: 0.4203, decode.d7.loss_mask: 0.5944, decode.d7.loss_dice: 0.8479, decode.d8.loss_cls: 0.4180, decode.d8.loss_mask: 0.5957, decode.d8.loss_dice: 0.8460, loss: 25.9456
2022-11-30 12:43:30,374 - mmseg - INFO - Iter [13350/40000]	lr: 8.863e-08, eta: 1 day, 8:21:46, time: 4.117, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4329, decode.loss_mask: 0.5844, decode.loss_dice: 0.8455, decode.d0.loss_cls: 7.3308, decode.d0.loss_mask: 0.5525, decode.d0.loss_dice: 0.9076, decode.d1.loss_cls: 0.5541, decode.d1.loss_mask: 0.6029, decode.d1.loss_dice: 0.9007, decode.d2.loss_cls: 0.4895, decode.d2.loss_mask: 0.5961, decode.d2.loss_dice: 0.8714, decode.d3.loss_cls: 0.4559, decode.d3.loss_mask: 0.5893, decode.d3.loss_dice: 0.8599, decode.d4.loss_cls: 0.4495, decode.d4.loss_mask: 0.5887, decode.d4.loss_dice: 0.8555, decode.d5.loss_cls: 0.4417, decode.d5.loss_mask: 0.5860, decode.d5.loss_dice: 0.8481, decode.d6.loss_cls: 0.4366, decode.d6.loss_mask: 0.5839, decode.d6.loss_dice: 0.8486, decode.d7.loss_cls: 0.4324, decode.d7.loss_mask: 0.5841, decode.d7.loss_dice: 0.8503, decode.d8.loss_cls: 0.4336, decode.d8.loss_mask: 0.5834, decode.d8.loss_dice: 0.8494, loss: 25.9450
2022-11-30 12:46:56,665 - mmseg - INFO - Iter [13400/40000]	lr: 8.847e-08, eta: 1 day, 8:17:43, time: 4.126, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4520, decode.loss_mask: 0.5751, decode.loss_dice: 0.8515, decode.d0.loss_cls: 7.3243, decode.d0.loss_mask: 0.5581, decode.d0.loss_dice: 0.9194, decode.d1.loss_cls: 0.5600, decode.d1.loss_mask: 0.5992, decode.d1.loss_dice: 0.9087, decode.d2.loss_cls: 0.5020, decode.d2.loss_mask: 0.5860, decode.d2.loss_dice: 0.8713, decode.d3.loss_cls: 0.4729, decode.d3.loss_mask: 0.5807, decode.d3.loss_dice: 0.8551, decode.d4.loss_cls: 0.4612, decode.d4.loss_mask: 0.5794, decode.d4.loss_dice: 0.8592, decode.d5.loss_cls: 0.4560, decode.d5.loss_mask: 0.5776, decode.d5.loss_dice: 0.8483, decode.d6.loss_cls: 0.4547, decode.d6.loss_mask: 0.5769, decode.d6.loss_dice: 0.8477, decode.d7.loss_cls: 0.4500, decode.d7.loss_mask: 0.5759, decode.d7.loss_dice: 0.8500, decode.d8.loss_cls: 0.4474, decode.d8.loss_mask: 0.5749, decode.d8.loss_dice: 0.8491, loss: 26.0242
2022-11-30 12:50:22,376 - mmseg - INFO - Iter [13450/40000]	lr: 8.830e-08, eta: 1 day, 8:13:39, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4332, decode.loss_mask: 0.5789, decode.loss_dice: 0.8451, decode.d0.loss_cls: 7.3092, decode.d0.loss_mask: 0.5547, decode.d0.loss_dice: 0.9116, decode.d1.loss_cls: 0.5492, decode.d1.loss_mask: 0.5987, decode.d1.loss_dice: 0.9019, decode.d2.loss_cls: 0.4929, decode.d2.loss_mask: 0.5863, decode.d2.loss_dice: 0.8654, decode.d3.loss_cls: 0.4588, decode.d3.loss_mask: 0.5799, decode.d3.loss_dice: 0.8460, decode.d4.loss_cls: 0.4517, decode.d4.loss_mask: 0.5771, decode.d4.loss_dice: 0.8447, decode.d5.loss_cls: 0.4401, decode.d5.loss_mask: 0.5770, decode.d5.loss_dice: 0.8408, decode.d6.loss_cls: 0.4390, decode.d6.loss_mask: 0.5773, decode.d6.loss_dice: 0.8370, decode.d7.loss_cls: 0.4344, decode.d7.loss_mask: 0.5789, decode.d7.loss_dice: 0.8416, decode.d8.loss_cls: 0.4336, decode.d8.loss_mask: 0.5760, decode.d8.loss_dice: 0.8430, loss: 25.8043
2022-11-30 12:53:48,481 - mmseg - INFO - Iter [13500/40000]	lr: 8.813e-08, eta: 1 day, 8:09:36, time: 4.122, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4425, decode.loss_mask: 0.5948, decode.loss_dice: 0.8659, decode.d0.loss_cls: 7.3027, decode.d0.loss_mask: 0.5711, decode.d0.loss_dice: 0.9341, decode.d1.loss_cls: 0.5706, decode.d1.loss_mask: 0.6137, decode.d1.loss_dice: 0.9243, decode.d2.loss_cls: 0.4939, decode.d2.loss_mask: 0.6055, decode.d2.loss_dice: 0.8899, decode.d3.loss_cls: 0.4636, decode.d3.loss_mask: 0.5993, decode.d3.loss_dice: 0.8770, decode.d4.loss_cls: 0.4604, decode.d4.loss_mask: 0.5973, decode.d4.loss_dice: 0.8728, decode.d5.loss_cls: 0.4482, decode.d5.loss_mask: 0.5974, decode.d5.loss_dice: 0.8713, decode.d6.loss_cls: 0.4416, decode.d6.loss_mask: 0.5964, decode.d6.loss_dice: 0.8652, decode.d7.loss_cls: 0.4433, decode.d7.loss_mask: 0.5953, decode.d7.loss_dice: 0.8646, decode.d8.loss_cls: 0.4419, decode.d8.loss_mask: 0.5955, decode.d8.loss_dice: 0.8651, loss: 26.3052
2022-11-30 12:57:14,297 - mmseg - INFO - Iter [13550/40000]	lr: 8.797e-08, eta: 1 day, 8:05:33, time: 4.116, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4351, decode.loss_mask: 0.5969, decode.loss_dice: 0.8660, decode.d0.loss_cls: 7.2937, decode.d0.loss_mask: 0.5682, decode.d0.loss_dice: 0.9321, decode.d1.loss_cls: 0.5619, decode.d1.loss_mask: 0.6195, decode.d1.loss_dice: 0.9204, decode.d2.loss_cls: 0.4933, decode.d2.loss_mask: 0.6071, decode.d2.loss_dice: 0.8854, decode.d3.loss_cls: 0.4615, decode.d3.loss_mask: 0.6019, decode.d3.loss_dice: 0.8738, decode.d4.loss_cls: 0.4505, decode.d4.loss_mask: 0.6006, decode.d4.loss_dice: 0.8721, decode.d5.loss_cls: 0.4394, decode.d5.loss_mask: 0.6025, decode.d5.loss_dice: 0.8677, decode.d6.loss_cls: 0.4399, decode.d6.loss_mask: 0.5965, decode.d6.loss_dice: 0.8644, decode.d7.loss_cls: 0.4351, decode.d7.loss_mask: 0.5964, decode.d7.loss_dice: 0.8690, decode.d8.loss_cls: 0.4358, decode.d8.loss_mask: 0.5982, decode.d8.loss_dice: 0.8660, loss: 26.2508
2022-11-30 13:00:40,512 - mmseg - INFO - Iter [13600/40000]	lr: 8.780e-08, eta: 1 day, 8:01:31, time: 4.124, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4378, decode.loss_mask: 0.5933, decode.loss_dice: 0.8712, decode.d0.loss_cls: 7.2948, decode.d0.loss_mask: 0.5695, decode.d0.loss_dice: 0.9378, decode.d1.loss_cls: 0.5720, decode.d1.loss_mask: 0.6154, decode.d1.loss_dice: 0.9303, decode.d2.loss_cls: 0.5085, decode.d2.loss_mask: 0.6053, decode.d2.loss_dice: 0.8966, decode.d3.loss_cls: 0.4726, decode.d3.loss_mask: 0.5991, decode.d3.loss_dice: 0.8823, decode.d4.loss_cls: 0.4583, decode.d4.loss_mask: 0.5957, decode.d4.loss_dice: 0.8799, decode.d5.loss_cls: 0.4468, decode.d5.loss_mask: 0.5946, decode.d5.loss_dice: 0.8792, decode.d6.loss_cls: 0.4433, decode.d6.loss_mask: 0.5957, decode.d6.loss_dice: 0.8743, decode.d7.loss_cls: 0.4403, decode.d7.loss_mask: 0.5955, decode.d7.loss_dice: 0.8771, decode.d8.loss_cls: 0.4330, decode.d8.loss_mask: 0.5971, decode.d8.loss_dice: 0.8768, loss: 26.3740
2022-11-30 13:04:06,113 - mmseg - INFO - Iter [13650/40000]	lr: 8.764e-08, eta: 1 day, 7:57:28, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4450, decode.loss_mask: 0.5801, decode.loss_dice: 0.8517, decode.d0.loss_cls: 7.2812, decode.d0.loss_mask: 0.5611, decode.d0.loss_dice: 0.9321, decode.d1.loss_cls: 0.5652, decode.d1.loss_mask: 0.6056, decode.d1.loss_dice: 0.9158, decode.d2.loss_cls: 0.5041, decode.d2.loss_mask: 0.5941, decode.d2.loss_dice: 0.8795, decode.d3.loss_cls: 0.4674, decode.d3.loss_mask: 0.5913, decode.d3.loss_dice: 0.8640, decode.d4.loss_cls: 0.4591, decode.d4.loss_mask: 0.5860, decode.d4.loss_dice: 0.8601, decode.d5.loss_cls: 0.4495, decode.d5.loss_mask: 0.5825, decode.d5.loss_dice: 0.8579, decode.d6.loss_cls: 0.4445, decode.d6.loss_mask: 0.5843, decode.d6.loss_dice: 0.8516, decode.d7.loss_cls: 0.4399, decode.d7.loss_mask: 0.5821, decode.d7.loss_dice: 0.8533, decode.d8.loss_cls: 0.4426, decode.d8.loss_mask: 0.5809, decode.d8.loss_dice: 0.8554, loss: 26.0679
2022-11-30 13:07:32,084 - mmseg - INFO - Iter [13700/40000]	lr: 8.747e-08, eta: 1 day, 7:53:26, time: 4.119, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4521, decode.loss_mask: 0.5775, decode.loss_dice: 0.8456, decode.d0.loss_cls: 7.2910, decode.d0.loss_mask: 0.5529, decode.d0.loss_dice: 0.9189, decode.d1.loss_cls: 0.5794, decode.d1.loss_mask: 0.6015, decode.d1.loss_dice: 0.9154, decode.d2.loss_cls: 0.5156, decode.d2.loss_mask: 0.5885, decode.d2.loss_dice: 0.8666, decode.d3.loss_cls: 0.4795, decode.d3.loss_mask: 0.5800, decode.d3.loss_dice: 0.8552, decode.d4.loss_cls: 0.4690, decode.d4.loss_mask: 0.5800, decode.d4.loss_dice: 0.8548, decode.d5.loss_cls: 0.4589, decode.d5.loss_mask: 0.5783, decode.d5.loss_dice: 0.8472, decode.d6.loss_cls: 0.4523, decode.d6.loss_mask: 0.5773, decode.d6.loss_dice: 0.8461, decode.d7.loss_cls: 0.4505, decode.d7.loss_mask: 0.5789, decode.d7.loss_dice: 0.8490, decode.d8.loss_cls: 0.4509, decode.d8.loss_mask: 0.5758, decode.d8.loss_dice: 0.8457, loss: 26.0349
2022-11-30 13:10:58,411 - mmseg - INFO - Iter [13750/40000]	lr: 8.730e-08, eta: 1 day, 7:49:25, time: 4.126, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4587, decode.loss_mask: 0.5763, decode.loss_dice: 0.8539, decode.d0.loss_cls: 7.2754, decode.d0.loss_mask: 0.5562, decode.d0.loss_dice: 0.9278, decode.d1.loss_cls: 0.5904, decode.d1.loss_mask: 0.5998, decode.d1.loss_dice: 0.9128, decode.d2.loss_cls: 0.5162, decode.d2.loss_mask: 0.5881, decode.d2.loss_dice: 0.8771, decode.d3.loss_cls: 0.4895, decode.d3.loss_mask: 0.5817, decode.d3.loss_dice: 0.8647, decode.d4.loss_cls: 0.4761, decode.d4.loss_mask: 0.5786, decode.d4.loss_dice: 0.8591, decode.d5.loss_cls: 0.4646, decode.d5.loss_mask: 0.5759, decode.d5.loss_dice: 0.8591, decode.d6.loss_cls: 0.4594, decode.d6.loss_mask: 0.5746, decode.d6.loss_dice: 0.8555, decode.d7.loss_cls: 0.4587, decode.d7.loss_mask: 0.5746, decode.d7.loss_dice: 0.8514, decode.d8.loss_cls: 0.4564, decode.d8.loss_mask: 0.5750, decode.d8.loss_dice: 0.8537, loss: 26.1413
2022-11-30 13:14:23,992 - mmseg - INFO - Iter [13800/40000]	lr: 8.714e-08, eta: 1 day, 7:45:23, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4600, decode.loss_mask: 0.5820, decode.loss_dice: 0.8549, decode.d0.loss_cls: 7.2529, decode.d0.loss_mask: 0.5564, decode.d0.loss_dice: 0.9319, decode.d1.loss_cls: 0.5774, decode.d1.loss_mask: 0.6032, decode.d1.loss_dice: 0.9144, decode.d2.loss_cls: 0.5122, decode.d2.loss_mask: 0.5929, decode.d2.loss_dice: 0.8812, decode.d3.loss_cls: 0.4832, decode.d3.loss_mask: 0.5885, decode.d3.loss_dice: 0.8624, decode.d4.loss_cls: 0.4717, decode.d4.loss_mask: 0.5872, decode.d4.loss_dice: 0.8633, decode.d5.loss_cls: 0.4638, decode.d5.loss_mask: 0.5809, decode.d5.loss_dice: 0.8594, decode.d6.loss_cls: 0.4605, decode.d6.loss_mask: 0.5814, decode.d6.loss_dice: 0.8549, decode.d7.loss_cls: 0.4627, decode.d7.loss_mask: 0.5829, decode.d7.loss_dice: 0.8557, decode.d8.loss_cls: 0.4592, decode.d8.loss_mask: 0.5816, decode.d8.loss_dice: 0.8570, loss: 26.1755
2022-11-30 13:17:50,052 - mmseg - INFO - Iter [13850/40000]	lr: 8.697e-08, eta: 1 day, 7:41:22, time: 4.121, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4429, decode.loss_mask: 0.5776, decode.loss_dice: 0.8420, decode.d0.loss_cls: 7.2453, decode.d0.loss_mask: 0.5510, decode.d0.loss_dice: 0.9115, decode.d1.loss_cls: 0.5645, decode.d1.loss_mask: 0.5984, decode.d1.loss_dice: 0.9022, decode.d2.loss_cls: 0.5022, decode.d2.loss_mask: 0.5877, decode.d2.loss_dice: 0.8663, decode.d3.loss_cls: 0.4693, decode.d3.loss_mask: 0.5833, decode.d3.loss_dice: 0.8503, decode.d4.loss_cls: 0.4605, decode.d4.loss_mask: 0.5810, decode.d4.loss_dice: 0.8498, decode.d5.loss_cls: 0.4481, decode.d5.loss_mask: 0.5804, decode.d5.loss_dice: 0.8475, decode.d6.loss_cls: 0.4442, decode.d6.loss_mask: 0.5793, decode.d6.loss_dice: 0.8423, decode.d7.loss_cls: 0.4415, decode.d7.loss_mask: 0.5785, decode.d7.loss_dice: 0.8405, decode.d8.loss_cls: 0.4416, decode.d8.loss_mask: 0.5783, decode.d8.loss_dice: 0.8430, loss: 25.8510
2022-11-30 13:21:15,789 - mmseg - INFO - Iter [13900/40000]	lr: 8.680e-08, eta: 1 day, 7:37:21, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4345, decode.loss_mask: 0.5824, decode.loss_dice: 0.8574, decode.d0.loss_cls: 7.2343, decode.d0.loss_mask: 0.5593, decode.d0.loss_dice: 0.9133, decode.d1.loss_cls: 0.5584, decode.d1.loss_mask: 0.6002, decode.d1.loss_dice: 0.9118, decode.d2.loss_cls: 0.4954, decode.d2.loss_mask: 0.5897, decode.d2.loss_dice: 0.8759, decode.d3.loss_cls: 0.4565, decode.d3.loss_mask: 0.5844, decode.d3.loss_dice: 0.8611, decode.d4.loss_cls: 0.4513, decode.d4.loss_mask: 0.5859, decode.d4.loss_dice: 0.8612, decode.d5.loss_cls: 0.4399, decode.d5.loss_mask: 0.5843, decode.d5.loss_dice: 0.8606, decode.d6.loss_cls: 0.4356, decode.d6.loss_mask: 0.5806, decode.d6.loss_dice: 0.8539, decode.d7.loss_cls: 0.4356, decode.d7.loss_mask: 0.5802, decode.d7.loss_dice: 0.8541, decode.d8.loss_cls: 0.4355, decode.d8.loss_mask: 0.5798, decode.d8.loss_dice: 0.8533, loss: 25.9061
2022-11-30 13:24:44,387 - mmseg - INFO - Iter [13950/40000]	lr: 8.664e-08, eta: 1 day, 7:33:25, time: 4.172, data_time: 0.066, memory: 51902, decode.loss_cls: 0.4459, decode.loss_mask: 0.5878, decode.loss_dice: 0.8524, decode.d0.loss_cls: 7.2285, decode.d0.loss_mask: 0.5679, decode.d0.loss_dice: 0.9319, decode.d1.loss_cls: 0.5633, decode.d1.loss_mask: 0.6148, decode.d1.loss_dice: 0.9171, decode.d2.loss_cls: 0.5087, decode.d2.loss_mask: 0.5990, decode.d2.loss_dice: 0.8796, decode.d3.loss_cls: 0.4713, decode.d3.loss_mask: 0.5966, decode.d3.loss_dice: 0.8640, decode.d4.loss_cls: 0.4625, decode.d4.loss_mask: 0.5917, decode.d4.loss_dice: 0.8593, decode.d5.loss_cls: 0.4551, decode.d5.loss_mask: 0.5876, decode.d5.loss_dice: 0.8572, decode.d6.loss_cls: 0.4491, decode.d6.loss_mask: 0.5901, decode.d6.loss_dice: 0.8570, decode.d7.loss_cls: 0.4527, decode.d7.loss_mask: 0.5885, decode.d7.loss_dice: 0.8529, decode.d8.loss_cls: 0.4476, decode.d8.loss_mask: 0.5866, decode.d8.loss_dice: 0.8571, loss: 26.1239
2022-11-30 13:28:10,220 - mmseg - INFO - Saving checkpoint at 14000 iterations
2022-11-30 13:28:58,586 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 13:28:58,586 - mmseg - INFO - Iter [14000/40000]	lr: 8.647e-08, eta: 1 day, 7:30:54, time: 5.084, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4220, decode.loss_mask: 0.5619, decode.loss_dice: 0.8471, decode.d0.loss_cls: 7.2205, decode.d0.loss_mask: 0.5399, decode.d0.loss_dice: 0.9119, decode.d1.loss_cls: 0.5533, decode.d1.loss_mask: 0.5834, decode.d1.loss_dice: 0.9044, decode.d2.loss_cls: 0.4867, decode.d2.loss_mask: 0.5683, decode.d2.loss_dice: 0.8663, decode.d3.loss_cls: 0.4455, decode.d3.loss_mask: 0.5636, decode.d3.loss_dice: 0.8499, decode.d4.loss_cls: 0.4397, decode.d4.loss_mask: 0.5631, decode.d4.loss_dice: 0.8476, decode.d5.loss_cls: 0.4287, decode.d5.loss_mask: 0.5606, decode.d5.loss_dice: 0.8481, decode.d6.loss_cls: 0.4245, decode.d6.loss_mask: 0.5619, decode.d6.loss_dice: 0.8429, decode.d7.loss_cls: 0.4258, decode.d7.loss_mask: 0.5588, decode.d7.loss_dice: 0.8440, decode.d8.loss_cls: 0.4228, decode.d8.loss_mask: 0.5594, decode.d8.loss_dice: 0.8462, loss: 25.4988
2022-11-30 13:31:56,626 - mmseg - INFO - per class results:
2022-11-30 13:31:56,631 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 82.84 | 90.09 |
|       building      | 84.52 |  91.0 |
|         sky         | 95.05 | 97.36 |
|        floor        | 84.88 | 89.12 |
|         tree        |  78.8 | 89.02 |
|       ceiling       | 87.25 | 92.89 |
|         road        | 87.89 | 92.41 |
|         bed         | 93.37 | 96.73 |
|      windowpane     | 66.91 | 82.13 |
|        grass        | 71.92 | 90.46 |
|       cabinet       | 62.94 | 72.53 |
|       sidewalk      | 73.01 | 85.58 |
|        person       | 88.36 | 93.98 |
|        earth        | 44.22 | 58.64 |
|         door        | 62.97 | 79.67 |
|        table        | 72.65 | 83.22 |
|       mountain      | 60.95 |  72.2 |
|        plant        | 57.18 | 74.15 |
|       curtain       | 82.38 | 90.47 |
|        chair        | 68.86 | 79.31 |
|         car         | 89.06 | 94.76 |
|        water        | 61.81 | 79.49 |
|       painting      | 82.02 | 92.82 |
|         sofa        | 84.89 | 91.23 |
|        shelf        | 46.76 | 59.42 |
|        house        | 50.52 | 67.59 |
|         sea         |  72.3 | 89.19 |
|        mirror       |  80.4 | 90.18 |
|         rug         | 72.94 |  87.3 |
|        field        | 34.92 | 45.61 |
|       armchair      | 63.68 | 78.78 |
|         seat        |  67.2 |  89.8 |
|        fence        | 54.62 |  76.6 |
|         desk        | 60.16 | 81.44 |
|         rock        | 58.42 | 69.44 |
|       wardrobe      | 55.75 | 84.06 |
|         lamp        |  80.9 | 89.54 |
|       bathtub       | 90.97 | 93.37 |
|       railing       | 48.17 | 73.76 |
|       cushion       | 77.04 | 89.37 |
|         base        | 46.59 | 74.34 |
|         box         | 40.15 |  58.7 |
|        column       | 59.63 |  73.6 |
|      signboard      | 45.74 | 65.49 |
|   chest of drawers  | 45.33 | 66.66 |
|       counter       |  61.8 | 71.36 |
|         sand        | 62.46 | 89.23 |
|         sink        | 83.22 | 86.51 |
|      skyscraper     | 33.75 | 41.03 |
|      fireplace      | 81.92 | 95.11 |
|     refrigerator    | 83.85 | 95.31 |
|      grandstand     | 44.02 | 77.23 |
|         path        | 23.72 | 31.13 |
|        stairs       | 31.93 | 40.21 |
|        runway       |  74.8 | 95.02 |
|         case        | 75.22 |  89.0 |
|      pool table     | 95.66 | 98.49 |
|        pillow       | 73.34 | 85.19 |
|     screen door     | 89.48 | 94.52 |
|       stairway      | 53.81 | 76.92 |
|        river        | 25.69 | 29.22 |
|        bridge       | 78.86 | 90.93 |
|       bookcase      | 38.61 | 66.27 |
|        blind        | 47.64 | 57.98 |
|     coffee table    |  72.8 | 89.64 |
|        toilet       | 93.29 | 96.88 |
|        flower       | 47.33 | 69.69 |
|         book        | 58.61 | 84.59 |
|         hill        |  9.86 | 22.23 |
|        bench        | 74.65 | 82.87 |
|      countertop     | 68.51 | 82.53 |
|        stove        |  85.2 | 89.49 |
|         palm        | 55.85 | 82.06 |
|    kitchen island   | 48.16 | 90.55 |
|       computer      | 82.14 | 89.57 |
|     swivel chair    | 55.04 | 86.96 |
|         boat        | 57.04 | 87.33 |
|         bar         | 69.42 | 74.69 |
|    arcade machine   | 91.06 | 98.87 |
|        hovel        | 50.88 | 72.66 |
|         bus         |  94.1 | 96.73 |
|        towel        | 81.44 | 91.47 |
|        light        | 67.01 | 80.04 |
|        truck        | 55.29 | 72.92 |
|        tower        | 36.11 | 63.79 |
|      chandelier     | 76.06 | 85.27 |
|        awning       | 32.14 |  52.4 |
|     streetlight     | 47.09 | 68.72 |
|        booth        | 51.79 | 73.17 |
| television receiver |  72.8 | 89.57 |
|       airplane      | 90.58 | 95.89 |
|      dirt track     |  9.79 | 11.76 |
|       apparel       | 53.82 | 91.65 |
|         pole        | 40.44 |  60.5 |
|         land        |  0.32 |  0.43 |
|      bannister      | 21.79 | 35.96 |
|      escalator      | 65.71 |  83.7 |
|       ottoman       | 54.82 | 89.16 |
|        bottle       |  53.4 | 82.59 |
|        buffet       | 33.19 | 41.51 |
|        poster       | 31.44 | 53.98 |
|        stage        | 23.53 | 61.42 |
|         van         |  48.8 | 74.06 |
|         ship        | 34.99 | 36.89 |
|       fountain      | 41.42 |  42.7 |
|    conveyer belt    | 86.17 | 97.37 |
|        canopy       | 50.44 | 64.58 |
|        washer       |  91.2 | 93.75 |
|      plaything      | 35.81 | 61.43 |
|    swimming pool    | 44.02 | 73.82 |
|        stool        | 59.98 | 84.52 |
|        barrel       | 58.72 | 67.21 |
|        basket       | 45.13 | 73.33 |
|      waterfall      |  53.6 | 58.19 |
|         tent        | 95.62 | 97.65 |
|         bag         | 34.15 | 48.93 |
|       minibike      |  81.3 | 93.69 |
|        cradle       | 91.19 | 97.37 |
|         oven        | 63.47 |  82.9 |
|         ball        | 53.55 | 63.75 |
|         food        | 68.96 | 83.01 |
|         step        | 26.27 |  40.3 |
|         tank        | 52.05 | 53.92 |
|      trade name     | 32.95 | 49.51 |
|      microwave      | 89.03 | 94.66 |
|         pot         | 61.28 | 74.37 |
|        animal       | 82.97 | 85.54 |
|       bicycle       | 59.03 | 84.44 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 70.29 |  90.6 |
|        screen       | 61.23 | 95.91 |
|       blanket       | 38.74 | 53.91 |
|      sculpture      | 69.35 | 91.19 |
|         hood        | 73.42 |  79.5 |
|        sconce       | 65.92 | 81.51 |
|         vase        | 56.15 | 81.02 |
|    traffic light    | 51.62 | 73.79 |
|         tray        | 27.28 | 45.04 |
|        ashcan       | 49.41 | 74.69 |
|         fan         | 75.04 | 87.33 |
|         pier        | 37.53 | 42.01 |
|      crt screen     |  6.36 | 16.27 |
|        plate        |  69.2 | 86.19 |
|       monitor       |  5.95 |  8.12 |
|    bulletin board   |  59.1 | 88.04 |
|        shower       | 23.25 | 28.46 |
|       radiator      | 73.16 | 90.73 |
|        glass        | 28.97 | 32.44 |
|        clock        | 62.85 | 75.29 |
|         flag        | 71.34 | 86.08 |
+---------------------+-------+-------+
2022-11-30 13:31:56,631 - mmseg - INFO - Summary:
2022-11-30 13:31:56,631 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 86.76 | 59.78 | 74.29 |
+-------+-------+-------+
2022-11-30 13:31:56,634 - mmseg - INFO - The previous best checkpoint /mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune/lr1.0_lrd0.9/best_mIoU_iter_12000.pth was removed
2022-11-30 13:32:45,211 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_14000.pth.
2022-11-30 13:32:45,211 - mmseg - INFO - Best mIoU is 0.5978 at 14000 iter.
2022-11-30 13:32:45,223 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 13:32:45,223 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8676, mIoU: 0.5978, mAcc: 0.7429, IoU.wall: 0.8284, IoU.building: 0.8452, IoU.sky: 0.9505, IoU.floor: 0.8488, IoU.tree: 0.7880, IoU.ceiling: 0.8725, IoU.road: 0.8789, IoU.bed : 0.9337, IoU.windowpane: 0.6691, IoU.grass: 0.7192, IoU.cabinet: 0.6294, IoU.sidewalk: 0.7301, IoU.person: 0.8836, IoU.earth: 0.4422, IoU.door: 0.6297, IoU.table: 0.7265, IoU.mountain: 0.6095, IoU.plant: 0.5718, IoU.curtain: 0.8238, IoU.chair: 0.6886, IoU.car: 0.8906, IoU.water: 0.6181, IoU.painting: 0.8202, IoU.sofa: 0.8489, IoU.shelf: 0.4676, IoU.house: 0.5052, IoU.sea: 0.7230, IoU.mirror: 0.8040, IoU.rug: 0.7294, IoU.field: 0.3492, IoU.armchair: 0.6368, IoU.seat: 0.6720, IoU.fence: 0.5462, IoU.desk: 0.6016, IoU.rock: 0.5842, IoU.wardrobe: 0.5575, IoU.lamp: 0.8090, IoU.bathtub: 0.9097, IoU.railing: 0.4817, IoU.cushion: 0.7704, IoU.base: 0.4659, IoU.box: 0.4015, IoU.column: 0.5963, IoU.signboard: 0.4574, IoU.chest of drawers: 0.4533, IoU.counter: 0.6180, IoU.sand: 0.6246, IoU.sink: 0.8322, IoU.skyscraper: 0.3375, IoU.fireplace: 0.8192, IoU.refrigerator: 0.8385, IoU.grandstand: 0.4402, IoU.path: 0.2372, IoU.stairs: 0.3193, IoU.runway: 0.7480, IoU.case: 0.7522, IoU.pool table: 0.9566, IoU.pillow: 0.7334, IoU.screen door: 0.8948, IoU.stairway: 0.5381, IoU.river: 0.2569, IoU.bridge: 0.7886, IoU.bookcase: 0.3861, IoU.blind: 0.4764, IoU.coffee table: 0.7280, IoU.toilet: 0.9329, IoU.flower: 0.4733, IoU.book: 0.5861, IoU.hill: 0.0986, IoU.bench: 0.7465, IoU.countertop: 0.6851, IoU.stove: 0.8520, IoU.palm: 0.5585, IoU.kitchen island: 0.4816, IoU.computer: 0.8214, IoU.swivel chair: 0.5504, IoU.boat: 0.5704, IoU.bar: 0.6942, IoU.arcade machine: 0.9106, IoU.hovel: 0.5088, IoU.bus: 0.9410, IoU.towel: 0.8144, IoU.light: 0.6701, IoU.truck: 0.5529, IoU.tower: 0.3611, IoU.chandelier: 0.7606, IoU.awning: 0.3214, IoU.streetlight: 0.4709, IoU.booth: 0.5179, IoU.television receiver: 0.7280, IoU.airplane: 0.9058, IoU.dirt track: 0.0979, IoU.apparel: 0.5382, IoU.pole: 0.4044, IoU.land: 0.0032, IoU.bannister: 0.2179, IoU.escalator: 0.6571, IoU.ottoman: 0.5482, IoU.bottle: 0.5340, IoU.buffet: 0.3319, IoU.poster: 0.3144, IoU.stage: 0.2353, IoU.van: 0.4880, IoU.ship: 0.3499, IoU.fountain: 0.4142, IoU.conveyer belt: 0.8617, IoU.canopy: 0.5044, IoU.washer: 0.9120, IoU.plaything: 0.3581, IoU.swimming pool: 0.4402, IoU.stool: 0.5998, IoU.barrel: 0.5872, IoU.basket: 0.4513, IoU.waterfall: 0.5360, IoU.tent: 0.9562, IoU.bag: 0.3415, IoU.minibike: 0.8130, IoU.cradle: 0.9119, IoU.oven: 0.6347, IoU.ball: 0.5355, IoU.food: 0.6896, IoU.step: 0.2627, IoU.tank: 0.5205, IoU.trade name: 0.3295, IoU.microwave: 0.8903, IoU.pot: 0.6128, IoU.animal: 0.8297, IoU.bicycle: 0.5903, IoU.lake: 0.0000, IoU.dishwasher: 0.7029, IoU.screen: 0.6123, IoU.blanket: 0.3874, IoU.sculpture: 0.6935, IoU.hood: 0.7342, IoU.sconce: 0.6592, IoU.vase: 0.5615, IoU.traffic light: 0.5162, IoU.tray: 0.2728, IoU.ashcan: 0.4941, IoU.fan: 0.7504, IoU.pier: 0.3753, IoU.crt screen: 0.0636, IoU.plate: 0.6920, IoU.monitor: 0.0595, IoU.bulletin board: 0.5910, IoU.shower: 0.2325, IoU.radiator: 0.7316, IoU.glass: 0.2897, IoU.clock: 0.6285, IoU.flag: 0.7134, Acc.wall: 0.9009, Acc.building: 0.9100, Acc.sky: 0.9736, Acc.floor: 0.8912, Acc.tree: 0.8902, Acc.ceiling: 0.9289, Acc.road: 0.9241, Acc.bed : 0.9673, Acc.windowpane: 0.8213, Acc.grass: 0.9046, Acc.cabinet: 0.7253, Acc.sidewalk: 0.8558, Acc.person: 0.9398, Acc.earth: 0.5864, Acc.door: 0.7967, Acc.table: 0.8322, Acc.mountain: 0.7220, Acc.plant: 0.7415, Acc.curtain: 0.9047, Acc.chair: 0.7931, Acc.car: 0.9476, Acc.water: 0.7949, Acc.painting: 0.9282, Acc.sofa: 0.9123, Acc.shelf: 0.5942, Acc.house: 0.6759, Acc.sea: 0.8919, Acc.mirror: 0.9018, Acc.rug: 0.8730, Acc.field: 0.4561, Acc.armchair: 0.7878, Acc.seat: 0.8980, Acc.fence: 0.7660, Acc.desk: 0.8144, Acc.rock: 0.6944, Acc.wardrobe: 0.8406, Acc.lamp: 0.8954, Acc.bathtub: 0.9337, Acc.railing: 0.7376, Acc.cushion: 0.8937, Acc.base: 0.7434, Acc.box: 0.5870, Acc.column: 0.7360, Acc.signboard: 0.6549, Acc.chest of drawers: 0.6666, Acc.counter: 0.7136, Acc.sand: 0.8923, Acc.sink: 0.8651, Acc.skyscraper: 0.4103, Acc.fireplace: 0.9511, Acc.refrigerator: 0.9531, Acc.grandstand: 0.7723, Acc.path: 0.3113, Acc.stairs: 0.4021, Acc.runway: 0.9502, Acc.case: 0.8900, Acc.pool table: 0.9849, Acc.pillow: 0.8519, Acc.screen door: 0.9452, Acc.stairway: 0.7692, Acc.river: 0.2922, Acc.bridge: 0.9093, Acc.bookcase: 0.6627, Acc.blind: 0.5798, Acc.coffee table: 0.8964, Acc.toilet: 0.9688, Acc.flower: 0.6969, Acc.book: 0.8459, Acc.hill: 0.2223, Acc.bench: 0.8287, Acc.countertop: 0.8253, Acc.stove: 0.8949, Acc.palm: 0.8206, Acc.kitchen island: 0.9055, Acc.computer: 0.8957, Acc.swivel chair: 0.8696, Acc.boat: 0.8733, Acc.bar: 0.7469, Acc.arcade machine: 0.9887, Acc.hovel: 0.7266, Acc.bus: 0.9673, Acc.towel: 0.9147, Acc.light: 0.8004, Acc.truck: 0.7292, Acc.tower: 0.6379, Acc.chandelier: 0.8527, Acc.awning: 0.5240, Acc.streetlight: 0.6872, Acc.booth: 0.7317, Acc.television receiver: 0.8957, Acc.airplane: 0.9589, Acc.dirt track: 0.1176, Acc.apparel: 0.9165, Acc.pole: 0.6050, Acc.land: 0.0043, Acc.bannister: 0.3596, Acc.escalator: 0.8370, Acc.ottoman: 0.8916, Acc.bottle: 0.8259, Acc.buffet: 0.4151, Acc.poster: 0.5398, Acc.stage: 0.6142, Acc.van: 0.7406, Acc.ship: 0.3689, Acc.fountain: 0.4270, Acc.conveyer belt: 0.9737, Acc.canopy: 0.6458, Acc.washer: 0.9375, Acc.plaything: 0.6143, Acc.swimming pool: 0.7382, Acc.stool: 0.8452, Acc.barrel: 0.6721, Acc.basket: 0.7333, Acc.waterfall: 0.5819, Acc.tent: 0.9765, Acc.bag: 0.4893, Acc.minibike: 0.9369, Acc.cradle: 0.9737, Acc.oven: 0.8290, Acc.ball: 0.6375, Acc.food: 0.8301, Acc.step: 0.4030, Acc.tank: 0.5392, Acc.trade name: 0.4951, Acc.microwave: 0.9466, Acc.pot: 0.7437, Acc.animal: 0.8554, Acc.bicycle: 0.8444, Acc.lake: 0.0000, Acc.dishwasher: 0.9060, Acc.screen: 0.9591, Acc.blanket: 0.5391, Acc.sculpture: 0.9119, Acc.hood: 0.7950, Acc.sconce: 0.8151, Acc.vase: 0.8102, Acc.traffic light: 0.7379, Acc.tray: 0.4504, Acc.ashcan: 0.7469, Acc.fan: 0.8733, Acc.pier: 0.4201, Acc.crt screen: 0.1627, Acc.plate: 0.8619, Acc.monitor: 0.0812, Acc.bulletin board: 0.8804, Acc.shower: 0.2846, Acc.radiator: 0.9073, Acc.glass: 0.3244, Acc.clock: 0.7529, Acc.flag: 0.8608
2022-11-30 13:36:11,287 - mmseg - INFO - Iter [14050/40000]	lr: 8.631e-08, eta: 1 day, 7:33:52, time: 8.654, data_time: 4.552, memory: 51902, decode.loss_cls: 0.4262, decode.loss_mask: 0.5808, decode.loss_dice: 0.8420, decode.d0.loss_cls: 7.2057, decode.d0.loss_mask: 0.5566, decode.d0.loss_dice: 0.9055, decode.d1.loss_cls: 0.5453, decode.d1.loss_mask: 0.5998, decode.d1.loss_dice: 0.8994, decode.d2.loss_cls: 0.4834, decode.d2.loss_mask: 0.5888, decode.d2.loss_dice: 0.8647, decode.d3.loss_cls: 0.4524, decode.d3.loss_mask: 0.5861, decode.d3.loss_dice: 0.8546, decode.d4.loss_cls: 0.4395, decode.d4.loss_mask: 0.5844, decode.d4.loss_dice: 0.8555, decode.d5.loss_cls: 0.4317, decode.d5.loss_mask: 0.5818, decode.d5.loss_dice: 0.8485, decode.d6.loss_cls: 0.4275, decode.d6.loss_mask: 0.5814, decode.d6.loss_dice: 0.8461, decode.d7.loss_cls: 0.4254, decode.d7.loss_mask: 0.5814, decode.d7.loss_dice: 0.8475, decode.d8.loss_cls: 0.4230, decode.d8.loss_mask: 0.5802, decode.d8.loss_dice: 0.8443, loss: 25.6893
2022-11-30 13:39:37,277 - mmseg - INFO - Iter [14100/40000]	lr: 8.614e-08, eta: 1 day, 7:29:49, time: 4.120, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4225, decode.loss_mask: 0.5760, decode.loss_dice: 0.8386, decode.d0.loss_cls: 7.1946, decode.d0.loss_mask: 0.5557, decode.d0.loss_dice: 0.9108, decode.d1.loss_cls: 0.5450, decode.d1.loss_mask: 0.6033, decode.d1.loss_dice: 0.8998, decode.d2.loss_cls: 0.4887, decode.d2.loss_mask: 0.5897, decode.d2.loss_dice: 0.8603, decode.d3.loss_cls: 0.4535, decode.d3.loss_mask: 0.5799, decode.d3.loss_dice: 0.8425, decode.d4.loss_cls: 0.4474, decode.d4.loss_mask: 0.5762, decode.d4.loss_dice: 0.8388, decode.d5.loss_cls: 0.4353, decode.d5.loss_mask: 0.5757, decode.d5.loss_dice: 0.8406, decode.d6.loss_cls: 0.4283, decode.d6.loss_mask: 0.5746, decode.d6.loss_dice: 0.8372, decode.d7.loss_cls: 0.4223, decode.d7.loss_mask: 0.5754, decode.d7.loss_dice: 0.8395, decode.d8.loss_cls: 0.4250, decode.d8.loss_mask: 0.5762, decode.d8.loss_dice: 0.8372, loss: 25.5905
2022-11-30 13:43:03,360 - mmseg - INFO - Iter [14150/40000]	lr: 8.597e-08, eta: 1 day, 7:25:47, time: 4.122, data_time: 0.017, memory: 51902, decode.loss_cls: 0.4381, decode.loss_mask: 0.5981, decode.loss_dice: 0.8556, decode.d0.loss_cls: 7.1750, decode.d0.loss_mask: 0.5778, decode.d0.loss_dice: 0.9262, decode.d1.loss_cls: 0.5635, decode.d1.loss_mask: 0.6192, decode.d1.loss_dice: 0.9083, decode.d2.loss_cls: 0.5022, decode.d2.loss_mask: 0.6067, decode.d2.loss_dice: 0.8773, decode.d3.loss_cls: 0.4680, decode.d3.loss_mask: 0.6023, decode.d3.loss_dice: 0.8601, decode.d4.loss_cls: 0.4568, decode.d4.loss_mask: 0.6030, decode.d4.loss_dice: 0.8619, decode.d5.loss_cls: 0.4491, decode.d5.loss_mask: 0.5972, decode.d5.loss_dice: 0.8535, decode.d6.loss_cls: 0.4409, decode.d6.loss_mask: 0.5997, decode.d6.loss_dice: 0.8538, decode.d7.loss_cls: 0.4422, decode.d7.loss_mask: 0.5981, decode.d7.loss_dice: 0.8542, decode.d8.loss_cls: 0.4392, decode.d8.loss_mask: 0.5956, decode.d8.loss_dice: 0.8587, loss: 26.0824
2022-11-30 13:46:29,166 - mmseg - INFO - Iter [14200/40000]	lr: 8.581e-08, eta: 1 day, 7:21:44, time: 4.116, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4154, decode.loss_mask: 0.5774, decode.loss_dice: 0.8342, decode.d0.loss_cls: 7.1772, decode.d0.loss_mask: 0.5519, decode.d0.loss_dice: 0.9032, decode.d1.loss_cls: 0.5423, decode.d1.loss_mask: 0.5943, decode.d1.loss_dice: 0.8952, decode.d2.loss_cls: 0.4755, decode.d2.loss_mask: 0.5815, decode.d2.loss_dice: 0.8549, decode.d3.loss_cls: 0.4366, decode.d3.loss_mask: 0.5799, decode.d3.loss_dice: 0.8381, decode.d4.loss_cls: 0.4273, decode.d4.loss_mask: 0.5765, decode.d4.loss_dice: 0.8388, decode.d5.loss_cls: 0.4217, decode.d5.loss_mask: 0.5743, decode.d5.loss_dice: 0.8326, decode.d6.loss_cls: 0.4167, decode.d6.loss_mask: 0.5759, decode.d6.loss_dice: 0.8315, decode.d7.loss_cls: 0.4145, decode.d7.loss_mask: 0.5757, decode.d7.loss_dice: 0.8328, decode.d8.loss_cls: 0.4149, decode.d8.loss_mask: 0.5765, decode.d8.loss_dice: 0.8332, loss: 25.4004
2022-11-30 13:49:54,828 - mmseg - INFO - Iter [14250/40000]	lr: 8.564e-08, eta: 1 day, 7:17:42, time: 4.113, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4512, decode.loss_mask: 0.5848, decode.loss_dice: 0.8593, decode.d0.loss_cls: 7.1736, decode.d0.loss_mask: 0.5650, decode.d0.loss_dice: 0.9255, decode.d1.loss_cls: 0.5870, decode.d1.loss_mask: 0.6059, decode.d1.loss_dice: 0.9127, decode.d2.loss_cls: 0.5152, decode.d2.loss_mask: 0.5953, decode.d2.loss_dice: 0.8763, decode.d3.loss_cls: 0.4823, decode.d3.loss_mask: 0.5889, decode.d3.loss_dice: 0.8616, decode.d4.loss_cls: 0.4731, decode.d4.loss_mask: 0.5884, decode.d4.loss_dice: 0.8615, decode.d5.loss_cls: 0.4634, decode.d5.loss_mask: 0.5861, decode.d5.loss_dice: 0.8635, decode.d6.loss_cls: 0.4554, decode.d6.loss_mask: 0.5837, decode.d6.loss_dice: 0.8622, decode.d7.loss_cls: 0.4547, decode.d7.loss_mask: 0.5856, decode.d7.loss_dice: 0.8604, decode.d8.loss_cls: 0.4529, decode.d8.loss_mask: 0.5858, decode.d8.loss_dice: 0.8603, loss: 26.1215
2022-11-30 13:53:21,175 - mmseg - INFO - Iter [14300/40000]	lr: 8.547e-08, eta: 1 day, 7:13:41, time: 4.127, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4571, decode.loss_mask: 0.5808, decode.loss_dice: 0.8462, decode.d0.loss_cls: 7.1579, decode.d0.loss_mask: 0.5593, decode.d0.loss_dice: 0.9199, decode.d1.loss_cls: 0.5791, decode.d1.loss_mask: 0.6099, decode.d1.loss_dice: 0.9126, decode.d2.loss_cls: 0.5148, decode.d2.loss_mask: 0.5977, decode.d2.loss_dice: 0.8722, decode.d3.loss_cls: 0.4764, decode.d3.loss_mask: 0.5868, decode.d3.loss_dice: 0.8558, decode.d4.loss_cls: 0.4691, decode.d4.loss_mask: 0.5839, decode.d4.loss_dice: 0.8516, decode.d5.loss_cls: 0.4594, decode.d5.loss_mask: 0.5835, decode.d5.loss_dice: 0.8524, decode.d6.loss_cls: 0.4593, decode.d6.loss_mask: 0.5814, decode.d6.loss_dice: 0.8447, decode.d7.loss_cls: 0.4568, decode.d7.loss_mask: 0.5799, decode.d7.loss_dice: 0.8463, decode.d8.loss_cls: 0.4517, decode.d8.loss_mask: 0.5830, decode.d8.loss_dice: 0.8476, loss: 25.9771
2022-11-30 13:56:46,938 - mmseg - INFO - Iter [14350/40000]	lr: 8.531e-08, eta: 1 day, 7:09:39, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4335, decode.loss_mask: 0.5784, decode.loss_dice: 0.8465, decode.d0.loss_cls: 7.1450, decode.d0.loss_mask: 0.5523, decode.d0.loss_dice: 0.9134, decode.d1.loss_cls: 0.5598, decode.d1.loss_mask: 0.6002, decode.d1.loss_dice: 0.9000, decode.d2.loss_cls: 0.4949, decode.d2.loss_mask: 0.5869, decode.d2.loss_dice: 0.8595, decode.d3.loss_cls: 0.4567, decode.d3.loss_mask: 0.5826, decode.d3.loss_dice: 0.8521, decode.d4.loss_cls: 0.4505, decode.d4.loss_mask: 0.5809, decode.d4.loss_dice: 0.8501, decode.d5.loss_cls: 0.4398, decode.d5.loss_mask: 0.5796, decode.d5.loss_dice: 0.8454, decode.d6.loss_cls: 0.4387, decode.d6.loss_mask: 0.5786, decode.d6.loss_dice: 0.8446, decode.d7.loss_cls: 0.4336, decode.d7.loss_mask: 0.5768, decode.d7.loss_dice: 0.8423, decode.d8.loss_cls: 0.4326, decode.d8.loss_mask: 0.5769, decode.d8.loss_dice: 0.8442, loss: 25.6763
2022-11-30 14:00:12,652 - mmseg - INFO - Iter [14400/40000]	lr: 8.514e-08, eta: 1 day, 7:05:37, time: 4.114, data_time: 0.021, memory: 51902, decode.loss_cls: 0.4374, decode.loss_mask: 0.5864, decode.loss_dice: 0.8542, decode.d0.loss_cls: 7.1359, decode.d0.loss_mask: 0.5595, decode.d0.loss_dice: 0.9184, decode.d1.loss_cls: 0.5592, decode.d1.loss_mask: 0.6127, decode.d1.loss_dice: 0.9143, decode.d2.loss_cls: 0.5013, decode.d2.loss_mask: 0.5992, decode.d2.loss_dice: 0.8798, decode.d3.loss_cls: 0.4660, decode.d3.loss_mask: 0.5929, decode.d3.loss_dice: 0.8620, decode.d4.loss_cls: 0.4534, decode.d4.loss_mask: 0.5926, decode.d4.loss_dice: 0.8605, decode.d5.loss_cls: 0.4452, decode.d5.loss_mask: 0.5896, decode.d5.loss_dice: 0.8594, decode.d6.loss_cls: 0.4382, decode.d6.loss_mask: 0.5879, decode.d6.loss_dice: 0.8537, decode.d7.loss_cls: 0.4358, decode.d7.loss_mask: 0.5879, decode.d7.loss_dice: 0.8547, decode.d8.loss_cls: 0.4362, decode.d8.loss_mask: 0.5887, decode.d8.loss_dice: 0.8559, loss: 25.9189
2022-11-30 14:03:38,561 - mmseg - INFO - Iter [14450/40000]	lr: 8.497e-08, eta: 1 day, 7:01:36, time: 4.118, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4323, decode.loss_mask: 0.5785, decode.loss_dice: 0.8429, decode.d0.loss_cls: 7.1124, decode.d0.loss_mask: 0.5556, decode.d0.loss_dice: 0.9119, decode.d1.loss_cls: 0.5585, decode.d1.loss_mask: 0.5997, decode.d1.loss_dice: 0.9007, decode.d2.loss_cls: 0.4942, decode.d2.loss_mask: 0.5882, decode.d2.loss_dice: 0.8644, decode.d3.loss_cls: 0.4560, decode.d3.loss_mask: 0.5854, decode.d3.loss_dice: 0.8572, decode.d4.loss_cls: 0.4487, decode.d4.loss_mask: 0.5847, decode.d4.loss_dice: 0.8527, decode.d5.loss_cls: 0.4354, decode.d5.loss_mask: 0.5843, decode.d5.loss_dice: 0.8485, decode.d6.loss_cls: 0.4299, decode.d6.loss_mask: 0.5821, decode.d6.loss_dice: 0.8489, decode.d7.loss_cls: 0.4310, decode.d7.loss_mask: 0.5827, decode.d7.loss_dice: 0.8484, decode.d8.loss_cls: 0.4291, decode.d8.loss_mask: 0.5819, decode.d8.loss_dice: 0.8466, loss: 25.6730
2022-11-30 14:07:04,530 - mmseg - INFO - Iter [14500/40000]	lr: 8.481e-08, eta: 1 day, 6:57:35, time: 4.119, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4523, decode.loss_mask: 0.5801, decode.loss_dice: 0.8338, decode.d0.loss_cls: 7.1201, decode.d0.loss_mask: 0.5589, decode.d0.loss_dice: 0.9082, decode.d1.loss_cls: 0.5741, decode.d1.loss_mask: 0.6055, decode.d1.loss_dice: 0.9029, decode.d2.loss_cls: 0.5137, decode.d2.loss_mask: 0.5921, decode.d2.loss_dice: 0.8611, decode.d3.loss_cls: 0.4802, decode.d3.loss_mask: 0.5860, decode.d3.loss_dice: 0.8420, decode.d4.loss_cls: 0.4708, decode.d4.loss_mask: 0.5811, decode.d4.loss_dice: 0.8452, decode.d5.loss_cls: 0.4589, decode.d5.loss_mask: 0.5814, decode.d5.loss_dice: 0.8399, decode.d6.loss_cls: 0.4537, decode.d6.loss_mask: 0.5788, decode.d6.loss_dice: 0.8383, decode.d7.loss_cls: 0.4553, decode.d7.loss_mask: 0.5790, decode.d7.loss_dice: 0.8350, decode.d8.loss_cls: 0.4508, decode.d8.loss_mask: 0.5813, decode.d8.loss_dice: 0.8359, loss: 25.7964
2022-11-30 14:10:32,587 - mmseg - INFO - Iter [14550/40000]	lr: 8.464e-08, eta: 1 day, 6:53:38, time: 4.161, data_time: 0.065, memory: 51902, decode.loss_cls: 0.4264, decode.loss_mask: 0.5879, decode.loss_dice: 0.8611, decode.d0.loss_cls: 7.1234, decode.d0.loss_mask: 0.5637, decode.d0.loss_dice: 0.9267, decode.d1.loss_cls: 0.5594, decode.d1.loss_mask: 0.6059, decode.d1.loss_dice: 0.9180, decode.d2.loss_cls: 0.4937, decode.d2.loss_mask: 0.5956, decode.d2.loss_dice: 0.8791, decode.d3.loss_cls: 0.4617, decode.d3.loss_mask: 0.5916, decode.d3.loss_dice: 0.8648, decode.d4.loss_cls: 0.4512, decode.d4.loss_mask: 0.5900, decode.d4.loss_dice: 0.8633, decode.d5.loss_cls: 0.4393, decode.d5.loss_mask: 0.5868, decode.d5.loss_dice: 0.8635, decode.d6.loss_cls: 0.4343, decode.d6.loss_mask: 0.5874, decode.d6.loss_dice: 0.8615, decode.d7.loss_cls: 0.4304, decode.d7.loss_mask: 0.5884, decode.d7.loss_dice: 0.8618, decode.d8.loss_cls: 0.4290, decode.d8.loss_mask: 0.5883, decode.d8.loss_dice: 0.8597, loss: 25.8942
2022-11-30 14:13:58,133 - mmseg - INFO - Iter [14600/40000]	lr: 8.448e-08, eta: 1 day, 6:49:37, time: 4.111, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4431, decode.loss_mask: 0.5713, decode.loss_dice: 0.8384, decode.d0.loss_cls: 7.0956, decode.d0.loss_mask: 0.5497, decode.d0.loss_dice: 0.9091, decode.d1.loss_cls: 0.5664, decode.d1.loss_mask: 0.5903, decode.d1.loss_dice: 0.8968, decode.d2.loss_cls: 0.5073, decode.d2.loss_mask: 0.5820, decode.d2.loss_dice: 0.8578, decode.d3.loss_cls: 0.4716, decode.d3.loss_mask: 0.5749, decode.d3.loss_dice: 0.8452, decode.d4.loss_cls: 0.4572, decode.d4.loss_mask: 0.5718, decode.d4.loss_dice: 0.8429, decode.d5.loss_cls: 0.4503, decode.d5.loss_mask: 0.5712, decode.d5.loss_dice: 0.8378, decode.d6.loss_cls: 0.4457, decode.d6.loss_mask: 0.5709, decode.d6.loss_dice: 0.8357, decode.d7.loss_cls: 0.4420, decode.d7.loss_mask: 0.5696, decode.d7.loss_dice: 0.8375, decode.d8.loss_cls: 0.4406, decode.d8.loss_mask: 0.5715, decode.d8.loss_dice: 0.8343, loss: 25.5787
2022-11-30 14:17:23,917 - mmseg - INFO - Iter [14650/40000]	lr: 8.431e-08, eta: 1 day, 6:45:37, time: 4.116, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4362, decode.loss_mask: 0.5969, decode.loss_dice: 0.8616, decode.d0.loss_cls: 7.0818, decode.d0.loss_mask: 0.5680, decode.d0.loss_dice: 0.9165, decode.d1.loss_cls: 0.5523, decode.d1.loss_mask: 0.6163, decode.d1.loss_dice: 0.9178, decode.d2.loss_cls: 0.4925, decode.d2.loss_mask: 0.6060, decode.d2.loss_dice: 0.8841, decode.d3.loss_cls: 0.4619, decode.d3.loss_mask: 0.6013, decode.d3.loss_dice: 0.8676, decode.d4.loss_cls: 0.4540, decode.d4.loss_mask: 0.6003, decode.d4.loss_dice: 0.8653, decode.d5.loss_cls: 0.4457, decode.d5.loss_mask: 0.5979, decode.d5.loss_dice: 0.8623, decode.d6.loss_cls: 0.4385, decode.d6.loss_mask: 0.5975, decode.d6.loss_dice: 0.8633, decode.d7.loss_cls: 0.4391, decode.d7.loss_mask: 0.5971, decode.d7.loss_dice: 0.8581, decode.d8.loss_cls: 0.4376, decode.d8.loss_mask: 0.5972, decode.d8.loss_dice: 0.8624, loss: 25.9772
2022-11-30 14:20:49,925 - mmseg - INFO - Iter [14700/40000]	lr: 8.414e-08, eta: 1 day, 6:41:37, time: 4.120, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4117, decode.loss_mask: 0.5901, decode.loss_dice: 0.8486, decode.d0.loss_cls: 7.0680, decode.d0.loss_mask: 0.5658, decode.d0.loss_dice: 0.9084, decode.d1.loss_cls: 0.5321, decode.d1.loss_mask: 0.6101, decode.d1.loss_dice: 0.9080, decode.d2.loss_cls: 0.4696, decode.d2.loss_mask: 0.5984, decode.d2.loss_dice: 0.8687, decode.d3.loss_cls: 0.4344, decode.d3.loss_mask: 0.5934, decode.d3.loss_dice: 0.8554, decode.d4.loss_cls: 0.4281, decode.d4.loss_mask: 0.5925, decode.d4.loss_dice: 0.8530, decode.d5.loss_cls: 0.4172, decode.d5.loss_mask: 0.5907, decode.d5.loss_dice: 0.8538, decode.d6.loss_cls: 0.4181, decode.d6.loss_mask: 0.5886, decode.d6.loss_dice: 0.8507, decode.d7.loss_cls: 0.4147, decode.d7.loss_mask: 0.5886, decode.d7.loss_dice: 0.8487, decode.d8.loss_cls: 0.4142, decode.d8.loss_mask: 0.5875, decode.d8.loss_dice: 0.8441, loss: 25.5534
2022-11-30 14:24:15,230 - mmseg - INFO - Iter [14750/40000]	lr: 8.398e-08, eta: 1 day, 6:37:36, time: 4.106, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4237, decode.loss_mask: 0.5716, decode.loss_dice: 0.8431, decode.d0.loss_cls: 7.0755, decode.d0.loss_mask: 0.5536, decode.d0.loss_dice: 0.9160, decode.d1.loss_cls: 0.5454, decode.d1.loss_mask: 0.5971, decode.d1.loss_dice: 0.9009, decode.d2.loss_cls: 0.4796, decode.d2.loss_mask: 0.5844, decode.d2.loss_dice: 0.8695, decode.d3.loss_cls: 0.4431, decode.d3.loss_mask: 0.5773, decode.d3.loss_dice: 0.8556, decode.d4.loss_cls: 0.4397, decode.d4.loss_mask: 0.5740, decode.d4.loss_dice: 0.8486, decode.d5.loss_cls: 0.4315, decode.d5.loss_mask: 0.5749, decode.d5.loss_dice: 0.8487, decode.d6.loss_cls: 0.4259, decode.d6.loss_mask: 0.5734, decode.d6.loss_dice: 0.8446, decode.d7.loss_cls: 0.4211, decode.d7.loss_mask: 0.5731, decode.d7.loss_dice: 0.8455, decode.d8.loss_cls: 0.4200, decode.d8.loss_mask: 0.5722, decode.d8.loss_dice: 0.8449, loss: 25.4744
2022-11-30 14:27:41,164 - mmseg - INFO - Iter [14800/40000]	lr: 8.381e-08, eta: 1 day, 6:33:37, time: 4.119, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4253, decode.loss_mask: 0.5709, decode.loss_dice: 0.8450, decode.d0.loss_cls: 7.0858, decode.d0.loss_mask: 0.5488, decode.d0.loss_dice: 0.9222, decode.d1.loss_cls: 0.5472, decode.d1.loss_mask: 0.5972, decode.d1.loss_dice: 0.9117, decode.d2.loss_cls: 0.4839, decode.d2.loss_mask: 0.5851, decode.d2.loss_dice: 0.8799, decode.d3.loss_cls: 0.4485, decode.d3.loss_mask: 0.5795, decode.d3.loss_dice: 0.8623, decode.d4.loss_cls: 0.4438, decode.d4.loss_mask: 0.5739, decode.d4.loss_dice: 0.8566, decode.d5.loss_cls: 0.4341, decode.d5.loss_mask: 0.5728, decode.d5.loss_dice: 0.8513, decode.d6.loss_cls: 0.4306, decode.d6.loss_mask: 0.5718, decode.d6.loss_dice: 0.8489, decode.d7.loss_cls: 0.4276, decode.d7.loss_mask: 0.5728, decode.d7.loss_dice: 0.8512, decode.d8.loss_cls: 0.4278, decode.d8.loss_mask: 0.5702, decode.d8.loss_dice: 0.8519, loss: 25.5788
2022-11-30 14:31:07,169 - mmseg - INFO - Iter [14850/40000]	lr: 8.364e-08, eta: 1 day, 6:29:38, time: 4.120, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4381, decode.loss_mask: 0.5861, decode.loss_dice: 0.8618, decode.d0.loss_cls: 7.0462, decode.d0.loss_mask: 0.5644, decode.d0.loss_dice: 0.9365, decode.d1.loss_cls: 0.5664, decode.d1.loss_mask: 0.6111, decode.d1.loss_dice: 0.9240, decode.d2.loss_cls: 0.4976, decode.d2.loss_mask: 0.5963, decode.d2.loss_dice: 0.8901, decode.d3.loss_cls: 0.4613, decode.d3.loss_mask: 0.5914, decode.d3.loss_dice: 0.8674, decode.d4.loss_cls: 0.4538, decode.d4.loss_mask: 0.5874, decode.d4.loss_dice: 0.8692, decode.d5.loss_cls: 0.4456, decode.d5.loss_mask: 0.5863, decode.d5.loss_dice: 0.8659, decode.d6.loss_cls: 0.4431, decode.d6.loss_mask: 0.5856, decode.d6.loss_dice: 0.8594, decode.d7.loss_cls: 0.4406, decode.d7.loss_mask: 0.5865, decode.d7.loss_dice: 0.8603, decode.d8.loss_cls: 0.4383, decode.d8.loss_mask: 0.5865, decode.d8.loss_dice: 0.8619, loss: 25.9093
2022-11-30 14:34:33,097 - mmseg - INFO - Iter [14900/40000]	lr: 8.348e-08, eta: 1 day, 6:25:39, time: 4.119, data_time: 0.021, memory: 51902, decode.loss_cls: 0.4474, decode.loss_mask: 0.5696, decode.loss_dice: 0.8503, decode.d0.loss_cls: 7.0582, decode.d0.loss_mask: 0.5483, decode.d0.loss_dice: 0.9208, decode.d1.loss_cls: 0.5733, decode.d1.loss_mask: 0.5894, decode.d1.loss_dice: 0.9068, decode.d2.loss_cls: 0.5154, decode.d2.loss_mask: 0.5797, decode.d2.loss_dice: 0.8714, decode.d3.loss_cls: 0.4758, decode.d3.loss_mask: 0.5749, decode.d3.loss_dice: 0.8547, decode.d4.loss_cls: 0.4651, decode.d4.loss_mask: 0.5747, decode.d4.loss_dice: 0.8572, decode.d5.loss_cls: 0.4574, decode.d5.loss_mask: 0.5703, decode.d5.loss_dice: 0.8520, decode.d6.loss_cls: 0.4497, decode.d6.loss_mask: 0.5687, decode.d6.loss_dice: 0.8487, decode.d7.loss_cls: 0.4516, decode.d7.loss_mask: 0.5698, decode.d7.loss_dice: 0.8476, decode.d8.loss_cls: 0.4463, decode.d8.loss_mask: 0.5698, decode.d8.loss_dice: 0.8504, loss: 25.7152
2022-11-30 14:37:58,885 - mmseg - INFO - Iter [14950/40000]	lr: 8.331e-08, eta: 1 day, 6:21:40, time: 4.116, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4349, decode.loss_mask: 0.5976, decode.loss_dice: 0.8610, decode.d0.loss_cls: 7.0403, decode.d0.loss_mask: 0.5772, decode.d0.loss_dice: 0.9297, decode.d1.loss_cls: 0.5552, decode.d1.loss_mask: 0.6244, decode.d1.loss_dice: 0.9206, decode.d2.loss_cls: 0.4932, decode.d2.loss_mask: 0.6106, decode.d2.loss_dice: 0.8855, decode.d3.loss_cls: 0.4565, decode.d3.loss_mask: 0.6035, decode.d3.loss_dice: 0.8772, decode.d4.loss_cls: 0.4495, decode.d4.loss_mask: 0.5997, decode.d4.loss_dice: 0.8704, decode.d5.loss_cls: 0.4418, decode.d5.loss_mask: 0.5987, decode.d5.loss_dice: 0.8646, decode.d6.loss_cls: 0.4350, decode.d6.loss_mask: 0.5972, decode.d6.loss_dice: 0.8656, decode.d7.loss_cls: 0.4314, decode.d7.loss_mask: 0.5985, decode.d7.loss_dice: 0.8679, decode.d8.loss_cls: 0.4337, decode.d8.loss_mask: 0.5973, decode.d8.loss_dice: 0.8653, loss: 25.9844
2022-11-30 14:41:24,842 - mmseg - INFO - Saving checkpoint at 15000 iterations
2022-11-30 14:42:13,801 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 14:42:13,801 - mmseg - INFO - Iter [15000/40000]	lr: 8.315e-08, eta: 1 day, 6:19:03, time: 5.098, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4229, decode.loss_mask: 0.5776, decode.loss_dice: 0.8356, decode.d0.loss_cls: 7.0094, decode.d0.loss_mask: 0.5526, decode.d0.loss_dice: 0.9067, decode.d1.loss_cls: 0.5345, decode.d1.loss_mask: 0.6018, decode.d1.loss_dice: 0.8962, decode.d2.loss_cls: 0.4803, decode.d2.loss_mask: 0.5881, decode.d2.loss_dice: 0.8566, decode.d3.loss_cls: 0.4491, decode.d3.loss_mask: 0.5807, decode.d3.loss_dice: 0.8413, decode.d4.loss_cls: 0.4355, decode.d4.loss_mask: 0.5787, decode.d4.loss_dice: 0.8431, decode.d5.loss_cls: 0.4274, decode.d5.loss_mask: 0.5782, decode.d5.loss_dice: 0.8396, decode.d6.loss_cls: 0.4221, decode.d6.loss_mask: 0.5777, decode.d6.loss_dice: 0.8374, decode.d7.loss_cls: 0.4253, decode.d7.loss_mask: 0.5780, decode.d7.loss_dice: 0.8372, decode.d8.loss_cls: 0.4230, decode.d8.loss_mask: 0.5781, decode.d8.loss_dice: 0.8374, loss: 25.3522
2022-11-30 14:45:11,835 - mmseg - INFO - per class results:
2022-11-30 14:45:11,840 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 83.07 | 89.68 |
|       building      |  84.8 | 91.22 |
|         sky         |  95.1 | 97.08 |
|        floor        | 84.72 |  89.6 |
|         tree        | 79.11 | 90.17 |
|       ceiling       | 87.77 | 93.41 |
|         road        | 87.66 | 91.21 |
|         bed         | 93.32 | 96.77 |
|      windowpane     | 66.42 | 79.88 |
|        grass        | 72.61 | 86.58 |
|       cabinet       | 63.68 | 74.92 |
|       sidewalk      | 72.67 |  87.9 |
|        person       | 88.53 | 94.34 |
|        earth        | 45.17 | 61.77 |
|         door        | 62.42 | 84.05 |
|        table        | 73.54 | 83.26 |
|       mountain      | 58.02 | 69.19 |
|        plant        | 56.54 | 72.42 |
|       curtain       | 82.13 | 92.27 |
|        chair        | 69.89 | 78.82 |
|         car         | 89.22 | 95.45 |
|        water        | 60.66 | 80.56 |
|       painting      | 82.82 | 92.32 |
|         sofa        | 86.39 | 91.93 |
|        shelf        | 48.84 | 59.87 |
|        house        |  50.3 |  74.0 |
|         sea         | 68.05 | 83.84 |
|        mirror       | 81.88 | 92.87 |
|         rug         | 73.39 | 89.22 |
|        field        | 36.64 | 52.85 |
|       armchair      | 65.11 | 82.94 |
|         seat        | 66.81 | 87.44 |
|        fence        | 55.98 | 77.94 |
|         desk        | 61.69 | 82.94 |
|         rock        | 62.41 | 77.01 |
|       wardrobe      | 52.81 | 75.88 |
|         lamp        | 80.68 | 90.96 |
|       bathtub       | 91.56 | 93.46 |
|       railing       | 47.55 |  67.2 |
|       cushion       | 77.89 | 88.53 |
|         base        | 44.22 | 71.44 |
|         box         | 40.68 | 58.91 |
|        column       | 57.59 | 77.39 |
|      signboard      | 46.13 | 68.29 |
|   chest of drawers  | 44.28 | 67.97 |
|       counter       |  54.0 |  72.2 |
|         sand        |  61.8 | 87.83 |
|         sink        |  82.5 | 86.59 |
|      skyscraper     | 36.44 | 45.16 |
|      fireplace      | 81.44 | 95.63 |
|     refrigerator    | 83.18 | 95.28 |
|      grandstand     | 45.24 | 82.37 |
|         path        | 30.29 | 38.15 |
|        stairs       | 40.47 | 53.84 |
|        runway       | 74.36 | 95.03 |
|         case        | 69.45 | 86.36 |
|      pool table     | 95.49 | 98.18 |
|        pillow       | 73.92 | 85.91 |
|     screen door     | 84.15 | 92.11 |
|       stairway      | 60.04 | 72.62 |
|        river        | 23.05 | 27.05 |
|        bridge       | 77.36 | 90.89 |
|       bookcase      | 35.39 | 53.11 |
|        blind        | 42.87 | 51.73 |
|     coffee table    | 73.27 | 90.87 |
|        toilet       | 93.33 | 96.75 |
|        flower       |  46.5 | 67.15 |
|         book        | 60.15 | 85.36 |
|         hill        |  8.37 | 14.59 |
|        bench        | 73.75 | 82.63 |
|      countertop     | 70.72 |  86.2 |
|        stove        | 85.41 | 89.57 |
|         palm        | 57.07 | 84.07 |
|    kitchen island   | 39.36 | 72.15 |
|       computer      | 81.15 | 89.99 |
|     swivel chair    | 58.15 | 83.21 |
|         boat        | 54.97 | 87.51 |
|         bar         | 63.84 | 68.74 |
|    arcade machine   | 90.37 | 98.64 |
|        hovel        | 43.74 | 60.71 |
|         bus         | 93.58 | 95.79 |
|        towel        | 76.59 | 95.37 |
|        light        | 67.32 | 81.22 |
|        truck        | 53.78 | 74.06 |
|        tower        | 34.82 | 62.98 |
|      chandelier     | 77.51 |  87.6 |
|        awning       | 32.53 |  53.1 |
|     streetlight     | 45.06 | 65.76 |
|        booth        | 55.47 | 66.68 |
| television receiver |  75.5 | 92.06 |
|       airplane      | 88.74 | 96.17 |
|      dirt track     |  9.51 | 12.89 |
|       apparel       |  55.4 | 94.01 |
|         pole        | 42.01 | 59.56 |
|         land        |  1.39 |  1.9  |
|      bannister      | 22.82 |  29.9 |
|      escalator      | 64.47 | 84.84 |
|       ottoman       | 64.54 |  86.9 |
|        bottle       | 53.61 | 80.54 |
|        buffet       | 37.58 | 47.82 |
|        poster       | 37.24 | 60.02 |
|        stage        | 30.68 | 68.66 |
|         van         | 49.11 |  61.2 |
|         ship        | 36.17 |  37.8 |
|       fountain      | 40.42 | 44.27 |
|    conveyer belt    | 81.39 | 97.82 |
|        canopy       | 43.53 |  60.9 |
|        washer       | 90.99 | 93.46 |
|      plaything      | 38.69 | 58.22 |
|    swimming pool    |  51.0 | 75.16 |
|        stool        | 64.61 | 84.28 |
|        barrel       | 75.23 | 83.17 |
|        basket       | 48.81 | 77.24 |
|      waterfall      | 52.95 | 57.44 |
|         tent        | 96.21 | 98.01 |
|         bag         | 35.02 | 45.97 |
|       minibike      | 80.54 | 93.85 |
|        cradle       | 91.06 | 96.73 |
|         oven        | 65.61 | 82.25 |
|         ball        |  47.3 | 52.92 |
|         food        | 63.21 | 72.26 |
|         step        | 21.88 | 36.29 |
|         tank        | 51.98 | 53.45 |
|      trade name     | 32.91 | 39.56 |
|      microwave      | 90.52 |  96.4 |
|         pot         | 61.44 | 75.51 |
|        animal       | 80.01 | 81.79 |
|       bicycle       | 62.41 | 83.62 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 79.75 | 90.41 |
|        screen       |  61.2 | 96.06 |
|       blanket       | 33.63 | 46.13 |
|      sculpture      | 76.38 | 89.98 |
|         hood        | 66.36 | 74.71 |
|        sconce       | 66.35 | 81.78 |
|         vase        | 56.85 | 82.17 |
|    traffic light    | 52.59 |  72.0 |
|         tray        | 29.66 | 44.18 |
|        ashcan       | 49.64 | 73.11 |
|         fan         | 74.12 | 86.41 |
|         pier        |  38.5 | 44.47 |
|      crt screen     |  1.53 |  3.81 |
|        plate        | 69.14 | 86.67 |
|       monitor       |  4.44 |  6.14 |
|    bulletin board   | 68.37 | 82.28 |
|        shower       | 23.88 | 29.26 |
|       radiator      | 72.55 | 93.37 |
|        glass        | 28.06 | 31.13 |
|        clock        | 61.48 | 74.29 |
|         flag        | 71.12 | 87.68 |
+---------------------+-------+-------+
2022-11-30 14:45:11,840 - mmseg - INFO - Summary:
2022-11-30 14:45:11,840 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 86.81 | 59.94 | 73.78 |
+-------+-------+-------+
2022-11-30 14:45:11,844 - mmseg - INFO - The previous best checkpoint /mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune/lr1.0_lrd0.9/best_mIoU_iter_14000.pth was removed
2022-11-30 14:46:01,399 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_15000.pth.
2022-11-30 14:46:01,399 - mmseg - INFO - Best mIoU is 0.5994 at 15000 iter.
2022-11-30 14:46:01,407 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 14:46:01,407 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8681, mIoU: 0.5994, mAcc: 0.7378, IoU.wall: 0.8307, IoU.building: 0.8480, IoU.sky: 0.9510, IoU.floor: 0.8472, IoU.tree: 0.7911, IoU.ceiling: 0.8777, IoU.road: 0.8766, IoU.bed : 0.9332, IoU.windowpane: 0.6642, IoU.grass: 0.7261, IoU.cabinet: 0.6368, IoU.sidewalk: 0.7267, IoU.person: 0.8853, IoU.earth: 0.4517, IoU.door: 0.6242, IoU.table: 0.7354, IoU.mountain: 0.5802, IoU.plant: 0.5654, IoU.curtain: 0.8213, IoU.chair: 0.6989, IoU.car: 0.8922, IoU.water: 0.6066, IoU.painting: 0.8282, IoU.sofa: 0.8639, IoU.shelf: 0.4884, IoU.house: 0.5030, IoU.sea: 0.6805, IoU.mirror: 0.8188, IoU.rug: 0.7339, IoU.field: 0.3664, IoU.armchair: 0.6511, IoU.seat: 0.6681, IoU.fence: 0.5598, IoU.desk: 0.6169, IoU.rock: 0.6241, IoU.wardrobe: 0.5281, IoU.lamp: 0.8068, IoU.bathtub: 0.9156, IoU.railing: 0.4755, IoU.cushion: 0.7789, IoU.base: 0.4422, IoU.box: 0.4068, IoU.column: 0.5759, IoU.signboard: 0.4613, IoU.chest of drawers: 0.4428, IoU.counter: 0.5400, IoU.sand: 0.6180, IoU.sink: 0.8250, IoU.skyscraper: 0.3644, IoU.fireplace: 0.8144, IoU.refrigerator: 0.8318, IoU.grandstand: 0.4524, IoU.path: 0.3029, IoU.stairs: 0.4047, IoU.runway: 0.7436, IoU.case: 0.6945, IoU.pool table: 0.9549, IoU.pillow: 0.7392, IoU.screen door: 0.8415, IoU.stairway: 0.6004, IoU.river: 0.2305, IoU.bridge: 0.7736, IoU.bookcase: 0.3539, IoU.blind: 0.4287, IoU.coffee table: 0.7327, IoU.toilet: 0.9333, IoU.flower: 0.4650, IoU.book: 0.6015, IoU.hill: 0.0837, IoU.bench: 0.7375, IoU.countertop: 0.7072, IoU.stove: 0.8541, IoU.palm: 0.5707, IoU.kitchen island: 0.3936, IoU.computer: 0.8115, IoU.swivel chair: 0.5815, IoU.boat: 0.5497, IoU.bar: 0.6384, IoU.arcade machine: 0.9037, IoU.hovel: 0.4374, IoU.bus: 0.9358, IoU.towel: 0.7659, IoU.light: 0.6732, IoU.truck: 0.5378, IoU.tower: 0.3482, IoU.chandelier: 0.7751, IoU.awning: 0.3253, IoU.streetlight: 0.4506, IoU.booth: 0.5547, IoU.television receiver: 0.7550, IoU.airplane: 0.8874, IoU.dirt track: 0.0951, IoU.apparel: 0.5540, IoU.pole: 0.4201, IoU.land: 0.0139, IoU.bannister: 0.2282, IoU.escalator: 0.6447, IoU.ottoman: 0.6454, IoU.bottle: 0.5361, IoU.buffet: 0.3758, IoU.poster: 0.3724, IoU.stage: 0.3068, IoU.van: 0.4911, IoU.ship: 0.3617, IoU.fountain: 0.4042, IoU.conveyer belt: 0.8139, IoU.canopy: 0.4353, IoU.washer: 0.9099, IoU.plaything: 0.3869, IoU.swimming pool: 0.5100, IoU.stool: 0.6461, IoU.barrel: 0.7523, IoU.basket: 0.4881, IoU.waterfall: 0.5295, IoU.tent: 0.9621, IoU.bag: 0.3502, IoU.minibike: 0.8054, IoU.cradle: 0.9106, IoU.oven: 0.6561, IoU.ball: 0.4730, IoU.food: 0.6321, IoU.step: 0.2188, IoU.tank: 0.5198, IoU.trade name: 0.3291, IoU.microwave: 0.9052, IoU.pot: 0.6144, IoU.animal: 0.8001, IoU.bicycle: 0.6241, IoU.lake: 0.0000, IoU.dishwasher: 0.7975, IoU.screen: 0.6120, IoU.blanket: 0.3363, IoU.sculpture: 0.7638, IoU.hood: 0.6636, IoU.sconce: 0.6635, IoU.vase: 0.5685, IoU.traffic light: 0.5259, IoU.tray: 0.2966, IoU.ashcan: 0.4964, IoU.fan: 0.7412, IoU.pier: 0.3850, IoU.crt screen: 0.0153, IoU.plate: 0.6914, IoU.monitor: 0.0444, IoU.bulletin board: 0.6837, IoU.shower: 0.2388, IoU.radiator: 0.7255, IoU.glass: 0.2806, IoU.clock: 0.6148, IoU.flag: 0.7112, Acc.wall: 0.8968, Acc.building: 0.9122, Acc.sky: 0.9708, Acc.floor: 0.8960, Acc.tree: 0.9017, Acc.ceiling: 0.9341, Acc.road: 0.9121, Acc.bed : 0.9677, Acc.windowpane: 0.7988, Acc.grass: 0.8658, Acc.cabinet: 0.7492, Acc.sidewalk: 0.8790, Acc.person: 0.9434, Acc.earth: 0.6177, Acc.door: 0.8405, Acc.table: 0.8326, Acc.mountain: 0.6919, Acc.plant: 0.7242, Acc.curtain: 0.9227, Acc.chair: 0.7882, Acc.car: 0.9545, Acc.water: 0.8056, Acc.painting: 0.9232, Acc.sofa: 0.9193, Acc.shelf: 0.5987, Acc.house: 0.7400, Acc.sea: 0.8384, Acc.mirror: 0.9287, Acc.rug: 0.8922, Acc.field: 0.5285, Acc.armchair: 0.8294, Acc.seat: 0.8744, Acc.fence: 0.7794, Acc.desk: 0.8294, Acc.rock: 0.7701, Acc.wardrobe: 0.7588, Acc.lamp: 0.9096, Acc.bathtub: 0.9346, Acc.railing: 0.6720, Acc.cushion: 0.8853, Acc.base: 0.7144, Acc.box: 0.5891, Acc.column: 0.7739, Acc.signboard: 0.6829, Acc.chest of drawers: 0.6797, Acc.counter: 0.7220, Acc.sand: 0.8783, Acc.sink: 0.8659, Acc.skyscraper: 0.4516, Acc.fireplace: 0.9563, Acc.refrigerator: 0.9528, Acc.grandstand: 0.8237, Acc.path: 0.3815, Acc.stairs: 0.5384, Acc.runway: 0.9503, Acc.case: 0.8636, Acc.pool table: 0.9818, Acc.pillow: 0.8591, Acc.screen door: 0.9211, Acc.stairway: 0.7262, Acc.river: 0.2705, Acc.bridge: 0.9089, Acc.bookcase: 0.5311, Acc.blind: 0.5173, Acc.coffee table: 0.9087, Acc.toilet: 0.9675, Acc.flower: 0.6715, Acc.book: 0.8536, Acc.hill: 0.1459, Acc.bench: 0.8263, Acc.countertop: 0.8620, Acc.stove: 0.8957, Acc.palm: 0.8407, Acc.kitchen island: 0.7215, Acc.computer: 0.8999, Acc.swivel chair: 0.8321, Acc.boat: 0.8751, Acc.bar: 0.6874, Acc.arcade machine: 0.9864, Acc.hovel: 0.6071, Acc.bus: 0.9579, Acc.towel: 0.9537, Acc.light: 0.8122, Acc.truck: 0.7406, Acc.tower: 0.6298, Acc.chandelier: 0.8760, Acc.awning: 0.5310, Acc.streetlight: 0.6576, Acc.booth: 0.6668, Acc.television receiver: 0.9206, Acc.airplane: 0.9617, Acc.dirt track: 0.1289, Acc.apparel: 0.9401, Acc.pole: 0.5956, Acc.land: 0.0190, Acc.bannister: 0.2990, Acc.escalator: 0.8484, Acc.ottoman: 0.8690, Acc.bottle: 0.8054, Acc.buffet: 0.4782, Acc.poster: 0.6002, Acc.stage: 0.6866, Acc.van: 0.6120, Acc.ship: 0.3780, Acc.fountain: 0.4427, Acc.conveyer belt: 0.9782, Acc.canopy: 0.6090, Acc.washer: 0.9346, Acc.plaything: 0.5822, Acc.swimming pool: 0.7516, Acc.stool: 0.8428, Acc.barrel: 0.8317, Acc.basket: 0.7724, Acc.waterfall: 0.5744, Acc.tent: 0.9801, Acc.bag: 0.4597, Acc.minibike: 0.9385, Acc.cradle: 0.9673, Acc.oven: 0.8225, Acc.ball: 0.5292, Acc.food: 0.7226, Acc.step: 0.3629, Acc.tank: 0.5345, Acc.trade name: 0.3956, Acc.microwave: 0.9640, Acc.pot: 0.7551, Acc.animal: 0.8179, Acc.bicycle: 0.8362, Acc.lake: 0.0000, Acc.dishwasher: 0.9041, Acc.screen: 0.9606, Acc.blanket: 0.4613, Acc.sculpture: 0.8998, Acc.hood: 0.7471, Acc.sconce: 0.8178, Acc.vase: 0.8217, Acc.traffic light: 0.7200, Acc.tray: 0.4418, Acc.ashcan: 0.7311, Acc.fan: 0.8641, Acc.pier: 0.4447, Acc.crt screen: 0.0381, Acc.plate: 0.8667, Acc.monitor: 0.0614, Acc.bulletin board: 0.8228, Acc.shower: 0.2926, Acc.radiator: 0.9337, Acc.glass: 0.3113, Acc.clock: 0.7429, Acc.flag: 0.8768
2022-11-30 14:49:27,770 - mmseg - INFO - Iter [15050/40000]	lr: 8.298e-08, eta: 1 day, 6:21:22, time: 8.679, data_time: 4.571, memory: 51902, decode.loss_cls: 0.4486, decode.loss_mask: 0.5606, decode.loss_dice: 0.8554, decode.d0.loss_cls: 7.0426, decode.d0.loss_mask: 0.5382, decode.d0.loss_dice: 0.9279, decode.d1.loss_cls: 0.5692, decode.d1.loss_mask: 0.5806, decode.d1.loss_dice: 0.9142, decode.d2.loss_cls: 0.5062, decode.d2.loss_mask: 0.5711, decode.d2.loss_dice: 0.8771, decode.d3.loss_cls: 0.4706, decode.d3.loss_mask: 0.5668, decode.d3.loss_dice: 0.8637, decode.d4.loss_cls: 0.4609, decode.d4.loss_mask: 0.5643, decode.d4.loss_dice: 0.8597, decode.d5.loss_cls: 0.4524, decode.d5.loss_mask: 0.5620, decode.d5.loss_dice: 0.8582, decode.d6.loss_cls: 0.4509, decode.d6.loss_mask: 0.5609, decode.d6.loss_dice: 0.8549, decode.d7.loss_cls: 0.4500, decode.d7.loss_mask: 0.5601, decode.d7.loss_dice: 0.8551, decode.d8.loss_cls: 0.4472, decode.d8.loss_mask: 0.5613, decode.d8.loss_dice: 0.8550, loss: 25.6456
2022-11-30 14:52:53,730 - mmseg - INFO - Iter [15100/40000]	lr: 8.281e-08, eta: 1 day, 6:17:22, time: 4.119, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4440, decode.loss_mask: 0.5910, decode.loss_dice: 0.8537, decode.d0.loss_cls: 7.0104, decode.d0.loss_mask: 0.5655, decode.d0.loss_dice: 0.9279, decode.d1.loss_cls: 0.5696, decode.d1.loss_mask: 0.6190, decode.d1.loss_dice: 0.9227, decode.d2.loss_cls: 0.5072, decode.d2.loss_mask: 0.6040, decode.d2.loss_dice: 0.8808, decode.d3.loss_cls: 0.4677, decode.d3.loss_mask: 0.5997, decode.d3.loss_dice: 0.8645, decode.d4.loss_cls: 0.4597, decode.d4.loss_mask: 0.5960, decode.d4.loss_dice: 0.8657, decode.d5.loss_cls: 0.4475, decode.d5.loss_mask: 0.5938, decode.d5.loss_dice: 0.8591, decode.d6.loss_cls: 0.4432, decode.d6.loss_mask: 0.5928, decode.d6.loss_dice: 0.8560, decode.d7.loss_cls: 0.4397, decode.d7.loss_mask: 0.5921, decode.d7.loss_dice: 0.8561, decode.d8.loss_cls: 0.4415, decode.d8.loss_mask: 0.5927, decode.d8.loss_dice: 0.8549, loss: 25.9186
2022-11-30 14:56:19,494 - mmseg - INFO - Iter [15150/40000]	lr: 8.265e-08, eta: 1 day, 6:13:21, time: 4.115, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4315, decode.loss_mask: 0.5810, decode.loss_dice: 0.8494, decode.d0.loss_cls: 6.9987, decode.d0.loss_mask: 0.5571, decode.d0.loss_dice: 0.9139, decode.d1.loss_cls: 0.5552, decode.d1.loss_mask: 0.6008, decode.d1.loss_dice: 0.9085, decode.d2.loss_cls: 0.4954, decode.d2.loss_mask: 0.5891, decode.d2.loss_dice: 0.8711, decode.d3.loss_cls: 0.4559, decode.d3.loss_mask: 0.5845, decode.d3.loss_dice: 0.8603, decode.d4.loss_cls: 0.4479, decode.d4.loss_mask: 0.5814, decode.d4.loss_dice: 0.8549, decode.d5.loss_cls: 0.4378, decode.d5.loss_mask: 0.5791, decode.d5.loss_dice: 0.8514, decode.d6.loss_cls: 0.4349, decode.d6.loss_mask: 0.5781, decode.d6.loss_dice: 0.8494, decode.d7.loss_cls: 0.4346, decode.d7.loss_mask: 0.5787, decode.d7.loss_dice: 0.8530, decode.d8.loss_cls: 0.4305, decode.d8.loss_mask: 0.5810, decode.d8.loss_dice: 0.8490, loss: 25.5941
2022-11-30 14:59:47,448 - mmseg - INFO - Iter [15200/40000]	lr: 8.248e-08, eta: 1 day, 6:09:24, time: 4.159, data_time: 0.064, memory: 51902, decode.loss_cls: 0.4110, decode.loss_mask: 0.5940, decode.loss_dice: 0.8290, decode.d0.loss_cls: 6.9842, decode.d0.loss_mask: 0.5697, decode.d0.loss_dice: 0.8977, decode.d1.loss_cls: 0.5273, decode.d1.loss_mask: 0.6191, decode.d1.loss_dice: 0.8963, decode.d2.loss_cls: 0.4698, decode.d2.loss_mask: 0.6056, decode.d2.loss_dice: 0.8581, decode.d3.loss_cls: 0.4328, decode.d3.loss_mask: 0.5987, decode.d3.loss_dice: 0.8408, decode.d4.loss_cls: 0.4184, decode.d4.loss_mask: 0.5994, decode.d4.loss_dice: 0.8398, decode.d5.loss_cls: 0.4161, decode.d5.loss_mask: 0.5983, decode.d5.loss_dice: 0.8319, decode.d6.loss_cls: 0.4095, decode.d6.loss_mask: 0.5950, decode.d6.loss_dice: 0.8293, decode.d7.loss_cls: 0.4070, decode.d7.loss_mask: 0.5956, decode.d7.loss_dice: 0.8341, decode.d8.loss_cls: 0.4072, decode.d8.loss_mask: 0.5965, decode.d8.loss_dice: 0.8351, loss: 25.3475
2022-11-30 15:03:13,470 - mmseg - INFO - Iter [15250/40000]	lr: 8.231e-08, eta: 1 day, 6:05:24, time: 4.120, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4316, decode.loss_mask: 0.5749, decode.loss_dice: 0.8583, decode.d0.loss_cls: 6.9764, decode.d0.loss_mask: 0.5505, decode.d0.loss_dice: 0.9152, decode.d1.loss_cls: 0.5668, decode.d1.loss_mask: 0.6002, decode.d1.loss_dice: 0.9164, decode.d2.loss_cls: 0.4923, decode.d2.loss_mask: 0.5894, decode.d2.loss_dice: 0.8795, decode.d3.loss_cls: 0.4615, decode.d3.loss_mask: 0.5797, decode.d3.loss_dice: 0.8648, decode.d4.loss_cls: 0.4531, decode.d4.loss_mask: 0.5766, decode.d4.loss_dice: 0.8635, decode.d5.loss_cls: 0.4382, decode.d5.loss_mask: 0.5746, decode.d5.loss_dice: 0.8575, decode.d6.loss_cls: 0.4326, decode.d6.loss_mask: 0.5765, decode.d6.loss_dice: 0.8568, decode.d7.loss_cls: 0.4287, decode.d7.loss_mask: 0.5763, decode.d7.loss_dice: 0.8577, decode.d8.loss_cls: 0.4294, decode.d8.loss_mask: 0.5764, decode.d8.loss_dice: 0.8580, loss: 25.6132
2022-11-30 15:06:39,050 - mmseg - INFO - Iter [15300/40000]	lr: 8.215e-08, eta: 1 day, 6:01:24, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4261, decode.loss_mask: 0.5861, decode.loss_dice: 0.8540, decode.d0.loss_cls: 6.9700, decode.d0.loss_mask: 0.5557, decode.d0.loss_dice: 0.9141, decode.d1.loss_cls: 0.5447, decode.d1.loss_mask: 0.6081, decode.d1.loss_dice: 0.9089, decode.d2.loss_cls: 0.4820, decode.d2.loss_mask: 0.5954, decode.d2.loss_dice: 0.8768, decode.d3.loss_cls: 0.4524, decode.d3.loss_mask: 0.5895, decode.d3.loss_dice: 0.8583, decode.d4.loss_cls: 0.4388, decode.d4.loss_mask: 0.5901, decode.d4.loss_dice: 0.8575, decode.d5.loss_cls: 0.4311, decode.d5.loss_mask: 0.5869, decode.d5.loss_dice: 0.8580, decode.d6.loss_cls: 0.4245, decode.d6.loss_mask: 0.5869, decode.d6.loss_dice: 0.8555, decode.d7.loss_cls: 0.4255, decode.d7.loss_mask: 0.5855, decode.d7.loss_dice: 0.8522, decode.d8.loss_cls: 0.4250, decode.d8.loss_mask: 0.5831, decode.d8.loss_dice: 0.8535, loss: 25.5765
2022-11-30 15:10:04,557 - mmseg - INFO - Iter [15350/40000]	lr: 8.198e-08, eta: 1 day, 5:57:24, time: 4.110, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4321, decode.loss_mask: 0.5632, decode.loss_dice: 0.8488, decode.d0.loss_cls: 6.9686, decode.d0.loss_mask: 0.5454, decode.d0.loss_dice: 0.9176, decode.d1.loss_cls: 0.5555, decode.d1.loss_mask: 0.5891, decode.d1.loss_dice: 0.9133, decode.d2.loss_cls: 0.4995, decode.d2.loss_mask: 0.5724, decode.d2.loss_dice: 0.8716, decode.d3.loss_cls: 0.4611, decode.d3.loss_mask: 0.5704, decode.d3.loss_dice: 0.8552, decode.d4.loss_cls: 0.4507, decode.d4.loss_mask: 0.5705, decode.d4.loss_dice: 0.8534, decode.d5.loss_cls: 0.4401, decode.d5.loss_mask: 0.5656, decode.d5.loss_dice: 0.8522, decode.d6.loss_cls: 0.4350, decode.d6.loss_mask: 0.5650, decode.d6.loss_dice: 0.8496, decode.d7.loss_cls: 0.4292, decode.d7.loss_mask: 0.5663, decode.d7.loss_dice: 0.8505, decode.d8.loss_cls: 0.4313, decode.d8.loss_mask: 0.5658, decode.d8.loss_dice: 0.8485, loss: 25.4375
2022-11-30 15:13:30,421 - mmseg - INFO - Iter [15400/40000]	lr: 8.182e-08, eta: 1 day, 5:53:25, time: 4.117, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4301, decode.loss_mask: 0.5762, decode.loss_dice: 0.8354, decode.d0.loss_cls: 6.9541, decode.d0.loss_mask: 0.5510, decode.d0.loss_dice: 0.9007, decode.d1.loss_cls: 0.5502, decode.d1.loss_mask: 0.5973, decode.d1.loss_dice: 0.8954, decode.d2.loss_cls: 0.4889, decode.d2.loss_mask: 0.5839, decode.d2.loss_dice: 0.8570, decode.d3.loss_cls: 0.4526, decode.d3.loss_mask: 0.5802, decode.d3.loss_dice: 0.8413, decode.d4.loss_cls: 0.4457, decode.d4.loss_mask: 0.5785, decode.d4.loss_dice: 0.8421, decode.d5.loss_cls: 0.4323, decode.d5.loss_mask: 0.5758, decode.d5.loss_dice: 0.8359, decode.d6.loss_cls: 0.4306, decode.d6.loss_mask: 0.5755, decode.d6.loss_dice: 0.8394, decode.d7.loss_cls: 0.4257, decode.d7.loss_mask: 0.5747, decode.d7.loss_dice: 0.8349, decode.d8.loss_cls: 0.4262, decode.d8.loss_mask: 0.5760, decode.d8.loss_dice: 0.8378, loss: 25.3253
2022-11-30 15:16:56,331 - mmseg - INFO - Iter [15450/40000]	lr: 8.165e-08, eta: 1 day, 5:49:26, time: 4.118, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4137, decode.loss_mask: 0.5834, decode.loss_dice: 0.8322, decode.d0.loss_cls: 6.9378, decode.d0.loss_mask: 0.5581, decode.d0.loss_dice: 0.8955, decode.d1.loss_cls: 0.5330, decode.d1.loss_mask: 0.5988, decode.d1.loss_dice: 0.8860, decode.d2.loss_cls: 0.4719, decode.d2.loss_mask: 0.5871, decode.d2.loss_dice: 0.8508, decode.d3.loss_cls: 0.4406, decode.d3.loss_mask: 0.5848, decode.d3.loss_dice: 0.8340, decode.d4.loss_cls: 0.4290, decode.d4.loss_mask: 0.5850, decode.d4.loss_dice: 0.8327, decode.d5.loss_cls: 0.4177, decode.d5.loss_mask: 0.5831, decode.d5.loss_dice: 0.8323, decode.d6.loss_cls: 0.4166, decode.d6.loss_mask: 0.5812, decode.d6.loss_dice: 0.8289, decode.d7.loss_cls: 0.4111, decode.d7.loss_mask: 0.5817, decode.d7.loss_dice: 0.8306, decode.d8.loss_cls: 0.4107, decode.d8.loss_mask: 0.5843, decode.d8.loss_dice: 0.8290, loss: 25.1618
2022-11-30 15:20:21,677 - mmseg - INFO - Iter [15500/40000]	lr: 8.148e-08, eta: 1 day, 5:45:26, time: 4.107, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4271, decode.loss_mask: 0.5910, decode.loss_dice: 0.8597, decode.d0.loss_cls: 6.9291, decode.d0.loss_mask: 0.5672, decode.d0.loss_dice: 0.9288, decode.d1.loss_cls: 0.5510, decode.d1.loss_mask: 0.6091, decode.d1.loss_dice: 0.9207, decode.d2.loss_cls: 0.4866, decode.d2.loss_mask: 0.5995, decode.d2.loss_dice: 0.8879, decode.d3.loss_cls: 0.4508, decode.d3.loss_mask: 0.5938, decode.d3.loss_dice: 0.8702, decode.d4.loss_cls: 0.4471, decode.d4.loss_mask: 0.5923, decode.d4.loss_dice: 0.8699, decode.d5.loss_cls: 0.4351, decode.d5.loss_mask: 0.5907, decode.d5.loss_dice: 0.8627, decode.d6.loss_cls: 0.4294, decode.d6.loss_mask: 0.5919, decode.d6.loss_dice: 0.8622, decode.d7.loss_cls: 0.4276, decode.d7.loss_mask: 0.5934, decode.d7.loss_dice: 0.8618, decode.d8.loss_cls: 0.4279, decode.d8.loss_mask: 0.5920, decode.d8.loss_dice: 0.8607, loss: 25.7171
2022-11-30 15:23:47,450 - mmseg - INFO - Iter [15550/40000]	lr: 8.132e-08, eta: 1 day, 5:41:27, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4358, decode.loss_mask: 0.5740, decode.loss_dice: 0.8449, decode.d0.loss_cls: 6.9420, decode.d0.loss_mask: 0.5533, decode.d0.loss_dice: 0.9199, decode.d1.loss_cls: 0.5559, decode.d1.loss_mask: 0.5995, decode.d1.loss_dice: 0.9132, decode.d2.loss_cls: 0.4952, decode.d2.loss_mask: 0.5868, decode.d2.loss_dice: 0.8775, decode.d3.loss_cls: 0.4626, decode.d3.loss_mask: 0.5814, decode.d3.loss_dice: 0.8553, decode.d4.loss_cls: 0.4578, decode.d4.loss_mask: 0.5767, decode.d4.loss_dice: 0.8545, decode.d5.loss_cls: 0.4432, decode.d5.loss_mask: 0.5753, decode.d5.loss_dice: 0.8513, decode.d6.loss_cls: 0.4365, decode.d6.loss_mask: 0.5760, decode.d6.loss_dice: 0.8483, decode.d7.loss_cls: 0.4346, decode.d7.loss_mask: 0.5759, decode.d7.loss_dice: 0.8504, decode.d8.loss_cls: 0.4335, decode.d8.loss_mask: 0.5760, decode.d8.loss_dice: 0.8489, loss: 25.5364
2022-11-30 15:27:13,432 - mmseg - INFO - Iter [15600/40000]	lr: 8.115e-08, eta: 1 day, 5:37:29, time: 4.120, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4106, decode.loss_mask: 0.5884, decode.loss_dice: 0.8353, decode.d0.loss_cls: 6.9127, decode.d0.loss_mask: 0.5643, decode.d0.loss_dice: 0.8971, decode.d1.loss_cls: 0.5266, decode.d1.loss_mask: 0.6109, decode.d1.loss_dice: 0.8959, decode.d2.loss_cls: 0.4656, decode.d2.loss_mask: 0.5965, decode.d2.loss_dice: 0.8594, decode.d3.loss_cls: 0.4348, decode.d3.loss_mask: 0.5901, decode.d3.loss_dice: 0.8436, decode.d4.loss_cls: 0.4296, decode.d4.loss_mask: 0.5888, decode.d4.loss_dice: 0.8375, decode.d5.loss_cls: 0.4166, decode.d5.loss_mask: 0.5865, decode.d5.loss_dice: 0.8379, decode.d6.loss_cls: 0.4139, decode.d6.loss_mask: 0.5853, decode.d6.loss_dice: 0.8360, decode.d7.loss_cls: 0.4130, decode.d7.loss_mask: 0.5876, decode.d7.loss_dice: 0.8365, decode.d8.loss_cls: 0.4107, decode.d8.loss_mask: 0.5883, decode.d8.loss_dice: 0.8374, loss: 25.2375
2022-11-30 15:30:39,199 - mmseg - INFO - Iter [15650/40000]	lr: 8.098e-08, eta: 1 day, 5:33:30, time: 4.115, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4100, decode.loss_mask: 0.5692, decode.loss_dice: 0.8457, decode.d0.loss_cls: 6.9231, decode.d0.loss_mask: 0.5504, decode.d0.loss_dice: 0.9194, decode.d1.loss_cls: 0.5310, decode.d1.loss_mask: 0.5915, decode.d1.loss_dice: 0.9074, decode.d2.loss_cls: 0.4678, decode.d2.loss_mask: 0.5804, decode.d2.loss_dice: 0.8715, decode.d3.loss_cls: 0.4374, decode.d3.loss_mask: 0.5719, decode.d3.loss_dice: 0.8550, decode.d4.loss_cls: 0.4263, decode.d4.loss_mask: 0.5725, decode.d4.loss_dice: 0.8551, decode.d5.loss_cls: 0.4187, decode.d5.loss_mask: 0.5675, decode.d5.loss_dice: 0.8503, decode.d6.loss_cls: 0.4162, decode.d6.loss_mask: 0.5699, decode.d6.loss_dice: 0.8467, decode.d7.loss_cls: 0.4132, decode.d7.loss_mask: 0.5688, decode.d7.loss_dice: 0.8470, decode.d8.loss_cls: 0.4129, decode.d8.loss_mask: 0.5703, decode.d8.loss_dice: 0.8480, loss: 25.2152
2022-11-30 15:34:04,365 - mmseg - INFO - Iter [15700/40000]	lr: 8.082e-08, eta: 1 day, 5:29:31, time: 4.103, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4370, decode.loss_mask: 0.5745, decode.loss_dice: 0.8490, decode.d0.loss_cls: 6.9000, decode.d0.loss_mask: 0.5534, decode.d0.loss_dice: 0.9259, decode.d1.loss_cls: 0.5635, decode.d1.loss_mask: 0.5985, decode.d1.loss_dice: 0.9130, decode.d2.loss_cls: 0.5045, decode.d2.loss_mask: 0.5846, decode.d2.loss_dice: 0.8752, decode.d3.loss_cls: 0.4663, decode.d3.loss_mask: 0.5790, decode.d3.loss_dice: 0.8565, decode.d4.loss_cls: 0.4574, decode.d4.loss_mask: 0.5766, decode.d4.loss_dice: 0.8564, decode.d5.loss_cls: 0.4476, decode.d5.loss_mask: 0.5775, decode.d5.loss_dice: 0.8547, decode.d6.loss_cls: 0.4410, decode.d6.loss_mask: 0.5739, decode.d6.loss_dice: 0.8509, decode.d7.loss_cls: 0.4386, decode.d7.loss_mask: 0.5742, decode.d7.loss_dice: 0.8497, decode.d8.loss_cls: 0.4393, decode.d8.loss_mask: 0.5737, decode.d8.loss_dice: 0.8474, loss: 25.5400
2022-11-30 15:37:30,380 - mmseg - INFO - Iter [15750/40000]	lr: 8.065e-08, eta: 1 day, 5:25:34, time: 4.120, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4207, decode.loss_mask: 0.5879, decode.loss_dice: 0.8641, decode.d0.loss_cls: 6.8969, decode.d0.loss_mask: 0.5606, decode.d0.loss_dice: 0.9265, decode.d1.loss_cls: 0.5324, decode.d1.loss_mask: 0.6137, decode.d1.loss_dice: 0.9171, decode.d2.loss_cls: 0.4766, decode.d2.loss_mask: 0.5984, decode.d2.loss_dice: 0.8777, decode.d3.loss_cls: 0.4468, decode.d3.loss_mask: 0.5925, decode.d3.loss_dice: 0.8650, decode.d4.loss_cls: 0.4369, decode.d4.loss_mask: 0.5895, decode.d4.loss_dice: 0.8666, decode.d5.loss_cls: 0.4275, decode.d5.loss_mask: 0.5886, decode.d5.loss_dice: 0.8639, decode.d6.loss_cls: 0.4255, decode.d6.loss_mask: 0.5907, decode.d6.loss_dice: 0.8593, decode.d7.loss_cls: 0.4209, decode.d7.loss_mask: 0.5880, decode.d7.loss_dice: 0.8618, decode.d8.loss_cls: 0.4214, decode.d8.loss_mask: 0.5881, decode.d8.loss_dice: 0.8600, loss: 25.5656
2022-11-30 15:40:56,252 - mmseg - INFO - Iter [15800/40000]	lr: 8.049e-08, eta: 1 day, 5:21:36, time: 4.117, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4371, decode.loss_mask: 0.5761, decode.loss_dice: 0.8376, decode.d0.loss_cls: 6.8779, decode.d0.loss_mask: 0.5591, decode.d0.loss_dice: 0.9022, decode.d1.loss_cls: 0.5495, decode.d1.loss_mask: 0.6022, decode.d1.loss_dice: 0.9028, decode.d2.loss_cls: 0.4898, decode.d2.loss_mask: 0.5904, decode.d2.loss_dice: 0.8668, decode.d3.loss_cls: 0.4553, decode.d3.loss_mask: 0.5857, decode.d3.loss_dice: 0.8451, decode.d4.loss_cls: 0.4446, decode.d4.loss_mask: 0.5826, decode.d4.loss_dice: 0.8464, decode.d5.loss_cls: 0.4361, decode.d5.loss_mask: 0.5820, decode.d5.loss_dice: 0.8403, decode.d6.loss_cls: 0.4390, decode.d6.loss_mask: 0.5797, decode.d6.loss_dice: 0.8404, decode.d7.loss_cls: 0.4364, decode.d7.loss_mask: 0.5781, decode.d7.loss_dice: 0.8420, decode.d8.loss_cls: 0.4363, decode.d8.loss_mask: 0.5797, decode.d8.loss_dice: 0.8382, loss: 25.3792
2022-11-30 15:44:24,172 - mmseg - INFO - Iter [15850/40000]	lr: 8.032e-08, eta: 1 day, 5:17:42, time: 4.158, data_time: 0.063, memory: 51902, decode.loss_cls: 0.4261, decode.loss_mask: 0.5734, decode.loss_dice: 0.8291, decode.d0.loss_cls: 6.8593, decode.d0.loss_mask: 0.5555, decode.d0.loss_dice: 0.9098, decode.d1.loss_cls: 0.5495, decode.d1.loss_mask: 0.5986, decode.d1.loss_dice: 0.8988, decode.d2.loss_cls: 0.4841, decode.d2.loss_mask: 0.5864, decode.d2.loss_dice: 0.8558, decode.d3.loss_cls: 0.4475, decode.d3.loss_mask: 0.5785, decode.d3.loss_dice: 0.8415, decode.d4.loss_cls: 0.4386, decode.d4.loss_mask: 0.5752, decode.d4.loss_dice: 0.8389, decode.d5.loss_cls: 0.4308, decode.d5.loss_mask: 0.5718, decode.d5.loss_dice: 0.8367, decode.d6.loss_cls: 0.4284, decode.d6.loss_mask: 0.5750, decode.d6.loss_dice: 0.8315, decode.d7.loss_cls: 0.4243, decode.d7.loss_mask: 0.5736, decode.d7.loss_dice: 0.8322, decode.d8.loss_cls: 0.4240, decode.d8.loss_mask: 0.5741, decode.d8.loss_dice: 0.8342, loss: 25.1834
2022-11-30 15:47:49,829 - mmseg - INFO - Iter [15900/40000]	lr: 8.015e-08, eta: 1 day, 5:13:44, time: 4.113, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4122, decode.loss_mask: 0.5784, decode.loss_dice: 0.8402, decode.d0.loss_cls: 6.8720, decode.d0.loss_mask: 0.5574, decode.d0.loss_dice: 0.8996, decode.d1.loss_cls: 0.5344, decode.d1.loss_mask: 0.6041, decode.d1.loss_dice: 0.8927, decode.d2.loss_cls: 0.4727, decode.d2.loss_mask: 0.5915, decode.d2.loss_dice: 0.8566, decode.d3.loss_cls: 0.4404, decode.d3.loss_mask: 0.5845, decode.d3.loss_dice: 0.8465, decode.d4.loss_cls: 0.4272, decode.d4.loss_mask: 0.5828, decode.d4.loss_dice: 0.8465, decode.d5.loss_cls: 0.4178, decode.d5.loss_mask: 0.5843, decode.d5.loss_dice: 0.8440, decode.d6.loss_cls: 0.4140, decode.d6.loss_mask: 0.5810, decode.d6.loss_dice: 0.8408, decode.d7.loss_cls: 0.4118, decode.d7.loss_mask: 0.5792, decode.d7.loss_dice: 0.8426, decode.d8.loss_cls: 0.4094, decode.d8.loss_mask: 0.5805, decode.d8.loss_dice: 0.8430, loss: 25.1882
2022-11-30 15:51:15,716 - mmseg - INFO - Iter [15950/40000]	lr: 7.999e-08, eta: 1 day, 5:09:47, time: 4.118, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4002, decode.loss_mask: 0.5631, decode.loss_dice: 0.8184, decode.d0.loss_cls: 6.8606, decode.d0.loss_mask: 0.5378, decode.d0.loss_dice: 0.8833, decode.d1.loss_cls: 0.5367, decode.d1.loss_mask: 0.5865, decode.d1.loss_dice: 0.8753, decode.d2.loss_cls: 0.4597, decode.d2.loss_mask: 0.5730, decode.d2.loss_dice: 0.8417, decode.d3.loss_cls: 0.4286, decode.d3.loss_mask: 0.5668, decode.d3.loss_dice: 0.8294, decode.d4.loss_cls: 0.4138, decode.d4.loss_mask: 0.5656, decode.d4.loss_dice: 0.8271, decode.d5.loss_cls: 0.4049, decode.d5.loss_mask: 0.5644, decode.d5.loss_dice: 0.8246, decode.d6.loss_cls: 0.4003, decode.d6.loss_mask: 0.5637, decode.d6.loss_dice: 0.8186, decode.d7.loss_cls: 0.3967, decode.d7.loss_mask: 0.5639, decode.d7.loss_dice: 0.8193, decode.d8.loss_cls: 0.4005, decode.d8.loss_mask: 0.5614, decode.d8.loss_dice: 0.8184, loss: 24.7045
2022-11-30 15:54:41,356 - mmseg - INFO - Saving checkpoint at 16000 iterations
2022-11-30 15:55:31,043 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 15:55:31,044 - mmseg - INFO - Iter [16000/40000]	lr: 7.982e-08, eta: 1 day, 5:07:04, time: 5.107, data_time: 0.021, memory: 51902, decode.loss_cls: 0.4161, decode.loss_mask: 0.5844, decode.loss_dice: 0.8376, decode.d0.loss_cls: 6.8541, decode.d0.loss_mask: 0.5591, decode.d0.loss_dice: 0.9045, decode.d1.loss_cls: 0.5345, decode.d1.loss_mask: 0.6038, decode.d1.loss_dice: 0.8974, decode.d2.loss_cls: 0.4718, decode.d2.loss_mask: 0.5925, decode.d2.loss_dice: 0.8599, decode.d3.loss_cls: 0.4377, decode.d3.loss_mask: 0.5874, decode.d3.loss_dice: 0.8453, decode.d4.loss_cls: 0.4255, decode.d4.loss_mask: 0.5872, decode.d4.loss_dice: 0.8478, decode.d5.loss_cls: 0.4198, decode.d5.loss_mask: 0.5842, decode.d5.loss_dice: 0.8379, decode.d6.loss_cls: 0.4155, decode.d6.loss_mask: 0.5833, decode.d6.loss_dice: 0.8370, decode.d7.loss_cls: 0.4135, decode.d7.loss_mask: 0.5839, decode.d7.loss_dice: 0.8393, decode.d8.loss_cls: 0.4120, decode.d8.loss_mask: 0.5843, decode.d8.loss_dice: 0.8384, loss: 25.1957
2022-11-30 15:58:29,083 - mmseg - INFO - per class results:
2022-11-30 15:58:29,088 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 83.39 | 90.55 |
|       building      | 85.27 | 90.37 |
|         sky         | 95.13 | 97.22 |
|        floor        |  85.2 | 90.36 |
|         tree        | 78.75 | 90.58 |
|       ceiling       | 87.52 | 93.19 |
|         road        | 87.55 | 92.49 |
|         bed         | 93.37 | 96.66 |
|      windowpane     | 67.33 | 81.19 |
|        grass        | 69.13 | 84.27 |
|       cabinet       | 62.48 | 71.45 |
|       sidewalk      | 71.83 | 83.29 |
|        person       |  88.5 | 94.26 |
|        earth        |  44.2 | 57.53 |
|         door        | 63.25 | 79.74 |
|        table        | 72.13 |  82.3 |
|       mountain      | 60.75 |  71.6 |
|        plant        | 56.96 | 70.27 |
|       curtain       |  82.5 | 90.66 |
|        chair        | 69.07 | 77.67 |
|         car         | 89.53 | 95.46 |
|        water        | 62.08 | 78.93 |
|       painting      | 82.09 |  89.5 |
|         sofa        | 86.38 | 92.26 |
|        shelf        | 48.85 | 61.17 |
|        house        | 50.43 | 72.24 |
|         sea         | 69.91 | 82.24 |
|        mirror       | 82.07 | 91.98 |
|         rug         | 72.25 | 84.99 |
|        field        | 41.76 | 69.82 |
|       armchair      | 64.85 | 82.88 |
|         seat        |  66.8 | 90.61 |
|        fence        | 54.01 | 76.74 |
|         desk        | 59.65 | 83.56 |
|         rock        | 64.73 | 73.67 |
|       wardrobe      | 54.56 | 82.04 |
|         lamp        | 80.25 | 91.03 |
|       bathtub       |  91.7 | 93.72 |
|       railing       | 45.67 |  63.5 |
|       cushion       | 77.33 |  90.6 |
|         base        | 47.01 | 72.53 |
|         box         |  39.9 |  60.7 |
|        column       |  59.0 | 76.95 |
|      signboard      | 45.64 | 68.78 |
|   chest of drawers  | 45.87 | 79.36 |
|       counter       | 57.59 | 67.83 |
|         sand        | 61.26 | 87.55 |
|         sink        | 82.26 | 87.36 |
|      skyscraper     | 49.36 |  63.7 |
|      fireplace      | 79.33 | 95.91 |
|     refrigerator    | 83.83 | 95.33 |
|      grandstand     | 43.67 | 85.38 |
|         path        | 24.41 | 34.53 |
|        stairs       | 38.93 | 51.35 |
|        runway       |  74.4 |  94.8 |
|         case        | 69.54 | 88.83 |
|      pool table     | 95.78 | 98.54 |
|        pillow       | 72.36 | 84.01 |
|     screen door     | 81.02 | 87.25 |
|       stairway      | 57.81 | 75.05 |
|        river        | 20.77 | 29.64 |
|        bridge       | 70.19 | 90.91 |
|       bookcase      | 38.48 | 57.32 |
|        blind        | 38.96 | 47.84 |
|     coffee table    | 73.17 | 90.81 |
|        toilet       | 93.05 | 97.06 |
|        flower       | 43.09 |  68.8 |
|         book        | 59.68 | 81.86 |
|         hill        | 10.79 | 20.41 |
|        bench        | 73.21 |  82.9 |
|      countertop     | 74.06 | 87.46 |
|        stove        | 85.83 | 89.92 |
|         palm        | 57.38 | 81.91 |
|    kitchen island   | 40.44 | 85.95 |
|       computer      | 82.14 | 89.95 |
|     swivel chair    | 57.52 | 82.12 |
|         boat        | 54.83 | 88.16 |
|         bar         | 69.17 | 76.38 |
|    arcade machine   | 91.79 | 98.85 |
|        hovel        | 56.92 | 87.14 |
|         bus         | 93.22 | 95.88 |
|        towel        | 79.88 | 93.95 |
|        light        |  66.9 | 82.26 |
|        truck        | 54.43 | 74.18 |
|        tower        | 33.29 | 63.31 |
|      chandelier     | 76.59 |  86.8 |
|        awning       |  31.5 | 49.52 |
|     streetlight     | 45.37 | 66.99 |
|        booth        | 57.91 | 78.68 |
| television receiver | 79.19 | 89.49 |
|       airplane      | 89.18 | 96.38 |
|      dirt track     |  0.02 |  0.03 |
|       apparel       | 54.57 | 90.96 |
|         pole        | 39.59 | 60.89 |
|         land        |  1.38 |  1.78 |
|      bannister      |  18.0 | 35.15 |
|      escalator      | 64.79 | 83.98 |
|       ottoman       | 64.93 | 79.64 |
|        bottle       | 52.72 | 83.86 |
|        buffet       | 39.93 | 57.14 |
|        poster       | 45.39 | 73.14 |
|        stage        | 26.01 |  59.6 |
|         van         | 52.71 | 73.16 |
|         ship        | 29.24 | 30.81 |
|       fountain      | 45.42 |  49.5 |
|    conveyer belt    | 81.58 | 97.09 |
|        canopy       | 57.26 | 77.29 |
|        washer       | 91.15 | 93.58 |
|      plaything      | 39.64 | 62.68 |
|    swimming pool    | 44.83 | 74.28 |
|        stool        | 62.21 | 85.41 |
|        barrel       | 79.55 | 88.42 |
|        basket       | 40.32 | 64.61 |
|      waterfall      | 55.83 | 70.86 |
|         tent        | 94.24 | 98.27 |
|         bag         | 34.86 | 47.42 |
|       minibike      | 80.72 |  94.1 |
|        cradle       | 91.23 | 97.33 |
|         oven        | 65.77 | 83.83 |
|         ball        | 40.73 | 44.89 |
|         food        | 65.91 | 75.85 |
|         step        | 22.34 | 33.81 |
|         tank        | 64.74 | 67.28 |
|      trade name     | 32.39 | 40.09 |
|      microwave      | 89.64 | 94.41 |
|         pot         | 61.77 | 74.34 |
|        animal       | 84.04 | 86.91 |
|       bicycle       | 60.78 | 84.43 |
|         lake        |  3.75 |  5.84 |
|      dishwasher     | 80.17 | 90.47 |
|        screen       |  60.2 | 85.94 |
|       blanket       | 35.08 | 45.62 |
|      sculpture      |  71.7 | 91.07 |
|         hood        | 76.35 | 82.58 |
|        sconce       | 66.49 | 81.33 |
|         vase        | 59.25 | 82.49 |
|    traffic light    | 51.98 | 72.06 |
|         tray        | 29.96 | 44.98 |
|        ashcan       | 49.08 | 74.88 |
|         fan         | 73.82 | 86.58 |
|         pier        | 38.36 | 43.12 |
|      crt screen     | 17.55 |  48.6 |
|        plate        | 70.44 | 85.57 |
|       monitor       | 15.91 |  21.2 |
|    bulletin board   | 62.58 |  85.2 |
|        shower       | 24.26 | 30.46 |
|       radiator      |  72.5 | 93.52 |
|        glass        | 29.23 | 32.67 |
|        clock        | 63.19 | 76.21 |
|         flag        |  70.8 | 84.33 |
+---------------------+-------+-------+
2022-11-30 15:58:29,088 - mmseg - INFO - Summary:
2022-11-30 15:58:29,088 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 86.84 | 60.37 | 75.08 |
+-------+-------+-------+
2022-11-30 15:58:29,093 - mmseg - INFO - The previous best checkpoint /mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune/lr1.0_lrd0.9/best_mIoU_iter_15000.pth was removed
2022-11-30 15:59:18,821 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_16000.pth.
2022-11-30 15:59:18,821 - mmseg - INFO - Best mIoU is 0.6037 at 16000 iter.
2022-11-30 15:59:18,829 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 15:59:18,829 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8684, mIoU: 0.6037, mAcc: 0.7508, IoU.wall: 0.8339, IoU.building: 0.8527, IoU.sky: 0.9513, IoU.floor: 0.8520, IoU.tree: 0.7875, IoU.ceiling: 0.8752, IoU.road: 0.8755, IoU.bed : 0.9337, IoU.windowpane: 0.6733, IoU.grass: 0.6913, IoU.cabinet: 0.6248, IoU.sidewalk: 0.7183, IoU.person: 0.8850, IoU.earth: 0.4420, IoU.door: 0.6325, IoU.table: 0.7213, IoU.mountain: 0.6075, IoU.plant: 0.5696, IoU.curtain: 0.8250, IoU.chair: 0.6907, IoU.car: 0.8953, IoU.water: 0.6208, IoU.painting: 0.8209, IoU.sofa: 0.8638, IoU.shelf: 0.4885, IoU.house: 0.5043, IoU.sea: 0.6991, IoU.mirror: 0.8207, IoU.rug: 0.7225, IoU.field: 0.4176, IoU.armchair: 0.6485, IoU.seat: 0.6680, IoU.fence: 0.5401, IoU.desk: 0.5965, IoU.rock: 0.6473, IoU.wardrobe: 0.5456, IoU.lamp: 0.8025, IoU.bathtub: 0.9170, IoU.railing: 0.4567, IoU.cushion: 0.7733, IoU.base: 0.4701, IoU.box: 0.3990, IoU.column: 0.5900, IoU.signboard: 0.4564, IoU.chest of drawers: 0.4587, IoU.counter: 0.5759, IoU.sand: 0.6126, IoU.sink: 0.8226, IoU.skyscraper: 0.4936, IoU.fireplace: 0.7933, IoU.refrigerator: 0.8383, IoU.grandstand: 0.4367, IoU.path: 0.2441, IoU.stairs: 0.3893, IoU.runway: 0.7440, IoU.case: 0.6954, IoU.pool table: 0.9578, IoU.pillow: 0.7236, IoU.screen door: 0.8102, IoU.stairway: 0.5781, IoU.river: 0.2077, IoU.bridge: 0.7019, IoU.bookcase: 0.3848, IoU.blind: 0.3896, IoU.coffee table: 0.7317, IoU.toilet: 0.9305, IoU.flower: 0.4309, IoU.book: 0.5968, IoU.hill: 0.1079, IoU.bench: 0.7321, IoU.countertop: 0.7406, IoU.stove: 0.8583, IoU.palm: 0.5738, IoU.kitchen island: 0.4044, IoU.computer: 0.8214, IoU.swivel chair: 0.5752, IoU.boat: 0.5483, IoU.bar: 0.6917, IoU.arcade machine: 0.9179, IoU.hovel: 0.5692, IoU.bus: 0.9322, IoU.towel: 0.7988, IoU.light: 0.6690, IoU.truck: 0.5443, IoU.tower: 0.3329, IoU.chandelier: 0.7659, IoU.awning: 0.3150, IoU.streetlight: 0.4537, IoU.booth: 0.5791, IoU.television receiver: 0.7919, IoU.airplane: 0.8918, IoU.dirt track: 0.0002, IoU.apparel: 0.5457, IoU.pole: 0.3959, IoU.land: 0.0138, IoU.bannister: 0.1800, IoU.escalator: 0.6479, IoU.ottoman: 0.6493, IoU.bottle: 0.5272, IoU.buffet: 0.3993, IoU.poster: 0.4539, IoU.stage: 0.2601, IoU.van: 0.5271, IoU.ship: 0.2924, IoU.fountain: 0.4542, IoU.conveyer belt: 0.8158, IoU.canopy: 0.5726, IoU.washer: 0.9115, IoU.plaything: 0.3964, IoU.swimming pool: 0.4483, IoU.stool: 0.6221, IoU.barrel: 0.7955, IoU.basket: 0.4032, IoU.waterfall: 0.5583, IoU.tent: 0.9424, IoU.bag: 0.3486, IoU.minibike: 0.8072, IoU.cradle: 0.9123, IoU.oven: 0.6577, IoU.ball: 0.4073, IoU.food: 0.6591, IoU.step: 0.2234, IoU.tank: 0.6474, IoU.trade name: 0.3239, IoU.microwave: 0.8964, IoU.pot: 0.6177, IoU.animal: 0.8404, IoU.bicycle: 0.6078, IoU.lake: 0.0375, IoU.dishwasher: 0.8017, IoU.screen: 0.6020, IoU.blanket: 0.3508, IoU.sculpture: 0.7170, IoU.hood: 0.7635, IoU.sconce: 0.6649, IoU.vase: 0.5925, IoU.traffic light: 0.5198, IoU.tray: 0.2996, IoU.ashcan: 0.4908, IoU.fan: 0.7382, IoU.pier: 0.3836, IoU.crt screen: 0.1755, IoU.plate: 0.7044, IoU.monitor: 0.1591, IoU.bulletin board: 0.6258, IoU.shower: 0.2426, IoU.radiator: 0.7250, IoU.glass: 0.2923, IoU.clock: 0.6319, IoU.flag: 0.7080, Acc.wall: 0.9055, Acc.building: 0.9037, Acc.sky: 0.9722, Acc.floor: 0.9036, Acc.tree: 0.9058, Acc.ceiling: 0.9319, Acc.road: 0.9249, Acc.bed : 0.9666, Acc.windowpane: 0.8119, Acc.grass: 0.8427, Acc.cabinet: 0.7145, Acc.sidewalk: 0.8329, Acc.person: 0.9426, Acc.earth: 0.5753, Acc.door: 0.7974, Acc.table: 0.8230, Acc.mountain: 0.7160, Acc.plant: 0.7027, Acc.curtain: 0.9066, Acc.chair: 0.7767, Acc.car: 0.9546, Acc.water: 0.7893, Acc.painting: 0.8950, Acc.sofa: 0.9226, Acc.shelf: 0.6117, Acc.house: 0.7224, Acc.sea: 0.8224, Acc.mirror: 0.9198, Acc.rug: 0.8499, Acc.field: 0.6982, Acc.armchair: 0.8288, Acc.seat: 0.9061, Acc.fence: 0.7674, Acc.desk: 0.8356, Acc.rock: 0.7367, Acc.wardrobe: 0.8204, Acc.lamp: 0.9103, Acc.bathtub: 0.9372, Acc.railing: 0.6350, Acc.cushion: 0.9060, Acc.base: 0.7253, Acc.box: 0.6070, Acc.column: 0.7695, Acc.signboard: 0.6878, Acc.chest of drawers: 0.7936, Acc.counter: 0.6783, Acc.sand: 0.8755, Acc.sink: 0.8736, Acc.skyscraper: 0.6370, Acc.fireplace: 0.9591, Acc.refrigerator: 0.9533, Acc.grandstand: 0.8538, Acc.path: 0.3453, Acc.stairs: 0.5135, Acc.runway: 0.9480, Acc.case: 0.8883, Acc.pool table: 0.9854, Acc.pillow: 0.8401, Acc.screen door: 0.8725, Acc.stairway: 0.7505, Acc.river: 0.2964, Acc.bridge: 0.9091, Acc.bookcase: 0.5732, Acc.blind: 0.4784, Acc.coffee table: 0.9081, Acc.toilet: 0.9706, Acc.flower: 0.6880, Acc.book: 0.8186, Acc.hill: 0.2041, Acc.bench: 0.8290, Acc.countertop: 0.8746, Acc.stove: 0.8992, Acc.palm: 0.8191, Acc.kitchen island: 0.8595, Acc.computer: 0.8995, Acc.swivel chair: 0.8212, Acc.boat: 0.8816, Acc.bar: 0.7638, Acc.arcade machine: 0.9885, Acc.hovel: 0.8714, Acc.bus: 0.9588, Acc.towel: 0.9395, Acc.light: 0.8226, Acc.truck: 0.7418, Acc.tower: 0.6331, Acc.chandelier: 0.8680, Acc.awning: 0.4952, Acc.streetlight: 0.6699, Acc.booth: 0.7868, Acc.television receiver: 0.8949, Acc.airplane: 0.9638, Acc.dirt track: 0.0003, Acc.apparel: 0.9096, Acc.pole: 0.6089, Acc.land: 0.0178, Acc.bannister: 0.3515, Acc.escalator: 0.8398, Acc.ottoman: 0.7964, Acc.bottle: 0.8386, Acc.buffet: 0.5714, Acc.poster: 0.7314, Acc.stage: 0.5960, Acc.van: 0.7316, Acc.ship: 0.3081, Acc.fountain: 0.4950, Acc.conveyer belt: 0.9709, Acc.canopy: 0.7729, Acc.washer: 0.9358, Acc.plaything: 0.6268, Acc.swimming pool: 0.7428, Acc.stool: 0.8541, Acc.barrel: 0.8842, Acc.basket: 0.6461, Acc.waterfall: 0.7086, Acc.tent: 0.9827, Acc.bag: 0.4742, Acc.minibike: 0.9410, Acc.cradle: 0.9733, Acc.oven: 0.8383, Acc.ball: 0.4489, Acc.food: 0.7585, Acc.step: 0.3381, Acc.tank: 0.6728, Acc.trade name: 0.4009, Acc.microwave: 0.9441, Acc.pot: 0.7434, Acc.animal: 0.8691, Acc.bicycle: 0.8443, Acc.lake: 0.0584, Acc.dishwasher: 0.9047, Acc.screen: 0.8594, Acc.blanket: 0.4562, Acc.sculpture: 0.9107, Acc.hood: 0.8258, Acc.sconce: 0.8133, Acc.vase: 0.8249, Acc.traffic light: 0.7206, Acc.tray: 0.4498, Acc.ashcan: 0.7488, Acc.fan: 0.8658, Acc.pier: 0.4312, Acc.crt screen: 0.4860, Acc.plate: 0.8557, Acc.monitor: 0.2120, Acc.bulletin board: 0.8520, Acc.shower: 0.3046, Acc.radiator: 0.9352, Acc.glass: 0.3267, Acc.clock: 0.7621, Acc.flag: 0.8433
2022-11-30 16:02:44,884 - mmseg - INFO - Iter [16050/40000]	lr: 7.965e-08, eta: 1 day, 5:08:47, time: 8.677, data_time: 4.574, memory: 51902, decode.loss_cls: 0.4243, decode.loss_mask: 0.5552, decode.loss_dice: 0.8406, decode.d0.loss_cls: 6.8530, decode.d0.loss_mask: 0.5405, decode.d0.loss_dice: 0.9127, decode.d1.loss_cls: 0.5394, decode.d1.loss_mask: 0.5797, decode.d1.loss_dice: 0.9016, decode.d2.loss_cls: 0.4769, decode.d2.loss_mask: 0.5637, decode.d2.loss_dice: 0.8640, decode.d3.loss_cls: 0.4465, decode.d3.loss_mask: 0.5584, decode.d3.loss_dice: 0.8479, decode.d4.loss_cls: 0.4350, decode.d4.loss_mask: 0.5593, decode.d4.loss_dice: 0.8512, decode.d5.loss_cls: 0.4243, decode.d5.loss_mask: 0.5594, decode.d5.loss_dice: 0.8451, decode.d6.loss_cls: 0.4223, decode.d6.loss_mask: 0.5552, decode.d6.loss_dice: 0.8411, decode.d7.loss_cls: 0.4244, decode.d7.loss_mask: 0.5562, decode.d7.loss_dice: 0.8404, decode.d8.loss_cls: 0.4200, decode.d8.loss_mask: 0.5572, decode.d8.loss_dice: 0.8388, loss: 25.0342
2022-11-30 16:06:10,976 - mmseg - INFO - Iter [16100/40000]	lr: 7.949e-08, eta: 1 day, 5:04:49, time: 4.122, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4065, decode.loss_mask: 0.5627, decode.loss_dice: 0.8286, decode.d0.loss_cls: 6.8381, decode.d0.loss_mask: 0.5414, decode.d0.loss_dice: 0.8920, decode.d1.loss_cls: 0.5150, decode.d1.loss_mask: 0.5839, decode.d1.loss_dice: 0.8891, decode.d2.loss_cls: 0.4590, decode.d2.loss_mask: 0.5712, decode.d2.loss_dice: 0.8450, decode.d3.loss_cls: 0.4319, decode.d3.loss_mask: 0.5639, decode.d3.loss_dice: 0.8311, decode.d4.loss_cls: 0.4184, decode.d4.loss_mask: 0.5635, decode.d4.loss_dice: 0.8342, decode.d5.loss_cls: 0.4113, decode.d5.loss_mask: 0.5644, decode.d5.loss_dice: 0.8288, decode.d6.loss_cls: 0.4063, decode.d6.loss_mask: 0.5658, decode.d6.loss_dice: 0.8282, decode.d7.loss_cls: 0.4094, decode.d7.loss_mask: 0.5642, decode.d7.loss_dice: 0.8295, decode.d8.loss_cls: 0.4060, decode.d8.loss_mask: 0.5625, decode.d8.loss_dice: 0.8277, loss: 24.7798
2022-11-30 16:09:36,487 - mmseg - INFO - Iter [16150/40000]	lr: 7.932e-08, eta: 1 day, 5:00:50, time: 4.110, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4237, decode.loss_mask: 0.5658, decode.loss_dice: 0.8214, decode.d0.loss_cls: 6.8390, decode.d0.loss_mask: 0.5432, decode.d0.loss_dice: 0.8861, decode.d1.loss_cls: 0.5356, decode.d1.loss_mask: 0.5892, decode.d1.loss_dice: 0.8843, decode.d2.loss_cls: 0.4791, decode.d2.loss_mask: 0.5754, decode.d2.loss_dice: 0.8549, decode.d3.loss_cls: 0.4481, decode.d3.loss_mask: 0.5695, decode.d3.loss_dice: 0.8345, decode.d4.loss_cls: 0.4396, decode.d4.loss_mask: 0.5682, decode.d4.loss_dice: 0.8311, decode.d5.loss_cls: 0.4271, decode.d5.loss_mask: 0.5681, decode.d5.loss_dice: 0.8267, decode.d6.loss_cls: 0.4257, decode.d6.loss_mask: 0.5668, decode.d6.loss_dice: 0.8220, decode.d7.loss_cls: 0.4209, decode.d7.loss_mask: 0.5660, decode.d7.loss_dice: 0.8239, decode.d8.loss_cls: 0.4181, decode.d8.loss_mask: 0.5661, decode.d8.loss_dice: 0.8308, loss: 24.9509
2022-11-30 16:13:02,385 - mmseg - INFO - Iter [16200/40000]	lr: 7.915e-08, eta: 1 day, 4:56:52, time: 4.118, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4135, decode.loss_mask: 0.5673, decode.loss_dice: 0.8420, decode.d0.loss_cls: 6.8129, decode.d0.loss_mask: 0.5448, decode.d0.loss_dice: 0.9142, decode.d1.loss_cls: 0.5262, decode.d1.loss_mask: 0.5918, decode.d1.loss_dice: 0.9072, decode.d2.loss_cls: 0.4688, decode.d2.loss_mask: 0.5763, decode.d2.loss_dice: 0.8645, decode.d3.loss_cls: 0.4361, decode.d3.loss_mask: 0.5715, decode.d3.loss_dice: 0.8508, decode.d4.loss_cls: 0.4328, decode.d4.loss_mask: 0.5685, decode.d4.loss_dice: 0.8507, decode.d5.loss_cls: 0.4193, decode.d5.loss_mask: 0.5668, decode.d5.loss_dice: 0.8501, decode.d6.loss_cls: 0.4166, decode.d6.loss_mask: 0.5671, decode.d6.loss_dice: 0.8422, decode.d7.loss_cls: 0.4124, decode.d7.loss_mask: 0.5668, decode.d7.loss_dice: 0.8443, decode.d8.loss_cls: 0.4115, decode.d8.loss_mask: 0.5672, decode.d8.loss_dice: 0.8445, loss: 25.0489
2022-11-30 16:16:28,035 - mmseg - INFO - Iter [16250/40000]	lr: 7.899e-08, eta: 1 day, 4:52:54, time: 4.113, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4273, decode.loss_mask: 0.5710, decode.loss_dice: 0.8408, decode.d0.loss_cls: 6.8085, decode.d0.loss_mask: 0.5560, decode.d0.loss_dice: 0.9131, decode.d1.loss_cls: 0.5417, decode.d1.loss_mask: 0.6023, decode.d1.loss_dice: 0.8991, decode.d2.loss_cls: 0.4793, decode.d2.loss_mask: 0.5869, decode.d2.loss_dice: 0.8629, decode.d3.loss_cls: 0.4466, decode.d3.loss_mask: 0.5803, decode.d3.loss_dice: 0.8519, decode.d4.loss_cls: 0.4414, decode.d4.loss_mask: 0.5764, decode.d4.loss_dice: 0.8474, decode.d5.loss_cls: 0.4292, decode.d5.loss_mask: 0.5745, decode.d5.loss_dice: 0.8478, decode.d6.loss_cls: 0.4279, decode.d6.loss_mask: 0.5737, decode.d6.loss_dice: 0.8460, decode.d7.loss_cls: 0.4283, decode.d7.loss_mask: 0.5731, decode.d7.loss_dice: 0.8448, decode.d8.loss_cls: 0.4267, decode.d8.loss_mask: 0.5730, decode.d8.loss_dice: 0.8413, loss: 25.2193
2022-11-30 16:19:53,681 - mmseg - INFO - Iter [16300/40000]	lr: 7.882e-08, eta: 1 day, 4:48:56, time: 4.113, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4321, decode.loss_mask: 0.5831, decode.loss_dice: 0.8592, decode.d0.loss_cls: 6.7982, decode.d0.loss_mask: 0.5640, decode.d0.loss_dice: 0.9280, decode.d1.loss_cls: 0.5473, decode.d1.loss_mask: 0.6056, decode.d1.loss_dice: 0.9240, decode.d2.loss_cls: 0.4932, decode.d2.loss_mask: 0.5924, decode.d2.loss_dice: 0.8807, decode.d3.loss_cls: 0.4537, decode.d3.loss_mask: 0.5884, decode.d3.loss_dice: 0.8668, decode.d4.loss_cls: 0.4456, decode.d4.loss_mask: 0.5868, decode.d4.loss_dice: 0.8674, decode.d5.loss_cls: 0.4376, decode.d5.loss_mask: 0.5853, decode.d5.loss_dice: 0.8631, decode.d6.loss_cls: 0.4358, decode.d6.loss_mask: 0.5814, decode.d6.loss_dice: 0.8574, decode.d7.loss_cls: 0.4322, decode.d7.loss_mask: 0.5808, decode.d7.loss_dice: 0.8621, decode.d8.loss_cls: 0.4335, decode.d8.loss_mask: 0.5807, decode.d8.loss_dice: 0.8550, loss: 25.5214
2022-11-30 16:23:19,258 - mmseg - INFO - Iter [16350/40000]	lr: 7.866e-08, eta: 1 day, 4:44:57, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4244, decode.loss_mask: 0.5925, decode.loss_dice: 0.8512, decode.d0.loss_cls: 6.7816, decode.d0.loss_mask: 0.5719, decode.d0.loss_dice: 0.9216, decode.d1.loss_cls: 0.5314, decode.d1.loss_mask: 0.6198, decode.d1.loss_dice: 0.9187, decode.d2.loss_cls: 0.4731, decode.d2.loss_mask: 0.6028, decode.d2.loss_dice: 0.8821, decode.d3.loss_cls: 0.4450, decode.d3.loss_mask: 0.5966, decode.d3.loss_dice: 0.8605, decode.d4.loss_cls: 0.4354, decode.d4.loss_mask: 0.5958, decode.d4.loss_dice: 0.8582, decode.d5.loss_cls: 0.4264, decode.d5.loss_mask: 0.5910, decode.d5.loss_dice: 0.8561, decode.d6.loss_cls: 0.4222, decode.d6.loss_mask: 0.5911, decode.d6.loss_dice: 0.8555, decode.d7.loss_cls: 0.4220, decode.d7.loss_mask: 0.5913, decode.d7.loss_dice: 0.8549, decode.d8.loss_cls: 0.4189, decode.d8.loss_mask: 0.5927, decode.d8.loss_dice: 0.8522, loss: 25.4372
2022-11-30 16:26:45,003 - mmseg - INFO - Iter [16400/40000]	lr: 7.849e-08, eta: 1 day, 4:41:00, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4048, decode.loss_mask: 0.5612, decode.loss_dice: 0.8222, decode.d0.loss_cls: 6.7788, decode.d0.loss_mask: 0.5409, decode.d0.loss_dice: 0.8883, decode.d1.loss_cls: 0.5237, decode.d1.loss_mask: 0.5827, decode.d1.loss_dice: 0.8785, decode.d2.loss_cls: 0.4653, decode.d2.loss_mask: 0.5700, decode.d2.loss_dice: 0.8436, decode.d3.loss_cls: 0.4311, decode.d3.loss_mask: 0.5665, decode.d3.loss_dice: 0.8274, decode.d4.loss_cls: 0.4188, decode.d4.loss_mask: 0.5656, decode.d4.loss_dice: 0.8282, decode.d5.loss_cls: 0.4129, decode.d5.loss_mask: 0.5609, decode.d5.loss_dice: 0.8257, decode.d6.loss_cls: 0.4109, decode.d6.loss_mask: 0.5607, decode.d6.loss_dice: 0.8215, decode.d7.loss_cls: 0.4055, decode.d7.loss_mask: 0.5600, decode.d7.loss_dice: 0.8253, decode.d8.loss_cls: 0.4068, decode.d8.loss_mask: 0.5590, decode.d8.loss_dice: 0.8225, loss: 24.6693
2022-11-30 16:30:12,673 - mmseg - INFO - Iter [16450/40000]	lr: 7.832e-08, eta: 1 day, 4:37:05, time: 4.153, data_time: 0.067, memory: 51902, decode.loss_cls: 0.4046, decode.loss_mask: 0.5755, decode.loss_dice: 0.8301, decode.d0.loss_cls: 6.7535, decode.d0.loss_mask: 0.5542, decode.d0.loss_dice: 0.8962, decode.d1.loss_cls: 0.5299, decode.d1.loss_mask: 0.6001, decode.d1.loss_dice: 0.8920, decode.d2.loss_cls: 0.4656, decode.d2.loss_mask: 0.5878, decode.d2.loss_dice: 0.8538, decode.d3.loss_cls: 0.4330, decode.d3.loss_mask: 0.5806, decode.d3.loss_dice: 0.8389, decode.d4.loss_cls: 0.4247, decode.d4.loss_mask: 0.5811, decode.d4.loss_dice: 0.8392, decode.d5.loss_cls: 0.4132, decode.d5.loss_mask: 0.5750, decode.d5.loss_dice: 0.8358, decode.d6.loss_cls: 0.4107, decode.d6.loss_mask: 0.5750, decode.d6.loss_dice: 0.8314, decode.d7.loss_cls: 0.4045, decode.d7.loss_mask: 0.5738, decode.d7.loss_dice: 0.8303, decode.d8.loss_cls: 0.4029, decode.d8.loss_mask: 0.5735, decode.d8.loss_dice: 0.8308, loss: 24.8977
2022-11-30 16:33:38,704 - mmseg - INFO - Iter [16500/40000]	lr: 7.816e-08, eta: 1 day, 4:33:08, time: 4.121, data_time: 0.018, memory: 51902, decode.loss_cls: 0.4139, decode.loss_mask: 0.5751, decode.loss_dice: 0.8357, decode.d0.loss_cls: 6.7617, decode.d0.loss_mask: 0.5531, decode.d0.loss_dice: 0.8952, decode.d1.loss_cls: 0.5289, decode.d1.loss_mask: 0.6038, decode.d1.loss_dice: 0.8973, decode.d2.loss_cls: 0.4707, decode.d2.loss_mask: 0.5850, decode.d2.loss_dice: 0.8539, decode.d3.loss_cls: 0.4356, decode.d3.loss_mask: 0.5812, decode.d3.loss_dice: 0.8442, decode.d4.loss_cls: 0.4284, decode.d4.loss_mask: 0.5800, decode.d4.loss_dice: 0.8459, decode.d5.loss_cls: 0.4149, decode.d5.loss_mask: 0.5764, decode.d5.loss_dice: 0.8416, decode.d6.loss_cls: 0.4135, decode.d6.loss_mask: 0.5757, decode.d6.loss_dice: 0.8360, decode.d7.loss_cls: 0.4141, decode.d7.loss_mask: 0.5766, decode.d7.loss_dice: 0.8343, decode.d8.loss_cls: 0.4088, decode.d8.loss_mask: 0.5776, decode.d8.loss_dice: 0.8356, loss: 24.9946
2022-11-30 16:37:04,463 - mmseg - INFO - Iter [16550/40000]	lr: 7.799e-08, eta: 1 day, 4:29:11, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4147, decode.loss_mask: 0.5641, decode.loss_dice: 0.8323, decode.d0.loss_cls: 6.7649, decode.d0.loss_mask: 0.5452, decode.d0.loss_dice: 0.9116, decode.d1.loss_cls: 0.5349, decode.d1.loss_mask: 0.5911, decode.d1.loss_dice: 0.8929, decode.d2.loss_cls: 0.4689, decode.d2.loss_mask: 0.5757, decode.d2.loss_dice: 0.8595, decode.d3.loss_cls: 0.4349, decode.d3.loss_mask: 0.5699, decode.d3.loss_dice: 0.8417, decode.d4.loss_cls: 0.4292, decode.d4.loss_mask: 0.5683, decode.d4.loss_dice: 0.8424, decode.d5.loss_cls: 0.4164, decode.d5.loss_mask: 0.5683, decode.d5.loss_dice: 0.8408, decode.d6.loss_cls: 0.4142, decode.d6.loss_mask: 0.5655, decode.d6.loss_dice: 0.8344, decode.d7.loss_cls: 0.4139, decode.d7.loss_mask: 0.5657, decode.d7.loss_dice: 0.8354, decode.d8.loss_cls: 0.4155, decode.d8.loss_mask: 0.5641, decode.d8.loss_dice: 0.8321, loss: 24.9085
2022-11-30 16:40:30,419 - mmseg - INFO - Iter [16600/40000]	lr: 7.782e-08, eta: 1 day, 4:25:15, time: 4.119, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4266, decode.loss_mask: 0.5789, decode.loss_dice: 0.8458, decode.d0.loss_cls: 6.7492, decode.d0.loss_mask: 0.5568, decode.d0.loss_dice: 0.9061, decode.d1.loss_cls: 0.5391, decode.d1.loss_mask: 0.6011, decode.d1.loss_dice: 0.9003, decode.d2.loss_cls: 0.4812, decode.d2.loss_mask: 0.5908, decode.d2.loss_dice: 0.8676, decode.d3.loss_cls: 0.4488, decode.d3.loss_mask: 0.5830, decode.d3.loss_dice: 0.8559, decode.d4.loss_cls: 0.4431, decode.d4.loss_mask: 0.5820, decode.d4.loss_dice: 0.8505, decode.d5.loss_cls: 0.4324, decode.d5.loss_mask: 0.5818, decode.d5.loss_dice: 0.8496, decode.d6.loss_cls: 0.4299, decode.d6.loss_mask: 0.5794, decode.d6.loss_dice: 0.8421, decode.d7.loss_cls: 0.4228, decode.d7.loss_mask: 0.5791, decode.d7.loss_dice: 0.8483, decode.d8.loss_cls: 0.4256, decode.d8.loss_mask: 0.5807, decode.d8.loss_dice: 0.8516, loss: 25.2298
2022-11-30 16:43:55,759 - mmseg - INFO - Iter [16650/40000]	lr: 7.766e-08, eta: 1 day, 4:21:18, time: 4.107, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4224, decode.loss_mask: 0.5671, decode.loss_dice: 0.8427, decode.d0.loss_cls: 6.7375, decode.d0.loss_mask: 0.5484, decode.d0.loss_dice: 0.9040, decode.d1.loss_cls: 0.5387, decode.d1.loss_mask: 0.5916, decode.d1.loss_dice: 0.8975, decode.d2.loss_cls: 0.4784, decode.d2.loss_mask: 0.5813, decode.d2.loss_dice: 0.8668, decode.d3.loss_cls: 0.4431, decode.d3.loss_mask: 0.5729, decode.d3.loss_dice: 0.8518, decode.d4.loss_cls: 0.4341, decode.d4.loss_mask: 0.5718, decode.d4.loss_dice: 0.8505, decode.d5.loss_cls: 0.4264, decode.d5.loss_mask: 0.5690, decode.d5.loss_dice: 0.8469, decode.d6.loss_cls: 0.4242, decode.d6.loss_mask: 0.5691, decode.d6.loss_dice: 0.8466, decode.d7.loss_cls: 0.4204, decode.d7.loss_mask: 0.5697, decode.d7.loss_dice: 0.8457, decode.d8.loss_cls: 0.4197, decode.d8.loss_mask: 0.5663, decode.d8.loss_dice: 0.8466, loss: 25.0511
2022-11-30 16:47:21,484 - mmseg - INFO - Iter [16700/40000]	lr: 7.749e-08, eta: 1 day, 4:17:21, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4292, decode.loss_mask: 0.5737, decode.loss_dice: 0.8424, decode.d0.loss_cls: 6.7261, decode.d0.loss_mask: 0.5556, decode.d0.loss_dice: 0.9119, decode.d1.loss_cls: 0.5476, decode.d1.loss_mask: 0.5989, decode.d1.loss_dice: 0.9092, decode.d2.loss_cls: 0.4872, decode.d2.loss_mask: 0.5819, decode.d2.loss_dice: 0.8694, decode.d3.loss_cls: 0.4512, decode.d3.loss_mask: 0.5760, decode.d3.loss_dice: 0.8562, decode.d4.loss_cls: 0.4421, decode.d4.loss_mask: 0.5769, decode.d4.loss_dice: 0.8553, decode.d5.loss_cls: 0.4311, decode.d5.loss_mask: 0.5750, decode.d5.loss_dice: 0.8470, decode.d6.loss_cls: 0.4262, decode.d6.loss_mask: 0.5755, decode.d6.loss_dice: 0.8445, decode.d7.loss_cls: 0.4262, decode.d7.loss_mask: 0.5740, decode.d7.loss_dice: 0.8413, decode.d8.loss_cls: 0.4269, decode.d8.loss_mask: 0.5745, decode.d8.loss_dice: 0.8398, loss: 25.1726
2022-11-30 16:50:47,239 - mmseg - INFO - Iter [16750/40000]	lr: 7.733e-08, eta: 1 day, 4:13:25, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4178, decode.loss_mask: 0.5736, decode.loss_dice: 0.8216, decode.d0.loss_cls: 6.7241, decode.d0.loss_mask: 0.5573, decode.d0.loss_dice: 0.8836, decode.d1.loss_cls: 0.5234, decode.d1.loss_mask: 0.5986, decode.d1.loss_dice: 0.8797, decode.d2.loss_cls: 0.4714, decode.d2.loss_mask: 0.5858, decode.d2.loss_dice: 0.8453, decode.d3.loss_cls: 0.4424, decode.d3.loss_mask: 0.5771, decode.d3.loss_dice: 0.8304, decode.d4.loss_cls: 0.4287, decode.d4.loss_mask: 0.5767, decode.d4.loss_dice: 0.8327, decode.d5.loss_cls: 0.4210, decode.d5.loss_mask: 0.5750, decode.d5.loss_dice: 0.8270, decode.d6.loss_cls: 0.4215, decode.d6.loss_mask: 0.5706, decode.d6.loss_dice: 0.8204, decode.d7.loss_cls: 0.4149, decode.d7.loss_mask: 0.5745, decode.d7.loss_dice: 0.8231, decode.d8.loss_cls: 0.4165, decode.d8.loss_mask: 0.5733, decode.d8.loss_dice: 0.8205, loss: 24.8284
2022-11-30 16:54:13,063 - mmseg - INFO - Iter [16800/40000]	lr: 7.716e-08, eta: 1 day, 4:09:29, time: 4.116, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4055, decode.loss_mask: 0.5676, decode.loss_dice: 0.8209, decode.d0.loss_cls: 6.7146, decode.d0.loss_mask: 0.5457, decode.d0.loss_dice: 0.8861, decode.d1.loss_cls: 0.5221, decode.d1.loss_mask: 0.5902, decode.d1.loss_dice: 0.8792, decode.d2.loss_cls: 0.4608, decode.d2.loss_mask: 0.5806, decode.d2.loss_dice: 0.8458, decode.d3.loss_cls: 0.4311, decode.d3.loss_mask: 0.5728, decode.d3.loss_dice: 0.8293, decode.d4.loss_cls: 0.4197, decode.d4.loss_mask: 0.5719, decode.d4.loss_dice: 0.8297, decode.d5.loss_cls: 0.4116, decode.d5.loss_mask: 0.5694, decode.d5.loss_dice: 0.8207, decode.d6.loss_cls: 0.4083, decode.d6.loss_mask: 0.5692, decode.d6.loss_dice: 0.8185, decode.d7.loss_cls: 0.4040, decode.d7.loss_mask: 0.5691, decode.d7.loss_dice: 0.8213, decode.d8.loss_cls: 0.4011, decode.d8.loss_mask: 0.5694, decode.d8.loss_dice: 0.8224, loss: 24.6587
2022-11-30 16:57:38,676 - mmseg - INFO - Iter [16850/40000]	lr: 7.699e-08, eta: 1 day, 4:05:33, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4374, decode.loss_mask: 0.5741, decode.loss_dice: 0.8485, decode.d0.loss_cls: 6.7076, decode.d0.loss_mask: 0.5561, decode.d0.loss_dice: 0.9217, decode.d1.loss_cls: 0.5615, decode.d1.loss_mask: 0.5958, decode.d1.loss_dice: 0.9063, decode.d2.loss_cls: 0.4915, decode.d2.loss_mask: 0.5864, decode.d2.loss_dice: 0.8718, decode.d3.loss_cls: 0.4623, decode.d3.loss_mask: 0.5790, decode.d3.loss_dice: 0.8526, decode.d4.loss_cls: 0.4544, decode.d4.loss_mask: 0.5780, decode.d4.loss_dice: 0.8506, decode.d5.loss_cls: 0.4413, decode.d5.loss_mask: 0.5744, decode.d5.loss_dice: 0.8506, decode.d6.loss_cls: 0.4369, decode.d6.loss_mask: 0.5746, decode.d6.loss_dice: 0.8462, decode.d7.loss_cls: 0.4375, decode.d7.loss_mask: 0.5749, decode.d7.loss_dice: 0.8460, decode.d8.loss_cls: 0.4362, decode.d8.loss_mask: 0.5751, decode.d8.loss_dice: 0.8471, loss: 25.2765
2022-11-30 17:01:04,229 - mmseg - INFO - Iter [16900/40000]	lr: 7.683e-08, eta: 1 day, 4:01:37, time: 4.111, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4079, decode.loss_mask: 0.5913, decode.loss_dice: 0.8462, decode.d0.loss_cls: 6.6975, decode.d0.loss_mask: 0.5667, decode.d0.loss_dice: 0.9086, decode.d1.loss_cls: 0.5262, decode.d1.loss_mask: 0.6118, decode.d1.loss_dice: 0.9074, decode.d2.loss_cls: 0.4646, decode.d2.loss_mask: 0.6010, decode.d2.loss_dice: 0.8657, decode.d3.loss_cls: 0.4330, decode.d3.loss_mask: 0.5952, decode.d3.loss_dice: 0.8540, decode.d4.loss_cls: 0.4246, decode.d4.loss_mask: 0.5922, decode.d4.loss_dice: 0.8530, decode.d5.loss_cls: 0.4157, decode.d5.loss_mask: 0.5906, decode.d5.loss_dice: 0.8498, decode.d6.loss_cls: 0.4103, decode.d6.loss_mask: 0.5932, decode.d6.loss_dice: 0.8451, decode.d7.loss_cls: 0.4100, decode.d7.loss_mask: 0.5897, decode.d7.loss_dice: 0.8455, decode.d8.loss_cls: 0.4057, decode.d8.loss_mask: 0.5909, decode.d8.loss_dice: 0.8509, loss: 25.1443
2022-11-30 17:04:29,823 - mmseg - INFO - Iter [16950/40000]	lr: 7.666e-08, eta: 1 day, 3:57:41, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4120, decode.loss_mask: 0.5657, decode.loss_dice: 0.8359, decode.d0.loss_cls: 6.6863, decode.d0.loss_mask: 0.5492, decode.d0.loss_dice: 0.9083, decode.d1.loss_cls: 0.5395, decode.d1.loss_mask: 0.5883, decode.d1.loss_dice: 0.8989, decode.d2.loss_cls: 0.4708, decode.d2.loss_mask: 0.5786, decode.d2.loss_dice: 0.8574, decode.d3.loss_cls: 0.4399, decode.d3.loss_mask: 0.5709, decode.d3.loss_dice: 0.8441, decode.d4.loss_cls: 0.4316, decode.d4.loss_mask: 0.5703, decode.d4.loss_dice: 0.8410, decode.d5.loss_cls: 0.4189, decode.d5.loss_mask: 0.5676, decode.d5.loss_dice: 0.8405, decode.d6.loss_cls: 0.4196, decode.d6.loss_mask: 0.5646, decode.d6.loss_dice: 0.8389, decode.d7.loss_cls: 0.4112, decode.d7.loss_mask: 0.5642, decode.d7.loss_dice: 0.8381, decode.d8.loss_cls: 0.4125, decode.d8.loss_mask: 0.5647, decode.d8.loss_dice: 0.8363, loss: 24.8658
2022-11-30 17:07:55,618 - mmseg - INFO - Saving checkpoint at 17000 iterations
2022-11-30 17:08:47,754 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 17:08:47,755 - mmseg - INFO - Iter [17000/40000]	lr: 7.649e-08, eta: 1 day, 3:54:56, time: 5.159, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4182, decode.loss_mask: 0.5844, decode.loss_dice: 0.8309, decode.d0.loss_cls: 6.6644, decode.d0.loss_mask: 0.5671, decode.d0.loss_dice: 0.9037, decode.d1.loss_cls: 0.5395, decode.d1.loss_mask: 0.6074, decode.d1.loss_dice: 0.8977, decode.d2.loss_cls: 0.4812, decode.d2.loss_mask: 0.5946, decode.d2.loss_dice: 0.8565, decode.d3.loss_cls: 0.4445, decode.d3.loss_mask: 0.5894, decode.d3.loss_dice: 0.8415, decode.d4.loss_cls: 0.4412, decode.d4.loss_mask: 0.5871, decode.d4.loss_dice: 0.8401, decode.d5.loss_cls: 0.4248, decode.d5.loss_mask: 0.5867, decode.d5.loss_dice: 0.8347, decode.d6.loss_cls: 0.4211, decode.d6.loss_mask: 0.5846, decode.d6.loss_dice: 0.8323, decode.d7.loss_cls: 0.4225, decode.d7.loss_mask: 0.5849, decode.d7.loss_dice: 0.8337, decode.d8.loss_cls: 0.4219, decode.d8.loss_mask: 0.5828, decode.d8.loss_dice: 0.8325, loss: 25.0522
2022-11-30 17:11:45,755 - mmseg - INFO - per class results:
2022-11-30 17:11:45,760 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 82.46 | 88.53 |
|       building      | 85.53 | 92.65 |
|         sky         | 95.07 | 97.59 |
|        floor        | 85.07 | 90.12 |
|         tree        | 78.33 | 87.23 |
|       ceiling       | 87.03 |  93.0 |
|         road        | 88.13 | 91.87 |
|         bed         | 93.66 | 97.14 |
|      windowpane     | 67.42 |  82.8 |
|        grass        | 65.71 | 76.74 |
|       cabinet       | 62.52 | 71.58 |
|       sidewalk      | 73.42 | 87.93 |
|        person       | 88.36 | 93.95 |
|        earth        |  41.7 | 56.46 |
|         door        |  62.9 | 84.42 |
|        table        | 72.52 | 81.34 |
|       mountain      |  56.0 | 67.48 |
|        plant        | 56.41 | 72.35 |
|       curtain       | 81.35 | 91.68 |
|        chair        | 68.03 | 78.24 |
|         car         | 89.46 | 94.89 |
|        water        | 59.95 | 73.24 |
|       painting      | 82.67 |  92.0 |
|         sofa        | 86.74 | 92.22 |
|        shelf        | 48.38 | 62.42 |
|        house        | 53.26 | 66.49 |
|         sea         | 72.03 | 89.63 |
|        mirror       |  81.3 |  91.5 |
|         rug         | 72.71 | 86.93 |
|        field        |  34.8 | 76.06 |
|       armchair      | 63.65 | 80.06 |
|         seat        | 67.76 | 89.07 |
|        fence        | 56.98 | 77.21 |
|         desk        | 58.19 | 84.29 |
|         rock        | 59.65 | 79.32 |
|       wardrobe      | 53.94 |  78.5 |
|         lamp        | 80.21 | 89.32 |
|       bathtub       | 91.82 | 93.86 |
|       railing       | 47.91 | 69.65 |
|       cushion       |  77.1 |  91.4 |
|         base        | 41.73 |  76.4 |
|         box         | 41.79 | 59.28 |
|        column       | 59.78 | 74.68 |
|      signboard      | 45.01 | 68.48 |
|   chest of drawers  |  44.2 | 73.51 |
|       counter       | 51.77 | 68.51 |
|         sand        | 58.83 | 88.65 |
|         sink        | 82.22 | 87.44 |
|      skyscraper     | 43.65 | 55.16 |
|      fireplace      | 79.22 | 97.18 |
|     refrigerator    | 84.86 | 95.51 |
|      grandstand     | 46.71 | 83.45 |
|         path        | 21.25 | 25.62 |
|        stairs       | 35.75 | 46.62 |
|        runway       | 74.51 | 94.52 |
|         case        |  72.7 | 88.64 |
|      pool table     | 95.58 | 98.27 |
|        pillow       | 72.59 | 82.25 |
|     screen door     | 83.04 | 90.33 |
|       stairway      | 59.07 | 72.75 |
|        river        | 23.74 | 40.62 |
|        bridge       | 81.72 | 89.54 |
|       bookcase      | 39.82 | 59.86 |
|        blind        |  40.3 | 48.32 |
|     coffee table    | 73.54 | 90.89 |
|        toilet       | 92.94 | 96.48 |
|        flower       |  43.7 | 68.24 |
|         book        | 60.85 | 82.16 |
|         hill        |  7.84 | 15.11 |
|        bench        | 68.62 | 84.71 |
|      countertop     | 71.62 | 85.38 |
|        stove        | 85.21 | 90.17 |
|         palm        | 56.61 | 80.76 |
|    kitchen island   | 44.72 |  93.1 |
|       computer      | 82.17 | 90.16 |
|     swivel chair    | 55.56 |  85.8 |
|         boat        |  68.5 | 88.14 |
|         bar         | 67.95 | 73.42 |
|    arcade machine   | 90.97 | 98.61 |
|        hovel        | 50.36 | 74.51 |
|         bus         | 94.54 | 96.36 |
|        towel        | 79.63 | 94.98 |
|        light        | 65.41 | 79.52 |
|        truck        |  51.9 | 74.53 |
|        tower        | 33.17 | 62.95 |
|      chandelier     | 76.33 | 87.66 |
|        awning       | 33.56 | 52.33 |
|     streetlight     | 45.05 | 67.79 |
|        booth        | 51.48 | 60.25 |
| television receiver | 73.61 | 89.06 |
|       airplane      | 88.64 | 96.54 |
|      dirt track     |  2.97 |  5.54 |
|       apparel       | 54.12 | 87.89 |
|         pole        | 37.34 | 48.53 |
|         land        |  1.23 |  1.92 |
|      bannister      | 21.21 | 32.75 |
|      escalator      | 64.74 | 84.86 |
|       ottoman       | 59.34 | 82.98 |
|        bottle       |  52.1 | 82.33 |
|        buffet       | 43.44 | 65.12 |
|        poster       | 45.43 | 74.14 |
|        stage        | 30.81 | 75.54 |
|         van         | 53.54 |  76.2 |
|         ship        | 18.82 | 19.81 |
|       fountain      | 41.69 | 45.24 |
|    conveyer belt    | 73.01 | 97.32 |
|        canopy       | 58.59 | 78.81 |
|        washer       | 91.27 | 93.89 |
|      plaything      | 39.59 | 63.03 |
|    swimming pool    | 49.22 | 74.73 |
|        stool        | 53.26 | 85.96 |
|        barrel       | 82.49 | 92.64 |
|        basket       | 47.85 | 76.47 |
|      waterfall      | 46.43 | 57.75 |
|         tent        | 96.27 | 98.12 |
|         bag         | 35.57 | 47.59 |
|       minibike      | 81.38 | 93.33 |
|        cradle       | 91.35 | 97.33 |
|         oven        | 69.99 | 82.38 |
|         ball        | 41.05 | 45.08 |
|         food        | 64.14 | 74.52 |
|         step        | 21.45 | 33.31 |
|         tank        | 60.61 | 67.61 |
|      trade name     | 27.62 | 30.94 |
|      microwave      | 91.42 | 96.98 |
|         pot         |  60.8 | 74.33 |
|        animal       | 85.14 | 88.59 |
|       bicycle       | 61.42 | 83.13 |
|         lake        |  5.39 |  8.37 |
|      dishwasher     | 80.36 | 90.35 |
|        screen       | 60.97 | 96.42 |
|       blanket       | 38.64 | 51.73 |
|      sculpture      | 71.37 | 90.77 |
|         hood        | 75.23 | 95.12 |
|        sconce       | 66.91 | 82.15 |
|         vase        | 57.53 | 82.36 |
|    traffic light    | 51.51 | 70.98 |
|         tray        | 28.85 | 42.34 |
|        ashcan       | 54.36 | 74.86 |
|         fan         | 72.45 | 86.41 |
|         pier        |  37.8 | 41.23 |
|      crt screen     |  5.44 | 15.13 |
|        plate        | 68.83 | 85.38 |
|       monitor       |  3.63 |  4.56 |
|    bulletin board   | 65.08 | 84.39 |
|        shower       | 20.72 | 31.15 |
|       radiator      | 71.34 | 93.79 |
|        glass        | 29.07 | 32.46 |
|        clock        | 61.54 | 77.35 |
|         flag        | 69.97 | 86.68 |
+---------------------+-------+-------+
2022-11-30 17:11:45,760 - mmseg - INFO - Summary:
2022-11-30 17:11:45,760 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 86.49 | 59.85 | 74.71 |
+-------+-------+-------+
2022-11-30 17:11:45,765 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 17:11:45,765 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8649, mIoU: 0.5985, mAcc: 0.7471, IoU.wall: 0.8246, IoU.building: 0.8553, IoU.sky: 0.9507, IoU.floor: 0.8507, IoU.tree: 0.7833, IoU.ceiling: 0.8703, IoU.road: 0.8813, IoU.bed : 0.9366, IoU.windowpane: 0.6742, IoU.grass: 0.6571, IoU.cabinet: 0.6252, IoU.sidewalk: 0.7342, IoU.person: 0.8836, IoU.earth: 0.4170, IoU.door: 0.6290, IoU.table: 0.7252, IoU.mountain: 0.5600, IoU.plant: 0.5641, IoU.curtain: 0.8135, IoU.chair: 0.6803, IoU.car: 0.8946, IoU.water: 0.5995, IoU.painting: 0.8267, IoU.sofa: 0.8674, IoU.shelf: 0.4838, IoU.house: 0.5326, IoU.sea: 0.7203, IoU.mirror: 0.8130, IoU.rug: 0.7271, IoU.field: 0.3480, IoU.armchair: 0.6365, IoU.seat: 0.6776, IoU.fence: 0.5698, IoU.desk: 0.5819, IoU.rock: 0.5965, IoU.wardrobe: 0.5394, IoU.lamp: 0.8021, IoU.bathtub: 0.9182, IoU.railing: 0.4791, IoU.cushion: 0.7710, IoU.base: 0.4173, IoU.box: 0.4179, IoU.column: 0.5978, IoU.signboard: 0.4501, IoU.chest of drawers: 0.4420, IoU.counter: 0.5177, IoU.sand: 0.5883, IoU.sink: 0.8222, IoU.skyscraper: 0.4365, IoU.fireplace: 0.7922, IoU.refrigerator: 0.8486, IoU.grandstand: 0.4671, IoU.path: 0.2125, IoU.stairs: 0.3575, IoU.runway: 0.7451, IoU.case: 0.7270, IoU.pool table: 0.9558, IoU.pillow: 0.7259, IoU.screen door: 0.8304, IoU.stairway: 0.5907, IoU.river: 0.2374, IoU.bridge: 0.8172, IoU.bookcase: 0.3982, IoU.blind: 0.4030, IoU.coffee table: 0.7354, IoU.toilet: 0.9294, IoU.flower: 0.4370, IoU.book: 0.6085, IoU.hill: 0.0784, IoU.bench: 0.6862, IoU.countertop: 0.7162, IoU.stove: 0.8521, IoU.palm: 0.5661, IoU.kitchen island: 0.4472, IoU.computer: 0.8217, IoU.swivel chair: 0.5556, IoU.boat: 0.6850, IoU.bar: 0.6795, IoU.arcade machine: 0.9097, IoU.hovel: 0.5036, IoU.bus: 0.9454, IoU.towel: 0.7963, IoU.light: 0.6541, IoU.truck: 0.5190, IoU.tower: 0.3317, IoU.chandelier: 0.7633, IoU.awning: 0.3356, IoU.streetlight: 0.4505, IoU.booth: 0.5148, IoU.television receiver: 0.7361, IoU.airplane: 0.8864, IoU.dirt track: 0.0297, IoU.apparel: 0.5412, IoU.pole: 0.3734, IoU.land: 0.0123, IoU.bannister: 0.2121, IoU.escalator: 0.6474, IoU.ottoman: 0.5934, IoU.bottle: 0.5210, IoU.buffet: 0.4344, IoU.poster: 0.4543, IoU.stage: 0.3081, IoU.van: 0.5354, IoU.ship: 0.1882, IoU.fountain: 0.4169, IoU.conveyer belt: 0.7301, IoU.canopy: 0.5859, IoU.washer: 0.9127, IoU.plaything: 0.3959, IoU.swimming pool: 0.4922, IoU.stool: 0.5326, IoU.barrel: 0.8249, IoU.basket: 0.4785, IoU.waterfall: 0.4643, IoU.tent: 0.9627, IoU.bag: 0.3557, IoU.minibike: 0.8138, IoU.cradle: 0.9135, IoU.oven: 0.6999, IoU.ball: 0.4105, IoU.food: 0.6414, IoU.step: 0.2145, IoU.tank: 0.6061, IoU.trade name: 0.2762, IoU.microwave: 0.9142, IoU.pot: 0.6080, IoU.animal: 0.8514, IoU.bicycle: 0.6142, IoU.lake: 0.0539, IoU.dishwasher: 0.8036, IoU.screen: 0.6097, IoU.blanket: 0.3864, IoU.sculpture: 0.7137, IoU.hood: 0.7523, IoU.sconce: 0.6691, IoU.vase: 0.5753, IoU.traffic light: 0.5151, IoU.tray: 0.2885, IoU.ashcan: 0.5436, IoU.fan: 0.7245, IoU.pier: 0.3780, IoU.crt screen: 0.0544, IoU.plate: 0.6883, IoU.monitor: 0.0363, IoU.bulletin board: 0.6508, IoU.shower: 0.2072, IoU.radiator: 0.7134, IoU.glass: 0.2907, IoU.clock: 0.6154, IoU.flag: 0.6997, Acc.wall: 0.8853, Acc.building: 0.9265, Acc.sky: 0.9759, Acc.floor: 0.9012, Acc.tree: 0.8723, Acc.ceiling: 0.9300, Acc.road: 0.9187, Acc.bed : 0.9714, Acc.windowpane: 0.8280, Acc.grass: 0.7674, Acc.cabinet: 0.7158, Acc.sidewalk: 0.8793, Acc.person: 0.9395, Acc.earth: 0.5646, Acc.door: 0.8442, Acc.table: 0.8134, Acc.mountain: 0.6748, Acc.plant: 0.7235, Acc.curtain: 0.9168, Acc.chair: 0.7824, Acc.car: 0.9489, Acc.water: 0.7324, Acc.painting: 0.9200, Acc.sofa: 0.9222, Acc.shelf: 0.6242, Acc.house: 0.6649, Acc.sea: 0.8963, Acc.mirror: 0.9150, Acc.rug: 0.8693, Acc.field: 0.7606, Acc.armchair: 0.8006, Acc.seat: 0.8907, Acc.fence: 0.7721, Acc.desk: 0.8429, Acc.rock: 0.7932, Acc.wardrobe: 0.7850, Acc.lamp: 0.8932, Acc.bathtub: 0.9386, Acc.railing: 0.6965, Acc.cushion: 0.9140, Acc.base: 0.7640, Acc.box: 0.5928, Acc.column: 0.7468, Acc.signboard: 0.6848, Acc.chest of drawers: 0.7351, Acc.counter: 0.6851, Acc.sand: 0.8865, Acc.sink: 0.8744, Acc.skyscraper: 0.5516, Acc.fireplace: 0.9718, Acc.refrigerator: 0.9551, Acc.grandstand: 0.8345, Acc.path: 0.2562, Acc.stairs: 0.4662, Acc.runway: 0.9452, Acc.case: 0.8864, Acc.pool table: 0.9827, Acc.pillow: 0.8225, Acc.screen door: 0.9033, Acc.stairway: 0.7275, Acc.river: 0.4062, Acc.bridge: 0.8954, Acc.bookcase: 0.5986, Acc.blind: 0.4832, Acc.coffee table: 0.9089, Acc.toilet: 0.9648, Acc.flower: 0.6824, Acc.book: 0.8216, Acc.hill: 0.1511, Acc.bench: 0.8471, Acc.countertop: 0.8538, Acc.stove: 0.9017, Acc.palm: 0.8076, Acc.kitchen island: 0.9310, Acc.computer: 0.9016, Acc.swivel chair: 0.8580, Acc.boat: 0.8814, Acc.bar: 0.7342, Acc.arcade machine: 0.9861, Acc.hovel: 0.7451, Acc.bus: 0.9636, Acc.towel: 0.9498, Acc.light: 0.7952, Acc.truck: 0.7453, Acc.tower: 0.6295, Acc.chandelier: 0.8766, Acc.awning: 0.5233, Acc.streetlight: 0.6779, Acc.booth: 0.6025, Acc.television receiver: 0.8906, Acc.airplane: 0.9654, Acc.dirt track: 0.0554, Acc.apparel: 0.8789, Acc.pole: 0.4853, Acc.land: 0.0192, Acc.bannister: 0.3275, Acc.escalator: 0.8486, Acc.ottoman: 0.8298, Acc.bottle: 0.8233, Acc.buffet: 0.6512, Acc.poster: 0.7414, Acc.stage: 0.7554, Acc.van: 0.7620, Acc.ship: 0.1981, Acc.fountain: 0.4524, Acc.conveyer belt: 0.9732, Acc.canopy: 0.7881, Acc.washer: 0.9389, Acc.plaything: 0.6303, Acc.swimming pool: 0.7473, Acc.stool: 0.8596, Acc.barrel: 0.9264, Acc.basket: 0.7647, Acc.waterfall: 0.5775, Acc.tent: 0.9812, Acc.bag: 0.4759, Acc.minibike: 0.9333, Acc.cradle: 0.9733, Acc.oven: 0.8238, Acc.ball: 0.4508, Acc.food: 0.7452, Acc.step: 0.3331, Acc.tank: 0.6761, Acc.trade name: 0.3094, Acc.microwave: 0.9698, Acc.pot: 0.7433, Acc.animal: 0.8859, Acc.bicycle: 0.8313, Acc.lake: 0.0837, Acc.dishwasher: 0.9035, Acc.screen: 0.9642, Acc.blanket: 0.5173, Acc.sculpture: 0.9077, Acc.hood: 0.9512, Acc.sconce: 0.8215, Acc.vase: 0.8236, Acc.traffic light: 0.7098, Acc.tray: 0.4234, Acc.ashcan: 0.7486, Acc.fan: 0.8641, Acc.pier: 0.4123, Acc.crt screen: 0.1513, Acc.plate: 0.8538, Acc.monitor: 0.0456, Acc.bulletin board: 0.8439, Acc.shower: 0.3115, Acc.radiator: 0.9379, Acc.glass: 0.3246, Acc.clock: 0.7735, Acc.flag: 0.8668
2022-11-30 17:15:11,805 - mmseg - INFO - Iter [17050/40000]	lr: 7.633e-08, eta: 1 day, 3:55:00, time: 7.681, data_time: 3.579, memory: 51902, decode.loss_cls: 0.4108, decode.loss_mask: 0.5845, decode.loss_dice: 0.8374, decode.d0.loss_cls: 6.6666, decode.d0.loss_mask: 0.5671, decode.d0.loss_dice: 0.9124, decode.d1.loss_cls: 0.5298, decode.d1.loss_mask: 0.6102, decode.d1.loss_dice: 0.8966, decode.d2.loss_cls: 0.4710, decode.d2.loss_mask: 0.5929, decode.d2.loss_dice: 0.8621, decode.d3.loss_cls: 0.4364, decode.d3.loss_mask: 0.5891, decode.d3.loss_dice: 0.8498, decode.d4.loss_cls: 0.4263, decode.d4.loss_mask: 0.5863, decode.d4.loss_dice: 0.8438, decode.d5.loss_cls: 0.4175, decode.d5.loss_mask: 0.5855, decode.d5.loss_dice: 0.8404, decode.d6.loss_cls: 0.4174, decode.d6.loss_mask: 0.5812, decode.d6.loss_dice: 0.8354, decode.d7.loss_cls: 0.4110, decode.d7.loss_mask: 0.5828, decode.d7.loss_dice: 0.8373, decode.d8.loss_cls: 0.4131, decode.d8.loss_mask: 0.5838, decode.d8.loss_dice: 0.8353, loss: 25.0140
2022-11-30 17:18:39,709 - mmseg - INFO - Iter [17100/40000]	lr: 7.616e-08, eta: 1 day, 3:51:07, time: 4.158, data_time: 0.064, memory: 51902, decode.loss_cls: 0.3916, decode.loss_mask: 0.5574, decode.loss_dice: 0.8194, decode.d0.loss_cls: 6.6600, decode.d0.loss_mask: 0.5445, decode.d0.loss_dice: 0.8823, decode.d1.loss_cls: 0.5152, decode.d1.loss_mask: 0.5826, decode.d1.loss_dice: 0.8792, decode.d2.loss_cls: 0.4513, decode.d2.loss_mask: 0.5652, decode.d2.loss_dice: 0.8457, decode.d3.loss_cls: 0.4158, decode.d3.loss_mask: 0.5641, decode.d3.loss_dice: 0.8306, decode.d4.loss_cls: 0.4088, decode.d4.loss_mask: 0.5618, decode.d4.loss_dice: 0.8273, decode.d5.loss_cls: 0.3984, decode.d5.loss_mask: 0.5603, decode.d5.loss_dice: 0.8248, decode.d6.loss_cls: 0.3922, decode.d6.loss_mask: 0.5589, decode.d6.loss_dice: 0.8218, decode.d7.loss_cls: 0.3938, decode.d7.loss_mask: 0.5593, decode.d7.loss_dice: 0.8205, decode.d8.loss_cls: 0.3890, decode.d8.loss_mask: 0.5605, decode.d8.loss_dice: 0.8223, loss: 24.4049
2022-11-30 17:22:05,586 - mmseg - INFO - Iter [17150/40000]	lr: 7.600e-08, eta: 1 day, 3:47:10, time: 4.118, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4018, decode.loss_mask: 0.5717, decode.loss_dice: 0.8338, decode.d0.loss_cls: 6.6563, decode.d0.loss_mask: 0.5534, decode.d0.loss_dice: 0.9088, decode.d1.loss_cls: 0.5246, decode.d1.loss_mask: 0.5961, decode.d1.loss_dice: 0.8950, decode.d2.loss_cls: 0.4656, decode.d2.loss_mask: 0.5839, decode.d2.loss_dice: 0.8625, decode.d3.loss_cls: 0.4338, decode.d3.loss_mask: 0.5766, decode.d3.loss_dice: 0.8444, decode.d4.loss_cls: 0.4164, decode.d4.loss_mask: 0.5737, decode.d4.loss_dice: 0.8436, decode.d5.loss_cls: 0.4083, decode.d5.loss_mask: 0.5729, decode.d5.loss_dice: 0.8402, decode.d6.loss_cls: 0.4014, decode.d6.loss_mask: 0.5730, decode.d6.loss_dice: 0.8372, decode.d7.loss_cls: 0.4031, decode.d7.loss_mask: 0.5693, decode.d7.loss_dice: 0.8340, decode.d8.loss_cls: 0.3978, decode.d8.loss_mask: 0.5724, decode.d8.loss_dice: 0.8361, loss: 24.7880
2022-11-30 17:25:31,264 - mmseg - INFO - Iter [17200/40000]	lr: 7.583e-08, eta: 1 day, 3:43:14, time: 4.113, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4033, decode.loss_mask: 0.5679, decode.loss_dice: 0.8386, decode.d0.loss_cls: 6.6516, decode.d0.loss_mask: 0.5516, decode.d0.loss_dice: 0.9065, decode.d1.loss_cls: 0.5265, decode.d1.loss_mask: 0.5938, decode.d1.loss_dice: 0.8975, decode.d2.loss_cls: 0.4667, decode.d2.loss_mask: 0.5805, decode.d2.loss_dice: 0.8617, decode.d3.loss_cls: 0.4318, decode.d3.loss_mask: 0.5737, decode.d3.loss_dice: 0.8501, decode.d4.loss_cls: 0.4187, decode.d4.loss_mask: 0.5739, decode.d4.loss_dice: 0.8464, decode.d5.loss_cls: 0.4112, decode.d5.loss_mask: 0.5709, decode.d5.loss_dice: 0.8460, decode.d6.loss_cls: 0.4026, decode.d6.loss_mask: 0.5692, decode.d6.loss_dice: 0.8402, decode.d7.loss_cls: 0.3996, decode.d7.loss_mask: 0.5704, decode.d7.loss_dice: 0.8403, decode.d8.loss_cls: 0.4035, decode.d8.loss_mask: 0.5680, decode.d8.loss_dice: 0.8399, loss: 24.8023
2022-11-30 17:28:56,805 - mmseg - INFO - Iter [17250/40000]	lr: 7.566e-08, eta: 1 day, 3:39:17, time: 4.112, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3944, decode.loss_mask: 0.5714, decode.loss_dice: 0.8212, decode.d0.loss_cls: 6.6315, decode.d0.loss_mask: 0.5524, decode.d0.loss_dice: 0.8865, decode.d1.loss_cls: 0.5024, decode.d1.loss_mask: 0.5973, decode.d1.loss_dice: 0.8820, decode.d2.loss_cls: 0.4507, decode.d2.loss_mask: 0.5816, decode.d2.loss_dice: 0.8422, decode.d3.loss_cls: 0.4185, decode.d3.loss_mask: 0.5753, decode.d3.loss_dice: 0.8310, decode.d4.loss_cls: 0.4106, decode.d4.loss_mask: 0.5725, decode.d4.loss_dice: 0.8264, decode.d5.loss_cls: 0.4010, decode.d5.loss_mask: 0.5702, decode.d5.loss_dice: 0.8271, decode.d6.loss_cls: 0.3961, decode.d6.loss_mask: 0.5704, decode.d6.loss_dice: 0.8172, decode.d7.loss_cls: 0.3957, decode.d7.loss_mask: 0.5725, decode.d7.loss_dice: 0.8195, decode.d8.loss_cls: 0.3930, decode.d8.loss_mask: 0.5711, decode.d8.loss_dice: 0.8226, loss: 24.5043
2022-11-30 17:32:22,387 - mmseg - INFO - Iter [17300/40000]	lr: 7.550e-08, eta: 1 day, 3:35:21, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4138, decode.loss_mask: 0.5668, decode.loss_dice: 0.8350, decode.d0.loss_cls: 6.6298, decode.d0.loss_mask: 0.5489, decode.d0.loss_dice: 0.9035, decode.d1.loss_cls: 0.5273, decode.d1.loss_mask: 0.5935, decode.d1.loss_dice: 0.8926, decode.d2.loss_cls: 0.4671, decode.d2.loss_mask: 0.5791, decode.d2.loss_dice: 0.8580, decode.d3.loss_cls: 0.4356, decode.d3.loss_mask: 0.5718, decode.d3.loss_dice: 0.8451, decode.d4.loss_cls: 0.4322, decode.d4.loss_mask: 0.5670, decode.d4.loss_dice: 0.8419, decode.d5.loss_cls: 0.4207, decode.d5.loss_mask: 0.5659, decode.d5.loss_dice: 0.8382, decode.d6.loss_cls: 0.4161, decode.d6.loss_mask: 0.5661, decode.d6.loss_dice: 0.8344, decode.d7.loss_cls: 0.4150, decode.d7.loss_mask: 0.5639, decode.d7.loss_dice: 0.8370, decode.d8.loss_cls: 0.4148, decode.d8.loss_mask: 0.5646, decode.d8.loss_dice: 0.8355, loss: 24.7811
2022-11-30 17:35:48,310 - mmseg - INFO - Iter [17350/40000]	lr: 7.533e-08, eta: 1 day, 3:31:26, time: 4.118, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4163, decode.loss_mask: 0.5812, decode.loss_dice: 0.8586, decode.d0.loss_cls: 6.6160, decode.d0.loss_mask: 0.5634, decode.d0.loss_dice: 0.9243, decode.d1.loss_cls: 0.5415, decode.d1.loss_mask: 0.6049, decode.d1.loss_dice: 0.9143, decode.d2.loss_cls: 0.4817, decode.d2.loss_mask: 0.5932, decode.d2.loss_dice: 0.8755, decode.d3.loss_cls: 0.4420, decode.d3.loss_mask: 0.5866, decode.d3.loss_dice: 0.8593, decode.d4.loss_cls: 0.4346, decode.d4.loss_mask: 0.5861, decode.d4.loss_dice: 0.8577, decode.d5.loss_cls: 0.4273, decode.d5.loss_mask: 0.5853, decode.d5.loss_dice: 0.8584, decode.d6.loss_cls: 0.4240, decode.d6.loss_mask: 0.5823, decode.d6.loss_dice: 0.8518, decode.d7.loss_cls: 0.4199, decode.d7.loss_mask: 0.5834, decode.d7.loss_dice: 0.8539, decode.d8.loss_cls: 0.4171, decode.d8.loss_mask: 0.5835, decode.d8.loss_dice: 0.8563, loss: 25.1801
2022-11-30 17:39:13,563 - mmseg - INFO - Iter [17400/40000]	lr: 7.516e-08, eta: 1 day, 3:27:30, time: 4.105, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4199, decode.loss_mask: 0.5704, decode.loss_dice: 0.8513, decode.d0.loss_cls: 6.6214, decode.d0.loss_mask: 0.5515, decode.d0.loss_dice: 0.9205, decode.d1.loss_cls: 0.5373, decode.d1.loss_mask: 0.5961, decode.d1.loss_dice: 0.9143, decode.d2.loss_cls: 0.4787, decode.d2.loss_mask: 0.5833, decode.d2.loss_dice: 0.8772, decode.d3.loss_cls: 0.4454, decode.d3.loss_mask: 0.5747, decode.d3.loss_dice: 0.8593, decode.d4.loss_cls: 0.4371, decode.d4.loss_mask: 0.5732, decode.d4.loss_dice: 0.8579, decode.d5.loss_cls: 0.4269, decode.d5.loss_mask: 0.5720, decode.d5.loss_dice: 0.8511, decode.d6.loss_cls: 0.4252, decode.d6.loss_mask: 0.5717, decode.d6.loss_dice: 0.8548, decode.d7.loss_cls: 0.4205, decode.d7.loss_mask: 0.5725, decode.d7.loss_dice: 0.8552, decode.d8.loss_cls: 0.4190, decode.d8.loss_mask: 0.5720, decode.d8.loss_dice: 0.8531, loss: 25.0634
2022-11-30 17:42:39,436 - mmseg - INFO - Iter [17450/40000]	lr: 7.500e-08, eta: 1 day, 3:23:34, time: 4.117, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4124, decode.loss_mask: 0.5501, decode.loss_dice: 0.8411, decode.d0.loss_cls: 6.6134, decode.d0.loss_mask: 0.5293, decode.d0.loss_dice: 0.9025, decode.d1.loss_cls: 0.5275, decode.d1.loss_mask: 0.5762, decode.d1.loss_dice: 0.8939, decode.d2.loss_cls: 0.4622, decode.d2.loss_mask: 0.5626, decode.d2.loss_dice: 0.8587, decode.d3.loss_cls: 0.4295, decode.d3.loss_mask: 0.5571, decode.d3.loss_dice: 0.8458, decode.d4.loss_cls: 0.4193, decode.d4.loss_mask: 0.5562, decode.d4.loss_dice: 0.8495, decode.d5.loss_cls: 0.4117, decode.d5.loss_mask: 0.5523, decode.d5.loss_dice: 0.8422, decode.d6.loss_cls: 0.4105, decode.d6.loss_mask: 0.5529, decode.d6.loss_dice: 0.8406, decode.d7.loss_cls: 0.4044, decode.d7.loss_mask: 0.5525, decode.d7.loss_dice: 0.8421, decode.d8.loss_cls: 0.4071, decode.d8.loss_mask: 0.5524, decode.d8.loss_dice: 0.8391, loss: 24.5953
2022-11-30 17:46:04,978 - mmseg - INFO - Iter [17500/40000]	lr: 7.483e-08, eta: 1 day, 3:19:39, time: 4.111, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4033, decode.loss_mask: 0.5749, decode.loss_dice: 0.8368, decode.d0.loss_cls: 6.6007, decode.d0.loss_mask: 0.5612, decode.d0.loss_dice: 0.9016, decode.d1.loss_cls: 0.5258, decode.d1.loss_mask: 0.5980, decode.d1.loss_dice: 0.8922, decode.d2.loss_cls: 0.4592, decode.d2.loss_mask: 0.5888, decode.d2.loss_dice: 0.8611, decode.d3.loss_cls: 0.4236, decode.d3.loss_mask: 0.5846, decode.d3.loss_dice: 0.8468, decode.d4.loss_cls: 0.4180, decode.d4.loss_mask: 0.5818, decode.d4.loss_dice: 0.8443, decode.d5.loss_cls: 0.4100, decode.d5.loss_mask: 0.5786, decode.d5.loss_dice: 0.8391, decode.d6.loss_cls: 0.4064, decode.d6.loss_mask: 0.5763, decode.d6.loss_dice: 0.8372, decode.d7.loss_cls: 0.4029, decode.d7.loss_mask: 0.5763, decode.d7.loss_dice: 0.8401, decode.d8.loss_cls: 0.4035, decode.d8.loss_mask: 0.5751, decode.d8.loss_dice: 0.8413, loss: 24.7895
2022-11-30 17:49:30,819 - mmseg - INFO - Iter [17550/40000]	lr: 7.467e-08, eta: 1 day, 3:15:44, time: 4.117, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4324, decode.loss_mask: 0.5598, decode.loss_dice: 0.8387, decode.d0.loss_cls: 6.6036, decode.d0.loss_mask: 0.5374, decode.d0.loss_dice: 0.9099, decode.d1.loss_cls: 0.5539, decode.d1.loss_mask: 0.5816, decode.d1.loss_dice: 0.9044, decode.d2.loss_cls: 0.4847, decode.d2.loss_mask: 0.5696, decode.d2.loss_dice: 0.8647, decode.d3.loss_cls: 0.4538, decode.d3.loss_mask: 0.5642, decode.d3.loss_dice: 0.8505, decode.d4.loss_cls: 0.4428, decode.d4.loss_mask: 0.5624, decode.d4.loss_dice: 0.8480, decode.d5.loss_cls: 0.4353, decode.d5.loss_mask: 0.5596, decode.d5.loss_dice: 0.8427, decode.d6.loss_cls: 0.4298, decode.d6.loss_mask: 0.5590, decode.d6.loss_dice: 0.8380, decode.d7.loss_cls: 0.4285, decode.d7.loss_mask: 0.5593, decode.d7.loss_dice: 0.8407, decode.d8.loss_cls: 0.4295, decode.d8.loss_mask: 0.5596, decode.d8.loss_dice: 0.8378, loss: 24.8822
2022-11-30 17:52:56,546 - mmseg - INFO - Iter [17600/40000]	lr: 7.450e-08, eta: 1 day, 3:11:49, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4063, decode.loss_mask: 0.5652, decode.loss_dice: 0.8293, decode.d0.loss_cls: 6.5874, decode.d0.loss_mask: 0.5441, decode.d0.loss_dice: 0.8928, decode.d1.loss_cls: 0.5233, decode.d1.loss_mask: 0.5862, decode.d1.loss_dice: 0.8875, decode.d2.loss_cls: 0.4659, decode.d2.loss_mask: 0.5714, decode.d2.loss_dice: 0.8523, decode.d3.loss_cls: 0.4338, decode.d3.loss_mask: 0.5688, decode.d3.loss_dice: 0.8335, decode.d4.loss_cls: 0.4236, decode.d4.loss_mask: 0.5659, decode.d4.loss_dice: 0.8320, decode.d5.loss_cls: 0.4147, decode.d5.loss_mask: 0.5629, decode.d5.loss_dice: 0.8305, decode.d6.loss_cls: 0.4126, decode.d6.loss_mask: 0.5623, decode.d6.loss_dice: 0.8262, decode.d7.loss_cls: 0.4078, decode.d7.loss_mask: 0.5617, decode.d7.loss_dice: 0.8289, decode.d8.loss_cls: 0.4072, decode.d8.loss_mask: 0.5617, decode.d8.loss_dice: 0.8282, loss: 24.5741
2022-11-30 17:56:22,553 - mmseg - INFO - Iter [17650/40000]	lr: 7.433e-08, eta: 1 day, 3:07:54, time: 4.120, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4286, decode.loss_mask: 0.5836, decode.loss_dice: 0.8438, decode.d0.loss_cls: 6.5878, decode.d0.loss_mask: 0.5620, decode.d0.loss_dice: 0.9115, decode.d1.loss_cls: 0.5464, decode.d1.loss_mask: 0.6066, decode.d1.loss_dice: 0.9054, decode.d2.loss_cls: 0.4863, decode.d2.loss_mask: 0.5928, decode.d2.loss_dice: 0.8682, decode.d3.loss_cls: 0.4526, decode.d3.loss_mask: 0.5896, decode.d3.loss_dice: 0.8526, decode.d4.loss_cls: 0.4446, decode.d4.loss_mask: 0.5847, decode.d4.loss_dice: 0.8489, decode.d5.loss_cls: 0.4370, decode.d5.loss_mask: 0.5838, decode.d5.loss_dice: 0.8464, decode.d6.loss_cls: 0.4287, decode.d6.loss_mask: 0.5855, decode.d6.loss_dice: 0.8449, decode.d7.loss_cls: 0.4286, decode.d7.loss_mask: 0.5855, decode.d7.loss_dice: 0.8452, decode.d8.loss_cls: 0.4261, decode.d8.loss_mask: 0.5843, decode.d8.loss_dice: 0.8437, loss: 25.1356
2022-11-30 17:59:50,160 - mmseg - INFO - Iter [17700/40000]	lr: 7.417e-08, eta: 1 day, 3:04:02, time: 4.152, data_time: 0.064, memory: 51902, decode.loss_cls: 0.4079, decode.loss_mask: 0.5892, decode.loss_dice: 0.8474, decode.d0.loss_cls: 6.5486, decode.d0.loss_mask: 0.5688, decode.d0.loss_dice: 0.9062, decode.d1.loss_cls: 0.5273, decode.d1.loss_mask: 0.6164, decode.d1.loss_dice: 0.9088, decode.d2.loss_cls: 0.4652, decode.d2.loss_mask: 0.6018, decode.d2.loss_dice: 0.8712, decode.d3.loss_cls: 0.4337, decode.d3.loss_mask: 0.5946, decode.d3.loss_dice: 0.8577, decode.d4.loss_cls: 0.4258, decode.d4.loss_mask: 0.5943, decode.d4.loss_dice: 0.8544, decode.d5.loss_cls: 0.4134, decode.d5.loss_mask: 0.5909, decode.d5.loss_dice: 0.8482, decode.d6.loss_cls: 0.4097, decode.d6.loss_mask: 0.5891, decode.d6.loss_dice: 0.8494, decode.d7.loss_cls: 0.4078, decode.d7.loss_mask: 0.5896, decode.d7.loss_dice: 0.8501, decode.d8.loss_cls: 0.4089, decode.d8.loss_mask: 0.5890, decode.d8.loss_dice: 0.8481, loss: 25.0135
2022-11-30 18:03:16,087 - mmseg - INFO - Iter [17750/40000]	lr: 7.400e-08, eta: 1 day, 3:00:08, time: 4.119, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4081, decode.loss_mask: 0.5880, decode.loss_dice: 0.8435, decode.d0.loss_cls: 6.5698, decode.d0.loss_mask: 0.5627, decode.d0.loss_dice: 0.9048, decode.d1.loss_cls: 0.5227, decode.d1.loss_mask: 0.6077, decode.d1.loss_dice: 0.9025, decode.d2.loss_cls: 0.4594, decode.d2.loss_mask: 0.5970, decode.d2.loss_dice: 0.8683, decode.d3.loss_cls: 0.4373, decode.d3.loss_mask: 0.5910, decode.d3.loss_dice: 0.8556, decode.d4.loss_cls: 0.4249, decode.d4.loss_mask: 0.5882, decode.d4.loss_dice: 0.8522, decode.d5.loss_cls: 0.4133, decode.d5.loss_mask: 0.5860, decode.d5.loss_dice: 0.8525, decode.d6.loss_cls: 0.4119, decode.d6.loss_mask: 0.5854, decode.d6.loss_dice: 0.8456, decode.d7.loss_cls: 0.4081, decode.d7.loss_mask: 0.5848, decode.d7.loss_dice: 0.8473, decode.d8.loss_cls: 0.4085, decode.d8.loss_mask: 0.5844, decode.d8.loss_dice: 0.8455, loss: 24.9571
2022-11-30 18:06:41,984 - mmseg - INFO - Iter [17800/40000]	lr: 7.383e-08, eta: 1 day, 2:56:14, time: 4.118, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3985, decode.loss_mask: 0.5599, decode.loss_dice: 0.8116, decode.d0.loss_cls: 6.5551, decode.d0.loss_mask: 0.5374, decode.d0.loss_dice: 0.8817, decode.d1.loss_cls: 0.5249, decode.d1.loss_mask: 0.5827, decode.d1.loss_dice: 0.8742, decode.d2.loss_cls: 0.4608, decode.d2.loss_mask: 0.5687, decode.d2.loss_dice: 0.8400, decode.d3.loss_cls: 0.4250, decode.d3.loss_mask: 0.5637, decode.d3.loss_dice: 0.8218, decode.d4.loss_cls: 0.4175, decode.d4.loss_mask: 0.5613, decode.d4.loss_dice: 0.8185, decode.d5.loss_cls: 0.4067, decode.d5.loss_mask: 0.5592, decode.d5.loss_dice: 0.8146, decode.d6.loss_cls: 0.3996, decode.d6.loss_mask: 0.5587, decode.d6.loss_dice: 0.8090, decode.d7.loss_cls: 0.3992, decode.d7.loss_mask: 0.5598, decode.d7.loss_dice: 0.8148, decode.d8.loss_cls: 0.3993, decode.d8.loss_mask: 0.5587, decode.d8.loss_dice: 0.8122, loss: 24.2950
2022-11-30 18:10:07,522 - mmseg - INFO - Iter [17850/40000]	lr: 7.367e-08, eta: 1 day, 2:52:19, time: 4.111, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3846, decode.loss_mask: 0.5579, decode.loss_dice: 0.8125, decode.d0.loss_cls: 6.5419, decode.d0.loss_mask: 0.5348, decode.d0.loss_dice: 0.8736, decode.d1.loss_cls: 0.5032, decode.d1.loss_mask: 0.5759, decode.d1.loss_dice: 0.8768, decode.d2.loss_cls: 0.4406, decode.d2.loss_mask: 0.5652, decode.d2.loss_dice: 0.8366, decode.d3.loss_cls: 0.4132, decode.d3.loss_mask: 0.5608, decode.d3.loss_dice: 0.8218, decode.d4.loss_cls: 0.4013, decode.d4.loss_mask: 0.5590, decode.d4.loss_dice: 0.8159, decode.d5.loss_cls: 0.3901, decode.d5.loss_mask: 0.5579, decode.d5.loss_dice: 0.8158, decode.d6.loss_cls: 0.3846, decode.d6.loss_mask: 0.5561, decode.d6.loss_dice: 0.8118, decode.d7.loss_cls: 0.3806, decode.d7.loss_mask: 0.5557, decode.d7.loss_dice: 0.8133, decode.d8.loss_cls: 0.3826, decode.d8.loss_mask: 0.5565, decode.d8.loss_dice: 0.8173, loss: 24.0979
2022-11-30 18:13:33,234 - mmseg - INFO - Iter [17900/40000]	lr: 7.350e-08, eta: 1 day, 2:48:25, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4136, decode.loss_mask: 0.5641, decode.loss_dice: 0.8335, decode.d0.loss_cls: 6.5402, decode.d0.loss_mask: 0.5493, decode.d0.loss_dice: 0.9007, decode.d1.loss_cls: 0.5335, decode.d1.loss_mask: 0.5927, decode.d1.loss_dice: 0.8968, decode.d2.loss_cls: 0.4698, decode.d2.loss_mask: 0.5775, decode.d2.loss_dice: 0.8628, decode.d3.loss_cls: 0.4370, decode.d3.loss_mask: 0.5699, decode.d3.loss_dice: 0.8428, decode.d4.loss_cls: 0.4260, decode.d4.loss_mask: 0.5673, decode.d4.loss_dice: 0.8425, decode.d5.loss_cls: 0.4165, decode.d5.loss_mask: 0.5683, decode.d5.loss_dice: 0.8391, decode.d6.loss_cls: 0.4160, decode.d6.loss_mask: 0.5645, decode.d6.loss_dice: 0.8346, decode.d7.loss_cls: 0.4117, decode.d7.loss_mask: 0.5645, decode.d7.loss_dice: 0.8310, decode.d8.loss_cls: 0.4119, decode.d8.loss_mask: 0.5655, decode.d8.loss_dice: 0.8357, loss: 24.6792
2022-11-30 18:16:59,026 - mmseg - INFO - Iter [17950/40000]	lr: 7.333e-08, eta: 1 day, 2:44:32, time: 4.116, data_time: 0.021, memory: 51902, decode.loss_cls: 0.4008, decode.loss_mask: 0.5596, decode.loss_dice: 0.8137, decode.d0.loss_cls: 6.5169, decode.d0.loss_mask: 0.5365, decode.d0.loss_dice: 0.8723, decode.d1.loss_cls: 0.5079, decode.d1.loss_mask: 0.5858, decode.d1.loss_dice: 0.8743, decode.d2.loss_cls: 0.4544, decode.d2.loss_mask: 0.5704, decode.d2.loss_dice: 0.8383, decode.d3.loss_cls: 0.4274, decode.d3.loss_mask: 0.5637, decode.d3.loss_dice: 0.8212, decode.d4.loss_cls: 0.4198, decode.d4.loss_mask: 0.5619, decode.d4.loss_dice: 0.8197, decode.d5.loss_cls: 0.4114, decode.d5.loss_mask: 0.5596, decode.d5.loss_dice: 0.8116, decode.d6.loss_cls: 0.4076, decode.d6.loss_mask: 0.5583, decode.d6.loss_dice: 0.8151, decode.d7.loss_cls: 0.4015, decode.d7.loss_mask: 0.5588, decode.d7.loss_dice: 0.8125, decode.d8.loss_cls: 0.4015, decode.d8.loss_mask: 0.5594, decode.d8.loss_dice: 0.8097, loss: 24.2520
2022-11-30 18:20:24,693 - mmseg - INFO - Saving checkpoint at 18000 iterations
2022-11-30 18:21:14,043 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 18:21:14,043 - mmseg - INFO - Iter [18000/40000]	lr: 7.317e-08, eta: 1 day, 2:41:38, time: 5.100, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3982, decode.loss_mask: 0.5685, decode.loss_dice: 0.8348, decode.d0.loss_cls: 6.5049, decode.d0.loss_mask: 0.5511, decode.d0.loss_dice: 0.8969, decode.d1.loss_cls: 0.5066, decode.d1.loss_mask: 0.5959, decode.d1.loss_dice: 0.8997, decode.d2.loss_cls: 0.4561, decode.d2.loss_mask: 0.5792, decode.d2.loss_dice: 0.8555, decode.d3.loss_cls: 0.4207, decode.d3.loss_mask: 0.5753, decode.d3.loss_dice: 0.8403, decode.d4.loss_cls: 0.4116, decode.d4.loss_mask: 0.5726, decode.d4.loss_dice: 0.8406, decode.d5.loss_cls: 0.4055, decode.d5.loss_mask: 0.5686, decode.d5.loss_dice: 0.8392, decode.d6.loss_cls: 0.3990, decode.d6.loss_mask: 0.5699, decode.d6.loss_dice: 0.8349, decode.d7.loss_cls: 0.3946, decode.d7.loss_mask: 0.5694, decode.d7.loss_dice: 0.8400, decode.d8.loss_cls: 0.3987, decode.d8.loss_mask: 0.5696, decode.d8.loss_dice: 0.8322, loss: 24.5300
2022-11-30 18:24:12,154 - mmseg - INFO - per class results:
2022-11-30 18:24:12,159 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 83.41 | 89.61 |
|       building      | 85.48 | 91.91 |
|         sky         |  95.2 | 97.54 |
|        floor        | 85.35 | 89.58 |
|         tree        | 78.72 | 89.96 |
|       ceiling       | 87.57 | 93.65 |
|         road        | 87.73 | 90.97 |
|         bed         | 93.43 | 96.69 |
|      windowpane     | 68.96 | 80.82 |
|        grass        |  69.4 | 85.62 |
|       cabinet       | 62.63 | 73.97 |
|       sidewalk      | 71.97 | 85.39 |
|        person       | 88.37 |  94.6 |
|        earth        | 44.78 |  57.5 |
|         door        | 64.28 | 82.92 |
|        table        | 71.45 | 81.67 |
|       mountain      | 62.33 | 70.22 |
|        plant        | 56.59 | 69.66 |
|       curtain       | 82.47 | 91.62 |
|        chair        | 67.51 | 78.14 |
|         car         | 89.45 | 95.25 |
|        water        | 68.01 |  86.5 |
|       painting      | 80.98 |  93.2 |
|         sofa        | 85.29 | 90.68 |
|        shelf        |  48.0 | 61.54 |
|        house        | 56.07 | 70.32 |
|         sea         | 80.49 | 90.34 |
|        mirror       | 82.12 | 91.57 |
|         rug         | 74.19 | 90.29 |
|        field        | 36.77 | 60.92 |
|       armchair      | 61.32 | 81.64 |
|         seat        | 67.21 | 89.49 |
|        fence        | 58.07 | 75.83 |
|         desk        | 59.37 |  83.9 |
|         rock        | 61.83 | 83.18 |
|       wardrobe      | 56.82 | 85.54 |
|         lamp        |  80.3 | 90.29 |
|       bathtub       | 91.75 | 93.21 |
|       railing       | 47.32 | 68.46 |
|       cushion       | 76.99 | 90.97 |
|         base        |  50.7 | 69.98 |
|         box         | 41.08 | 61.02 |
|        column       | 57.02 | 75.94 |
|      signboard      | 46.98 | 66.24 |
|   chest of drawers  |  46.4 | 69.04 |
|       counter       | 52.67 | 63.83 |
|         sand        | 65.69 | 89.17 |
|         sink        | 83.29 | 87.04 |
|      skyscraper     |  42.8 | 53.04 |
|      fireplace      | 84.09 | 97.09 |
|     refrigerator    | 86.12 |  95.8 |
|      grandstand     | 45.33 | 78.58 |
|         path        | 28.97 |  42.6 |
|        stairs       | 34.16 | 45.76 |
|        runway       | 74.62 | 94.35 |
|         case        | 69.87 | 86.24 |
|      pool table     | 95.77 | 98.61 |
|        pillow       | 73.03 | 85.11 |
|     screen door     | 86.05 | 89.33 |
|       stairway      | 56.44 | 75.28 |
|        river        | 24.93 | 28.38 |
|        bridge       | 77.07 | 90.68 |
|       bookcase      | 31.87 | 43.26 |
|        blind        | 54.56 | 68.69 |
|     coffee table    | 72.05 | 89.52 |
|        toilet       | 93.16 | 96.99 |
|        flower       | 48.92 | 82.66 |
|         book        | 60.31 | 83.39 |
|         hill        | 13.04 | 26.97 |
|        bench        | 73.09 | 80.78 |
|      countertop     | 77.03 | 90.57 |
|        stove        | 85.51 | 90.13 |
|         palm        | 55.09 | 81.98 |
|    kitchen island   | 38.21 | 79.89 |
|       computer      | 81.39 | 90.86 |
|     swivel chair    | 57.05 | 85.14 |
|         boat        | 49.44 | 90.11 |
|         bar         | 58.54 | 62.54 |
|    arcade machine   | 91.77 | 98.77 |
|        hovel        | 52.18 | 75.47 |
|         bus         | 94.88 | 96.64 |
|        towel        | 84.48 | 95.21 |
|        light        | 65.66 | 82.92 |
|        truck        | 54.92 | 73.98 |
|        tower        | 33.55 | 64.47 |
|      chandelier     | 76.78 |  87.6 |
|        awning       |  29.8 | 55.05 |
|     streetlight     | 47.61 | 72.83 |
|        booth        | 57.25 | 69.58 |
| television receiver | 75.23 | 89.96 |
|       airplane      | 88.58 | 96.71 |
|      dirt track     |  1.36 |  1.54 |
|       apparel       | 53.94 | 90.22 |
|         pole        | 37.51 |  56.2 |
|         land        |  1.34 |  1.76 |
|      bannister      | 20.99 | 37.35 |
|      escalator      | 64.74 |  84.6 |
|       ottoman       | 64.09 | 87.21 |
|        bottle       | 53.08 | 84.13 |
|        buffet       | 36.93 | 45.89 |
|        poster       | 32.26 | 48.81 |
|        stage        | 32.32 | 74.54 |
|         van         |  56.0 | 75.31 |
|         ship        | 42.88 | 44.74 |
|       fountain      |  56.3 | 61.81 |
|    conveyer belt    | 78.02 | 97.47 |
|        canopy       | 46.85 |  62.8 |
|        washer       | 89.27 | 93.91 |
|      plaything      | 36.22 | 60.71 |
|    swimming pool    | 49.87 | 72.58 |
|        stool        | 60.53 | 85.48 |
|        barrel       | 82.03 | 96.63 |
|        basket       | 48.01 | 77.99 |
|      waterfall      | 69.11 | 88.28 |
|         tent        | 96.07 | 97.89 |
|         bag         | 35.07 | 50.55 |
|       minibike      | 80.72 | 93.65 |
|        cradle       |  91.4 | 97.58 |
|         oven        | 65.51 |  82.4 |
|         ball        | 43.44 | 48.65 |
|         food        | 68.25 | 84.21 |
|         step        | 28.47 | 48.23 |
|         tank        | 60.98 | 67.53 |
|      trade name     | 36.86 | 52.89 |
|      microwave      |  89.6 | 94.65 |
|         pot         | 60.86 | 73.38 |
|        animal       | 85.31 | 88.53 |
|       bicycle       | 62.41 | 83.91 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 79.98 | 90.59 |
|        screen       | 60.08 | 94.24 |
|       blanket       | 42.86 | 60.76 |
|      sculpture      | 70.96 | 90.73 |
|         hood        | 65.61 | 82.42 |
|        sconce       | 66.14 | 83.28 |
|         vase        | 58.33 | 82.79 |
|    traffic light    | 51.89 | 72.45 |
|         tray        | 32.87 | 57.37 |
|        ashcan       | 53.99 | 74.53 |
|         fan         | 74.19 | 86.21 |
|         pier        | 38.09 | 43.62 |
|      crt screen     |  2.95 |  8.06 |
|        plate        |  67.7 | 87.73 |
|       monitor       |  3.56 |  4.69 |
|    bulletin board   |  68.1 | 87.71 |
|        shower       | 22.86 | 28.63 |
|       radiator      |  70.6 |  93.3 |
|        glass        | 29.62 | 33.04 |
|        clock        | 62.16 | 76.22 |
|         flag        | 71.26 | 88.63 |
+---------------------+-------+-------+
2022-11-30 18:24:12,159 - mmseg - INFO - Summary:
2022-11-30 18:24:12,159 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 87.06 | 60.72 | 75.55 |
+-------+-------+-------+
2022-11-30 18:24:12,163 - mmseg - INFO - The previous best checkpoint /mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune/lr1.0_lrd0.9/best_mIoU_iter_16000.pth was removed
2022-11-30 18:25:00,708 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_18000.pth.
2022-11-30 18:25:00,708 - mmseg - INFO - Best mIoU is 0.6072 at 18000 iter.
2022-11-30 18:25:00,720 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 18:25:00,721 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8706, mIoU: 0.6072, mAcc: 0.7555, IoU.wall: 0.8341, IoU.building: 0.8548, IoU.sky: 0.9520, IoU.floor: 0.8535, IoU.tree: 0.7872, IoU.ceiling: 0.8757, IoU.road: 0.8773, IoU.bed : 0.9343, IoU.windowpane: 0.6896, IoU.grass: 0.6940, IoU.cabinet: 0.6263, IoU.sidewalk: 0.7197, IoU.person: 0.8837, IoU.earth: 0.4478, IoU.door: 0.6428, IoU.table: 0.7145, IoU.mountain: 0.6233, IoU.plant: 0.5659, IoU.curtain: 0.8247, IoU.chair: 0.6751, IoU.car: 0.8945, IoU.water: 0.6801, IoU.painting: 0.8098, IoU.sofa: 0.8529, IoU.shelf: 0.4800, IoU.house: 0.5607, IoU.sea: 0.8049, IoU.mirror: 0.8212, IoU.rug: 0.7419, IoU.field: 0.3677, IoU.armchair: 0.6132, IoU.seat: 0.6721, IoU.fence: 0.5807, IoU.desk: 0.5937, IoU.rock: 0.6183, IoU.wardrobe: 0.5682, IoU.lamp: 0.8030, IoU.bathtub: 0.9175, IoU.railing: 0.4732, IoU.cushion: 0.7699, IoU.base: 0.5070, IoU.box: 0.4108, IoU.column: 0.5702, IoU.signboard: 0.4698, IoU.chest of drawers: 0.4640, IoU.counter: 0.5267, IoU.sand: 0.6569, IoU.sink: 0.8329, IoU.skyscraper: 0.4280, IoU.fireplace: 0.8409, IoU.refrigerator: 0.8612, IoU.grandstand: 0.4533, IoU.path: 0.2897, IoU.stairs: 0.3416, IoU.runway: 0.7462, IoU.case: 0.6987, IoU.pool table: 0.9577, IoU.pillow: 0.7303, IoU.screen door: 0.8605, IoU.stairway: 0.5644, IoU.river: 0.2493, IoU.bridge: 0.7707, IoU.bookcase: 0.3187, IoU.blind: 0.5456, IoU.coffee table: 0.7205, IoU.toilet: 0.9316, IoU.flower: 0.4892, IoU.book: 0.6031, IoU.hill: 0.1304, IoU.bench: 0.7309, IoU.countertop: 0.7703, IoU.stove: 0.8551, IoU.palm: 0.5509, IoU.kitchen island: 0.3821, IoU.computer: 0.8139, IoU.swivel chair: 0.5705, IoU.boat: 0.4944, IoU.bar: 0.5854, IoU.arcade machine: 0.9177, IoU.hovel: 0.5218, IoU.bus: 0.9488, IoU.towel: 0.8448, IoU.light: 0.6566, IoU.truck: 0.5492, IoU.tower: 0.3355, IoU.chandelier: 0.7678, IoU.awning: 0.2980, IoU.streetlight: 0.4761, IoU.booth: 0.5725, IoU.television receiver: 0.7523, IoU.airplane: 0.8858, IoU.dirt track: 0.0136, IoU.apparel: 0.5394, IoU.pole: 0.3751, IoU.land: 0.0134, IoU.bannister: 0.2099, IoU.escalator: 0.6474, IoU.ottoman: 0.6409, IoU.bottle: 0.5308, IoU.buffet: 0.3693, IoU.poster: 0.3226, IoU.stage: 0.3232, IoU.van: 0.5600, IoU.ship: 0.4288, IoU.fountain: 0.5630, IoU.conveyer belt: 0.7802, IoU.canopy: 0.4685, IoU.washer: 0.8927, IoU.plaything: 0.3622, IoU.swimming pool: 0.4987, IoU.stool: 0.6053, IoU.barrel: 0.8203, IoU.basket: 0.4801, IoU.waterfall: 0.6911, IoU.tent: 0.9607, IoU.bag: 0.3507, IoU.minibike: 0.8072, IoU.cradle: 0.9140, IoU.oven: 0.6551, IoU.ball: 0.4344, IoU.food: 0.6825, IoU.step: 0.2847, IoU.tank: 0.6098, IoU.trade name: 0.3686, IoU.microwave: 0.8960, IoU.pot: 0.6086, IoU.animal: 0.8531, IoU.bicycle: 0.6241, IoU.lake: 0.0000, IoU.dishwasher: 0.7998, IoU.screen: 0.6008, IoU.blanket: 0.4286, IoU.sculpture: 0.7096, IoU.hood: 0.6561, IoU.sconce: 0.6614, IoU.vase: 0.5833, IoU.traffic light: 0.5189, IoU.tray: 0.3287, IoU.ashcan: 0.5399, IoU.fan: 0.7419, IoU.pier: 0.3809, IoU.crt screen: 0.0295, IoU.plate: 0.6770, IoU.monitor: 0.0356, IoU.bulletin board: 0.6810, IoU.shower: 0.2286, IoU.radiator: 0.7060, IoU.glass: 0.2962, IoU.clock: 0.6216, IoU.flag: 0.7126, Acc.wall: 0.8961, Acc.building: 0.9191, Acc.sky: 0.9754, Acc.floor: 0.8958, Acc.tree: 0.8996, Acc.ceiling: 0.9365, Acc.road: 0.9097, Acc.bed : 0.9669, Acc.windowpane: 0.8082, Acc.grass: 0.8562, Acc.cabinet: 0.7397, Acc.sidewalk: 0.8539, Acc.person: 0.9460, Acc.earth: 0.5750, Acc.door: 0.8292, Acc.table: 0.8167, Acc.mountain: 0.7022, Acc.plant: 0.6966, Acc.curtain: 0.9162, Acc.chair: 0.7814, Acc.car: 0.9525, Acc.water: 0.8650, Acc.painting: 0.9320, Acc.sofa: 0.9068, Acc.shelf: 0.6154, Acc.house: 0.7032, Acc.sea: 0.9034, Acc.mirror: 0.9157, Acc.rug: 0.9029, Acc.field: 0.6092, Acc.armchair: 0.8164, Acc.seat: 0.8949, Acc.fence: 0.7583, Acc.desk: 0.8390, Acc.rock: 0.8318, Acc.wardrobe: 0.8554, Acc.lamp: 0.9029, Acc.bathtub: 0.9321, Acc.railing: 0.6846, Acc.cushion: 0.9097, Acc.base: 0.6998, Acc.box: 0.6102, Acc.column: 0.7594, Acc.signboard: 0.6624, Acc.chest of drawers: 0.6904, Acc.counter: 0.6383, Acc.sand: 0.8917, Acc.sink: 0.8704, Acc.skyscraper: 0.5304, Acc.fireplace: 0.9709, Acc.refrigerator: 0.9580, Acc.grandstand: 0.7858, Acc.path: 0.4260, Acc.stairs: 0.4576, Acc.runway: 0.9435, Acc.case: 0.8624, Acc.pool table: 0.9861, Acc.pillow: 0.8511, Acc.screen door: 0.8933, Acc.stairway: 0.7528, Acc.river: 0.2838, Acc.bridge: 0.9068, Acc.bookcase: 0.4326, Acc.blind: 0.6869, Acc.coffee table: 0.8952, Acc.toilet: 0.9699, Acc.flower: 0.8266, Acc.book: 0.8339, Acc.hill: 0.2697, Acc.bench: 0.8078, Acc.countertop: 0.9057, Acc.stove: 0.9013, Acc.palm: 0.8198, Acc.kitchen island: 0.7989, Acc.computer: 0.9086, Acc.swivel chair: 0.8514, Acc.boat: 0.9011, Acc.bar: 0.6254, Acc.arcade machine: 0.9877, Acc.hovel: 0.7547, Acc.bus: 0.9664, Acc.towel: 0.9521, Acc.light: 0.8292, Acc.truck: 0.7398, Acc.tower: 0.6447, Acc.chandelier: 0.8760, Acc.awning: 0.5505, Acc.streetlight: 0.7283, Acc.booth: 0.6958, Acc.television receiver: 0.8996, Acc.airplane: 0.9671, Acc.dirt track: 0.0154, Acc.apparel: 0.9022, Acc.pole: 0.5620, Acc.land: 0.0176, Acc.bannister: 0.3735, Acc.escalator: 0.8460, Acc.ottoman: 0.8721, Acc.bottle: 0.8413, Acc.buffet: 0.4589, Acc.poster: 0.4881, Acc.stage: 0.7454, Acc.van: 0.7531, Acc.ship: 0.4474, Acc.fountain: 0.6181, Acc.conveyer belt: 0.9747, Acc.canopy: 0.6280, Acc.washer: 0.9391, Acc.plaything: 0.6071, Acc.swimming pool: 0.7258, Acc.stool: 0.8548, Acc.barrel: 0.9663, Acc.basket: 0.7799, Acc.waterfall: 0.8828, Acc.tent: 0.9789, Acc.bag: 0.5055, Acc.minibike: 0.9365, Acc.cradle: 0.9758, Acc.oven: 0.8240, Acc.ball: 0.4865, Acc.food: 0.8421, Acc.step: 0.4823, Acc.tank: 0.6753, Acc.trade name: 0.5289, Acc.microwave: 0.9465, Acc.pot: 0.7338, Acc.animal: 0.8853, Acc.bicycle: 0.8391, Acc.lake: 0.0000, Acc.dishwasher: 0.9059, Acc.screen: 0.9424, Acc.blanket: 0.6076, Acc.sculpture: 0.9073, Acc.hood: 0.8242, Acc.sconce: 0.8328, Acc.vase: 0.8279, Acc.traffic light: 0.7245, Acc.tray: 0.5737, Acc.ashcan: 0.7453, Acc.fan: 0.8621, Acc.pier: 0.4362, Acc.crt screen: 0.0806, Acc.plate: 0.8773, Acc.monitor: 0.0469, Acc.bulletin board: 0.8771, Acc.shower: 0.2863, Acc.radiator: 0.9330, Acc.glass: 0.3304, Acc.clock: 0.7622, Acc.flag: 0.8863
2022-11-30 18:28:26,581 - mmseg - INFO - Iter [18050/40000]	lr: 7.300e-08, eta: 1 day, 2:42:20, time: 8.651, data_time: 4.554, memory: 51902, decode.loss_cls: 0.4106, decode.loss_mask: 0.5713, decode.loss_dice: 0.8345, decode.d0.loss_cls: 6.5277, decode.d0.loss_mask: 0.5525, decode.d0.loss_dice: 0.9069, decode.d1.loss_cls: 0.5306, decode.d1.loss_mask: 0.5951, decode.d1.loss_dice: 0.8948, decode.d2.loss_cls: 0.4690, decode.d2.loss_mask: 0.5853, decode.d2.loss_dice: 0.8574, decode.d3.loss_cls: 0.4364, decode.d3.loss_mask: 0.5766, decode.d3.loss_dice: 0.8447, decode.d4.loss_cls: 0.4250, decode.d4.loss_mask: 0.5753, decode.d4.loss_dice: 0.8408, decode.d5.loss_cls: 0.4174, decode.d5.loss_mask: 0.5714, decode.d5.loss_dice: 0.8382, decode.d6.loss_cls: 0.4143, decode.d6.loss_mask: 0.5700, decode.d6.loss_dice: 0.8356, decode.d7.loss_cls: 0.4067, decode.d7.loss_mask: 0.5703, decode.d7.loss_dice: 0.8367, decode.d8.loss_cls: 0.4075, decode.d8.loss_mask: 0.5713, decode.d8.loss_dice: 0.8340, loss: 24.7078
2022-11-30 18:31:52,517 - mmseg - INFO - Iter [18100/40000]	lr: 7.284e-08, eta: 1 day, 2:38:25, time: 4.119, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3966, decode.loss_mask: 0.5680, decode.loss_dice: 0.8215, decode.d0.loss_cls: 6.4961, decode.d0.loss_mask: 0.5451, decode.d0.loss_dice: 0.8817, decode.d1.loss_cls: 0.5176, decode.d1.loss_mask: 0.5940, decode.d1.loss_dice: 0.8791, decode.d2.loss_cls: 0.4590, decode.d2.loss_mask: 0.5790, decode.d2.loss_dice: 0.8414, decode.d3.loss_cls: 0.4263, decode.d3.loss_mask: 0.5702, decode.d3.loss_dice: 0.8284, decode.d4.loss_cls: 0.4164, decode.d4.loss_mask: 0.5699, decode.d4.loss_dice: 0.8263, decode.d5.loss_cls: 0.4072, decode.d5.loss_mask: 0.5690, decode.d5.loss_dice: 0.8254, decode.d6.loss_cls: 0.4056, decode.d6.loss_mask: 0.5684, decode.d6.loss_dice: 0.8196, decode.d7.loss_cls: 0.3977, decode.d7.loss_mask: 0.5680, decode.d7.loss_dice: 0.8226, decode.d8.loss_cls: 0.3988, decode.d8.loss_mask: 0.5675, decode.d8.loss_dice: 0.8228, loss: 24.3893
2022-11-30 18:35:18,379 - mmseg - INFO - Iter [18150/40000]	lr: 7.267e-08, eta: 1 day, 2:34:31, time: 4.117, data_time: 0.023, memory: 51902, decode.loss_cls: 0.4055, decode.loss_mask: 0.5798, decode.loss_dice: 0.8319, decode.d0.loss_cls: 6.4829, decode.d0.loss_mask: 0.5597, decode.d0.loss_dice: 0.8973, decode.d1.loss_cls: 0.5140, decode.d1.loss_mask: 0.6024, decode.d1.loss_dice: 0.8895, decode.d2.loss_cls: 0.4614, decode.d2.loss_mask: 0.5892, decode.d2.loss_dice: 0.8511, decode.d3.loss_cls: 0.4262, decode.d3.loss_mask: 0.5820, decode.d3.loss_dice: 0.8389, decode.d4.loss_cls: 0.4217, decode.d4.loss_mask: 0.5813, decode.d4.loss_dice: 0.8343, decode.d5.loss_cls: 0.4119, decode.d5.loss_mask: 0.5806, decode.d5.loss_dice: 0.8327, decode.d6.loss_cls: 0.4055, decode.d6.loss_mask: 0.5794, decode.d6.loss_dice: 0.8303, decode.d7.loss_cls: 0.4074, decode.d7.loss_mask: 0.5787, decode.d7.loss_dice: 0.8292, decode.d8.loss_cls: 0.4038, decode.d8.loss_mask: 0.5793, decode.d8.loss_dice: 0.8347, loss: 24.6223
2022-11-30 18:38:43,858 - mmseg - INFO - Iter [18200/40000]	lr: 7.250e-08, eta: 1 day, 2:30:36, time: 4.110, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4007, decode.loss_mask: 0.5677, decode.loss_dice: 0.8485, decode.d0.loss_cls: 6.4863, decode.d0.loss_mask: 0.5420, decode.d0.loss_dice: 0.9085, decode.d1.loss_cls: 0.5243, decode.d1.loss_mask: 0.5903, decode.d1.loss_dice: 0.9057, decode.d2.loss_cls: 0.4594, decode.d2.loss_mask: 0.5802, decode.d2.loss_dice: 0.8666, decode.d3.loss_cls: 0.4298, decode.d3.loss_mask: 0.5734, decode.d3.loss_dice: 0.8486, decode.d4.loss_cls: 0.4193, decode.d4.loss_mask: 0.5719, decode.d4.loss_dice: 0.8494, decode.d5.loss_cls: 0.4106, decode.d5.loss_mask: 0.5702, decode.d5.loss_dice: 0.8482, decode.d6.loss_cls: 0.4053, decode.d6.loss_mask: 0.5679, decode.d6.loss_dice: 0.8428, decode.d7.loss_cls: 0.4012, decode.d7.loss_mask: 0.5689, decode.d7.loss_dice: 0.8448, decode.d8.loss_cls: 0.4026, decode.d8.loss_mask: 0.5675, decode.d8.loss_dice: 0.8455, loss: 24.6481
2022-11-30 18:42:09,573 - mmseg - INFO - Iter [18250/40000]	lr: 7.234e-08, eta: 1 day, 2:26:41, time: 4.114, data_time: 0.021, memory: 51902, decode.loss_cls: 0.4145, decode.loss_mask: 0.5747, decode.loss_dice: 0.8493, decode.d0.loss_cls: 6.4808, decode.d0.loss_mask: 0.5478, decode.d0.loss_dice: 0.9186, decode.d1.loss_cls: 0.5367, decode.d1.loss_mask: 0.5958, decode.d1.loss_dice: 0.9090, decode.d2.loss_cls: 0.4699, decode.d2.loss_mask: 0.5849, decode.d2.loss_dice: 0.8757, decode.d3.loss_cls: 0.4369, decode.d3.loss_mask: 0.5785, decode.d3.loss_dice: 0.8612, decode.d4.loss_cls: 0.4268, decode.d4.loss_mask: 0.5773, decode.d4.loss_dice: 0.8611, decode.d5.loss_cls: 0.4232, decode.d5.loss_mask: 0.5743, decode.d5.loss_dice: 0.8540, decode.d6.loss_cls: 0.4182, decode.d6.loss_mask: 0.5741, decode.d6.loss_dice: 0.8513, decode.d7.loss_cls: 0.4132, decode.d7.loss_mask: 0.5763, decode.d7.loss_dice: 0.8546, decode.d8.loss_cls: 0.4147, decode.d8.loss_mask: 0.5739, decode.d8.loss_dice: 0.8487, loss: 24.8759
2022-11-30 18:45:35,795 - mmseg - INFO - Iter [18300/40000]	lr: 7.217e-08, eta: 1 day, 2:22:47, time: 4.124, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4087, decode.loss_mask: 0.5685, decode.loss_dice: 0.8429, decode.d0.loss_cls: 6.4896, decode.d0.loss_mask: 0.5490, decode.d0.loss_dice: 0.9006, decode.d1.loss_cls: 0.5311, decode.d1.loss_mask: 0.5880, decode.d1.loss_dice: 0.8884, decode.d2.loss_cls: 0.4708, decode.d2.loss_mask: 0.5761, decode.d2.loss_dice: 0.8597, decode.d3.loss_cls: 0.4343, decode.d3.loss_mask: 0.5719, decode.d3.loss_dice: 0.8488, decode.d4.loss_cls: 0.4254, decode.d4.loss_mask: 0.5699, decode.d4.loss_dice: 0.8442, decode.d5.loss_cls: 0.4151, decode.d5.loss_mask: 0.5696, decode.d5.loss_dice: 0.8427, decode.d6.loss_cls: 0.4164, decode.d6.loss_mask: 0.5671, decode.d6.loss_dice: 0.8382, decode.d7.loss_cls: 0.4138, decode.d7.loss_mask: 0.5683, decode.d7.loss_dice: 0.8380, decode.d8.loss_cls: 0.4117, decode.d8.loss_mask: 0.5673, decode.d8.loss_dice: 0.8360, loss: 24.6521
2022-11-30 18:49:03,498 - mmseg - INFO - Iter [18350/40000]	lr: 7.200e-08, eta: 1 day, 2:18:55, time: 4.154, data_time: 0.066, memory: 51902, decode.loss_cls: 0.3960, decode.loss_mask: 0.5649, decode.loss_dice: 0.8217, decode.d0.loss_cls: 6.4571, decode.d0.loss_mask: 0.5472, decode.d0.loss_dice: 0.8856, decode.d1.loss_cls: 0.5056, decode.d1.loss_mask: 0.5895, decode.d1.loss_dice: 0.8771, decode.d2.loss_cls: 0.4523, decode.d2.loss_mask: 0.5748, decode.d2.loss_dice: 0.8457, decode.d3.loss_cls: 0.4170, decode.d3.loss_mask: 0.5726, decode.d3.loss_dice: 0.8320, decode.d4.loss_cls: 0.4082, decode.d4.loss_mask: 0.5709, decode.d4.loss_dice: 0.8255, decode.d5.loss_cls: 0.3996, decode.d5.loss_mask: 0.5685, decode.d5.loss_dice: 0.8267, decode.d6.loss_cls: 0.3957, decode.d6.loss_mask: 0.5667, decode.d6.loss_dice: 0.8207, decode.d7.loss_cls: 0.3953, decode.d7.loss_mask: 0.5651, decode.d7.loss_dice: 0.8193, decode.d8.loss_cls: 0.3930, decode.d8.loss_mask: 0.5661, decode.d8.loss_dice: 0.8186, loss: 24.2791
2022-11-30 18:52:29,399 - mmseg - INFO - Iter [18400/40000]	lr: 7.184e-08, eta: 1 day, 2:15:01, time: 4.118, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3958, decode.loss_mask: 0.5557, decode.loss_dice: 0.8338, decode.d0.loss_cls: 6.4544, decode.d0.loss_mask: 0.5391, decode.d0.loss_dice: 0.8978, decode.d1.loss_cls: 0.5143, decode.d1.loss_mask: 0.5816, decode.d1.loss_dice: 0.8870, decode.d2.loss_cls: 0.4600, decode.d2.loss_mask: 0.5666, decode.d2.loss_dice: 0.8533, decode.d3.loss_cls: 0.4283, decode.d3.loss_mask: 0.5605, decode.d3.loss_dice: 0.8412, decode.d4.loss_cls: 0.4155, decode.d4.loss_mask: 0.5596, decode.d4.loss_dice: 0.8373, decode.d5.loss_cls: 0.4018, decode.d5.loss_mask: 0.5562, decode.d5.loss_dice: 0.8306, decode.d6.loss_cls: 0.4012, decode.d6.loss_mask: 0.5551, decode.d6.loss_dice: 0.8288, decode.d7.loss_cls: 0.3968, decode.d7.loss_mask: 0.5558, decode.d7.loss_dice: 0.8314, decode.d8.loss_cls: 0.3950, decode.d8.loss_mask: 0.5570, decode.d8.loss_dice: 0.8337, loss: 24.3252
2022-11-30 18:55:55,315 - mmseg - INFO - Iter [18450/40000]	lr: 7.167e-08, eta: 1 day, 2:11:08, time: 4.118, data_time: 0.022, memory: 51902, decode.loss_cls: 0.4113, decode.loss_mask: 0.5489, decode.loss_dice: 0.8251, decode.d0.loss_cls: 6.4599, decode.d0.loss_mask: 0.5329, decode.d0.loss_dice: 0.8880, decode.d1.loss_cls: 0.5301, decode.d1.loss_mask: 0.5734, decode.d1.loss_dice: 0.8791, decode.d2.loss_cls: 0.4711, decode.d2.loss_mask: 0.5604, decode.d2.loss_dice: 0.8404, decode.d3.loss_cls: 0.4351, decode.d3.loss_mask: 0.5514, decode.d3.loss_dice: 0.8322, decode.d4.loss_cls: 0.4273, decode.d4.loss_mask: 0.5518, decode.d4.loss_dice: 0.8317, decode.d5.loss_cls: 0.4194, decode.d5.loss_mask: 0.5483, decode.d5.loss_dice: 0.8270, decode.d6.loss_cls: 0.4177, decode.d6.loss_mask: 0.5445, decode.d6.loss_dice: 0.8248, decode.d7.loss_cls: 0.4134, decode.d7.loss_mask: 0.5468, decode.d7.loss_dice: 0.8235, decode.d8.loss_cls: 0.4106, decode.d8.loss_mask: 0.5475, decode.d8.loss_dice: 0.8223, loss: 24.2959
2022-11-30 18:59:21,173 - mmseg - INFO - Iter [18500/40000]	lr: 7.151e-08, eta: 1 day, 2:07:14, time: 4.117, data_time: 0.021, memory: 51902, decode.loss_cls: 0.4152, decode.loss_mask: 0.5574, decode.loss_dice: 0.8216, decode.d0.loss_cls: 6.4649, decode.d0.loss_mask: 0.5427, decode.d0.loss_dice: 0.8962, decode.d1.loss_cls: 0.5259, decode.d1.loss_mask: 0.5827, decode.d1.loss_dice: 0.8801, decode.d2.loss_cls: 0.4705, decode.d2.loss_mask: 0.5717, decode.d2.loss_dice: 0.8389, decode.d3.loss_cls: 0.4343, decode.d3.loss_mask: 0.5637, decode.d3.loss_dice: 0.8281, decode.d4.loss_cls: 0.4285, decode.d4.loss_mask: 0.5599, decode.d4.loss_dice: 0.8235, decode.d5.loss_cls: 0.4198, decode.d5.loss_mask: 0.5585, decode.d5.loss_dice: 0.8218, decode.d6.loss_cls: 0.4189, decode.d6.loss_mask: 0.5574, decode.d6.loss_dice: 0.8212, decode.d7.loss_cls: 0.4151, decode.d7.loss_mask: 0.5578, decode.d7.loss_dice: 0.8204, decode.d8.loss_cls: 0.4134, decode.d8.loss_mask: 0.5571, decode.d8.loss_dice: 0.8213, loss: 24.3887
2022-11-30 19:02:46,747 - mmseg - INFO - Iter [18550/40000]	lr: 7.134e-08, eta: 1 day, 2:03:20, time: 4.111, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3923, decode.loss_mask: 0.5582, decode.loss_dice: 0.8146, decode.d0.loss_cls: 6.4371, decode.d0.loss_mask: 0.5398, decode.d0.loss_dice: 0.8830, decode.d1.loss_cls: 0.5067, decode.d1.loss_mask: 0.5789, decode.d1.loss_dice: 0.8736, decode.d2.loss_cls: 0.4449, decode.d2.loss_mask: 0.5712, decode.d2.loss_dice: 0.8387, decode.d3.loss_cls: 0.4115, decode.d3.loss_mask: 0.5621, decode.d3.loss_dice: 0.8278, decode.d4.loss_cls: 0.4056, decode.d4.loss_mask: 0.5618, decode.d4.loss_dice: 0.8240, decode.d5.loss_cls: 0.3954, decode.d5.loss_mask: 0.5585, decode.d5.loss_dice: 0.8204, decode.d6.loss_cls: 0.3925, decode.d6.loss_mask: 0.5593, decode.d6.loss_dice: 0.8183, decode.d7.loss_cls: 0.3878, decode.d7.loss_mask: 0.5588, decode.d7.loss_dice: 0.8199, decode.d8.loss_cls: 0.3869, decode.d8.loss_mask: 0.5577, decode.d8.loss_dice: 0.8206, loss: 24.1077
2022-11-30 19:06:12,684 - mmseg - INFO - Iter [18600/40000]	lr: 7.117e-08, eta: 1 day, 1:59:27, time: 4.119, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3986, decode.loss_mask: 0.5839, decode.loss_dice: 0.8365, decode.d0.loss_cls: 6.4228, decode.d0.loss_mask: 0.5615, decode.d0.loss_dice: 0.9002, decode.d1.loss_cls: 0.5224, decode.d1.loss_mask: 0.6008, decode.d1.loss_dice: 0.8892, decode.d2.loss_cls: 0.4629, decode.d2.loss_mask: 0.5898, decode.d2.loss_dice: 0.8579, decode.d3.loss_cls: 0.4278, decode.d3.loss_mask: 0.5847, decode.d3.loss_dice: 0.8432, decode.d4.loss_cls: 0.4181, decode.d4.loss_mask: 0.5835, decode.d4.loss_dice: 0.8380, decode.d5.loss_cls: 0.4070, decode.d5.loss_mask: 0.5837, decode.d5.loss_dice: 0.8410, decode.d6.loss_cls: 0.4044, decode.d6.loss_mask: 0.5819, decode.d6.loss_dice: 0.8360, decode.d7.loss_cls: 0.4044, decode.d7.loss_mask: 0.5818, decode.d7.loss_dice: 0.8390, decode.d8.loss_cls: 0.4011, decode.d8.loss_mask: 0.5838, decode.d8.loss_dice: 0.8359, loss: 24.6217
2022-11-30 19:09:38,172 - mmseg - INFO - Iter [18650/40000]	lr: 7.101e-08, eta: 1 day, 1:55:33, time: 4.110, data_time: 0.021, memory: 51902, decode.loss_cls: 0.4016, decode.loss_mask: 0.5586, decode.loss_dice: 0.8198, decode.d0.loss_cls: 6.4268, decode.d0.loss_mask: 0.5417, decode.d0.loss_dice: 0.8867, decode.d1.loss_cls: 0.5145, decode.d1.loss_mask: 0.5819, decode.d1.loss_dice: 0.8718, decode.d2.loss_cls: 0.4564, decode.d2.loss_mask: 0.5688, decode.d2.loss_dice: 0.8418, decode.d3.loss_cls: 0.4244, decode.d3.loss_mask: 0.5627, decode.d3.loss_dice: 0.8258, decode.d4.loss_cls: 0.4163, decode.d4.loss_mask: 0.5597, decode.d4.loss_dice: 0.8234, decode.d5.loss_cls: 0.4084, decode.d5.loss_mask: 0.5579, decode.d5.loss_dice: 0.8202, decode.d6.loss_cls: 0.4069, decode.d6.loss_mask: 0.5572, decode.d6.loss_dice: 0.8175, decode.d7.loss_cls: 0.4024, decode.d7.loss_mask: 0.5573, decode.d7.loss_dice: 0.8199, decode.d8.loss_cls: 0.4002, decode.d8.loss_mask: 0.5581, decode.d8.loss_dice: 0.8209, loss: 24.2096
2022-11-30 19:13:03,974 - mmseg - INFO - Iter [18700/40000]	lr: 7.084e-08, eta: 1 day, 1:51:40, time: 4.116, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4043, decode.loss_mask: 0.5753, decode.loss_dice: 0.8372, decode.d0.loss_cls: 6.4107, decode.d0.loss_mask: 0.5506, decode.d0.loss_dice: 0.9035, decode.d1.loss_cls: 0.5145, decode.d1.loss_mask: 0.6006, decode.d1.loss_dice: 0.9055, decode.d2.loss_cls: 0.4579, decode.d2.loss_mask: 0.5861, decode.d2.loss_dice: 0.8702, decode.d3.loss_cls: 0.4255, decode.d3.loss_mask: 0.5802, decode.d3.loss_dice: 0.8508, decode.d4.loss_cls: 0.4216, decode.d4.loss_mask: 0.5749, decode.d4.loss_dice: 0.8433, decode.d5.loss_cls: 0.4120, decode.d5.loss_mask: 0.5763, decode.d5.loss_dice: 0.8416, decode.d6.loss_cls: 0.4083, decode.d6.loss_mask: 0.5762, decode.d6.loss_dice: 0.8430, decode.d7.loss_cls: 0.4065, decode.d7.loss_mask: 0.5753, decode.d7.loss_dice: 0.8427, decode.d8.loss_cls: 0.4017, decode.d8.loss_mask: 0.5762, decode.d8.loss_dice: 0.8424, loss: 24.6153
2022-11-30 19:16:29,701 - mmseg - INFO - Iter [18750/40000]	lr: 7.067e-08, eta: 1 day, 1:47:47, time: 4.115, data_time: 0.022, memory: 51902, decode.loss_cls: 0.4121, decode.loss_mask: 0.5718, decode.loss_dice: 0.8386, decode.d0.loss_cls: 6.4098, decode.d0.loss_mask: 0.5542, decode.d0.loss_dice: 0.9127, decode.d1.loss_cls: 0.5293, decode.d1.loss_mask: 0.5920, decode.d1.loss_dice: 0.8952, decode.d2.loss_cls: 0.4698, decode.d2.loss_mask: 0.5825, decode.d2.loss_dice: 0.8591, decode.d3.loss_cls: 0.4340, decode.d3.loss_mask: 0.5769, decode.d3.loss_dice: 0.8469, decode.d4.loss_cls: 0.4284, decode.d4.loss_mask: 0.5741, decode.d4.loss_dice: 0.8470, decode.d5.loss_cls: 0.4183, decode.d5.loss_mask: 0.5743, decode.d5.loss_dice: 0.8412, decode.d6.loss_cls: 0.4153, decode.d6.loss_mask: 0.5708, decode.d6.loss_dice: 0.8395, decode.d7.loss_cls: 0.4149, decode.d7.loss_mask: 0.5685, decode.d7.loss_dice: 0.8405, decode.d8.loss_cls: 0.4127, decode.d8.loss_mask: 0.5705, decode.d8.loss_dice: 0.8376, loss: 24.6385
2022-11-30 19:19:55,289 - mmseg - INFO - Iter [18800/40000]	lr: 7.051e-08, eta: 1 day, 1:43:54, time: 4.112, data_time: 0.022, memory: 51902, decode.loss_cls: 0.3941, decode.loss_mask: 0.5684, decode.loss_dice: 0.8265, decode.d0.loss_cls: 6.3888, decode.d0.loss_mask: 0.5512, decode.d0.loss_dice: 0.8938, decode.d1.loss_cls: 0.5111, decode.d1.loss_mask: 0.5950, decode.d1.loss_dice: 0.8854, decode.d2.loss_cls: 0.4529, decode.d2.loss_mask: 0.5790, decode.d2.loss_dice: 0.8527, decode.d3.loss_cls: 0.4214, decode.d3.loss_mask: 0.5720, decode.d3.loss_dice: 0.8372, decode.d4.loss_cls: 0.4114, decode.d4.loss_mask: 0.5718, decode.d4.loss_dice: 0.8317, decode.d5.loss_cls: 0.4030, decode.d5.loss_mask: 0.5704, decode.d5.loss_dice: 0.8249, decode.d6.loss_cls: 0.4025, decode.d6.loss_mask: 0.5684, decode.d6.loss_dice: 0.8222, decode.d7.loss_cls: 0.3974, decode.d7.loss_mask: 0.5687, decode.d7.loss_dice: 0.8225, decode.d8.loss_cls: 0.3921, decode.d8.loss_mask: 0.5700, decode.d8.loss_dice: 0.8245, loss: 24.3112
2022-11-30 19:23:21,183 - mmseg - INFO - Iter [18850/40000]	lr: 7.034e-08, eta: 1 day, 1:40:01, time: 4.118, data_time: 0.021, memory: 51902, decode.loss_cls: 0.4056, decode.loss_mask: 0.5653, decode.loss_dice: 0.8333, decode.d0.loss_cls: 6.3959, decode.d0.loss_mask: 0.5474, decode.d0.loss_dice: 0.9046, decode.d1.loss_cls: 0.5417, decode.d1.loss_mask: 0.5841, decode.d1.loss_dice: 0.8936, decode.d2.loss_cls: 0.4672, decode.d2.loss_mask: 0.5757, decode.d2.loss_dice: 0.8536, decode.d3.loss_cls: 0.4320, decode.d3.loss_mask: 0.5709, decode.d3.loss_dice: 0.8405, decode.d4.loss_cls: 0.4269, decode.d4.loss_mask: 0.5677, decode.d4.loss_dice: 0.8325, decode.d5.loss_cls: 0.4171, decode.d5.loss_mask: 0.5677, decode.d5.loss_dice: 0.8318, decode.d6.loss_cls: 0.4116, decode.d6.loss_mask: 0.5644, decode.d6.loss_dice: 0.8276, decode.d7.loss_cls: 0.4072, decode.d7.loss_mask: 0.5658, decode.d7.loss_dice: 0.8324, decode.d8.loss_cls: 0.4061, decode.d8.loss_mask: 0.5657, decode.d8.loss_dice: 0.8324, loss: 24.4686
2022-11-30 19:26:46,907 - mmseg - INFO - Iter [18900/40000]	lr: 7.018e-08, eta: 1 day, 1:36:09, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3915, decode.loss_mask: 0.5717, decode.loss_dice: 0.8241, decode.d0.loss_cls: 6.3673, decode.d0.loss_mask: 0.5553, decode.d0.loss_dice: 0.8916, decode.d1.loss_cls: 0.5098, decode.d1.loss_mask: 0.5930, decode.d1.loss_dice: 0.8793, decode.d2.loss_cls: 0.4526, decode.d2.loss_mask: 0.5812, decode.d2.loss_dice: 0.8448, decode.d3.loss_cls: 0.4210, decode.d3.loss_mask: 0.5756, decode.d3.loss_dice: 0.8321, decode.d4.loss_cls: 0.4145, decode.d4.loss_mask: 0.5750, decode.d4.loss_dice: 0.8281, decode.d5.loss_cls: 0.4032, decode.d5.loss_mask: 0.5740, decode.d5.loss_dice: 0.8293, decode.d6.loss_cls: 0.3962, decode.d6.loss_mask: 0.5722, decode.d6.loss_dice: 0.8250, decode.d7.loss_cls: 0.3925, decode.d7.loss_mask: 0.5717, decode.d7.loss_dice: 0.8250, decode.d8.loss_cls: 0.3939, decode.d8.loss_mask: 0.5732, decode.d8.loss_dice: 0.8231, loss: 24.2878
2022-11-30 19:30:12,411 - mmseg - INFO - Iter [18950/40000]	lr: 7.001e-08, eta: 1 day, 1:32:16, time: 4.110, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3934, decode.loss_mask: 0.5544, decode.loss_dice: 0.8195, decode.d0.loss_cls: 6.3765, decode.d0.loss_mask: 0.5414, decode.d0.loss_dice: 0.8875, decode.d1.loss_cls: 0.5195, decode.d1.loss_mask: 0.5789, decode.d1.loss_dice: 0.8799, decode.d2.loss_cls: 0.4527, decode.d2.loss_mask: 0.5669, decode.d2.loss_dice: 0.8461, decode.d3.loss_cls: 0.4210, decode.d3.loss_mask: 0.5605, decode.d3.loss_dice: 0.8263, decode.d4.loss_cls: 0.4160, decode.d4.loss_mask: 0.5592, decode.d4.loss_dice: 0.8262, decode.d5.loss_cls: 0.4037, decode.d5.loss_mask: 0.5559, decode.d5.loss_dice: 0.8225, decode.d6.loss_cls: 0.3971, decode.d6.loss_mask: 0.5549, decode.d6.loss_dice: 0.8203, decode.d7.loss_cls: 0.3991, decode.d7.loss_mask: 0.5552, decode.d7.loss_dice: 0.8188, decode.d8.loss_cls: 0.3968, decode.d8.loss_mask: 0.5556, decode.d8.loss_dice: 0.8179, loss: 24.1239
2022-11-30 19:33:40,711 - mmseg - INFO - Saving checkpoint at 19000 iterations
2022-11-30 19:34:31,563 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 19:34:31,563 - mmseg - INFO - Iter [19000/40000]	lr: 6.984e-08, eta: 1 day, 1:29:23, time: 5.183, data_time: 0.067, memory: 51902, decode.loss_cls: 0.4204, decode.loss_mask: 0.5653, decode.loss_dice: 0.8392, decode.d0.loss_cls: 6.4003, decode.d0.loss_mask: 0.5484, decode.d0.loss_dice: 0.9087, decode.d1.loss_cls: 0.5333, decode.d1.loss_mask: 0.5851, decode.d1.loss_dice: 0.8993, decode.d2.loss_cls: 0.4806, decode.d2.loss_mask: 0.5741, decode.d2.loss_dice: 0.8590, decode.d3.loss_cls: 0.4462, decode.d3.loss_mask: 0.5682, decode.d3.loss_dice: 0.8479, decode.d4.loss_cls: 0.4362, decode.d4.loss_mask: 0.5685, decode.d4.loss_dice: 0.8437, decode.d5.loss_cls: 0.4236, decode.d5.loss_mask: 0.5650, decode.d5.loss_dice: 0.8494, decode.d6.loss_cls: 0.4196, decode.d6.loss_mask: 0.5645, decode.d6.loss_dice: 0.8409, decode.d7.loss_cls: 0.4197, decode.d7.loss_mask: 0.5652, decode.d7.loss_dice: 0.8420, decode.d8.loss_cls: 0.4178, decode.d8.loss_mask: 0.5639, decode.d8.loss_dice: 0.8396, loss: 24.6355
2022-11-30 19:37:29,579 - mmseg - INFO - per class results:
2022-11-30 19:37:29,583 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 82.99 | 89.74 |
|       building      |  85.3 | 91.27 |
|         sky         | 95.13 | 97.45 |
|        floor        | 84.95 |  89.7 |
|         tree        | 77.99 |  88.0 |
|       ceiling       | 87.12 | 92.55 |
|         road        | 87.86 | 91.89 |
|         bed         | 93.61 | 97.02 |
|      windowpane     | 68.76 | 82.73 |
|        grass        | 68.93 |  81.5 |
|       cabinet       | 63.35 | 75.07 |
|       sidewalk      | 74.14 |  88.2 |
|        person       | 88.42 | 94.14 |
|        earth        | 39.58 |  52.4 |
|         door        | 62.18 | 80.03 |
|        table        | 72.18 | 81.97 |
|       mountain      | 60.03 | 67.12 |
|        plant        | 55.83 | 74.05 |
|       curtain       |  82.9 | 90.51 |
|        chair        | 67.93 |  77.9 |
|         car         |  89.9 | 95.26 |
|        water        | 65.42 | 85.13 |
|       painting      | 82.13 | 92.41 |
|         sofa        | 85.25 | 92.28 |
|        shelf        | 51.36 |  63.6 |
|        house        | 52.59 | 70.35 |
|         sea         | 73.87 | 81.96 |
|        mirror       | 80.95 | 92.51 |
|         rug         | 72.05 | 85.54 |
|        field        | 38.17 | 77.35 |
|       armchair      | 61.86 | 81.16 |
|         seat        | 66.98 | 90.98 |
|        fence        | 56.85 |  76.3 |
|         desk        | 60.34 | 85.29 |
|         rock        | 62.32 | 82.17 |
|       wardrobe      | 56.43 | 89.14 |
|         lamp        | 80.92 | 90.75 |
|       bathtub       | 90.98 | 93.45 |
|       railing       | 45.87 |  69.0 |
|       cushion       | 76.91 | 90.97 |
|         base        | 48.17 | 69.99 |
|         box         |  41.2 | 58.93 |
|        column       | 58.98 | 78.06 |
|      signboard      | 45.31 | 69.28 |
|   chest of drawers  | 47.73 | 65.72 |
|       counter       | 55.98 | 71.09 |
|         sand        | 59.95 | 88.33 |
|         sink        |  82.6 | 87.12 |
|      skyscraper     | 44.16 | 58.72 |
|      fireplace      | 79.04 | 96.92 |
|     refrigerator    | 85.03 | 95.61 |
|      grandstand     | 45.13 | 75.02 |
|         path        | 29.64 | 37.79 |
|        stairs       | 34.41 | 43.75 |
|        runway       | 74.37 | 94.72 |
|         case        |  70.0 | 88.45 |
|      pool table     | 95.91 | 98.75 |
|        pillow       |  72.5 | 83.39 |
|     screen door     | 84.08 | 93.47 |
|       stairway      | 58.38 | 74.61 |
|        river        | 22.97 | 26.42 |
|        bridge       | 75.61 | 89.19 |
|       bookcase      |  44.0 | 70.78 |
|        blind        | 45.77 | 55.21 |
|     coffee table    | 72.24 | 88.53 |
|        toilet       | 93.19 | 96.81 |
|        flower       | 43.42 | 67.56 |
|         book        | 59.63 | 77.12 |
|         hill        | 11.87 | 24.13 |
|        bench        | 75.76 | 81.75 |
|      countertop     |  76.3 | 90.51 |
|        stove        | 85.87 | 89.78 |
|         palm        | 55.68 | 82.88 |
|    kitchen island   | 43.93 | 85.78 |
|       computer      | 82.19 | 91.46 |
|     swivel chair    | 56.85 | 83.92 |
|         boat        | 52.02 | 89.55 |
|         bar         | 74.35 | 82.86 |
|    arcade machine   | 91.55 | 98.71 |
|        hovel        | 52.43 | 69.57 |
|         bus         | 94.55 | 96.43 |
|        towel        | 84.66 | 93.45 |
|        light        |  65.7 | 79.09 |
|        truck        | 55.16 |  74.0 |
|        tower        | 34.82 | 61.86 |
|      chandelier     | 77.64 | 87.65 |
|        awning       | 34.15 | 58.37 |
|     streetlight     | 46.21 | 69.83 |
|        booth        | 56.08 | 71.03 |
| television receiver | 73.85 | 89.48 |
|       airplane      | 88.48 | 96.34 |
|      dirt track     |  8.29 | 15.23 |
|       apparel       | 56.47 | 87.85 |
|         pole        | 35.72 | 54.47 |
|         land        |  1.25 |  1.83 |
|      bannister      |  20.5 | 36.31 |
|      escalator      | 62.83 | 85.16 |
|       ottoman       | 58.13 | 79.42 |
|        bottle       | 53.51 | 77.93 |
|        buffet       | 11.53 | 12.97 |
|        poster       | 37.55 | 61.49 |
|        stage        | 30.74 | 82.27 |
|         van         | 57.19 | 76.84 |
|         ship        | 53.04 | 55.93 |
|       fountain      | 38.57 | 43.88 |
|    conveyer belt    | 79.61 | 97.43 |
|        canopy       | 46.26 | 65.17 |
|        washer       | 91.08 | 93.57 |
|      plaything      | 37.86 | 56.79 |
|    swimming pool    | 49.06 | 74.08 |
|        stool        |  63.2 | 79.96 |
|        barrel       | 64.36 | 94.75 |
|        basket       | 49.52 | 78.25 |
|      waterfall      | 44.95 | 54.91 |
|         tent        | 96.08 | 97.83 |
|         bag         | 34.59 | 47.51 |
|       minibike      | 81.44 | 93.61 |
|        cradle       | 91.37 | 97.51 |
|         oven        | 65.94 | 82.61 |
|         ball        | 38.37 | 41.25 |
|         food        | 63.99 | 75.48 |
|         step        | 21.79 | 36.69 |
|         tank        | 62.49 | 67.48 |
|      trade name     | 28.28 | 36.61 |
|      microwave      | 89.53 | 94.36 |
|         pot         | 60.92 |  72.9 |
|        animal       | 83.49 | 85.96 |
|       bicycle       | 60.53 | 82.69 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 80.31 |  90.5 |
|        screen       | 60.13 | 94.31 |
|       blanket       | 45.31 | 58.39 |
|      sculpture      | 71.86 | 90.38 |
|         hood        | 84.55 | 91.28 |
|        sconce       |  64.3 | 82.68 |
|         vase        | 57.24 | 82.72 |
|    traffic light    | 52.94 | 75.11 |
|         tray        |  31.1 | 49.07 |
|        ashcan       | 52.96 | 73.76 |
|         fan         | 73.22 | 85.47 |
|         pier        | 38.19 | 42.66 |
|      crt screen     |  4.5  | 11.76 |
|        plate        | 70.93 | 83.56 |
|       monitor       |  2.41 |  2.77 |
|    bulletin board   | 72.17 | 82.42 |
|        shower       | 21.52 | 30.52 |
|       radiator      | 73.26 | 92.72 |
|        glass        | 29.49 | 33.03 |
|        clock        | 64.73 |  76.2 |
|         flag        | 68.65 | 88.33 |
+---------------------+-------+-------+
2022-11-30 19:37:29,584 - mmseg - INFO - Summary:
2022-11-30 19:37:29,584 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 86.76 | 60.26 | 74.77 |
+-------+-------+-------+
2022-11-30 19:37:29,589 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 19:37:29,589 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8676, mIoU: 0.6026, mAcc: 0.7477, IoU.wall: 0.8299, IoU.building: 0.8530, IoU.sky: 0.9513, IoU.floor: 0.8495, IoU.tree: 0.7799, IoU.ceiling: 0.8712, IoU.road: 0.8786, IoU.bed : 0.9361, IoU.windowpane: 0.6876, IoU.grass: 0.6893, IoU.cabinet: 0.6335, IoU.sidewalk: 0.7414, IoU.person: 0.8842, IoU.earth: 0.3958, IoU.door: 0.6218, IoU.table: 0.7218, IoU.mountain: 0.6003, IoU.plant: 0.5583, IoU.curtain: 0.8290, IoU.chair: 0.6793, IoU.car: 0.8990, IoU.water: 0.6542, IoU.painting: 0.8213, IoU.sofa: 0.8525, IoU.shelf: 0.5136, IoU.house: 0.5259, IoU.sea: 0.7387, IoU.mirror: 0.8095, IoU.rug: 0.7205, IoU.field: 0.3817, IoU.armchair: 0.6186, IoU.seat: 0.6698, IoU.fence: 0.5685, IoU.desk: 0.6034, IoU.rock: 0.6232, IoU.wardrobe: 0.5643, IoU.lamp: 0.8092, IoU.bathtub: 0.9098, IoU.railing: 0.4587, IoU.cushion: 0.7691, IoU.base: 0.4817, IoU.box: 0.4120, IoU.column: 0.5898, IoU.signboard: 0.4531, IoU.chest of drawers: 0.4773, IoU.counter: 0.5598, IoU.sand: 0.5995, IoU.sink: 0.8260, IoU.skyscraper: 0.4416, IoU.fireplace: 0.7904, IoU.refrigerator: 0.8503, IoU.grandstand: 0.4513, IoU.path: 0.2964, IoU.stairs: 0.3441, IoU.runway: 0.7437, IoU.case: 0.7000, IoU.pool table: 0.9591, IoU.pillow: 0.7250, IoU.screen door: 0.8408, IoU.stairway: 0.5838, IoU.river: 0.2297, IoU.bridge: 0.7561, IoU.bookcase: 0.4400, IoU.blind: 0.4577, IoU.coffee table: 0.7224, IoU.toilet: 0.9319, IoU.flower: 0.4342, IoU.book: 0.5963, IoU.hill: 0.1187, IoU.bench: 0.7576, IoU.countertop: 0.7630, IoU.stove: 0.8587, IoU.palm: 0.5568, IoU.kitchen island: 0.4393, IoU.computer: 0.8219, IoU.swivel chair: 0.5685, IoU.boat: 0.5202, IoU.bar: 0.7435, IoU.arcade machine: 0.9155, IoU.hovel: 0.5243, IoU.bus: 0.9455, IoU.towel: 0.8466, IoU.light: 0.6570, IoU.truck: 0.5516, IoU.tower: 0.3482, IoU.chandelier: 0.7764, IoU.awning: 0.3415, IoU.streetlight: 0.4621, IoU.booth: 0.5608, IoU.television receiver: 0.7385, IoU.airplane: 0.8848, IoU.dirt track: 0.0829, IoU.apparel: 0.5647, IoU.pole: 0.3572, IoU.land: 0.0125, IoU.bannister: 0.2050, IoU.escalator: 0.6283, IoU.ottoman: 0.5813, IoU.bottle: 0.5351, IoU.buffet: 0.1153, IoU.poster: 0.3755, IoU.stage: 0.3074, IoU.van: 0.5719, IoU.ship: 0.5304, IoU.fountain: 0.3857, IoU.conveyer belt: 0.7961, IoU.canopy: 0.4626, IoU.washer: 0.9108, IoU.plaything: 0.3786, IoU.swimming pool: 0.4906, IoU.stool: 0.6320, IoU.barrel: 0.6436, IoU.basket: 0.4952, IoU.waterfall: 0.4495, IoU.tent: 0.9608, IoU.bag: 0.3459, IoU.minibike: 0.8144, IoU.cradle: 0.9137, IoU.oven: 0.6594, IoU.ball: 0.3837, IoU.food: 0.6399, IoU.step: 0.2179, IoU.tank: 0.6249, IoU.trade name: 0.2828, IoU.microwave: 0.8953, IoU.pot: 0.6092, IoU.animal: 0.8349, IoU.bicycle: 0.6053, IoU.lake: 0.0000, IoU.dishwasher: 0.8031, IoU.screen: 0.6013, IoU.blanket: 0.4531, IoU.sculpture: 0.7186, IoU.hood: 0.8455, IoU.sconce: 0.6430, IoU.vase: 0.5724, IoU.traffic light: 0.5294, IoU.tray: 0.3110, IoU.ashcan: 0.5296, IoU.fan: 0.7322, IoU.pier: 0.3819, IoU.crt screen: 0.0450, IoU.plate: 0.7093, IoU.monitor: 0.0241, IoU.bulletin board: 0.7217, IoU.shower: 0.2152, IoU.radiator: 0.7326, IoU.glass: 0.2949, IoU.clock: 0.6473, IoU.flag: 0.6865, Acc.wall: 0.8974, Acc.building: 0.9127, Acc.sky: 0.9745, Acc.floor: 0.8970, Acc.tree: 0.8800, Acc.ceiling: 0.9255, Acc.road: 0.9189, Acc.bed : 0.9702, Acc.windowpane: 0.8273, Acc.grass: 0.8150, Acc.cabinet: 0.7507, Acc.sidewalk: 0.8820, Acc.person: 0.9414, Acc.earth: 0.5240, Acc.door: 0.8003, Acc.table: 0.8197, Acc.mountain: 0.6712, Acc.plant: 0.7405, Acc.curtain: 0.9051, Acc.chair: 0.7790, Acc.car: 0.9526, Acc.water: 0.8513, Acc.painting: 0.9241, Acc.sofa: 0.9228, Acc.shelf: 0.6360, Acc.house: 0.7035, Acc.sea: 0.8196, Acc.mirror: 0.9251, Acc.rug: 0.8554, Acc.field: 0.7735, Acc.armchair: 0.8116, Acc.seat: 0.9098, Acc.fence: 0.7630, Acc.desk: 0.8529, Acc.rock: 0.8217, Acc.wardrobe: 0.8914, Acc.lamp: 0.9075, Acc.bathtub: 0.9345, Acc.railing: 0.6900, Acc.cushion: 0.9097, Acc.base: 0.6999, Acc.box: 0.5893, Acc.column: 0.7806, Acc.signboard: 0.6928, Acc.chest of drawers: 0.6572, Acc.counter: 0.7109, Acc.sand: 0.8833, Acc.sink: 0.8712, Acc.skyscraper: 0.5872, Acc.fireplace: 0.9692, Acc.refrigerator: 0.9561, Acc.grandstand: 0.7502, Acc.path: 0.3779, Acc.stairs: 0.4375, Acc.runway: 0.9472, Acc.case: 0.8845, Acc.pool table: 0.9875, Acc.pillow: 0.8339, Acc.screen door: 0.9347, Acc.stairway: 0.7461, Acc.river: 0.2642, Acc.bridge: 0.8919, Acc.bookcase: 0.7078, Acc.blind: 0.5521, Acc.coffee table: 0.8853, Acc.toilet: 0.9681, Acc.flower: 0.6756, Acc.book: 0.7712, Acc.hill: 0.2413, Acc.bench: 0.8175, Acc.countertop: 0.9051, Acc.stove: 0.8978, Acc.palm: 0.8288, Acc.kitchen island: 0.8578, Acc.computer: 0.9146, Acc.swivel chair: 0.8392, Acc.boat: 0.8955, Acc.bar: 0.8286, Acc.arcade machine: 0.9871, Acc.hovel: 0.6957, Acc.bus: 0.9643, Acc.towel: 0.9345, Acc.light: 0.7909, Acc.truck: 0.7400, Acc.tower: 0.6186, Acc.chandelier: 0.8765, Acc.awning: 0.5837, Acc.streetlight: 0.6983, Acc.booth: 0.7103, Acc.television receiver: 0.8948, Acc.airplane: 0.9634, Acc.dirt track: 0.1523, Acc.apparel: 0.8785, Acc.pole: 0.5447, Acc.land: 0.0183, Acc.bannister: 0.3631, Acc.escalator: 0.8516, Acc.ottoman: 0.7942, Acc.bottle: 0.7793, Acc.buffet: 0.1297, Acc.poster: 0.6149, Acc.stage: 0.8227, Acc.van: 0.7684, Acc.ship: 0.5593, Acc.fountain: 0.4388, Acc.conveyer belt: 0.9743, Acc.canopy: 0.6517, Acc.washer: 0.9357, Acc.plaything: 0.5679, Acc.swimming pool: 0.7408, Acc.stool: 0.7996, Acc.barrel: 0.9475, Acc.basket: 0.7825, Acc.waterfall: 0.5491, Acc.tent: 0.9783, Acc.bag: 0.4751, Acc.minibike: 0.9361, Acc.cradle: 0.9751, Acc.oven: 0.8261, Acc.ball: 0.4125, Acc.food: 0.7548, Acc.step: 0.3669, Acc.tank: 0.6748, Acc.trade name: 0.3661, Acc.microwave: 0.9436, Acc.pot: 0.7290, Acc.animal: 0.8596, Acc.bicycle: 0.8269, Acc.lake: 0.0000, Acc.dishwasher: 0.9050, Acc.screen: 0.9431, Acc.blanket: 0.5839, Acc.sculpture: 0.9038, Acc.hood: 0.9128, Acc.sconce: 0.8268, Acc.vase: 0.8272, Acc.traffic light: 0.7511, Acc.tray: 0.4907, Acc.ashcan: 0.7376, Acc.fan: 0.8547, Acc.pier: 0.4266, Acc.crt screen: 0.1176, Acc.plate: 0.8356, Acc.monitor: 0.0277, Acc.bulletin board: 0.8242, Acc.shower: 0.3052, Acc.radiator: 0.9272, Acc.glass: 0.3303, Acc.clock: 0.7620, Acc.flag: 0.8833
2022-11-30 19:40:56,248 - mmseg - INFO - Iter [19050/40000]	lr: 6.968e-08, eta: 1 day, 1:28:47, time: 7.694, data_time: 3.581, memory: 51902, decode.loss_cls: 0.3965, decode.loss_mask: 0.5571, decode.loss_dice: 0.8364, decode.d0.loss_cls: 6.3652, decode.d0.loss_mask: 0.5411, decode.d0.loss_dice: 0.8996, decode.d1.loss_cls: 0.5151, decode.d1.loss_mask: 0.5766, decode.d1.loss_dice: 0.8944, decode.d2.loss_cls: 0.4570, decode.d2.loss_mask: 0.5674, decode.d2.loss_dice: 0.8576, decode.d3.loss_cls: 0.4183, decode.d3.loss_mask: 0.5625, decode.d3.loss_dice: 0.8396, decode.d4.loss_cls: 0.4118, decode.d4.loss_mask: 0.5587, decode.d4.loss_dice: 0.8362, decode.d5.loss_cls: 0.4038, decode.d5.loss_mask: 0.5573, decode.d5.loss_dice: 0.8332, decode.d6.loss_cls: 0.4015, decode.d6.loss_mask: 0.5553, decode.d6.loss_dice: 0.8291, decode.d7.loss_cls: 0.4005, decode.d7.loss_mask: 0.5548, decode.d7.loss_dice: 0.8321, decode.d8.loss_cls: 0.3959, decode.d8.loss_mask: 0.5572, decode.d8.loss_dice: 0.8352, loss: 24.2471
2022-11-30 19:44:21,630 - mmseg - INFO - Iter [19100/40000]	lr: 6.951e-08, eta: 1 day, 1:24:53, time: 4.108, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3989, decode.loss_mask: 0.5786, decode.loss_dice: 0.8376, decode.d0.loss_cls: 6.3375, decode.d0.loss_mask: 0.5587, decode.d0.loss_dice: 0.8980, decode.d1.loss_cls: 0.5128, decode.d1.loss_mask: 0.6050, decode.d1.loss_dice: 0.8960, decode.d2.loss_cls: 0.4568, decode.d2.loss_mask: 0.5904, decode.d2.loss_dice: 0.8593, decode.d3.loss_cls: 0.4224, decode.d3.loss_mask: 0.5850, decode.d3.loss_dice: 0.8491, decode.d4.loss_cls: 0.4198, decode.d4.loss_mask: 0.5786, decode.d4.loss_dice: 0.8456, decode.d5.loss_cls: 0.4067, decode.d5.loss_mask: 0.5778, decode.d5.loss_dice: 0.8358, decode.d6.loss_cls: 0.4051, decode.d6.loss_mask: 0.5783, decode.d6.loss_dice: 0.8353, decode.d7.loss_cls: 0.4004, decode.d7.loss_mask: 0.5761, decode.d7.loss_dice: 0.8363, decode.d8.loss_cls: 0.4001, decode.d8.loss_mask: 0.5750, decode.d8.loss_dice: 0.8367, loss: 24.4939
2022-11-30 19:47:47,476 - mmseg - INFO - Iter [19150/40000]	lr: 6.934e-08, eta: 1 day, 1:21:00, time: 4.117, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3893, decode.loss_mask: 0.5452, decode.loss_dice: 0.8146, decode.d0.loss_cls: 6.3332, decode.d0.loss_mask: 0.5321, decode.d0.loss_dice: 0.8783, decode.d1.loss_cls: 0.4992, decode.d1.loss_mask: 0.5714, decode.d1.loss_dice: 0.8805, decode.d2.loss_cls: 0.4454, decode.d2.loss_mask: 0.5582, decode.d2.loss_dice: 0.8355, decode.d3.loss_cls: 0.4089, decode.d3.loss_mask: 0.5530, decode.d3.loss_dice: 0.8257, decode.d4.loss_cls: 0.4032, decode.d4.loss_mask: 0.5499, decode.d4.loss_dice: 0.8191, decode.d5.loss_cls: 0.3947, decode.d5.loss_mask: 0.5497, decode.d5.loss_dice: 0.8188, decode.d6.loss_cls: 0.3944, decode.d6.loss_mask: 0.5475, decode.d6.loss_dice: 0.8115, decode.d7.loss_cls: 0.3896, decode.d7.loss_mask: 0.5447, decode.d7.loss_dice: 0.8143, decode.d8.loss_cls: 0.3894, decode.d8.loss_mask: 0.5449, decode.d8.loss_dice: 0.8139, loss: 23.8560
2022-11-30 19:51:13,245 - mmseg - INFO - Iter [19200/40000]	lr: 6.918e-08, eta: 1 day, 1:17:07, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.4116, decode.loss_mask: 0.5773, decode.loss_dice: 0.8367, decode.d0.loss_cls: 6.3357, decode.d0.loss_mask: 0.5601, decode.d0.loss_dice: 0.9140, decode.d1.loss_cls: 0.5305, decode.d1.loss_mask: 0.6030, decode.d1.loss_dice: 0.9033, decode.d2.loss_cls: 0.4720, decode.d2.loss_mask: 0.5939, decode.d2.loss_dice: 0.8674, decode.d3.loss_cls: 0.4365, decode.d3.loss_mask: 0.5851, decode.d3.loss_dice: 0.8481, decode.d4.loss_cls: 0.4293, decode.d4.loss_mask: 0.5826, decode.d4.loss_dice: 0.8459, decode.d5.loss_cls: 0.4216, decode.d5.loss_mask: 0.5791, decode.d5.loss_dice: 0.8404, decode.d6.loss_cls: 0.4156, decode.d6.loss_mask: 0.5786, decode.d6.loss_dice: 0.8386, decode.d7.loss_cls: 0.4147, decode.d7.loss_mask: 0.5797, decode.d7.loss_dice: 0.8386, decode.d8.loss_cls: 0.4119, decode.d8.loss_mask: 0.5799, decode.d8.loss_dice: 0.8394, loss: 24.6713
2022-11-30 19:54:38,915 - mmseg - INFO - Iter [19250/40000]	lr: 6.901e-08, eta: 1 day, 1:13:14, time: 4.113, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3791, decode.loss_mask: 0.5569, decode.loss_dice: 0.8185, decode.d0.loss_cls: 6.3217, decode.d0.loss_mask: 0.5344, decode.d0.loss_dice: 0.8896, decode.d1.loss_cls: 0.4974, decode.d1.loss_mask: 0.5782, decode.d1.loss_dice: 0.8750, decode.d2.loss_cls: 0.4409, decode.d2.loss_mask: 0.5635, decode.d2.loss_dice: 0.8394, decode.d3.loss_cls: 0.4070, decode.d3.loss_mask: 0.5605, decode.d3.loss_dice: 0.8231, decode.d4.loss_cls: 0.3982, decode.d4.loss_mask: 0.5589, decode.d4.loss_dice: 0.8257, decode.d5.loss_cls: 0.3860, decode.d5.loss_mask: 0.5568, decode.d5.loss_dice: 0.8214, decode.d6.loss_cls: 0.3841, decode.d6.loss_mask: 0.5560, decode.d6.loss_dice: 0.8170, decode.d7.loss_cls: 0.3807, decode.d7.loss_mask: 0.5573, decode.d7.loss_dice: 0.8187, decode.d8.loss_cls: 0.3805, decode.d8.loss_mask: 0.5569, decode.d8.loss_dice: 0.8150, loss: 23.8985
2022-11-30 19:58:04,640 - mmseg - INFO - Iter [19300/40000]	lr: 6.885e-08, eta: 1 day, 1:09:21, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3856, decode.loss_mask: 0.5716, decode.loss_dice: 0.8272, decode.d0.loss_cls: 6.3314, decode.d0.loss_mask: 0.5506, decode.d0.loss_dice: 0.8934, decode.d1.loss_cls: 0.5060, decode.d1.loss_mask: 0.5946, decode.d1.loss_dice: 0.8845, decode.d2.loss_cls: 0.4441, decode.d2.loss_mask: 0.5836, decode.d2.loss_dice: 0.8497, decode.d3.loss_cls: 0.4143, decode.d3.loss_mask: 0.5780, decode.d3.loss_dice: 0.8310, decode.d4.loss_cls: 0.4014, decode.d4.loss_mask: 0.5741, decode.d4.loss_dice: 0.8326, decode.d5.loss_cls: 0.3953, decode.d5.loss_mask: 0.5709, decode.d5.loss_dice: 0.8269, decode.d6.loss_cls: 0.3911, decode.d6.loss_mask: 0.5718, decode.d6.loss_dice: 0.8260, decode.d7.loss_cls: 0.3888, decode.d7.loss_mask: 0.5715, decode.d7.loss_dice: 0.8268, decode.d8.loss_cls: 0.3880, decode.d8.loss_mask: 0.5707, decode.d8.loss_dice: 0.8252, loss: 24.2067
2022-11-30 20:01:30,516 - mmseg - INFO - Iter [19350/40000]	lr: 6.868e-08, eta: 1 day, 1:05:29, time: 4.117, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3852, decode.loss_mask: 0.5621, decode.loss_dice: 0.8077, decode.d0.loss_cls: 6.3293, decode.d0.loss_mask: 0.5455, decode.d0.loss_dice: 0.8740, decode.d1.loss_cls: 0.5109, decode.d1.loss_mask: 0.5884, decode.d1.loss_dice: 0.8678, decode.d2.loss_cls: 0.4520, decode.d2.loss_mask: 0.5725, decode.d2.loss_dice: 0.8310, decode.d3.loss_cls: 0.4140, decode.d3.loss_mask: 0.5667, decode.d3.loss_dice: 0.8185, decode.d4.loss_cls: 0.4066, decode.d4.loss_mask: 0.5658, decode.d4.loss_dice: 0.8191, decode.d5.loss_cls: 0.3925, decode.d5.loss_mask: 0.5630, decode.d5.loss_dice: 0.8152, decode.d6.loss_cls: 0.3879, decode.d6.loss_mask: 0.5632, decode.d6.loss_dice: 0.8103, decode.d7.loss_cls: 0.3863, decode.d7.loss_mask: 0.5640, decode.d7.loss_dice: 0.8133, decode.d8.loss_cls: 0.3870, decode.d8.loss_mask: 0.5628, decode.d8.loss_dice: 0.8099, loss: 23.9723
2022-11-30 20:04:56,030 - mmseg - INFO - Iter [19400/40000]	lr: 6.851e-08, eta: 1 day, 1:01:36, time: 4.110, data_time: 0.022, memory: 51902, decode.loss_cls: 0.4022, decode.loss_mask: 0.5652, decode.loss_dice: 0.8206, decode.d0.loss_cls: 6.2987, decode.d0.loss_mask: 0.5444, decode.d0.loss_dice: 0.8923, decode.d1.loss_cls: 0.5207, decode.d1.loss_mask: 0.5879, decode.d1.loss_dice: 0.8799, decode.d2.loss_cls: 0.4618, decode.d2.loss_mask: 0.5776, decode.d2.loss_dice: 0.8424, decode.d3.loss_cls: 0.4254, decode.d3.loss_mask: 0.5699, decode.d3.loss_dice: 0.8285, decode.d4.loss_cls: 0.4172, decode.d4.loss_mask: 0.5690, decode.d4.loss_dice: 0.8237, decode.d5.loss_cls: 0.4052, decode.d5.loss_mask: 0.5672, decode.d5.loss_dice: 0.8223, decode.d6.loss_cls: 0.4010, decode.d6.loss_mask: 0.5685, decode.d6.loss_dice: 0.8209, decode.d7.loss_cls: 0.4019, decode.d7.loss_mask: 0.5656, decode.d7.loss_dice: 0.8190, decode.d8.loss_cls: 0.4015, decode.d8.loss_mask: 0.5654, decode.d8.loss_dice: 0.8224, loss: 24.1883
2022-11-30 20:08:21,861 - mmseg - INFO - Iter [19450/40000]	lr: 6.835e-08, eta: 1 day, 0:57:44, time: 4.117, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4112, decode.loss_mask: 0.5560, decode.loss_dice: 0.8111, decode.d0.loss_cls: 6.3040, decode.d0.loss_mask: 0.5423, decode.d0.loss_dice: 0.8853, decode.d1.loss_cls: 0.5286, decode.d1.loss_mask: 0.5861, decode.d1.loss_dice: 0.8695, decode.d2.loss_cls: 0.4686, decode.d2.loss_mask: 0.5715, decode.d2.loss_dice: 0.8321, decode.d3.loss_cls: 0.4328, decode.d3.loss_mask: 0.5640, decode.d3.loss_dice: 0.8203, decode.d4.loss_cls: 0.4264, decode.d4.loss_mask: 0.5594, decode.d4.loss_dice: 0.8165, decode.d5.loss_cls: 0.4142, decode.d5.loss_mask: 0.5578, decode.d5.loss_dice: 0.8137, decode.d6.loss_cls: 0.4146, decode.d6.loss_mask: 0.5547, decode.d6.loss_dice: 0.8112, decode.d7.loss_cls: 0.4110, decode.d7.loss_mask: 0.5558, decode.d7.loss_dice: 0.8116, decode.d8.loss_cls: 0.4079, decode.d8.loss_mask: 0.5566, decode.d8.loss_dice: 0.8118, loss: 24.1066
2022-11-30 20:11:47,648 - mmseg - INFO - Iter [19500/40000]	lr: 6.818e-08, eta: 1 day, 0:53:52, time: 4.116, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3932, decode.loss_mask: 0.5608, decode.loss_dice: 0.8181, decode.d0.loss_cls: 6.3039, decode.d0.loss_mask: 0.5494, decode.d0.loss_dice: 0.8900, decode.d1.loss_cls: 0.5112, decode.d1.loss_mask: 0.5845, decode.d1.loss_dice: 0.8787, decode.d2.loss_cls: 0.4547, decode.d2.loss_mask: 0.5766, decode.d2.loss_dice: 0.8483, decode.d3.loss_cls: 0.4248, decode.d3.loss_mask: 0.5678, decode.d3.loss_dice: 0.8323, decode.d4.loss_cls: 0.4142, decode.d4.loss_mask: 0.5644, decode.d4.loss_dice: 0.8270, decode.d5.loss_cls: 0.3999, decode.d5.loss_mask: 0.5631, decode.d5.loss_dice: 0.8257, decode.d6.loss_cls: 0.3988, decode.d6.loss_mask: 0.5623, decode.d6.loss_dice: 0.8189, decode.d7.loss_cls: 0.3964, decode.d7.loss_mask: 0.5621, decode.d7.loss_dice: 0.8211, decode.d8.loss_cls: 0.3954, decode.d8.loss_mask: 0.5622, decode.d8.loss_dice: 0.8170, loss: 24.1227
2022-11-30 20:15:13,154 - mmseg - INFO - Iter [19550/40000]	lr: 6.801e-08, eta: 1 day, 0:49:59, time: 4.110, data_time: 0.022, memory: 51902, decode.loss_cls: 0.3978, decode.loss_mask: 0.5758, decode.loss_dice: 0.8422, decode.d0.loss_cls: 6.2705, decode.d0.loss_mask: 0.5537, decode.d0.loss_dice: 0.9061, decode.d1.loss_cls: 0.5092, decode.d1.loss_mask: 0.5940, decode.d1.loss_dice: 0.8961, decode.d2.loss_cls: 0.4496, decode.d2.loss_mask: 0.5838, decode.d2.loss_dice: 0.8661, decode.d3.loss_cls: 0.4219, decode.d3.loss_mask: 0.5808, decode.d3.loss_dice: 0.8531, decode.d4.loss_cls: 0.4129, decode.d4.loss_mask: 0.5802, decode.d4.loss_dice: 0.8511, decode.d5.loss_cls: 0.4051, decode.d5.loss_mask: 0.5771, decode.d5.loss_dice: 0.8432, decode.d6.loss_cls: 0.4001, decode.d6.loss_mask: 0.5770, decode.d6.loss_dice: 0.8402, decode.d7.loss_cls: 0.3998, decode.d7.loss_mask: 0.5785, decode.d7.loss_dice: 0.8433, decode.d8.loss_cls: 0.3993, decode.d8.loss_mask: 0.5759, decode.d8.loss_dice: 0.8429, loss: 24.4273
2022-11-30 20:18:41,377 - mmseg - INFO - Iter [19600/40000]	lr: 6.785e-08, eta: 1 day, 0:46:10, time: 4.164, data_time: 0.066, memory: 51902, decode.loss_cls: 0.3926, decode.loss_mask: 0.5705, decode.loss_dice: 0.8274, decode.d0.loss_cls: 6.2881, decode.d0.loss_mask: 0.5502, decode.d0.loss_dice: 0.8922, decode.d1.loss_cls: 0.5068, decode.d1.loss_mask: 0.5916, decode.d1.loss_dice: 0.8795, decode.d2.loss_cls: 0.4503, decode.d2.loss_mask: 0.5834, decode.d2.loss_dice: 0.8477, decode.d3.loss_cls: 0.4196, decode.d3.loss_mask: 0.5768, decode.d3.loss_dice: 0.8358, decode.d4.loss_cls: 0.4060, decode.d4.loss_mask: 0.5754, decode.d4.loss_dice: 0.8374, decode.d5.loss_cls: 0.4011, decode.d5.loss_mask: 0.5720, decode.d5.loss_dice: 0.8314, decode.d6.loss_cls: 0.3960, decode.d6.loss_mask: 0.5701, decode.d6.loss_dice: 0.8258, decode.d7.loss_cls: 0.3965, decode.d7.loss_mask: 0.5674, decode.d7.loss_dice: 0.8279, decode.d8.loss_cls: 0.3948, decode.d8.loss_mask: 0.5695, decode.d8.loss_dice: 0.8268, loss: 24.2107
2022-11-30 20:22:07,352 - mmseg - INFO - Iter [19650/40000]	lr: 6.768e-08, eta: 1 day, 0:42:18, time: 4.119, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3883, decode.loss_mask: 0.5783, decode.loss_dice: 0.8246, decode.d0.loss_cls: 6.2543, decode.d0.loss_mask: 0.5628, decode.d0.loss_dice: 0.8948, decode.d1.loss_cls: 0.5073, decode.d1.loss_mask: 0.6029, decode.d1.loss_dice: 0.8885, decode.d2.loss_cls: 0.4476, decode.d2.loss_mask: 0.5916, decode.d2.loss_dice: 0.8553, decode.d3.loss_cls: 0.4153, decode.d3.loss_mask: 0.5825, decode.d3.loss_dice: 0.8372, decode.d4.loss_cls: 0.4050, decode.d4.loss_mask: 0.5803, decode.d4.loss_dice: 0.8342, decode.d5.loss_cls: 0.3938, decode.d5.loss_mask: 0.5784, decode.d5.loss_dice: 0.8307, decode.d6.loss_cls: 0.3942, decode.d6.loss_mask: 0.5773, decode.d6.loss_dice: 0.8254, decode.d7.loss_cls: 0.3899, decode.d7.loss_mask: 0.5766, decode.d7.loss_dice: 0.8269, decode.d8.loss_cls: 0.3845, decode.d8.loss_mask: 0.5779, decode.d8.loss_dice: 0.8274, loss: 24.2337
2022-11-30 20:25:33,174 - mmseg - INFO - Iter [19700/40000]	lr: 6.752e-08, eta: 1 day, 0:38:27, time: 4.116, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3880, decode.loss_mask: 0.5702, decode.loss_dice: 0.8244, decode.d0.loss_cls: 6.2647, decode.d0.loss_mask: 0.5541, decode.d0.loss_dice: 0.8854, decode.d1.loss_cls: 0.4953, decode.d1.loss_mask: 0.5957, decode.d1.loss_dice: 0.8790, decode.d2.loss_cls: 0.4401, decode.d2.loss_mask: 0.5822, decode.d2.loss_dice: 0.8472, decode.d3.loss_cls: 0.4101, decode.d3.loss_mask: 0.5771, decode.d3.loss_dice: 0.8312, decode.d4.loss_cls: 0.4027, decode.d4.loss_mask: 0.5753, decode.d4.loss_dice: 0.8324, decode.d5.loss_cls: 0.3950, decode.d5.loss_mask: 0.5725, decode.d5.loss_dice: 0.8237, decode.d6.loss_cls: 0.3875, decode.d6.loss_mask: 0.5723, decode.d6.loss_dice: 0.8236, decode.d7.loss_cls: 0.3887, decode.d7.loss_mask: 0.5729, decode.d7.loss_dice: 0.8223, decode.d8.loss_cls: 0.3858, decode.d8.loss_mask: 0.5702, decode.d8.loss_dice: 0.8259, loss: 24.0955
2022-11-30 20:28:58,766 - mmseg - INFO - Iter [19750/40000]	lr: 6.735e-08, eta: 1 day, 0:34:35, time: 4.112, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3928, decode.loss_mask: 0.5632, decode.loss_dice: 0.8272, decode.d0.loss_cls: 6.2614, decode.d0.loss_mask: 0.5458, decode.d0.loss_dice: 0.8977, decode.d1.loss_cls: 0.5177, decode.d1.loss_mask: 0.5848, decode.d1.loss_dice: 0.8909, decode.d2.loss_cls: 0.4496, decode.d2.loss_mask: 0.5766, decode.d2.loss_dice: 0.8530, decode.d3.loss_cls: 0.4199, decode.d3.loss_mask: 0.5641, decode.d3.loss_dice: 0.8350, decode.d4.loss_cls: 0.4083, decode.d4.loss_mask: 0.5637, decode.d4.loss_dice: 0.8334, decode.d5.loss_cls: 0.4011, decode.d5.loss_mask: 0.5633, decode.d5.loss_dice: 0.8296, decode.d6.loss_cls: 0.3951, decode.d6.loss_mask: 0.5618, decode.d6.loss_dice: 0.8288, decode.d7.loss_cls: 0.3923, decode.d7.loss_mask: 0.5632, decode.d7.loss_dice: 0.8282, decode.d8.loss_cls: 0.3895, decode.d8.loss_mask: 0.5613, decode.d8.loss_dice: 0.8285, loss: 24.1277
2022-11-30 20:32:25,021 - mmseg - INFO - Iter [19800/40000]	lr: 6.718e-08, eta: 1 day, 0:30:44, time: 4.125, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3947, decode.loss_mask: 0.5639, decode.loss_dice: 0.8350, decode.d0.loss_cls: 6.2448, decode.d0.loss_mask: 0.5446, decode.d0.loss_dice: 0.9010, decode.d1.loss_cls: 0.5059, decode.d1.loss_mask: 0.5864, decode.d1.loss_dice: 0.8918, decode.d2.loss_cls: 0.4520, decode.d2.loss_mask: 0.5736, decode.d2.loss_dice: 0.8562, decode.d3.loss_cls: 0.4158, decode.d3.loss_mask: 0.5684, decode.d3.loss_dice: 0.8447, decode.d4.loss_cls: 0.4102, decode.d4.loss_mask: 0.5652, decode.d4.loss_dice: 0.8414, decode.d5.loss_cls: 0.4022, decode.d5.loss_mask: 0.5642, decode.d5.loss_dice: 0.8388, decode.d6.loss_cls: 0.3959, decode.d6.loss_mask: 0.5612, decode.d6.loss_dice: 0.8349, decode.d7.loss_cls: 0.3954, decode.d7.loss_mask: 0.5618, decode.d7.loss_dice: 0.8363, decode.d8.loss_cls: 0.3956, decode.d8.loss_mask: 0.5611, decode.d8.loss_dice: 0.8313, loss: 24.1743
2022-11-30 20:35:50,966 - mmseg - INFO - Iter [19850/40000]	lr: 6.702e-08, eta: 1 day, 0:26:53, time: 4.119, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3905, decode.loss_mask: 0.5585, decode.loss_dice: 0.8177, decode.d0.loss_cls: 6.2481, decode.d0.loss_mask: 0.5467, decode.d0.loss_dice: 0.8833, decode.d1.loss_cls: 0.5006, decode.d1.loss_mask: 0.5826, decode.d1.loss_dice: 0.8806, decode.d2.loss_cls: 0.4444, decode.d2.loss_mask: 0.5716, decode.d2.loss_dice: 0.8452, decode.d3.loss_cls: 0.4102, decode.d3.loss_mask: 0.5638, decode.d3.loss_dice: 0.8278, decode.d4.loss_cls: 0.4021, decode.d4.loss_mask: 0.5614, decode.d4.loss_dice: 0.8231, decode.d5.loss_cls: 0.3936, decode.d5.loss_mask: 0.5603, decode.d5.loss_dice: 0.8244, decode.d6.loss_cls: 0.3905, decode.d6.loss_mask: 0.5586, decode.d6.loss_dice: 0.8197, decode.d7.loss_cls: 0.3941, decode.d7.loss_mask: 0.5580, decode.d7.loss_dice: 0.8186, decode.d8.loss_cls: 0.3869, decode.d8.loss_mask: 0.5577, decode.d8.loss_dice: 0.8178, loss: 23.9383
2022-11-30 20:39:16,438 - mmseg - INFO - Iter [19900/40000]	lr: 6.685e-08, eta: 1 day, 0:23:02, time: 4.109, data_time: 0.021, memory: 51902, decode.loss_cls: 0.4038, decode.loss_mask: 0.5740, decode.loss_dice: 0.8257, decode.d0.loss_cls: 6.2308, decode.d0.loss_mask: 0.5590, decode.d0.loss_dice: 0.8880, decode.d1.loss_cls: 0.5198, decode.d1.loss_mask: 0.6023, decode.d1.loss_dice: 0.8902, decode.d2.loss_cls: 0.4642, decode.d2.loss_mask: 0.5898, decode.d2.loss_dice: 0.8548, decode.d3.loss_cls: 0.4292, decode.d3.loss_mask: 0.5824, decode.d3.loss_dice: 0.8396, decode.d4.loss_cls: 0.4250, decode.d4.loss_mask: 0.5786, decode.d4.loss_dice: 0.8340, decode.d5.loss_cls: 0.4084, decode.d5.loss_mask: 0.5778, decode.d5.loss_dice: 0.8355, decode.d6.loss_cls: 0.4071, decode.d6.loss_mask: 0.5762, decode.d6.loss_dice: 0.8301, decode.d7.loss_cls: 0.4033, decode.d7.loss_mask: 0.5776, decode.d7.loss_dice: 0.8319, decode.d8.loss_cls: 0.4047, decode.d8.loss_mask: 0.5755, decode.d8.loss_dice: 0.8293, loss: 24.3487
2022-11-30 20:42:42,439 - mmseg - INFO - Iter [19950/40000]	lr: 6.668e-08, eta: 1 day, 0:19:11, time: 4.120, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3990, decode.loss_mask: 0.5573, decode.loss_dice: 0.8214, decode.d0.loss_cls: 6.2240, decode.d0.loss_mask: 0.5412, decode.d0.loss_dice: 0.8868, decode.d1.loss_cls: 0.5217, decode.d1.loss_mask: 0.5837, decode.d1.loss_dice: 0.8797, decode.d2.loss_cls: 0.4611, decode.d2.loss_mask: 0.5708, decode.d2.loss_dice: 0.8395, decode.d3.loss_cls: 0.4200, decode.d3.loss_mask: 0.5634, decode.d3.loss_dice: 0.8278, decode.d4.loss_cls: 0.4130, decode.d4.loss_mask: 0.5617, decode.d4.loss_dice: 0.8231, decode.d5.loss_cls: 0.3997, decode.d5.loss_mask: 0.5598, decode.d5.loss_dice: 0.8240, decode.d6.loss_cls: 0.4015, decode.d6.loss_mask: 0.5601, decode.d6.loss_dice: 0.8203, decode.d7.loss_cls: 0.3955, decode.d7.loss_mask: 0.5611, decode.d7.loss_dice: 0.8211, decode.d8.loss_cls: 0.3964, decode.d8.loss_mask: 0.5602, decode.d8.loss_dice: 0.8213, loss: 24.0162
2022-11-30 20:46:08,752 - mmseg - INFO - Saving checkpoint at 20000 iterations
2022-11-30 20:47:00,359 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 20:47:00,359 - mmseg - INFO - Iter [20000/40000]	lr: 6.652e-08, eta: 1 day, 0:16:12, time: 5.158, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3888, decode.loss_mask: 0.5634, decode.loss_dice: 0.8250, decode.d0.loss_cls: 6.2334, decode.d0.loss_mask: 0.5446, decode.d0.loss_dice: 0.8828, decode.d1.loss_cls: 0.4992, decode.d1.loss_mask: 0.5877, decode.d1.loss_dice: 0.8870, decode.d2.loss_cls: 0.4457, decode.d2.loss_mask: 0.5762, decode.d2.loss_dice: 0.8464, decode.d3.loss_cls: 0.4150, decode.d3.loss_mask: 0.5685, decode.d3.loss_dice: 0.8286, decode.d4.loss_cls: 0.4026, decode.d4.loss_mask: 0.5661, decode.d4.loss_dice: 0.8323, decode.d5.loss_cls: 0.3952, decode.d5.loss_mask: 0.5659, decode.d5.loss_dice: 0.8298, decode.d6.loss_cls: 0.3940, decode.d6.loss_mask: 0.5620, decode.d6.loss_dice: 0.8252, decode.d7.loss_cls: 0.3913, decode.d7.loss_mask: 0.5623, decode.d7.loss_dice: 0.8237, decode.d8.loss_cls: 0.3901, decode.d8.loss_mask: 0.5629, decode.d8.loss_dice: 0.8276, loss: 24.0234
2022-11-30 20:49:58,414 - mmseg - INFO - per class results:
2022-11-30 20:49:58,419 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 83.58 | 89.45 |
|       building      | 85.54 | 92.49 |
|         sky         | 95.22 | 97.32 |
|        floor        | 85.11 | 90.43 |
|         tree        | 78.72 | 88.73 |
|       ceiling       |  87.5 | 93.65 |
|         road        | 87.35 | 90.45 |
|         bed         | 93.58 | 97.01 |
|      windowpane     | 68.51 | 83.38 |
|        grass        | 71.33 | 87.58 |
|       cabinet       |  62.4 | 73.51 |
|       sidewalk      | 72.78 |  87.8 |
|        person       | 88.47 | 94.33 |
|        earth        | 46.06 |  62.5 |
|         door        |  63.7 | 80.52 |
|        table        |  73.3 | 82.48 |
|       mountain      | 64.25 | 78.97 |
|        plant        | 56.89 | 71.93 |
|       curtain       | 83.04 | 91.08 |
|        chair        | 69.39 | 80.46 |
|         car         | 89.48 | 94.97 |
|        water        | 66.43 | 81.33 |
|       painting      | 82.47 |  90.4 |
|         sofa        | 86.75 | 92.85 |
|        shelf        | 50.51 | 65.85 |
|        house        | 51.96 | 66.96 |
|         sea         | 74.24 | 89.66 |
|        mirror       | 82.74 | 91.82 |
|         rug         | 72.89 | 85.51 |
|        field        | 32.17 | 47.38 |
|       armchair      | 62.19 | 76.55 |
|         seat        | 67.24 | 89.58 |
|        fence        | 58.82 | 77.93 |
|         desk        | 56.55 | 82.91 |
|         rock        | 59.67 | 77.29 |
|       wardrobe      | 54.67 | 81.79 |
|         lamp        | 80.52 |  90.0 |
|       bathtub       | 90.89 | 92.37 |
|       railing       | 44.57 | 62.82 |
|       cushion       | 77.69 | 88.97 |
|         base        | 44.74 |  60.8 |
|         box         | 41.11 | 56.52 |
|        column       | 57.26 | 75.73 |
|      signboard      | 46.33 | 65.56 |
|   chest of drawers  | 47.41 |  66.0 |
|       counter       | 46.79 | 62.91 |
|         sand        |  64.2 | 87.87 |
|         sink        | 83.18 | 87.02 |
|      skyscraper     | 35.14 | 40.15 |
|      fireplace      |  79.8 | 95.22 |
|     refrigerator    | 83.83 | 95.99 |
|      grandstand     | 46.61 | 82.79 |
|         path        | 31.24 | 42.28 |
|        stairs       | 35.43 | 46.21 |
|        runway       | 74.66 |  94.4 |
|         case        |  67.6 |  87.7 |
|      pool table     | 95.95 | 98.67 |
|        pillow       | 73.33 | 82.92 |
|     screen door     | 85.33 | 89.96 |
|       stairway      | 57.71 | 72.53 |
|        river        | 30.87 | 36.32 |
|        bridge       | 76.63 | 90.13 |
|       bookcase      | 37.76 | 59.38 |
|        blind        | 45.71 | 57.54 |
|     coffee table    | 72.14 | 89.62 |
|        toilet       | 92.77 | 96.38 |
|        flower       | 42.84 | 64.51 |
|         book        | 59.32 | 80.92 |
|         hill        |  7.83 | 14.73 |
|        bench        | 72.16 | 83.75 |
|      countertop     | 73.39 | 92.22 |
|        stove        | 85.52 | 89.51 |
|         palm        | 55.17 | 83.31 |
|    kitchen island   | 46.97 | 81.84 |
|       computer      | 83.54 | 91.71 |
|     swivel chair    | 58.25 | 83.13 |
|         boat        |  52.6 | 89.45 |
|         bar         | 71.25 | 78.25 |
|    arcade machine   | 91.43 | 98.57 |
|        hovel        | 31.32 |  43.9 |
|         bus         | 94.51 |  96.9 |
|        towel        | 78.39 | 95.42 |
|        light        | 66.97 | 80.88 |
|        truck        | 52.23 | 72.88 |
|        tower        | 33.14 | 63.21 |
|      chandelier     | 76.86 | 88.34 |
|        awning       |  32.4 | 52.67 |
|     streetlight     | 46.08 | 71.93 |
|        booth        | 59.88 | 75.18 |
| television receiver | 76.08 | 91.68 |
|       airplane      |  89.0 | 97.14 |
|      dirt track     | 23.12 | 37.28 |
|       apparel       | 54.58 | 92.51 |
|         pole        | 34.69 | 52.32 |
|         land        |  1.1  |  1.44 |
|      bannister      | 20.38 | 37.18 |
|      escalator      | 66.05 | 83.75 |
|       ottoman       | 57.59 | 79.41 |
|        bottle       |  52.7 | 81.96 |
|        buffet       | 34.55 | 47.98 |
|        poster       | 36.83 | 60.24 |
|        stage        | 26.81 | 58.97 |
|         van         | 53.55 | 77.27 |
|         ship        | 32.92 | 34.79 |
|       fountain      | 38.01 | 43.69 |
|    conveyer belt    | 81.11 | 97.26 |
|        canopy       | 46.94 | 63.05 |
|        washer       | 91.05 | 93.62 |
|      plaything      | 37.37 |  60.4 |
|    swimming pool    | 45.18 | 74.97 |
|        stool        | 61.03 | 85.89 |
|        barrel       |  86.3 | 96.37 |
|        basket       | 45.52 | 76.49 |
|      waterfall      | 49.62 | 60.83 |
|         tent        | 96.16 | 98.15 |
|         bag         | 35.73 | 48.82 |
|       minibike      | 81.21 | 94.01 |
|        cradle       | 91.43 | 97.42 |
|         oven        | 70.59 | 83.83 |
|         ball        | 43.61 | 47.68 |
|         food        | 66.23 |  76.3 |
|         step        | 28.17 | 37.05 |
|         tank        | 61.26 | 67.59 |
|      trade name     | 36.13 | 48.54 |
|      microwave      | 91.63 | 96.65 |
|         pot         | 61.49 | 73.94 |
|        animal       | 83.36 |  85.8 |
|       bicycle       | 61.28 | 86.38 |
|         lake        |  4.99 |  7.67 |
|      dishwasher     | 80.57 | 90.31 |
|        screen       | 60.88 | 93.98 |
|       blanket       | 36.05 | 49.95 |
|      sculpture      | 68.86 | 90.53 |
|         hood        | 80.54 | 91.02 |
|        sconce       | 65.68 | 82.44 |
|         vase        |  57.6 | 81.23 |
|    traffic light    |  52.1 | 75.46 |
|         tray        | 32.93 | 54.94 |
|        ashcan       | 53.72 | 75.68 |
|         fan         | 73.48 | 87.37 |
|         pier        | 37.68 | 43.64 |
|      crt screen     |  4.99 | 13.93 |
|        plate        | 71.69 | 81.71 |
|       monitor       |  2.91 |  3.57 |
|    bulletin board   | 59.69 | 85.61 |
|        shower       | 14.94 | 29.26 |
|       radiator      | 72.68 | 92.37 |
|        glass        | 29.15 | 32.29 |
|        clock        | 62.76 | 77.97 |
|         flag        | 70.16 |  87.1 |
+---------------------+-------+-------+
2022-11-30 20:49:58,419 - mmseg - INFO - Summary:
2022-11-30 20:49:58,419 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 87.02 | 60.19 | 74.61 |
+-------+-------+-------+
2022-11-30 20:49:58,425 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 20:49:58,425 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8702, mIoU: 0.6019, mAcc: 0.7461, IoU.wall: 0.8358, IoU.building: 0.8554, IoU.sky: 0.9522, IoU.floor: 0.8511, IoU.tree: 0.7872, IoU.ceiling: 0.8750, IoU.road: 0.8735, IoU.bed : 0.9358, IoU.windowpane: 0.6851, IoU.grass: 0.7133, IoU.cabinet: 0.6240, IoU.sidewalk: 0.7278, IoU.person: 0.8847, IoU.earth: 0.4606, IoU.door: 0.6370, IoU.table: 0.7330, IoU.mountain: 0.6425, IoU.plant: 0.5689, IoU.curtain: 0.8304, IoU.chair: 0.6939, IoU.car: 0.8948, IoU.water: 0.6643, IoU.painting: 0.8247, IoU.sofa: 0.8675, IoU.shelf: 0.5051, IoU.house: 0.5196, IoU.sea: 0.7424, IoU.mirror: 0.8274, IoU.rug: 0.7289, IoU.field: 0.3217, IoU.armchair: 0.6219, IoU.seat: 0.6724, IoU.fence: 0.5882, IoU.desk: 0.5655, IoU.rock: 0.5967, IoU.wardrobe: 0.5467, IoU.lamp: 0.8052, IoU.bathtub: 0.9089, IoU.railing: 0.4457, IoU.cushion: 0.7769, IoU.base: 0.4474, IoU.box: 0.4111, IoU.column: 0.5726, IoU.signboard: 0.4633, IoU.chest of drawers: 0.4741, IoU.counter: 0.4679, IoU.sand: 0.6420, IoU.sink: 0.8318, IoU.skyscraper: 0.3514, IoU.fireplace: 0.7980, IoU.refrigerator: 0.8383, IoU.grandstand: 0.4661, IoU.path: 0.3124, IoU.stairs: 0.3543, IoU.runway: 0.7466, IoU.case: 0.6760, IoU.pool table: 0.9595, IoU.pillow: 0.7333, IoU.screen door: 0.8533, IoU.stairway: 0.5771, IoU.river: 0.3087, IoU.bridge: 0.7663, IoU.bookcase: 0.3776, IoU.blind: 0.4571, IoU.coffee table: 0.7214, IoU.toilet: 0.9277, IoU.flower: 0.4284, IoU.book: 0.5932, IoU.hill: 0.0783, IoU.bench: 0.7216, IoU.countertop: 0.7339, IoU.stove: 0.8552, IoU.palm: 0.5517, IoU.kitchen island: 0.4697, IoU.computer: 0.8354, IoU.swivel chair: 0.5825, IoU.boat: 0.5260, IoU.bar: 0.7125, IoU.arcade machine: 0.9143, IoU.hovel: 0.3132, IoU.bus: 0.9451, IoU.towel: 0.7839, IoU.light: 0.6697, IoU.truck: 0.5223, IoU.tower: 0.3314, IoU.chandelier: 0.7686, IoU.awning: 0.3240, IoU.streetlight: 0.4608, IoU.booth: 0.5988, IoU.television receiver: 0.7608, IoU.airplane: 0.8900, IoU.dirt track: 0.2312, IoU.apparel: 0.5458, IoU.pole: 0.3469, IoU.land: 0.0110, IoU.bannister: 0.2038, IoU.escalator: 0.6605, IoU.ottoman: 0.5759, IoU.bottle: 0.5270, IoU.buffet: 0.3455, IoU.poster: 0.3683, IoU.stage: 0.2681, IoU.van: 0.5355, IoU.ship: 0.3292, IoU.fountain: 0.3801, IoU.conveyer belt: 0.8111, IoU.canopy: 0.4694, IoU.washer: 0.9105, IoU.plaything: 0.3737, IoU.swimming pool: 0.4518, IoU.stool: 0.6103, IoU.barrel: 0.8630, IoU.basket: 0.4552, IoU.waterfall: 0.4962, IoU.tent: 0.9616, IoU.bag: 0.3573, IoU.minibike: 0.8121, IoU.cradle: 0.9143, IoU.oven: 0.7059, IoU.ball: 0.4361, IoU.food: 0.6623, IoU.step: 0.2817, IoU.tank: 0.6126, IoU.trade name: 0.3613, IoU.microwave: 0.9163, IoU.pot: 0.6149, IoU.animal: 0.8336, IoU.bicycle: 0.6128, IoU.lake: 0.0499, IoU.dishwasher: 0.8057, IoU.screen: 0.6088, IoU.blanket: 0.3605, IoU.sculpture: 0.6886, IoU.hood: 0.8054, IoU.sconce: 0.6568, IoU.vase: 0.5760, IoU.traffic light: 0.5210, IoU.tray: 0.3293, IoU.ashcan: 0.5372, IoU.fan: 0.7348, IoU.pier: 0.3768, IoU.crt screen: 0.0499, IoU.plate: 0.7169, IoU.monitor: 0.0291, IoU.bulletin board: 0.5969, IoU.shower: 0.1494, IoU.radiator: 0.7268, IoU.glass: 0.2915, IoU.clock: 0.6276, IoU.flag: 0.7016, Acc.wall: 0.8945, Acc.building: 0.9249, Acc.sky: 0.9732, Acc.floor: 0.9043, Acc.tree: 0.8873, Acc.ceiling: 0.9365, Acc.road: 0.9045, Acc.bed : 0.9701, Acc.windowpane: 0.8338, Acc.grass: 0.8758, Acc.cabinet: 0.7351, Acc.sidewalk: 0.8780, Acc.person: 0.9433, Acc.earth: 0.6250, Acc.door: 0.8052, Acc.table: 0.8248, Acc.mountain: 0.7897, Acc.plant: 0.7193, Acc.curtain: 0.9108, Acc.chair: 0.8046, Acc.car: 0.9497, Acc.water: 0.8133, Acc.painting: 0.9040, Acc.sofa: 0.9285, Acc.shelf: 0.6585, Acc.house: 0.6696, Acc.sea: 0.8966, Acc.mirror: 0.9182, Acc.rug: 0.8551, Acc.field: 0.4738, Acc.armchair: 0.7655, Acc.seat: 0.8958, Acc.fence: 0.7793, Acc.desk: 0.8291, Acc.rock: 0.7729, Acc.wardrobe: 0.8179, Acc.lamp: 0.9000, Acc.bathtub: 0.9237, Acc.railing: 0.6282, Acc.cushion: 0.8897, Acc.base: 0.6080, Acc.box: 0.5652, Acc.column: 0.7573, Acc.signboard: 0.6556, Acc.chest of drawers: 0.6600, Acc.counter: 0.6291, Acc.sand: 0.8787, Acc.sink: 0.8702, Acc.skyscraper: 0.4015, Acc.fireplace: 0.9522, Acc.refrigerator: 0.9599, Acc.grandstand: 0.8279, Acc.path: 0.4228, Acc.stairs: 0.4621, Acc.runway: 0.9440, Acc.case: 0.8770, Acc.pool table: 0.9867, Acc.pillow: 0.8292, Acc.screen door: 0.8996, Acc.stairway: 0.7253, Acc.river: 0.3632, Acc.bridge: 0.9013, Acc.bookcase: 0.5938, Acc.blind: 0.5754, Acc.coffee table: 0.8962, Acc.toilet: 0.9638, Acc.flower: 0.6451, Acc.book: 0.8092, Acc.hill: 0.1473, Acc.bench: 0.8375, Acc.countertop: 0.9222, Acc.stove: 0.8951, Acc.palm: 0.8331, Acc.kitchen island: 0.8184, Acc.computer: 0.9171, Acc.swivel chair: 0.8313, Acc.boat: 0.8945, Acc.bar: 0.7825, Acc.arcade machine: 0.9857, Acc.hovel: 0.4390, Acc.bus: 0.9690, Acc.towel: 0.9542, Acc.light: 0.8088, Acc.truck: 0.7288, Acc.tower: 0.6321, Acc.chandelier: 0.8834, Acc.awning: 0.5267, Acc.streetlight: 0.7193, Acc.booth: 0.7518, Acc.television receiver: 0.9168, Acc.airplane: 0.9714, Acc.dirt track: 0.3728, Acc.apparel: 0.9251, Acc.pole: 0.5232, Acc.land: 0.0144, Acc.bannister: 0.3718, Acc.escalator: 0.8375, Acc.ottoman: 0.7941, Acc.bottle: 0.8196, Acc.buffet: 0.4798, Acc.poster: 0.6024, Acc.stage: 0.5897, Acc.van: 0.7727, Acc.ship: 0.3479, Acc.fountain: 0.4369, Acc.conveyer belt: 0.9726, Acc.canopy: 0.6305, Acc.washer: 0.9362, Acc.plaything: 0.6040, Acc.swimming pool: 0.7497, Acc.stool: 0.8589, Acc.barrel: 0.9637, Acc.basket: 0.7649, Acc.waterfall: 0.6083, Acc.tent: 0.9815, Acc.bag: 0.4882, Acc.minibike: 0.9401, Acc.cradle: 0.9742, Acc.oven: 0.8383, Acc.ball: 0.4768, Acc.food: 0.7630, Acc.step: 0.3705, Acc.tank: 0.6759, Acc.trade name: 0.4854, Acc.microwave: 0.9665, Acc.pot: 0.7394, Acc.animal: 0.8580, Acc.bicycle: 0.8638, Acc.lake: 0.0767, Acc.dishwasher: 0.9031, Acc.screen: 0.9398, Acc.blanket: 0.4995, Acc.sculpture: 0.9053, Acc.hood: 0.9102, Acc.sconce: 0.8244, Acc.vase: 0.8123, Acc.traffic light: 0.7546, Acc.tray: 0.5494, Acc.ashcan: 0.7568, Acc.fan: 0.8737, Acc.pier: 0.4364, Acc.crt screen: 0.1393, Acc.plate: 0.8171, Acc.monitor: 0.0357, Acc.bulletin board: 0.8561, Acc.shower: 0.2926, Acc.radiator: 0.9237, Acc.glass: 0.3229, Acc.clock: 0.7797, Acc.flag: 0.8710
2022-11-30 20:53:24,364 - mmseg - INFO - Iter [20050/40000]	lr: 6.635e-08, eta: 1 day, 0:15:18, time: 7.680, data_time: 3.582, memory: 51902, decode.loss_cls: 0.3980, decode.loss_mask: 0.5567, decode.loss_dice: 0.8175, decode.d0.loss_cls: 6.2334, decode.d0.loss_mask: 0.5408, decode.d0.loss_dice: 0.8865, decode.d1.loss_cls: 0.5124, decode.d1.loss_mask: 0.5833, decode.d1.loss_dice: 0.8805, decode.d2.loss_cls: 0.4572, decode.d2.loss_mask: 0.5695, decode.d2.loss_dice: 0.8387, decode.d3.loss_cls: 0.4196, decode.d3.loss_mask: 0.5635, decode.d3.loss_dice: 0.8269, decode.d4.loss_cls: 0.4122, decode.d4.loss_mask: 0.5598, decode.d4.loss_dice: 0.8272, decode.d5.loss_cls: 0.4044, decode.d5.loss_mask: 0.5582, decode.d5.loss_dice: 0.8201, decode.d6.loss_cls: 0.4013, decode.d6.loss_mask: 0.5555, decode.d6.loss_dice: 0.8179, decode.d7.loss_cls: 0.3961, decode.d7.loss_mask: 0.5573, decode.d7.loss_dice: 0.8176, decode.d8.loss_cls: 0.3956, decode.d8.loss_mask: 0.5562, decode.d8.loss_dice: 0.8194, loss: 23.9832
2022-11-30 20:56:50,267 - mmseg - INFO - Iter [20100/40000]	lr: 6.618e-08, eta: 1 day, 0:11:27, time: 4.118, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3819, decode.loss_mask: 0.5502, decode.loss_dice: 0.8204, decode.d0.loss_cls: 6.2280, decode.d0.loss_mask: 0.5267, decode.d0.loss_dice: 0.8842, decode.d1.loss_cls: 0.4986, decode.d1.loss_mask: 0.5710, decode.d1.loss_dice: 0.8753, decode.d2.loss_cls: 0.4430, decode.d2.loss_mask: 0.5564, decode.d2.loss_dice: 0.8397, decode.d3.loss_cls: 0.4060, decode.d3.loss_mask: 0.5530, decode.d3.loss_dice: 0.8289, decode.d4.loss_cls: 0.3998, decode.d4.loss_mask: 0.5483, decode.d4.loss_dice: 0.8271, decode.d5.loss_cls: 0.3910, decode.d5.loss_mask: 0.5487, decode.d5.loss_dice: 0.8209, decode.d6.loss_cls: 0.3885, decode.d6.loss_mask: 0.5467, decode.d6.loss_dice: 0.8188, decode.d7.loss_cls: 0.3855, decode.d7.loss_mask: 0.5474, decode.d7.loss_dice: 0.8225, decode.d8.loss_cls: 0.3848, decode.d8.loss_mask: 0.5484, decode.d8.loss_dice: 0.8189, loss: 23.7605
2022-11-30 21:00:16,145 - mmseg - INFO - Iter [20150/40000]	lr: 6.602e-08, eta: 1 day, 0:07:35, time: 4.118, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3905, decode.loss_mask: 0.5674, decode.loss_dice: 0.8190, decode.d0.loss_cls: 6.1939, decode.d0.loss_mask: 0.5466, decode.d0.loss_dice: 0.8889, decode.d1.loss_cls: 0.5154, decode.d1.loss_mask: 0.5897, decode.d1.loss_dice: 0.8729, decode.d2.loss_cls: 0.4529, decode.d2.loss_mask: 0.5775, decode.d2.loss_dice: 0.8424, decode.d3.loss_cls: 0.4212, decode.d3.loss_mask: 0.5718, decode.d3.loss_dice: 0.8271, decode.d4.loss_cls: 0.4111, decode.d4.loss_mask: 0.5684, decode.d4.loss_dice: 0.8220, decode.d5.loss_cls: 0.4034, decode.d5.loss_mask: 0.5670, decode.d5.loss_dice: 0.8198, decode.d6.loss_cls: 0.3959, decode.d6.loss_mask: 0.5680, decode.d6.loss_dice: 0.8174, decode.d7.loss_cls: 0.3924, decode.d7.loss_mask: 0.5674, decode.d7.loss_dice: 0.8201, decode.d8.loss_cls: 0.3935, decode.d8.loss_mask: 0.5671, decode.d8.loss_dice: 0.8218, loss: 24.0125
2022-11-30 21:03:42,213 - mmseg - INFO - Iter [20200/40000]	lr: 6.585e-08, eta: 1 day, 0:03:44, time: 4.121, data_time: 0.021, memory: 51902, decode.loss_cls: 0.4069, decode.loss_mask: 0.5514, decode.loss_dice: 0.7979, decode.d0.loss_cls: 6.1867, decode.d0.loss_mask: 0.5373, decode.d0.loss_dice: 0.8719, decode.d1.loss_cls: 0.5236, decode.d1.loss_mask: 0.5769, decode.d1.loss_dice: 0.8611, decode.d2.loss_cls: 0.4612, decode.d2.loss_mask: 0.5634, decode.d2.loss_dice: 0.8236, decode.d3.loss_cls: 0.4250, decode.d3.loss_mask: 0.5572, decode.d3.loss_dice: 0.8090, decode.d4.loss_cls: 0.4199, decode.d4.loss_mask: 0.5563, decode.d4.loss_dice: 0.8037, decode.d5.loss_cls: 0.4105, decode.d5.loss_mask: 0.5542, decode.d5.loss_dice: 0.8028, decode.d6.loss_cls: 0.4074, decode.d6.loss_mask: 0.5527, decode.d6.loss_dice: 0.7979, decode.d7.loss_cls: 0.4064, decode.d7.loss_mask: 0.5517, decode.d7.loss_dice: 0.8023, decode.d8.loss_cls: 0.4060, decode.d8.loss_mask: 0.5506, decode.d8.loss_dice: 0.8005, loss: 23.7761
2022-11-30 21:07:10,214 - mmseg - INFO - Iter [20250/40000]	lr: 6.569e-08, eta: 23:59:55, time: 4.160, data_time: 0.067, memory: 51902, decode.loss_cls: 0.4111, decode.loss_mask: 0.5603, decode.loss_dice: 0.8321, decode.d0.loss_cls: 6.2075, decode.d0.loss_mask: 0.5377, decode.d0.loss_dice: 0.8975, decode.d1.loss_cls: 0.5238, decode.d1.loss_mask: 0.5783, decode.d1.loss_dice: 0.8876, decode.d2.loss_cls: 0.4697, decode.d2.loss_mask: 0.5694, decode.d2.loss_dice: 0.8550, decode.d3.loss_cls: 0.4350, decode.d3.loss_mask: 0.5650, decode.d3.loss_dice: 0.8384, decode.d4.loss_cls: 0.4285, decode.d4.loss_mask: 0.5632, decode.d4.loss_dice: 0.8365, decode.d5.loss_cls: 0.4216, decode.d5.loss_mask: 0.5601, decode.d5.loss_dice: 0.8344, decode.d6.loss_cls: 0.4132, decode.d6.loss_mask: 0.5605, decode.d6.loss_dice: 0.8306, decode.d7.loss_cls: 0.4106, decode.d7.loss_mask: 0.5617, decode.d7.loss_dice: 0.8313, decode.d8.loss_cls: 0.4141, decode.d8.loss_mask: 0.5586, decode.d8.loss_dice: 0.8273, loss: 24.2205
2022-11-30 21:10:36,001 - mmseg - INFO - Iter [20300/40000]	lr: 6.552e-08, eta: 23:56:03, time: 4.116, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3873, decode.loss_mask: 0.5468, decode.loss_dice: 0.8178, decode.d0.loss_cls: 6.1823, decode.d0.loss_mask: 0.5293, decode.d0.loss_dice: 0.8801, decode.d1.loss_cls: 0.5049, decode.d1.loss_mask: 0.5688, decode.d1.loss_dice: 0.8763, decode.d2.loss_cls: 0.4475, decode.d2.loss_mask: 0.5573, decode.d2.loss_dice: 0.8426, decode.d3.loss_cls: 0.4192, decode.d3.loss_mask: 0.5514, decode.d3.loss_dice: 0.8263, decode.d4.loss_cls: 0.4077, decode.d4.loss_mask: 0.5487, decode.d4.loss_dice: 0.8264, decode.d5.loss_cls: 0.4003, decode.d5.loss_mask: 0.5461, decode.d5.loss_dice: 0.8205, decode.d6.loss_cls: 0.3932, decode.d6.loss_mask: 0.5452, decode.d6.loss_dice: 0.8162, decode.d7.loss_cls: 0.3896, decode.d7.loss_mask: 0.5456, decode.d7.loss_dice: 0.8182, decode.d8.loss_cls: 0.3881, decode.d8.loss_mask: 0.5454, decode.d8.loss_dice: 0.8165, loss: 23.7454
2022-11-30 21:14:01,970 - mmseg - INFO - Iter [20350/40000]	lr: 6.535e-08, eta: 23:52:12, time: 4.119, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3946, decode.loss_mask: 0.5720, decode.loss_dice: 0.8285, decode.d0.loss_cls: 6.1565, decode.d0.loss_mask: 0.5598, decode.d0.loss_dice: 0.9015, decode.d1.loss_cls: 0.5152, decode.d1.loss_mask: 0.5997, decode.d1.loss_dice: 0.8868, decode.d2.loss_cls: 0.4621, decode.d2.loss_mask: 0.5823, decode.d2.loss_dice: 0.8489, decode.d3.loss_cls: 0.4236, decode.d3.loss_mask: 0.5767, decode.d3.loss_dice: 0.8348, decode.d4.loss_cls: 0.4153, decode.d4.loss_mask: 0.5747, decode.d4.loss_dice: 0.8324, decode.d5.loss_cls: 0.4038, decode.d5.loss_mask: 0.5713, decode.d5.loss_dice: 0.8269, decode.d6.loss_cls: 0.4019, decode.d6.loss_mask: 0.5718, decode.d6.loss_dice: 0.8249, decode.d7.loss_cls: 0.3954, decode.d7.loss_mask: 0.5714, decode.d7.loss_dice: 0.8275, decode.d8.loss_cls: 0.3941, decode.d8.loss_mask: 0.5711, decode.d8.loss_dice: 0.8271, loss: 24.1524
2022-11-30 21:17:27,764 - mmseg - INFO - Iter [20400/40000]	lr: 6.519e-08, eta: 23:48:21, time: 4.116, data_time: 0.021, memory: 51902, decode.loss_cls: 0.4001, decode.loss_mask: 0.5429, decode.loss_dice: 0.8180, decode.d0.loss_cls: 6.1682, decode.d0.loss_mask: 0.5282, decode.d0.loss_dice: 0.8947, decode.d1.loss_cls: 0.5122, decode.d1.loss_mask: 0.5675, decode.d1.loss_dice: 0.8839, decode.d2.loss_cls: 0.4548, decode.d2.loss_mask: 0.5541, decode.d2.loss_dice: 0.8423, decode.d3.loss_cls: 0.4243, decode.d3.loss_mask: 0.5508, decode.d3.loss_dice: 0.8254, decode.d4.loss_cls: 0.4159, decode.d4.loss_mask: 0.5485, decode.d4.loss_dice: 0.8279, decode.d5.loss_cls: 0.4076, decode.d5.loss_mask: 0.5463, decode.d5.loss_dice: 0.8198, decode.d6.loss_cls: 0.4040, decode.d6.loss_mask: 0.5454, decode.d6.loss_dice: 0.8160, decode.d7.loss_cls: 0.4025, decode.d7.loss_mask: 0.5458, decode.d7.loss_dice: 0.8204, decode.d8.loss_cls: 0.4036, decode.d8.loss_mask: 0.5433, decode.d8.loss_dice: 0.8196, loss: 23.8338
2022-11-30 21:20:53,376 - mmseg - INFO - Iter [20450/40000]	lr: 6.502e-08, eta: 23:44:30, time: 4.112, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3882, decode.loss_mask: 0.5703, decode.loss_dice: 0.8449, decode.d0.loss_cls: 6.1660, decode.d0.loss_mask: 0.5557, decode.d0.loss_dice: 0.9115, decode.d1.loss_cls: 0.5058, decode.d1.loss_mask: 0.5913, decode.d1.loss_dice: 0.9054, decode.d2.loss_cls: 0.4462, decode.d2.loss_mask: 0.5832, decode.d2.loss_dice: 0.8705, decode.d3.loss_cls: 0.4150, decode.d3.loss_mask: 0.5755, decode.d3.loss_dice: 0.8567, decode.d4.loss_cls: 0.4079, decode.d4.loss_mask: 0.5740, decode.d4.loss_dice: 0.8510, decode.d5.loss_cls: 0.3976, decode.d5.loss_mask: 0.5704, decode.d5.loss_dice: 0.8499, decode.d6.loss_cls: 0.3915, decode.d6.loss_mask: 0.5696, decode.d6.loss_dice: 0.8447, decode.d7.loss_cls: 0.3903, decode.d7.loss_mask: 0.5700, decode.d7.loss_dice: 0.8483, decode.d8.loss_cls: 0.3898, decode.d8.loss_mask: 0.5709, decode.d8.loss_dice: 0.8449, loss: 24.2565
2022-11-30 21:24:18,928 - mmseg - INFO - Iter [20500/40000]	lr: 6.485e-08, eta: 23:40:39, time: 4.111, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3796, decode.loss_mask: 0.5506, decode.loss_dice: 0.8373, decode.d0.loss_cls: 6.1816, decode.d0.loss_mask: 0.5339, decode.d0.loss_dice: 0.9013, decode.d1.loss_cls: 0.5008, decode.d1.loss_mask: 0.5760, decode.d1.loss_dice: 0.8944, decode.d2.loss_cls: 0.4426, decode.d2.loss_mask: 0.5654, decode.d2.loss_dice: 0.8572, decode.d3.loss_cls: 0.4121, decode.d3.loss_mask: 0.5578, decode.d3.loss_dice: 0.8443, decode.d4.loss_cls: 0.4044, decode.d4.loss_mask: 0.5533, decode.d4.loss_dice: 0.8389, decode.d5.loss_cls: 0.3925, decode.d5.loss_mask: 0.5515, decode.d5.loss_dice: 0.8359, decode.d6.loss_cls: 0.3866, decode.d6.loss_mask: 0.5505, decode.d6.loss_dice: 0.8299, decode.d7.loss_cls: 0.3866, decode.d7.loss_mask: 0.5516, decode.d7.loss_dice: 0.8313, decode.d8.loss_cls: 0.3816, decode.d8.loss_mask: 0.5507, decode.d8.loss_dice: 0.8310, loss: 23.9112
2022-11-30 21:27:44,857 - mmseg - INFO - Iter [20550/40000]	lr: 6.469e-08, eta: 23:36:49, time: 4.119, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3982, decode.loss_mask: 0.5597, decode.loss_dice: 0.8181, decode.d0.loss_cls: 6.1520, decode.d0.loss_mask: 0.5426, decode.d0.loss_dice: 0.8978, decode.d1.loss_cls: 0.5199, decode.d1.loss_mask: 0.5864, decode.d1.loss_dice: 0.8815, decode.d2.loss_cls: 0.4560, decode.d2.loss_mask: 0.5715, decode.d2.loss_dice: 0.8433, decode.d3.loss_cls: 0.4244, decode.d3.loss_mask: 0.5650, decode.d3.loss_dice: 0.8267, decode.d4.loss_cls: 0.4148, decode.d4.loss_mask: 0.5601, decode.d4.loss_dice: 0.8251, decode.d5.loss_cls: 0.4037, decode.d5.loss_mask: 0.5610, decode.d5.loss_dice: 0.8227, decode.d6.loss_cls: 0.3981, decode.d6.loss_mask: 0.5596, decode.d6.loss_dice: 0.8195, decode.d7.loss_cls: 0.3963, decode.d7.loss_mask: 0.5577, decode.d7.loss_dice: 0.8208, decode.d8.loss_cls: 0.4012, decode.d8.loss_mask: 0.5586, decode.d8.loss_dice: 0.8180, loss: 23.9605
2022-11-30 21:31:10,687 - mmseg - INFO - Iter [20600/40000]	lr: 6.452e-08, eta: 23:32:58, time: 4.117, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3897, decode.loss_mask: 0.5542, decode.loss_dice: 0.8102, decode.d0.loss_cls: 6.1431, decode.d0.loss_mask: 0.5345, decode.d0.loss_dice: 0.8765, decode.d1.loss_cls: 0.5022, decode.d1.loss_mask: 0.5760, decode.d1.loss_dice: 0.8616, decode.d2.loss_cls: 0.4447, decode.d2.loss_mask: 0.5633, decode.d2.loss_dice: 0.8326, decode.d3.loss_cls: 0.4098, decode.d3.loss_mask: 0.5591, decode.d3.loss_dice: 0.8199, decode.d4.loss_cls: 0.4062, decode.d4.loss_mask: 0.5589, decode.d4.loss_dice: 0.8155, decode.d5.loss_cls: 0.3959, decode.d5.loss_mask: 0.5595, decode.d5.loss_dice: 0.8143, decode.d6.loss_cls: 0.3913, decode.d6.loss_mask: 0.5549, decode.d6.loss_dice: 0.8133, decode.d7.loss_cls: 0.3924, decode.d7.loss_mask: 0.5558, decode.d7.loss_dice: 0.8118, decode.d8.loss_cls: 0.3903, decode.d8.loss_mask: 0.5549, decode.d8.loss_dice: 0.8135, loss: 23.7059
2022-11-30 21:34:36,077 - mmseg - INFO - Iter [20650/40000]	lr: 6.436e-08, eta: 23:29:08, time: 4.108, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3863, decode.loss_mask: 0.5720, decode.loss_dice: 0.8374, decode.d0.loss_cls: 6.1195, decode.d0.loss_mask: 0.5496, decode.d0.loss_dice: 0.8928, decode.d1.loss_cls: 0.5062, decode.d1.loss_mask: 0.5931, decode.d1.loss_dice: 0.8941, decode.d2.loss_cls: 0.4412, decode.d2.loss_mask: 0.5851, decode.d2.loss_dice: 0.8607, decode.d3.loss_cls: 0.4098, decode.d3.loss_mask: 0.5791, decode.d3.loss_dice: 0.8462, decode.d4.loss_cls: 0.3963, decode.d4.loss_mask: 0.5779, decode.d4.loss_dice: 0.8411, decode.d5.loss_cls: 0.3933, decode.d5.loss_mask: 0.5767, decode.d5.loss_dice: 0.8368, decode.d6.loss_cls: 0.3859, decode.d6.loss_mask: 0.5749, decode.d6.loss_dice: 0.8380, decode.d7.loss_cls: 0.3855, decode.d7.loss_mask: 0.5712, decode.d7.loss_dice: 0.8373, decode.d8.loss_cls: 0.3872, decode.d8.loss_mask: 0.5715, decode.d8.loss_dice: 0.8346, loss: 24.0814
2022-11-30 21:38:02,014 - mmseg - INFO - Iter [20700/40000]	lr: 6.419e-08, eta: 23:25:17, time: 4.119, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3819, decode.loss_mask: 0.5668, decode.loss_dice: 0.8157, decode.d0.loss_cls: 6.1122, decode.d0.loss_mask: 0.5510, decode.d0.loss_dice: 0.8856, decode.d1.loss_cls: 0.4964, decode.d1.loss_mask: 0.5946, decode.d1.loss_dice: 0.8814, decode.d2.loss_cls: 0.4384, decode.d2.loss_mask: 0.5815, decode.d2.loss_dice: 0.8464, decode.d3.loss_cls: 0.4087, decode.d3.loss_mask: 0.5722, decode.d3.loss_dice: 0.8301, decode.d4.loss_cls: 0.4010, decode.d4.loss_mask: 0.5666, decode.d4.loss_dice: 0.8301, decode.d5.loss_cls: 0.3917, decode.d5.loss_mask: 0.5666, decode.d5.loss_dice: 0.8242, decode.d6.loss_cls: 0.3870, decode.d6.loss_mask: 0.5646, decode.d6.loss_dice: 0.8218, decode.d7.loss_cls: 0.3886, decode.d7.loss_mask: 0.5627, decode.d7.loss_dice: 0.8196, decode.d8.loss_cls: 0.3856, decode.d8.loss_mask: 0.5644, decode.d8.loss_dice: 0.8153, loss: 23.8525
2022-11-30 21:41:27,947 - mmseg - INFO - Iter [20750/40000]	lr: 6.402e-08, eta: 23:21:27, time: 4.119, data_time: 0.022, memory: 51902, decode.loss_cls: 0.3847, decode.loss_mask: 0.5656, decode.loss_dice: 0.8276, decode.d0.loss_cls: 6.1247, decode.d0.loss_mask: 0.5529, decode.d0.loss_dice: 0.8914, decode.d1.loss_cls: 0.5131, decode.d1.loss_mask: 0.5927, decode.d1.loss_dice: 0.8858, decode.d2.loss_cls: 0.4517, decode.d2.loss_mask: 0.5758, decode.d2.loss_dice: 0.8456, decode.d3.loss_cls: 0.4157, decode.d3.loss_mask: 0.5700, decode.d3.loss_dice: 0.8352, decode.d4.loss_cls: 0.4066, decode.d4.loss_mask: 0.5675, decode.d4.loss_dice: 0.8340, decode.d5.loss_cls: 0.3952, decode.d5.loss_mask: 0.5657, decode.d5.loss_dice: 0.8295, decode.d6.loss_cls: 0.3929, decode.d6.loss_mask: 0.5656, decode.d6.loss_dice: 0.8258, decode.d7.loss_cls: 0.3905, decode.d7.loss_mask: 0.5632, decode.d7.loss_dice: 0.8246, decode.d8.loss_cls: 0.3869, decode.d8.loss_mask: 0.5661, decode.d8.loss_dice: 0.8264, loss: 23.9727
2022-11-30 21:44:53,389 - mmseg - INFO - Iter [20800/40000]	lr: 6.386e-08, eta: 23:17:37, time: 4.109, data_time: 0.020, memory: 51902, decode.loss_cls: 0.4110, decode.loss_mask: 0.5553, decode.loss_dice: 0.8225, decode.d0.loss_cls: 6.1362, decode.d0.loss_mask: 0.5438, decode.d0.loss_dice: 0.8966, decode.d1.loss_cls: 0.5239, decode.d1.loss_mask: 0.5791, decode.d1.loss_dice: 0.8805, decode.d2.loss_cls: 0.4690, decode.d2.loss_mask: 0.5643, decode.d2.loss_dice: 0.8435, decode.d3.loss_cls: 0.4345, decode.d3.loss_mask: 0.5621, decode.d3.loss_dice: 0.8286, decode.d4.loss_cls: 0.4232, decode.d4.loss_mask: 0.5603, decode.d4.loss_dice: 0.8289, decode.d5.loss_cls: 0.4160, decode.d5.loss_mask: 0.5568, decode.d5.loss_dice: 0.8217, decode.d6.loss_cls: 0.4089, decode.d6.loss_mask: 0.5569, decode.d6.loss_dice: 0.8191, decode.d7.loss_cls: 0.4069, decode.d7.loss_mask: 0.5570, decode.d7.loss_dice: 0.8220, decode.d8.loss_cls: 0.4089, decode.d8.loss_mask: 0.5573, decode.d8.loss_dice: 0.8209, loss: 24.0157
2022-11-30 21:48:19,113 - mmseg - INFO - Iter [20850/40000]	lr: 6.369e-08, eta: 23:13:47, time: 4.114, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3748, decode.loss_mask: 0.5547, decode.loss_dice: 0.8089, decode.d0.loss_cls: 6.1138, decode.d0.loss_mask: 0.5333, decode.d0.loss_dice: 0.8688, decode.d1.loss_cls: 0.4868, decode.d1.loss_mask: 0.5742, decode.d1.loss_dice: 0.8683, decode.d2.loss_cls: 0.4244, decode.d2.loss_mask: 0.5668, decode.d2.loss_dice: 0.8335, decode.d3.loss_cls: 0.3965, decode.d3.loss_mask: 0.5627, decode.d3.loss_dice: 0.8179, decode.d4.loss_cls: 0.3881, decode.d4.loss_mask: 0.5613, decode.d4.loss_dice: 0.8186, decode.d5.loss_cls: 0.3802, decode.d5.loss_mask: 0.5580, decode.d5.loss_dice: 0.8097, decode.d6.loss_cls: 0.3768, decode.d6.loss_mask: 0.5563, decode.d6.loss_dice: 0.8088, decode.d7.loss_cls: 0.3736, decode.d7.loss_mask: 0.5550, decode.d7.loss_dice: 0.8123, decode.d8.loss_cls: 0.3726, decode.d8.loss_mask: 0.5563, decode.d8.loss_dice: 0.8077, loss: 23.5209
2022-11-30 21:51:47,345 - mmseg - INFO - Iter [20900/40000]	lr: 6.352e-08, eta: 23:09:59, time: 4.165, data_time: 0.066, memory: 51902, decode.loss_cls: 0.3818, decode.loss_mask: 0.5630, decode.loss_dice: 0.8161, decode.d0.loss_cls: 6.1102, decode.d0.loss_mask: 0.5439, decode.d0.loss_dice: 0.8788, decode.d1.loss_cls: 0.5110, decode.d1.loss_mask: 0.5859, decode.d1.loss_dice: 0.8686, decode.d2.loss_cls: 0.4469, decode.d2.loss_mask: 0.5717, decode.d2.loss_dice: 0.8367, decode.d3.loss_cls: 0.4113, decode.d3.loss_mask: 0.5665, decode.d3.loss_dice: 0.8203, decode.d4.loss_cls: 0.4017, decode.d4.loss_mask: 0.5644, decode.d4.loss_dice: 0.8222, decode.d5.loss_cls: 0.3926, decode.d5.loss_mask: 0.5638, decode.d5.loss_dice: 0.8176, decode.d6.loss_cls: 0.3865, decode.d6.loss_mask: 0.5615, decode.d6.loss_dice: 0.8153, decode.d7.loss_cls: 0.3852, decode.d7.loss_mask: 0.5621, decode.d7.loss_dice: 0.8167, decode.d8.loss_cls: 0.3808, decode.d8.loss_mask: 0.5616, decode.d8.loss_dice: 0.8169, loss: 23.7617
2022-11-30 21:55:13,049 - mmseg - INFO - Iter [20950/40000]	lr: 6.336e-08, eta: 23:06:10, time: 4.114, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3581, decode.loss_mask: 0.5465, decode.loss_dice: 0.8061, decode.d0.loss_cls: 6.1003, decode.d0.loss_mask: 0.5309, decode.d0.loss_dice: 0.8668, decode.d1.loss_cls: 0.4697, decode.d1.loss_mask: 0.5716, decode.d1.loss_dice: 0.8649, decode.d2.loss_cls: 0.4155, decode.d2.loss_mask: 0.5567, decode.d2.loss_dice: 0.8291, decode.d3.loss_cls: 0.3843, decode.d3.loss_mask: 0.5521, decode.d3.loss_dice: 0.8138, decode.d4.loss_cls: 0.3788, decode.d4.loss_mask: 0.5478, decode.d4.loss_dice: 0.8120, decode.d5.loss_cls: 0.3687, decode.d5.loss_mask: 0.5458, decode.d5.loss_dice: 0.8071, decode.d6.loss_cls: 0.3641, decode.d6.loss_mask: 0.5458, decode.d6.loss_dice: 0.8076, decode.d7.loss_cls: 0.3614, decode.d7.loss_mask: 0.5468, decode.d7.loss_dice: 0.8098, decode.d8.loss_cls: 0.3599, decode.d8.loss_mask: 0.5465, decode.d8.loss_dice: 0.8073, loss: 23.2760
2022-11-30 21:58:38,669 - mmseg - INFO - Saving checkpoint at 21000 iterations
2022-11-30 21:59:28,948 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 21:59:28,948 - mmseg - INFO - Iter [21000/40000]	lr: 6.319e-08, eta: 23:03:05, time: 5.118, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3864, decode.loss_mask: 0.5481, decode.loss_dice: 0.8063, decode.d0.loss_cls: 6.0886, decode.d0.loss_mask: 0.5365, decode.d0.loss_dice: 0.8742, decode.d1.loss_cls: 0.4966, decode.d1.loss_mask: 0.5730, decode.d1.loss_dice: 0.8626, decode.d2.loss_cls: 0.4445, decode.d2.loss_mask: 0.5581, decode.d2.loss_dice: 0.8342, decode.d3.loss_cls: 0.4088, decode.d3.loss_mask: 0.5553, decode.d3.loss_dice: 0.8191, decode.d4.loss_cls: 0.3965, decode.d4.loss_mask: 0.5537, decode.d4.loss_dice: 0.8183, decode.d5.loss_cls: 0.3865, decode.d5.loss_mask: 0.5520, decode.d5.loss_dice: 0.8130, decode.d6.loss_cls: 0.3868, decode.d6.loss_mask: 0.5498, decode.d6.loss_dice: 0.8087, decode.d7.loss_cls: 0.3837, decode.d7.loss_mask: 0.5473, decode.d7.loss_dice: 0.8095, decode.d8.loss_cls: 0.3822, decode.d8.loss_mask: 0.5489, decode.d8.loss_dice: 0.8079, loss: 23.5372
2022-11-30 22:02:26,982 - mmseg - INFO - per class results:
2022-11-30 22:02:26,987 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 83.19 | 89.03 |
|       building      | 84.74 | 91.39 |
|         sky         |  95.2 | 97.23 |
|        floor        | 84.74 | 89.51 |
|         tree        | 78.62 | 90.48 |
|       ceiling       | 87.01 | 93.59 |
|         road        | 86.87 | 89.84 |
|         bed         | 93.85 | 97.18 |
|      windowpane     | 68.21 | 84.57 |
|        grass        | 68.94 | 82.97 |
|       cabinet       | 61.48 | 70.69 |
|       sidewalk      | 71.15 | 85.67 |
|        person       | 88.45 | 94.28 |
|        earth        | 45.26 | 64.01 |
|         door        | 64.02 | 80.89 |
|        table        | 72.04 | 82.46 |
|       mountain      | 64.46 |  79.8 |
|        plant        | 56.87 | 68.71 |
|       curtain       | 84.24 | 91.74 |
|        chair        | 69.37 | 80.78 |
|         car         | 89.25 | 94.62 |
|        water        | 65.41 | 79.23 |
|       painting      | 82.36 | 92.78 |
|         sofa        |  87.1 | 92.62 |
|        shelf        | 48.38 | 59.59 |
|        house        | 52.35 | 70.62 |
|         sea         | 73.46 | 90.71 |
|        mirror       | 81.38 | 91.28 |
|         rug         | 71.47 | 86.57 |
|        field        |  32.8 | 54.57 |
|       armchair      | 64.67 | 79.86 |
|         seat        | 67.07 | 89.72 |
|        fence        | 58.34 |  75.4 |
|         desk        | 59.64 | 84.01 |
|         rock        |  58.4 | 73.33 |
|       wardrobe      | 57.61 | 86.74 |
|         lamp        | 80.66 | 89.61 |
|       bathtub       | 91.56 | 93.44 |
|       railing       |  48.7 | 71.76 |
|       cushion       | 78.04 | 91.55 |
|         base        | 49.64 | 72.52 |
|         box         | 41.28 | 57.66 |
|        column       | 60.87 | 69.32 |
|      signboard      | 47.29 | 66.68 |
|   chest of drawers  |  42.3 | 72.54 |
|       counter       | 57.96 | 68.66 |
|         sand        | 61.99 | 88.12 |
|         sink        | 83.23 | 86.93 |
|      skyscraper     | 37.66 | 48.86 |
|      fireplace      | 79.92 | 95.88 |
|     refrigerator    | 84.62 | 95.72 |
|      grandstand     | 49.03 | 83.42 |
|         path        | 30.64 | 42.96 |
|        stairs       | 33.76 | 43.05 |
|        runway       | 71.28 | 91.13 |
|         case        | 68.59 |  85.9 |
|      pool table     | 95.85 | 98.98 |
|        pillow       | 73.43 | 82.78 |
|     screen door     | 86.02 | 94.71 |
|       stairway      | 57.68 | 75.12 |
|        river        | 29.48 | 35.11 |
|        bridge       | 72.34 | 86.31 |
|       bookcase      |  38.1 | 65.71 |
|        blind        | 36.75 |  41.4 |
|     coffee table    | 72.47 | 87.86 |
|        toilet       | 93.18 | 96.93 |
|        flower       |  44.9 |  72.7 |
|         book        | 60.92 | 80.42 |
|         hill        |  12.5 | 22.01 |
|        bench        |  74.6 | 84.58 |
|      countertop     | 75.64 | 90.87 |
|        stove        | 85.23 | 89.46 |
|         palm        | 54.83 | 83.44 |
|    kitchen island   | 39.49 | 93.26 |
|       computer      | 83.13 | 90.85 |
|     swivel chair    | 55.98 | 80.94 |
|         boat        | 51.44 | 88.81 |
|         bar         | 71.93 | 78.57 |
|    arcade machine   | 89.34 |  99.0 |
|        hovel        | 50.94 |  75.0 |
|         bus         | 94.84 |  96.6 |
|        towel        | 82.84 | 93.44 |
|        light        | 66.98 | 81.39 |
|        truck        | 50.85 | 74.03 |
|        tower        | 33.16 | 63.59 |
|      chandelier     | 75.55 | 88.67 |
|        awning       | 30.67 | 51.17 |
|     streetlight     |  45.8 | 71.88 |
|        booth        | 62.18 |  78.7 |
| television receiver | 75.45 | 89.65 |
|       airplane      |  89.4 | 96.72 |
|      dirt track     | 20.89 | 31.25 |
|       apparel       | 54.39 | 92.38 |
|         pole        | 36.86 | 50.25 |
|         land        |  0.7  |  1.04 |
|      bannister      | 23.06 | 29.25 |
|      escalator      | 63.64 | 84.94 |
|       ottoman       | 59.44 | 81.31 |
|        bottle       | 52.29 | 80.65 |
|        buffet       | 40.33 | 56.53 |
|        poster       | 34.34 | 46.85 |
|        stage        | 30.08 |  79.4 |
|         van         | 51.78 | 75.05 |
|         ship        | 31.61 | 36.58 |
|       fountain      | 39.06 | 44.99 |
|    conveyer belt    | 78.77 | 97.39 |
|        canopy       | 57.46 |  92.4 |
|        washer       |  90.7 | 93.73 |
|      plaything      | 38.37 | 56.43 |
|    swimming pool    |  45.7 | 75.16 |
|        stool        | 57.68 | 82.57 |
|        barrel       | 85.19 | 96.03 |
|        basket       | 43.97 |  70.2 |
|      waterfall      | 46.77 | 57.61 |
|         tent        | 96.36 | 98.04 |
|         bag         | 34.65 |  46.8 |
|       minibike      |  81.1 | 94.37 |
|        cradle       | 91.39 | 97.46 |
|         oven        | 65.81 | 84.02 |
|         ball        | 40.95 | 44.22 |
|         food        | 68.78 | 84.79 |
|         step        | 22.23 | 38.44 |
|         tank        | 61.24 |  67.6 |
|      trade name     | 33.78 | 42.67 |
|      microwave      |  89.6 | 94.73 |
|         pot         | 61.55 | 73.48 |
|        animal       | 83.91 | 87.29 |
|       bicycle       | 62.26 | 85.21 |
|         lake        | 16.89 | 26.36 |
|      dishwasher     | 80.08 | 90.49 |
|        screen       | 60.89 |  96.3 |
|       blanket       | 48.27 | 59.94 |
|      sculpture      | 73.25 | 90.84 |
|         hood        | 80.49 | 92.76 |
|        sconce       | 67.28 | 83.16 |
|         vase        | 58.65 | 81.66 |
|    traffic light    | 53.04 | 74.94 |
|         tray        | 32.66 | 52.57 |
|        ashcan       | 55.52 | 78.81 |
|         fan         | 72.94 | 85.99 |
|         pier        |  38.5 | 40.77 |
|      crt screen     |  3.52 |  9.22 |
|        plate        | 71.45 | 83.97 |
|       monitor       |  4.1  |  5.23 |
|    bulletin board   | 54.51 | 84.29 |
|        shower       | 19.42 | 29.94 |
|       radiator      | 73.48 | 91.58 |
|        glass        | 29.26 | 32.22 |
|        clock        |  62.1 | 75.24 |
|         flag        | 70.48 | 87.63 |
+---------------------+-------+-------+
2022-11-30 22:02:26,987 - mmseg - INFO - Summary:
2022-11-30 22:02:26,987 - mmseg - INFO - 
+------+------+-------+
| aAcc | mIoU |  mAcc |
+------+------+-------+
| 86.8 | 60.5 | 75.39 |
+------+------+-------+
2022-11-30 22:02:26,992 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 22:02:26,992 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8680, mIoU: 0.6050, mAcc: 0.7539, IoU.wall: 0.8319, IoU.building: 0.8474, IoU.sky: 0.9520, IoU.floor: 0.8474, IoU.tree: 0.7862, IoU.ceiling: 0.8701, IoU.road: 0.8687, IoU.bed : 0.9385, IoU.windowpane: 0.6821, IoU.grass: 0.6894, IoU.cabinet: 0.6148, IoU.sidewalk: 0.7115, IoU.person: 0.8845, IoU.earth: 0.4526, IoU.door: 0.6402, IoU.table: 0.7204, IoU.mountain: 0.6446, IoU.plant: 0.5687, IoU.curtain: 0.8424, IoU.chair: 0.6937, IoU.car: 0.8925, IoU.water: 0.6541, IoU.painting: 0.8236, IoU.sofa: 0.8710, IoU.shelf: 0.4838, IoU.house: 0.5235, IoU.sea: 0.7346, IoU.mirror: 0.8138, IoU.rug: 0.7147, IoU.field: 0.3280, IoU.armchair: 0.6467, IoU.seat: 0.6707, IoU.fence: 0.5834, IoU.desk: 0.5964, IoU.rock: 0.5840, IoU.wardrobe: 0.5761, IoU.lamp: 0.8066, IoU.bathtub: 0.9156, IoU.railing: 0.4870, IoU.cushion: 0.7804, IoU.base: 0.4964, IoU.box: 0.4128, IoU.column: 0.6087, IoU.signboard: 0.4729, IoU.chest of drawers: 0.4230, IoU.counter: 0.5796, IoU.sand: 0.6199, IoU.sink: 0.8323, IoU.skyscraper: 0.3766, IoU.fireplace: 0.7992, IoU.refrigerator: 0.8462, IoU.grandstand: 0.4903, IoU.path: 0.3064, IoU.stairs: 0.3376, IoU.runway: 0.7128, IoU.case: 0.6859, IoU.pool table: 0.9585, IoU.pillow: 0.7343, IoU.screen door: 0.8602, IoU.stairway: 0.5768, IoU.river: 0.2948, IoU.bridge: 0.7234, IoU.bookcase: 0.3810, IoU.blind: 0.3675, IoU.coffee table: 0.7247, IoU.toilet: 0.9318, IoU.flower: 0.4490, IoU.book: 0.6092, IoU.hill: 0.1250, IoU.bench: 0.7460, IoU.countertop: 0.7564, IoU.stove: 0.8523, IoU.palm: 0.5483, IoU.kitchen island: 0.3949, IoU.computer: 0.8313, IoU.swivel chair: 0.5598, IoU.boat: 0.5144, IoU.bar: 0.7193, IoU.arcade machine: 0.8934, IoU.hovel: 0.5094, IoU.bus: 0.9484, IoU.towel: 0.8284, IoU.light: 0.6698, IoU.truck: 0.5085, IoU.tower: 0.3316, IoU.chandelier: 0.7555, IoU.awning: 0.3067, IoU.streetlight: 0.4580, IoU.booth: 0.6218, IoU.television receiver: 0.7545, IoU.airplane: 0.8940, IoU.dirt track: 0.2089, IoU.apparel: 0.5439, IoU.pole: 0.3686, IoU.land: 0.0070, IoU.bannister: 0.2306, IoU.escalator: 0.6364, IoU.ottoman: 0.5944, IoU.bottle: 0.5229, IoU.buffet: 0.4033, IoU.poster: 0.3434, IoU.stage: 0.3008, IoU.van: 0.5178, IoU.ship: 0.3161, IoU.fountain: 0.3906, IoU.conveyer belt: 0.7877, IoU.canopy: 0.5746, IoU.washer: 0.9070, IoU.plaything: 0.3837, IoU.swimming pool: 0.4570, IoU.stool: 0.5768, IoU.barrel: 0.8519, IoU.basket: 0.4397, IoU.waterfall: 0.4677, IoU.tent: 0.9636, IoU.bag: 0.3465, IoU.minibike: 0.8110, IoU.cradle: 0.9139, IoU.oven: 0.6581, IoU.ball: 0.4095, IoU.food: 0.6878, IoU.step: 0.2223, IoU.tank: 0.6124, IoU.trade name: 0.3378, IoU.microwave: 0.8960, IoU.pot: 0.6155, IoU.animal: 0.8391, IoU.bicycle: 0.6226, IoU.lake: 0.1689, IoU.dishwasher: 0.8008, IoU.screen: 0.6089, IoU.blanket: 0.4827, IoU.sculpture: 0.7325, IoU.hood: 0.8049, IoU.sconce: 0.6728, IoU.vase: 0.5865, IoU.traffic light: 0.5304, IoU.tray: 0.3266, IoU.ashcan: 0.5552, IoU.fan: 0.7294, IoU.pier: 0.3850, IoU.crt screen: 0.0352, IoU.plate: 0.7145, IoU.monitor: 0.0410, IoU.bulletin board: 0.5451, IoU.shower: 0.1942, IoU.radiator: 0.7348, IoU.glass: 0.2926, IoU.clock: 0.6210, IoU.flag: 0.7048, Acc.wall: 0.8903, Acc.building: 0.9139, Acc.sky: 0.9723, Acc.floor: 0.8951, Acc.tree: 0.9048, Acc.ceiling: 0.9359, Acc.road: 0.8984, Acc.bed : 0.9718, Acc.windowpane: 0.8457, Acc.grass: 0.8297, Acc.cabinet: 0.7069, Acc.sidewalk: 0.8567, Acc.person: 0.9428, Acc.earth: 0.6401, Acc.door: 0.8089, Acc.table: 0.8246, Acc.mountain: 0.7980, Acc.plant: 0.6871, Acc.curtain: 0.9174, Acc.chair: 0.8078, Acc.car: 0.9462, Acc.water: 0.7923, Acc.painting: 0.9278, Acc.sofa: 0.9262, Acc.shelf: 0.5959, Acc.house: 0.7062, Acc.sea: 0.9071, Acc.mirror: 0.9128, Acc.rug: 0.8657, Acc.field: 0.5457, Acc.armchair: 0.7986, Acc.seat: 0.8972, Acc.fence: 0.7540, Acc.desk: 0.8401, Acc.rock: 0.7333, Acc.wardrobe: 0.8674, Acc.lamp: 0.8961, Acc.bathtub: 0.9344, Acc.railing: 0.7176, Acc.cushion: 0.9155, Acc.base: 0.7252, Acc.box: 0.5766, Acc.column: 0.6932, Acc.signboard: 0.6668, Acc.chest of drawers: 0.7254, Acc.counter: 0.6866, Acc.sand: 0.8812, Acc.sink: 0.8693, Acc.skyscraper: 0.4886, Acc.fireplace: 0.9588, Acc.refrigerator: 0.9572, Acc.grandstand: 0.8342, Acc.path: 0.4296, Acc.stairs: 0.4305, Acc.runway: 0.9113, Acc.case: 0.8590, Acc.pool table: 0.9898, Acc.pillow: 0.8278, Acc.screen door: 0.9471, Acc.stairway: 0.7512, Acc.river: 0.3511, Acc.bridge: 0.8631, Acc.bookcase: 0.6571, Acc.blind: 0.4140, Acc.coffee table: 0.8786, Acc.toilet: 0.9693, Acc.flower: 0.7270, Acc.book: 0.8042, Acc.hill: 0.2201, Acc.bench: 0.8458, Acc.countertop: 0.9087, Acc.stove: 0.8946, Acc.palm: 0.8344, Acc.kitchen island: 0.9326, Acc.computer: 0.9085, Acc.swivel chair: 0.8094, Acc.boat: 0.8881, Acc.bar: 0.7857, Acc.arcade machine: 0.9900, Acc.hovel: 0.7500, Acc.bus: 0.9660, Acc.towel: 0.9344, Acc.light: 0.8139, Acc.truck: 0.7403, Acc.tower: 0.6359, Acc.chandelier: 0.8867, Acc.awning: 0.5117, Acc.streetlight: 0.7188, Acc.booth: 0.7870, Acc.television receiver: 0.8965, Acc.airplane: 0.9672, Acc.dirt track: 0.3125, Acc.apparel: 0.9238, Acc.pole: 0.5025, Acc.land: 0.0104, Acc.bannister: 0.2925, Acc.escalator: 0.8494, Acc.ottoman: 0.8131, Acc.bottle: 0.8065, Acc.buffet: 0.5653, Acc.poster: 0.4685, Acc.stage: 0.7940, Acc.van: 0.7505, Acc.ship: 0.3658, Acc.fountain: 0.4499, Acc.conveyer belt: 0.9739, Acc.canopy: 0.9240, Acc.washer: 0.9373, Acc.plaything: 0.5643, Acc.swimming pool: 0.7516, Acc.stool: 0.8257, Acc.barrel: 0.9603, Acc.basket: 0.7020, Acc.waterfall: 0.5761, Acc.tent: 0.9804, Acc.bag: 0.4680, Acc.minibike: 0.9437, Acc.cradle: 0.9746, Acc.oven: 0.8402, Acc.ball: 0.4422, Acc.food: 0.8479, Acc.step: 0.3844, Acc.tank: 0.6760, Acc.trade name: 0.4267, Acc.microwave: 0.9473, Acc.pot: 0.7348, Acc.animal: 0.8729, Acc.bicycle: 0.8521, Acc.lake: 0.2636, Acc.dishwasher: 0.9049, Acc.screen: 0.9630, Acc.blanket: 0.5994, Acc.sculpture: 0.9084, Acc.hood: 0.9276, Acc.sconce: 0.8316, Acc.vase: 0.8166, Acc.traffic light: 0.7494, Acc.tray: 0.5257, Acc.ashcan: 0.7881, Acc.fan: 0.8599, Acc.pier: 0.4077, Acc.crt screen: 0.0922, Acc.plate: 0.8397, Acc.monitor: 0.0523, Acc.bulletin board: 0.8429, Acc.shower: 0.2994, Acc.radiator: 0.9158, Acc.glass: 0.3222, Acc.clock: 0.7524, Acc.flag: 0.8763
2022-11-30 22:05:52,909 - mmseg - INFO - Iter [21050/40000]	lr: 6.303e-08, eta: 23:01:56, time: 7.679, data_time: 3.580, memory: 51902, decode.loss_cls: 0.4019, decode.loss_mask: 0.5632, decode.loss_dice: 0.8353, decode.d0.loss_cls: 6.0756, decode.d0.loss_mask: 0.5449, decode.d0.loss_dice: 0.9019, decode.d1.loss_cls: 0.5220, decode.d1.loss_mask: 0.5878, decode.d1.loss_dice: 0.8907, decode.d2.loss_cls: 0.4620, decode.d2.loss_mask: 0.5754, decode.d2.loss_dice: 0.8566, decode.d3.loss_cls: 0.4254, decode.d3.loss_mask: 0.5687, decode.d3.loss_dice: 0.8451, decode.d4.loss_cls: 0.4189, decode.d4.loss_mask: 0.5649, decode.d4.loss_dice: 0.8405, decode.d5.loss_cls: 0.4078, decode.d5.loss_mask: 0.5648, decode.d5.loss_dice: 0.8364, decode.d6.loss_cls: 0.4047, decode.d6.loss_mask: 0.5641, decode.d6.loss_dice: 0.8364, decode.d7.loss_cls: 0.4053, decode.d7.loss_mask: 0.5618, decode.d7.loss_dice: 0.8336, decode.d8.loss_cls: 0.4039, decode.d8.loss_mask: 0.5632, decode.d8.loss_dice: 0.8359, loss: 24.0988
2022-11-30 22:09:18,920 - mmseg - INFO - Iter [21100/40000]	lr: 6.286e-08, eta: 22:58:06, time: 4.120, data_time: 0.021, memory: 51902, decode.loss_cls: 0.4019, decode.loss_mask: 0.5604, decode.loss_dice: 0.8351, decode.d0.loss_cls: 6.0833, decode.d0.loss_mask: 0.5405, decode.d0.loss_dice: 0.9056, decode.d1.loss_cls: 0.5193, decode.d1.loss_mask: 0.5842, decode.d1.loss_dice: 0.8943, decode.d2.loss_cls: 0.4602, decode.d2.loss_mask: 0.5723, decode.d2.loss_dice: 0.8593, decode.d3.loss_cls: 0.4264, decode.d3.loss_mask: 0.5669, decode.d3.loss_dice: 0.8456, decode.d4.loss_cls: 0.4175, decode.d4.loss_mask: 0.5601, decode.d4.loss_dice: 0.8418, decode.d5.loss_cls: 0.4069, decode.d5.loss_mask: 0.5576, decode.d5.loss_dice: 0.8399, decode.d6.loss_cls: 0.4068, decode.d6.loss_mask: 0.5593, decode.d6.loss_dice: 0.8356, decode.d7.loss_cls: 0.4007, decode.d7.loss_mask: 0.5588, decode.d7.loss_dice: 0.8377, decode.d8.loss_cls: 0.3977, decode.d8.loss_mask: 0.5620, decode.d8.loss_dice: 0.8381, loss: 24.0756
2022-11-30 22:12:44,626 - mmseg - INFO - Iter [21150/40000]	lr: 6.269e-08, eta: 22:54:15, time: 4.114, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3858, decode.loss_mask: 0.5595, decode.loss_dice: 0.8192, decode.d0.loss_cls: 6.0631, decode.d0.loss_mask: 0.5474, decode.d0.loss_dice: 0.8814, decode.d1.loss_cls: 0.5050, decode.d1.loss_mask: 0.5873, decode.d1.loss_dice: 0.8816, decode.d2.loss_cls: 0.4451, decode.d2.loss_mask: 0.5730, decode.d2.loss_dice: 0.8421, decode.d3.loss_cls: 0.4092, decode.d3.loss_mask: 0.5676, decode.d3.loss_dice: 0.8278, decode.d4.loss_cls: 0.4019, decode.d4.loss_mask: 0.5641, decode.d4.loss_dice: 0.8278, decode.d5.loss_cls: 0.3973, decode.d5.loss_mask: 0.5617, decode.d5.loss_dice: 0.8228, decode.d6.loss_cls: 0.3882, decode.d6.loss_mask: 0.5613, decode.d6.loss_dice: 0.8206, decode.d7.loss_cls: 0.3900, decode.d7.loss_mask: 0.5586, decode.d7.loss_dice: 0.8219, decode.d8.loss_cls: 0.3850, decode.d8.loss_mask: 0.5590, decode.d8.loss_dice: 0.8219, loss: 23.7769
2022-11-30 22:16:10,301 - mmseg - INFO - Iter [21200/40000]	lr: 6.253e-08, eta: 22:50:25, time: 4.113, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3838, decode.loss_mask: 0.5633, decode.loss_dice: 0.8311, decode.d0.loss_cls: 6.0886, decode.d0.loss_mask: 0.5454, decode.d0.loss_dice: 0.8931, decode.d1.loss_cls: 0.5018, decode.d1.loss_mask: 0.5874, decode.d1.loss_dice: 0.8888, decode.d2.loss_cls: 0.4444, decode.d2.loss_mask: 0.5744, decode.d2.loss_dice: 0.8532, decode.d3.loss_cls: 0.4121, decode.d3.loss_mask: 0.5691, decode.d3.loss_dice: 0.8400, decode.d4.loss_cls: 0.3991, decode.d4.loss_mask: 0.5684, decode.d4.loss_dice: 0.8377, decode.d5.loss_cls: 0.3876, decode.d5.loss_mask: 0.5666, decode.d5.loss_dice: 0.8345, decode.d6.loss_cls: 0.3844, decode.d6.loss_mask: 0.5645, decode.d6.loss_dice: 0.8299, decode.d7.loss_cls: 0.3809, decode.d7.loss_mask: 0.5632, decode.d7.loss_dice: 0.8304, decode.d8.loss_cls: 0.3837, decode.d8.loss_mask: 0.5623, decode.d8.loss_dice: 0.8259, loss: 23.8954
2022-11-30 22:19:35,718 - mmseg - INFO - Iter [21250/40000]	lr: 6.236e-08, eta: 22:46:35, time: 4.108, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3827, decode.loss_mask: 0.5557, decode.loss_dice: 0.8077, decode.d0.loss_cls: 6.0532, decode.d0.loss_mask: 0.5447, decode.d0.loss_dice: 0.8779, decode.d1.loss_cls: 0.5057, decode.d1.loss_mask: 0.5827, decode.d1.loss_dice: 0.8728, decode.d2.loss_cls: 0.4403, decode.d2.loss_mask: 0.5696, decode.d2.loss_dice: 0.8320, decode.d3.loss_cls: 0.4081, decode.d3.loss_mask: 0.5630, decode.d3.loss_dice: 0.8206, decode.d4.loss_cls: 0.3986, decode.d4.loss_mask: 0.5601, decode.d4.loss_dice: 0.8184, decode.d5.loss_cls: 0.3909, decode.d5.loss_mask: 0.5586, decode.d5.loss_dice: 0.8123, decode.d6.loss_cls: 0.3866, decode.d6.loss_mask: 0.5559, decode.d6.loss_dice: 0.8117, decode.d7.loss_cls: 0.3841, decode.d7.loss_mask: 0.5562, decode.d7.loss_dice: 0.8132, decode.d8.loss_cls: 0.3864, decode.d8.loss_mask: 0.5550, decode.d8.loss_dice: 0.8090, loss: 23.6137
2022-11-30 22:23:01,852 - mmseg - INFO - Iter [21300/40000]	lr: 6.219e-08, eta: 22:42:45, time: 4.123, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3752, decode.loss_mask: 0.5655, decode.loss_dice: 0.8157, decode.d0.loss_cls: 6.0408, decode.d0.loss_mask: 0.5511, decode.d0.loss_dice: 0.8779, decode.d1.loss_cls: 0.4921, decode.d1.loss_mask: 0.5877, decode.d1.loss_dice: 0.8783, decode.d2.loss_cls: 0.4363, decode.d2.loss_mask: 0.5796, decode.d2.loss_dice: 0.8375, decode.d3.loss_cls: 0.4039, decode.d3.loss_mask: 0.5710, decode.d3.loss_dice: 0.8241, decode.d4.loss_cls: 0.3909, decode.d4.loss_mask: 0.5690, decode.d4.loss_dice: 0.8220, decode.d5.loss_cls: 0.3847, decode.d5.loss_mask: 0.5650, decode.d5.loss_dice: 0.8205, decode.d6.loss_cls: 0.3800, decode.d6.loss_mask: 0.5653, decode.d6.loss_dice: 0.8164, decode.d7.loss_cls: 0.3796, decode.d7.loss_mask: 0.5649, decode.d7.loss_dice: 0.8159, decode.d8.loss_cls: 0.3761, decode.d8.loss_mask: 0.5653, decode.d8.loss_dice: 0.8139, loss: 23.6662
2022-11-30 22:26:27,634 - mmseg - INFO - Iter [21350/40000]	lr: 6.203e-08, eta: 22:38:55, time: 4.116, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3763, decode.loss_mask: 0.5567, decode.loss_dice: 0.8193, decode.d0.loss_cls: 6.0355, decode.d0.loss_mask: 0.5418, decode.d0.loss_dice: 0.8845, decode.d1.loss_cls: 0.4950, decode.d1.loss_mask: 0.5830, decode.d1.loss_dice: 0.8682, decode.d2.loss_cls: 0.4360, decode.d2.loss_mask: 0.5709, decode.d2.loss_dice: 0.8394, decode.d3.loss_cls: 0.4032, decode.d3.loss_mask: 0.5642, decode.d3.loss_dice: 0.8241, decode.d4.loss_cls: 0.3983, decode.d4.loss_mask: 0.5618, decode.d4.loss_dice: 0.8186, decode.d5.loss_cls: 0.3843, decode.d5.loss_mask: 0.5608, decode.d5.loss_dice: 0.8192, decode.d6.loss_cls: 0.3781, decode.d6.loss_mask: 0.5599, decode.d6.loss_dice: 0.8195, decode.d7.loss_cls: 0.3768, decode.d7.loss_mask: 0.5591, decode.d7.loss_dice: 0.8184, decode.d8.loss_cls: 0.3772, decode.d8.loss_mask: 0.5566, decode.d8.loss_dice: 0.8151, loss: 23.6020
2022-11-30 22:29:52,952 - mmseg - INFO - Iter [21400/40000]	lr: 6.186e-08, eta: 22:35:05, time: 4.106, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3850, decode.loss_mask: 0.5563, decode.loss_dice: 0.8136, decode.d0.loss_cls: 6.0271, decode.d0.loss_mask: 0.5422, decode.d0.loss_dice: 0.8841, decode.d1.loss_cls: 0.5084, decode.d1.loss_mask: 0.5818, decode.d1.loss_dice: 0.8724, decode.d2.loss_cls: 0.4442, decode.d2.loss_mask: 0.5671, decode.d2.loss_dice: 0.8394, decode.d3.loss_cls: 0.4097, decode.d3.loss_mask: 0.5627, decode.d3.loss_dice: 0.8198, decode.d4.loss_cls: 0.3980, decode.d4.loss_mask: 0.5625, decode.d4.loss_dice: 0.8204, decode.d5.loss_cls: 0.3902, decode.d5.loss_mask: 0.5588, decode.d5.loss_dice: 0.8167, decode.d6.loss_cls: 0.3878, decode.d6.loss_mask: 0.5590, decode.d6.loss_dice: 0.8184, decode.d7.loss_cls: 0.3841, decode.d7.loss_mask: 0.5576, decode.d7.loss_dice: 0.8182, decode.d8.loss_cls: 0.3827, decode.d8.loss_mask: 0.5575, decode.d8.loss_dice: 0.8103, loss: 23.6359
2022-11-30 22:33:18,834 - mmseg - INFO - Iter [21450/40000]	lr: 6.170e-08, eta: 22:31:16, time: 4.118, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3796, decode.loss_mask: 0.5574, decode.loss_dice: 0.8226, decode.d0.loss_cls: 6.0233, decode.d0.loss_mask: 0.5402, decode.d0.loss_dice: 0.8871, decode.d1.loss_cls: 0.5016, decode.d1.loss_mask: 0.5822, decode.d1.loss_dice: 0.8807, decode.d2.loss_cls: 0.4446, decode.d2.loss_mask: 0.5675, decode.d2.loss_dice: 0.8496, decode.d3.loss_cls: 0.4086, decode.d3.loss_mask: 0.5627, decode.d3.loss_dice: 0.8319, decode.d4.loss_cls: 0.4031, decode.d4.loss_mask: 0.5589, decode.d4.loss_dice: 0.8270, decode.d5.loss_cls: 0.3904, decode.d5.loss_mask: 0.5567, decode.d5.loss_dice: 0.8280, decode.d6.loss_cls: 0.3906, decode.d6.loss_mask: 0.5551, decode.d6.loss_dice: 0.8230, decode.d7.loss_cls: 0.3855, decode.d7.loss_mask: 0.5560, decode.d7.loss_dice: 0.8263, decode.d8.loss_cls: 0.3822, decode.d8.loss_mask: 0.5589, decode.d8.loss_dice: 0.8245, loss: 23.7058
2022-11-30 22:36:47,200 - mmseg - INFO - Iter [21500/40000]	lr: 6.153e-08, eta: 22:27:28, time: 4.167, data_time: 0.067, memory: 51902, decode.loss_cls: 0.3941, decode.loss_mask: 0.5524, decode.loss_dice: 0.8242, decode.d0.loss_cls: 6.0374, decode.d0.loss_mask: 0.5387, decode.d0.loss_dice: 0.8919, decode.d1.loss_cls: 0.5104, decode.d1.loss_mask: 0.5758, decode.d1.loss_dice: 0.8880, decode.d2.loss_cls: 0.4531, decode.d2.loss_mask: 0.5641, decode.d2.loss_dice: 0.8491, decode.d3.loss_cls: 0.4188, decode.d3.loss_mask: 0.5594, decode.d3.loss_dice: 0.8348, decode.d4.loss_cls: 0.4103, decode.d4.loss_mask: 0.5583, decode.d4.loss_dice: 0.8292, decode.d5.loss_cls: 0.4003, decode.d5.loss_mask: 0.5577, decode.d5.loss_dice: 0.8295, decode.d6.loss_cls: 0.3999, decode.d6.loss_mask: 0.5542, decode.d6.loss_dice: 0.8205, decode.d7.loss_cls: 0.3970, decode.d7.loss_mask: 0.5529, decode.d7.loss_dice: 0.8229, decode.d8.loss_cls: 0.3945, decode.d8.loss_mask: 0.5525, decode.d8.loss_dice: 0.8228, loss: 23.7945
2022-11-30 22:40:12,691 - mmseg - INFO - Iter [21550/40000]	lr: 6.136e-08, eta: 22:23:39, time: 4.110, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3764, decode.loss_mask: 0.5454, decode.loss_dice: 0.8132, decode.d0.loss_cls: 6.0183, decode.d0.loss_mask: 0.5300, decode.d0.loss_dice: 0.8773, decode.d1.loss_cls: 0.5026, decode.d1.loss_mask: 0.5718, decode.d1.loss_dice: 0.8725, decode.d2.loss_cls: 0.4399, decode.d2.loss_mask: 0.5553, decode.d2.loss_dice: 0.8385, decode.d3.loss_cls: 0.4010, decode.d3.loss_mask: 0.5503, decode.d3.loss_dice: 0.8213, decode.d4.loss_cls: 0.3947, decode.d4.loss_mask: 0.5467, decode.d4.loss_dice: 0.8169, decode.d5.loss_cls: 0.3846, decode.d5.loss_mask: 0.5471, decode.d5.loss_dice: 0.8133, decode.d6.loss_cls: 0.3832, decode.d6.loss_mask: 0.5455, decode.d6.loss_dice: 0.8099, decode.d7.loss_cls: 0.3796, decode.d7.loss_mask: 0.5439, decode.d7.loss_dice: 0.8131, decode.d8.loss_cls: 0.3760, decode.d8.loss_mask: 0.5440, decode.d8.loss_dice: 0.8127, loss: 23.4253
2022-11-30 22:43:38,300 - mmseg - INFO - Iter [21600/40000]	lr: 6.120e-08, eta: 22:19:49, time: 4.112, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3791, decode.loss_mask: 0.5598, decode.loss_dice: 0.8167, decode.d0.loss_cls: 6.0019, decode.d0.loss_mask: 0.5409, decode.d0.loss_dice: 0.8855, decode.d1.loss_cls: 0.4872, decode.d1.loss_mask: 0.5841, decode.d1.loss_dice: 0.8807, decode.d2.loss_cls: 0.4365, decode.d2.loss_mask: 0.5671, decode.d2.loss_dice: 0.8410, decode.d3.loss_cls: 0.4067, decode.d3.loss_mask: 0.5629, decode.d3.loss_dice: 0.8261, decode.d4.loss_cls: 0.3974, decode.d4.loss_mask: 0.5634, decode.d4.loss_dice: 0.8216, decode.d5.loss_cls: 0.3879, decode.d5.loss_mask: 0.5595, decode.d5.loss_dice: 0.8203, decode.d6.loss_cls: 0.3845, decode.d6.loss_mask: 0.5602, decode.d6.loss_dice: 0.8184, decode.d7.loss_cls: 0.3825, decode.d7.loss_mask: 0.5583, decode.d7.loss_dice: 0.8176, decode.d8.loss_cls: 0.3780, decode.d8.loss_mask: 0.5582, decode.d8.loss_dice: 0.8153, loss: 23.5994
2022-11-30 22:47:04,301 - mmseg - INFO - Iter [21650/40000]	lr: 6.103e-08, eta: 22:16:00, time: 4.120, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3821, decode.loss_mask: 0.5630, decode.loss_dice: 0.8246, decode.d0.loss_cls: 6.0184, decode.d0.loss_mask: 0.5444, decode.d0.loss_dice: 0.8927, decode.d1.loss_cls: 0.4973, decode.d1.loss_mask: 0.5853, decode.d1.loss_dice: 0.8837, decode.d2.loss_cls: 0.4356, decode.d2.loss_mask: 0.5714, decode.d2.loss_dice: 0.8479, decode.d3.loss_cls: 0.4047, decode.d3.loss_mask: 0.5661, decode.d3.loss_dice: 0.8353, decode.d4.loss_cls: 0.3953, decode.d4.loss_mask: 0.5651, decode.d4.loss_dice: 0.8342, decode.d5.loss_cls: 0.3894, decode.d5.loss_mask: 0.5639, decode.d5.loss_dice: 0.8290, decode.d6.loss_cls: 0.3818, decode.d6.loss_mask: 0.5619, decode.d6.loss_dice: 0.8244, decode.d7.loss_cls: 0.3786, decode.d7.loss_mask: 0.5624, decode.d7.loss_dice: 0.8247, decode.d8.loss_cls: 0.3771, decode.d8.loss_mask: 0.5624, decode.d8.loss_dice: 0.8260, loss: 23.7285
2022-11-30 22:50:30,210 - mmseg - INFO - Iter [21700/40000]	lr: 6.086e-08, eta: 22:12:11, time: 4.118, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3781, decode.loss_mask: 0.5517, decode.loss_dice: 0.8155, decode.d0.loss_cls: 5.9781, decode.d0.loss_mask: 0.5404, decode.d0.loss_dice: 0.8775, decode.d1.loss_cls: 0.5004, decode.d1.loss_mask: 0.5781, decode.d1.loss_dice: 0.8702, decode.d2.loss_cls: 0.4372, decode.d2.loss_mask: 0.5646, decode.d2.loss_dice: 0.8378, decode.d3.loss_cls: 0.4075, decode.d3.loss_mask: 0.5583, decode.d3.loss_dice: 0.8200, decode.d4.loss_cls: 0.3961, decode.d4.loss_mask: 0.5568, decode.d4.loss_dice: 0.8232, decode.d5.loss_cls: 0.3849, decode.d5.loss_mask: 0.5536, decode.d5.loss_dice: 0.8212, decode.d6.loss_cls: 0.3823, decode.d6.loss_mask: 0.5530, decode.d6.loss_dice: 0.8149, decode.d7.loss_cls: 0.3786, decode.d7.loss_mask: 0.5518, decode.d7.loss_dice: 0.8178, decode.d8.loss_cls: 0.3792, decode.d8.loss_mask: 0.5496, decode.d8.loss_dice: 0.8184, loss: 23.4971
2022-11-30 22:53:55,824 - mmseg - INFO - Iter [21750/40000]	lr: 6.070e-08, eta: 22:08:22, time: 4.112, data_time: 0.022, memory: 51902, decode.loss_cls: 0.3815, decode.loss_mask: 0.5583, decode.loss_dice: 0.8169, decode.d0.loss_cls: 5.9768, decode.d0.loss_mask: 0.5438, decode.d0.loss_dice: 0.8777, decode.d1.loss_cls: 0.4887, decode.d1.loss_mask: 0.5853, decode.d1.loss_dice: 0.8705, decode.d2.loss_cls: 0.4323, decode.d2.loss_mask: 0.5721, decode.d2.loss_dice: 0.8350, decode.d3.loss_cls: 0.4053, decode.d3.loss_mask: 0.5662, decode.d3.loss_dice: 0.8208, decode.d4.loss_cls: 0.3917, decode.d4.loss_mask: 0.5635, decode.d4.loss_dice: 0.8206, decode.d5.loss_cls: 0.3855, decode.d5.loss_mask: 0.5611, decode.d5.loss_dice: 0.8198, decode.d6.loss_cls: 0.3838, decode.d6.loss_mask: 0.5597, decode.d6.loss_dice: 0.8116, decode.d7.loss_cls: 0.3819, decode.d7.loss_mask: 0.5595, decode.d7.loss_dice: 0.8152, decode.d8.loss_cls: 0.3822, decode.d8.loss_mask: 0.5618, decode.d8.loss_dice: 0.8173, loss: 23.5466
2022-11-30 22:57:21,502 - mmseg - INFO - Iter [21800/40000]	lr: 6.053e-08, eta: 22:04:33, time: 4.114, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3966, decode.loss_mask: 0.5576, decode.loss_dice: 0.8102, decode.d0.loss_cls: 5.9751, decode.d0.loss_mask: 0.5370, decode.d0.loss_dice: 0.8815, decode.d1.loss_cls: 0.5119, decode.d1.loss_mask: 0.5778, decode.d1.loss_dice: 0.8703, decode.d2.loss_cls: 0.4510, decode.d2.loss_mask: 0.5647, decode.d2.loss_dice: 0.8360, decode.d3.loss_cls: 0.4218, decode.d3.loss_mask: 0.5619, decode.d3.loss_dice: 0.8225, decode.d4.loss_cls: 0.4094, decode.d4.loss_mask: 0.5585, decode.d4.loss_dice: 0.8199, decode.d5.loss_cls: 0.4019, decode.d5.loss_mask: 0.5571, decode.d5.loss_dice: 0.8151, decode.d6.loss_cls: 0.3983, decode.d6.loss_mask: 0.5552, decode.d6.loss_dice: 0.8089, decode.d7.loss_cls: 0.3958, decode.d7.loss_mask: 0.5556, decode.d7.loss_dice: 0.8100, decode.d8.loss_cls: 0.3940, decode.d8.loss_mask: 0.5568, decode.d8.loss_dice: 0.8129, loss: 23.6254
2022-11-30 23:00:47,707 - mmseg - INFO - Iter [21850/40000]	lr: 6.036e-08, eta: 22:00:45, time: 4.124, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3754, decode.loss_mask: 0.5613, decode.loss_dice: 0.8117, decode.d0.loss_cls: 5.9569, decode.d0.loss_mask: 0.5445, decode.d0.loss_dice: 0.8756, decode.d1.loss_cls: 0.4877, decode.d1.loss_mask: 0.5853, decode.d1.loss_dice: 0.8718, decode.d2.loss_cls: 0.4382, decode.d2.loss_mask: 0.5727, decode.d2.loss_dice: 0.8351, decode.d3.loss_cls: 0.4010, decode.d3.loss_mask: 0.5654, decode.d3.loss_dice: 0.8205, decode.d4.loss_cls: 0.3928, decode.d4.loss_mask: 0.5628, decode.d4.loss_dice: 0.8182, decode.d5.loss_cls: 0.3824, decode.d5.loss_mask: 0.5599, decode.d5.loss_dice: 0.8148, decode.d6.loss_cls: 0.3806, decode.d6.loss_mask: 0.5587, decode.d6.loss_dice: 0.8107, decode.d7.loss_cls: 0.3789, decode.d7.loss_mask: 0.5583, decode.d7.loss_dice: 0.8121, decode.d8.loss_cls: 0.3772, decode.d8.loss_mask: 0.5601, decode.d8.loss_dice: 0.8115, loss: 23.4820
2022-11-30 23:04:13,260 - mmseg - INFO - Iter [21900/40000]	lr: 6.020e-08, eta: 21:56:56, time: 4.111, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3795, decode.loss_mask: 0.5629, decode.loss_dice: 0.8153, decode.d0.loss_cls: 5.9542, decode.d0.loss_mask: 0.5460, decode.d0.loss_dice: 0.8728, decode.d1.loss_cls: 0.4937, decode.d1.loss_mask: 0.5883, decode.d1.loss_dice: 0.8749, decode.d2.loss_cls: 0.4386, decode.d2.loss_mask: 0.5759, decode.d2.loss_dice: 0.8395, decode.d3.loss_cls: 0.4045, decode.d3.loss_mask: 0.5691, decode.d3.loss_dice: 0.8246, decode.d4.loss_cls: 0.3943, decode.d4.loss_mask: 0.5681, decode.d4.loss_dice: 0.8218, decode.d5.loss_cls: 0.3839, decode.d5.loss_mask: 0.5646, decode.d5.loss_dice: 0.8177, decode.d6.loss_cls: 0.3808, decode.d6.loss_mask: 0.5625, decode.d6.loss_dice: 0.8177, decode.d7.loss_cls: 0.3773, decode.d7.loss_mask: 0.5633, decode.d7.loss_dice: 0.8154, decode.d8.loss_cls: 0.3812, decode.d8.loss_mask: 0.5625, decode.d8.loss_dice: 0.8160, loss: 23.5669
2022-11-30 23:07:39,125 - mmseg - INFO - Iter [21950/40000]	lr: 6.003e-08, eta: 21:53:07, time: 4.117, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3852, decode.loss_mask: 0.5584, decode.loss_dice: 0.8170, decode.d0.loss_cls: 5.9874, decode.d0.loss_mask: 0.5477, decode.d0.loss_dice: 0.8914, decode.d1.loss_cls: 0.4949, decode.d1.loss_mask: 0.5846, decode.d1.loss_dice: 0.8724, decode.d2.loss_cls: 0.4421, decode.d2.loss_mask: 0.5700, decode.d2.loss_dice: 0.8387, decode.d3.loss_cls: 0.4083, decode.d3.loss_mask: 0.5644, decode.d3.loss_dice: 0.8268, decode.d4.loss_cls: 0.4006, decode.d4.loss_mask: 0.5620, decode.d4.loss_dice: 0.8246, decode.d5.loss_cls: 0.3898, decode.d5.loss_mask: 0.5630, decode.d5.loss_dice: 0.8196, decode.d6.loss_cls: 0.3869, decode.d6.loss_mask: 0.5612, decode.d6.loss_dice: 0.8158, decode.d7.loss_cls: 0.3806, decode.d7.loss_mask: 0.5590, decode.d7.loss_dice: 0.8168, decode.d8.loss_cls: 0.3837, decode.d8.loss_mask: 0.5578, decode.d8.loss_dice: 0.8145, loss: 23.6250
2022-11-30 23:11:04,902 - mmseg - INFO - Saving checkpoint at 22000 iterations
2022-11-30 23:11:53,920 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 23:11:53,920 - mmseg - INFO - Iter [22000/40000]	lr: 5.987e-08, eta: 21:49:59, time: 5.096, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3755, decode.loss_mask: 0.5434, decode.loss_dice: 0.7967, decode.d0.loss_cls: 5.9643, decode.d0.loss_mask: 0.5249, decode.d0.loss_dice: 0.8582, decode.d1.loss_cls: 0.4933, decode.d1.loss_mask: 0.5656, decode.d1.loss_dice: 0.8553, decode.d2.loss_cls: 0.4382, decode.d2.loss_mask: 0.5562, decode.d2.loss_dice: 0.8176, decode.d3.loss_cls: 0.4037, decode.d3.loss_mask: 0.5485, decode.d3.loss_dice: 0.8062, decode.d4.loss_cls: 0.3915, decode.d4.loss_mask: 0.5468, decode.d4.loss_dice: 0.8055, decode.d5.loss_cls: 0.3825, decode.d5.loss_mask: 0.5425, decode.d5.loss_dice: 0.8018, decode.d6.loss_cls: 0.3807, decode.d6.loss_mask: 0.5425, decode.d6.loss_dice: 0.7983, decode.d7.loss_cls: 0.3758, decode.d7.loss_mask: 0.5425, decode.d7.loss_dice: 0.7980, decode.d8.loss_cls: 0.3752, decode.d8.loss_mask: 0.5425, decode.d8.loss_dice: 0.7977, loss: 23.1712
2022-11-30 23:14:52,066 - mmseg - INFO - per class results:
2022-11-30 23:14:52,071 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 83.27 | 90.23 |
|       building      | 85.16 | 91.27 |
|         sky         | 95.17 | 97.29 |
|        floor        | 85.27 | 90.63 |
|         tree        | 78.99 | 90.15 |
|       ceiling       | 86.89 | 92.14 |
|         road        | 88.04 | 92.34 |
|         bed         | 93.65 | 96.99 |
|      windowpane     |  68.4 | 82.65 |
|        grass        | 67.75 | 78.47 |
|       cabinet       | 61.06 | 69.98 |
|       sidewalk      | 73.99 |  87.0 |
|        person       | 88.33 | 93.85 |
|        earth        | 43.98 |  59.1 |
|         door        | 63.46 | 81.01 |
|        table        |  73.0 | 82.35 |
|       mountain      | 66.66 | 78.32 |
|        plant        | 58.24 | 72.68 |
|       curtain       | 82.59 | 91.66 |
|        chair        | 68.13 | 78.14 |
|         car         | 89.74 | 94.78 |
|        water        | 66.75 | 85.67 |
|       painting      | 82.91 | 91.65 |
|         sofa        | 85.14 | 90.82 |
|        shelf        | 50.59 | 60.93 |
|        house        |  51.8 | 68.37 |
|         sea         | 78.98 |  87.8 |
|        mirror       | 81.17 | 92.38 |
|         rug         | 73.18 | 84.53 |
|        field        | 38.65 | 73.77 |
|       armchair      | 61.89 | 81.64 |
|         seat        | 68.68 | 88.69 |
|        fence        | 56.49 | 71.89 |
|         desk        | 58.41 | 83.76 |
|         rock        | 62.12 | 76.23 |
|       wardrobe      | 55.59 | 81.34 |
|         lamp        | 80.64 | 88.91 |
|       bathtub       | 91.75 | 94.08 |
|       railing       | 45.48 | 63.96 |
|       cushion       | 76.76 | 89.64 |
|         base        | 47.06 | 76.57 |
|         box         | 41.82 | 59.46 |
|        column       | 62.18 | 74.32 |
|      signboard      |  48.8 | 68.55 |
|   chest of drawers  |  44.6 | 74.97 |
|       counter       |  55.6 | 67.56 |
|         sand        | 62.57 | 89.58 |
|         sink        | 81.88 |  86.2 |
|      skyscraper     | 46.39 | 59.81 |
|      fireplace      | 76.94 | 89.99 |
|     refrigerator    |  83.0 | 95.79 |
|      grandstand     | 48.43 | 80.83 |
|         path        | 29.38 | 41.96 |
|        stairs       | 39.15 | 51.71 |
|        runway       | 74.49 | 94.36 |
|         case        | 69.16 | 86.54 |
|      pool table     | 95.87 | 98.52 |
|        pillow       | 72.55 | 81.61 |
|     screen door     | 82.68 |  92.4 |
|       stairway      | 61.02 | 72.21 |
|        river        | 26.04 | 30.88 |
|        bridge       | 73.63 | 87.01 |
|       bookcase      |  38.3 | 52.62 |
|        blind        | 47.64 | 59.27 |
|     coffee table    | 75.34 | 91.69 |
|        toilet       | 93.17 | 96.91 |
|        flower       | 48.69 | 74.92 |
|         book        | 61.78 | 82.42 |
|         hill        |  7.79 | 13.58 |
|        bench        | 70.99 | 84.49 |
|      countertop     | 69.68 | 89.99 |
|        stove        | 85.78 | 89.85 |
|         palm        | 54.96 | 83.99 |
|    kitchen island   | 41.41 | 88.53 |
|       computer      | 81.64 | 88.71 |
|     swivel chair    | 56.57 | 83.83 |
|         boat        | 53.09 | 87.91 |
|         bar         | 72.27 | 77.93 |
|    arcade machine   | 91.27 |  98.8 |
|        hovel        | 53.51 | 80.79 |
|         bus         | 95.04 |  97.7 |
|        towel        | 83.01 | 92.69 |
|        light        | 65.55 |  78.2 |
|        truck        | 52.31 |  73.1 |
|        tower        | 33.06 | 63.34 |
|      chandelier     | 75.83 |  87.7 |
|        awning       | 36.06 | 53.29 |
|     streetlight     | 46.01 | 69.44 |
|        booth        | 54.33 | 79.25 |
| television receiver | 77.36 | 91.95 |
|       airplane      |  88.6 | 96.53 |
|      dirt track     | 10.26 | 16.86 |
|       apparel       | 55.26 |  84.0 |
|         pole        | 37.98 | 55.38 |
|         land        |  1.4  |  1.9  |
|      bannister      |  19.9 | 34.96 |
|      escalator      | 62.85 | 84.72 |
|       ottoman       |  57.9 | 86.33 |
|        bottle       | 52.27 | 81.55 |
|        buffet       | 43.93 | 63.61 |
|        poster       | 35.99 | 48.22 |
|        stage        | 29.52 |  59.8 |
|         van         | 51.78 | 76.36 |
|         ship        | 37.61 | 39.96 |
|       fountain      | 38.74 | 44.13 |
|    conveyer belt    | 81.59 | 97.23 |
|        canopy       | 60.91 | 90.29 |
|        washer       | 91.08 | 93.65 |
|      plaything      | 39.97 | 60.59 |
|    swimming pool    | 48.85 | 74.63 |
|        stool        | 59.92 | 80.88 |
|        barrel       | 68.02 | 76.03 |
|        basket       | 46.68 | 73.47 |
|      waterfall      | 46.52 | 57.89 |
|         tent        | 93.84 | 97.99 |
|         bag         | 34.74 | 46.89 |
|       minibike      | 81.54 | 93.39 |
|        cradle       | 91.41 | 97.37 |
|         oven        |  68.2 | 83.86 |
|         ball        | 39.05 | 42.21 |
|         food        | 68.34 | 81.78 |
|         step        | 29.43 | 43.67 |
|         tank        | 63.72 | 67.33 |
|      trade name     | 36.09 | 49.76 |
|      microwave      | 90.45 | 95.32 |
|         pot         | 62.23 | 74.66 |
|        animal       | 80.48 | 82.79 |
|       bicycle       | 61.68 | 84.25 |
|         lake        |  0.04 |  0.05 |
|      dishwasher     | 80.42 | 90.64 |
|        screen       | 61.94 | 95.48 |
|       blanket       | 43.84 | 62.26 |
|      sculpture      | 73.03 | 90.09 |
|         hood        | 70.84 |  75.5 |
|        sconce       | 67.28 | 81.83 |
|         vase        | 58.04 | 81.84 |
|    traffic light    | 52.01 | 71.96 |
|         tray        | 35.08 | 51.73 |
|        ashcan       | 50.81 | 78.99 |
|         fan         | 73.11 | 86.88 |
|         pier        | 37.61 | 41.39 |
|      crt screen     |  1.34 |  3.49 |
|        plate        | 71.88 | 82.93 |
|       monitor       |  3.81 |  5.27 |
|    bulletin board   | 64.02 | 90.13 |
|        shower       | 17.56 | 30.48 |
|       radiator      | 73.16 | 92.55 |
|        glass        | 28.38 | 31.07 |
|        clock        | 60.35 | 76.38 |
|         flag        | 72.12 | 86.75 |
+---------------------+-------+-------+
2022-11-30 23:14:52,071 - mmseg - INFO - Summary:
2022-11-30 23:14:52,071 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 87.01 | 60.53 | 74.99 |
+-------+-------+-------+
2022-11-30 23:14:52,077 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-11-30 23:14:52,077 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8701, mIoU: 0.6053, mAcc: 0.7499, IoU.wall: 0.8327, IoU.building: 0.8516, IoU.sky: 0.9517, IoU.floor: 0.8527, IoU.tree: 0.7899, IoU.ceiling: 0.8689, IoU.road: 0.8804, IoU.bed : 0.9365, IoU.windowpane: 0.6840, IoU.grass: 0.6775, IoU.cabinet: 0.6106, IoU.sidewalk: 0.7399, IoU.person: 0.8833, IoU.earth: 0.4398, IoU.door: 0.6346, IoU.table: 0.7300, IoU.mountain: 0.6666, IoU.plant: 0.5824, IoU.curtain: 0.8259, IoU.chair: 0.6813, IoU.car: 0.8974, IoU.water: 0.6675, IoU.painting: 0.8291, IoU.sofa: 0.8514, IoU.shelf: 0.5059, IoU.house: 0.5180, IoU.sea: 0.7898, IoU.mirror: 0.8117, IoU.rug: 0.7318, IoU.field: 0.3865, IoU.armchair: 0.6189, IoU.seat: 0.6868, IoU.fence: 0.5649, IoU.desk: 0.5841, IoU.rock: 0.6212, IoU.wardrobe: 0.5559, IoU.lamp: 0.8064, IoU.bathtub: 0.9175, IoU.railing: 0.4548, IoU.cushion: 0.7676, IoU.base: 0.4706, IoU.box: 0.4182, IoU.column: 0.6218, IoU.signboard: 0.4880, IoU.chest of drawers: 0.4460, IoU.counter: 0.5560, IoU.sand: 0.6257, IoU.sink: 0.8188, IoU.skyscraper: 0.4639, IoU.fireplace: 0.7694, IoU.refrigerator: 0.8300, IoU.grandstand: 0.4843, IoU.path: 0.2938, IoU.stairs: 0.3915, IoU.runway: 0.7449, IoU.case: 0.6916, IoU.pool table: 0.9587, IoU.pillow: 0.7255, IoU.screen door: 0.8268, IoU.stairway: 0.6102, IoU.river: 0.2604, IoU.bridge: 0.7363, IoU.bookcase: 0.3830, IoU.blind: 0.4764, IoU.coffee table: 0.7534, IoU.toilet: 0.9317, IoU.flower: 0.4869, IoU.book: 0.6178, IoU.hill: 0.0779, IoU.bench: 0.7099, IoU.countertop: 0.6968, IoU.stove: 0.8578, IoU.palm: 0.5496, IoU.kitchen island: 0.4141, IoU.computer: 0.8164, IoU.swivel chair: 0.5657, IoU.boat: 0.5309, IoU.bar: 0.7227, IoU.arcade machine: 0.9127, IoU.hovel: 0.5351, IoU.bus: 0.9504, IoU.towel: 0.8301, IoU.light: 0.6555, IoU.truck: 0.5231, IoU.tower: 0.3306, IoU.chandelier: 0.7583, IoU.awning: 0.3606, IoU.streetlight: 0.4601, IoU.booth: 0.5433, IoU.television receiver: 0.7736, IoU.airplane: 0.8860, IoU.dirt track: 0.1026, IoU.apparel: 0.5526, IoU.pole: 0.3798, IoU.land: 0.0140, IoU.bannister: 0.1990, IoU.escalator: 0.6285, IoU.ottoman: 0.5790, IoU.bottle: 0.5227, IoU.buffet: 0.4393, IoU.poster: 0.3599, IoU.stage: 0.2952, IoU.van: 0.5178, IoU.ship: 0.3761, IoU.fountain: 0.3874, IoU.conveyer belt: 0.8159, IoU.canopy: 0.6091, IoU.washer: 0.9108, IoU.plaything: 0.3997, IoU.swimming pool: 0.4885, IoU.stool: 0.5992, IoU.barrel: 0.6802, IoU.basket: 0.4668, IoU.waterfall: 0.4652, IoU.tent: 0.9384, IoU.bag: 0.3474, IoU.minibike: 0.8154, IoU.cradle: 0.9141, IoU.oven: 0.6820, IoU.ball: 0.3905, IoU.food: 0.6834, IoU.step: 0.2943, IoU.tank: 0.6372, IoU.trade name: 0.3609, IoU.microwave: 0.9045, IoU.pot: 0.6223, IoU.animal: 0.8048, IoU.bicycle: 0.6168, IoU.lake: 0.0004, IoU.dishwasher: 0.8042, IoU.screen: 0.6194, IoU.blanket: 0.4384, IoU.sculpture: 0.7303, IoU.hood: 0.7084, IoU.sconce: 0.6728, IoU.vase: 0.5804, IoU.traffic light: 0.5201, IoU.tray: 0.3508, IoU.ashcan: 0.5081, IoU.fan: 0.7311, IoU.pier: 0.3761, IoU.crt screen: 0.0134, IoU.plate: 0.7188, IoU.monitor: 0.0381, IoU.bulletin board: 0.6402, IoU.shower: 0.1756, IoU.radiator: 0.7316, IoU.glass: 0.2838, IoU.clock: 0.6035, IoU.flag: 0.7212, Acc.wall: 0.9023, Acc.building: 0.9127, Acc.sky: 0.9729, Acc.floor: 0.9063, Acc.tree: 0.9015, Acc.ceiling: 0.9214, Acc.road: 0.9234, Acc.bed : 0.9699, Acc.windowpane: 0.8265, Acc.grass: 0.7847, Acc.cabinet: 0.6998, Acc.sidewalk: 0.8700, Acc.person: 0.9385, Acc.earth: 0.5910, Acc.door: 0.8101, Acc.table: 0.8235, Acc.mountain: 0.7832, Acc.plant: 0.7268, Acc.curtain: 0.9166, Acc.chair: 0.7814, Acc.car: 0.9478, Acc.water: 0.8567, Acc.painting: 0.9165, Acc.sofa: 0.9082, Acc.shelf: 0.6093, Acc.house: 0.6837, Acc.sea: 0.8780, Acc.mirror: 0.9238, Acc.rug: 0.8453, Acc.field: 0.7377, Acc.armchair: 0.8164, Acc.seat: 0.8869, Acc.fence: 0.7189, Acc.desk: 0.8376, Acc.rock: 0.7623, Acc.wardrobe: 0.8134, Acc.lamp: 0.8891, Acc.bathtub: 0.9408, Acc.railing: 0.6396, Acc.cushion: 0.8964, Acc.base: 0.7657, Acc.box: 0.5946, Acc.column: 0.7432, Acc.signboard: 0.6855, Acc.chest of drawers: 0.7497, Acc.counter: 0.6756, Acc.sand: 0.8958, Acc.sink: 0.8620, Acc.skyscraper: 0.5981, Acc.fireplace: 0.8999, Acc.refrigerator: 0.9579, Acc.grandstand: 0.8083, Acc.path: 0.4196, Acc.stairs: 0.5171, Acc.runway: 0.9436, Acc.case: 0.8654, Acc.pool table: 0.9852, Acc.pillow: 0.8161, Acc.screen door: 0.9240, Acc.stairway: 0.7221, Acc.river: 0.3088, Acc.bridge: 0.8701, Acc.bookcase: 0.5262, Acc.blind: 0.5927, Acc.coffee table: 0.9169, Acc.toilet: 0.9691, Acc.flower: 0.7492, Acc.book: 0.8242, Acc.hill: 0.1358, Acc.bench: 0.8449, Acc.countertop: 0.8999, Acc.stove: 0.8985, Acc.palm: 0.8399, Acc.kitchen island: 0.8853, Acc.computer: 0.8871, Acc.swivel chair: 0.8383, Acc.boat: 0.8791, Acc.bar: 0.7793, Acc.arcade machine: 0.9880, Acc.hovel: 0.8079, Acc.bus: 0.9770, Acc.towel: 0.9269, Acc.light: 0.7820, Acc.truck: 0.7310, Acc.tower: 0.6334, Acc.chandelier: 0.8770, Acc.awning: 0.5329, Acc.streetlight: 0.6944, Acc.booth: 0.7925, Acc.television receiver: 0.9195, Acc.airplane: 0.9653, Acc.dirt track: 0.1686, Acc.apparel: 0.8400, Acc.pole: 0.5538, Acc.land: 0.0190, Acc.bannister: 0.3496, Acc.escalator: 0.8472, Acc.ottoman: 0.8633, Acc.bottle: 0.8155, Acc.buffet: 0.6361, Acc.poster: 0.4822, Acc.stage: 0.5980, Acc.van: 0.7636, Acc.ship: 0.3996, Acc.fountain: 0.4413, Acc.conveyer belt: 0.9723, Acc.canopy: 0.9029, Acc.washer: 0.9365, Acc.plaything: 0.6059, Acc.swimming pool: 0.7463, Acc.stool: 0.8088, Acc.barrel: 0.7603, Acc.basket: 0.7347, Acc.waterfall: 0.5789, Acc.tent: 0.9799, Acc.bag: 0.4689, Acc.minibike: 0.9339, Acc.cradle: 0.9737, Acc.oven: 0.8386, Acc.ball: 0.4221, Acc.food: 0.8178, Acc.step: 0.4367, Acc.tank: 0.6733, Acc.trade name: 0.4976, Acc.microwave: 0.9532, Acc.pot: 0.7466, Acc.animal: 0.8279, Acc.bicycle: 0.8425, Acc.lake: 0.0005, Acc.dishwasher: 0.9064, Acc.screen: 0.9548, Acc.blanket: 0.6226, Acc.sculpture: 0.9009, Acc.hood: 0.7550, Acc.sconce: 0.8183, Acc.vase: 0.8184, Acc.traffic light: 0.7196, Acc.tray: 0.5173, Acc.ashcan: 0.7899, Acc.fan: 0.8688, Acc.pier: 0.4139, Acc.crt screen: 0.0349, Acc.plate: 0.8293, Acc.monitor: 0.0527, Acc.bulletin board: 0.9013, Acc.shower: 0.3048, Acc.radiator: 0.9255, Acc.glass: 0.3107, Acc.clock: 0.7638, Acc.flag: 0.8675
2022-11-30 23:18:18,479 - mmseg - INFO - Iter [22050/40000]	lr: 5.970e-08, eta: 21:48:36, time: 7.691, data_time: 3.583, memory: 51902, decode.loss_cls: 0.3883, decode.loss_mask: 0.5605, decode.loss_dice: 0.8307, decode.d0.loss_cls: 5.9467, decode.d0.loss_mask: 0.5409, decode.d0.loss_dice: 0.8956, decode.d1.loss_cls: 0.5018, decode.d1.loss_mask: 0.5853, decode.d1.loss_dice: 0.8914, decode.d2.loss_cls: 0.4459, decode.d2.loss_mask: 0.5712, decode.d2.loss_dice: 0.8540, decode.d3.loss_cls: 0.4145, decode.d3.loss_mask: 0.5652, decode.d3.loss_dice: 0.8395, decode.d4.loss_cls: 0.4070, decode.d4.loss_mask: 0.5651, decode.d4.loss_dice: 0.8385, decode.d5.loss_cls: 0.3960, decode.d5.loss_mask: 0.5612, decode.d5.loss_dice: 0.8330, decode.d6.loss_cls: 0.3940, decode.d6.loss_mask: 0.5588, decode.d6.loss_dice: 0.8254, decode.d7.loss_cls: 0.3907, decode.d7.loss_mask: 0.5576, decode.d7.loss_dice: 0.8305, decode.d8.loss_cls: 0.3908, decode.d8.loss_mask: 0.5600, decode.d8.loss_dice: 0.8302, loss: 23.7703
2022-11-30 23:21:44,377 - mmseg - INFO - Iter [22100/40000]	lr: 5.953e-08, eta: 21:44:47, time: 4.118, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3748, decode.loss_mask: 0.5561, decode.loss_dice: 0.8184, decode.d0.loss_cls: 5.9598, decode.d0.loss_mask: 0.5444, decode.d0.loss_dice: 0.8906, decode.d1.loss_cls: 0.4939, decode.d1.loss_mask: 0.5800, decode.d1.loss_dice: 0.8762, decode.d2.loss_cls: 0.4321, decode.d2.loss_mask: 0.5683, decode.d2.loss_dice: 0.8368, decode.d3.loss_cls: 0.3995, decode.d3.loss_mask: 0.5634, decode.d3.loss_dice: 0.8302, decode.d4.loss_cls: 0.3944, decode.d4.loss_mask: 0.5608, decode.d4.loss_dice: 0.8266, decode.d5.loss_cls: 0.3886, decode.d5.loss_mask: 0.5575, decode.d5.loss_dice: 0.8241, decode.d6.loss_cls: 0.3789, decode.d6.loss_mask: 0.5578, decode.d6.loss_dice: 0.8214, decode.d7.loss_cls: 0.3776, decode.d7.loss_mask: 0.5562, decode.d7.loss_dice: 0.8243, decode.d8.loss_cls: 0.3762, decode.d8.loss_mask: 0.5575, decode.d8.loss_dice: 0.8196, loss: 23.5459
2022-11-30 23:25:12,049 - mmseg - INFO - Iter [22150/40000]	lr: 5.937e-08, eta: 21:40:59, time: 4.153, data_time: 0.065, memory: 51902, decode.loss_cls: 0.3802, decode.loss_mask: 0.5523, decode.loss_dice: 0.7931, decode.d0.loss_cls: 5.9381, decode.d0.loss_mask: 0.5336, decode.d0.loss_dice: 0.8588, decode.d1.loss_cls: 0.4948, decode.d1.loss_mask: 0.5724, decode.d1.loss_dice: 0.8559, decode.d2.loss_cls: 0.4344, decode.d2.loss_mask: 0.5616, decode.d2.loss_dice: 0.8213, decode.d3.loss_cls: 0.4062, decode.d3.loss_mask: 0.5556, decode.d3.loss_dice: 0.8046, decode.d4.loss_cls: 0.3952, decode.d4.loss_mask: 0.5536, decode.d4.loss_dice: 0.8008, decode.d5.loss_cls: 0.3863, decode.d5.loss_mask: 0.5528, decode.d5.loss_dice: 0.7960, decode.d6.loss_cls: 0.3861, decode.d6.loss_mask: 0.5515, decode.d6.loss_dice: 0.7937, decode.d7.loss_cls: 0.3787, decode.d7.loss_mask: 0.5525, decode.d7.loss_dice: 0.7962, decode.d8.loss_cls: 0.3817, decode.d8.loss_mask: 0.5497, decode.d8.loss_dice: 0.7931, loss: 23.2309
2022-11-30 23:28:38,104 - mmseg - INFO - Iter [22200/40000]	lr: 5.920e-08, eta: 21:37:11, time: 4.120, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3769, decode.loss_mask: 0.5402, decode.loss_dice: 0.8091, decode.d0.loss_cls: 5.9598, decode.d0.loss_mask: 0.5258, decode.d0.loss_dice: 0.8823, decode.d1.loss_cls: 0.5002, decode.d1.loss_mask: 0.5662, decode.d1.loss_dice: 0.8661, decode.d2.loss_cls: 0.4357, decode.d2.loss_mask: 0.5522, decode.d2.loss_dice: 0.8303, decode.d3.loss_cls: 0.4006, decode.d3.loss_mask: 0.5468, decode.d3.loss_dice: 0.8170, decode.d4.loss_cls: 0.3941, decode.d4.loss_mask: 0.5450, decode.d4.loss_dice: 0.8125, decode.d5.loss_cls: 0.3838, decode.d5.loss_mask: 0.5410, decode.d5.loss_dice: 0.8127, decode.d6.loss_cls: 0.3826, decode.d6.loss_mask: 0.5396, decode.d6.loss_dice: 0.8093, decode.d7.loss_cls: 0.3770, decode.d7.loss_mask: 0.5401, decode.d7.loss_dice: 0.8124, decode.d8.loss_cls: 0.3764, decode.d8.loss_mask: 0.5391, decode.d8.loss_dice: 0.8103, loss: 23.2850
2022-11-30 23:32:03,864 - mmseg - INFO - Iter [22250/40000]	lr: 5.903e-08, eta: 21:33:22, time: 4.116, data_time: 0.022, memory: 51902, decode.loss_cls: 0.3823, decode.loss_mask: 0.5583, decode.loss_dice: 0.8152, decode.d0.loss_cls: 5.9243, decode.d0.loss_mask: 0.5473, decode.d0.loss_dice: 0.8816, decode.d1.loss_cls: 0.5054, decode.d1.loss_mask: 0.5862, decode.d1.loss_dice: 0.8715, decode.d2.loss_cls: 0.4450, decode.d2.loss_mask: 0.5722, decode.d2.loss_dice: 0.8409, decode.d3.loss_cls: 0.4120, decode.d3.loss_mask: 0.5680, decode.d3.loss_dice: 0.8243, decode.d4.loss_cls: 0.4030, decode.d4.loss_mask: 0.5648, decode.d4.loss_dice: 0.8207, decode.d5.loss_cls: 0.3945, decode.d5.loss_mask: 0.5606, decode.d5.loss_dice: 0.8184, decode.d6.loss_cls: 0.3882, decode.d6.loss_mask: 0.5597, decode.d6.loss_dice: 0.8137, decode.d7.loss_cls: 0.3853, decode.d7.loss_mask: 0.5586, decode.d7.loss_dice: 0.8162, decode.d8.loss_cls: 0.3839, decode.d8.loss_mask: 0.5587, decode.d8.loss_dice: 0.8142, loss: 23.5750
2022-11-30 23:35:29,610 - mmseg - INFO - Iter [22300/40000]	lr: 5.887e-08, eta: 21:29:33, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3904, decode.loss_mask: 0.5557, decode.loss_dice: 0.8260, decode.d0.loss_cls: 5.9323, decode.d0.loss_mask: 0.5422, decode.d0.loss_dice: 0.8950, decode.d1.loss_cls: 0.5080, decode.d1.loss_mask: 0.5804, decode.d1.loss_dice: 0.8826, decode.d2.loss_cls: 0.4529, decode.d2.loss_mask: 0.5674, decode.d2.loss_dice: 0.8480, decode.d3.loss_cls: 0.4170, decode.d3.loss_mask: 0.5602, decode.d3.loss_dice: 0.8332, decode.d4.loss_cls: 0.4083, decode.d4.loss_mask: 0.5572, decode.d4.loss_dice: 0.8308, decode.d5.loss_cls: 0.3997, decode.d5.loss_mask: 0.5572, decode.d5.loss_dice: 0.8311, decode.d6.loss_cls: 0.3971, decode.d6.loss_mask: 0.5587, decode.d6.loss_dice: 0.8259, decode.d7.loss_cls: 0.3927, decode.d7.loss_mask: 0.5583, decode.d7.loss_dice: 0.8291, decode.d8.loss_cls: 0.3908, decode.d8.loss_mask: 0.5566, decode.d8.loss_dice: 0.8269, loss: 23.7117
2022-11-30 23:38:54,988 - mmseg - INFO - Iter [22350/40000]	lr: 5.870e-08, eta: 21:25:44, time: 4.107, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3703, decode.loss_mask: 0.5563, decode.loss_dice: 0.8120, decode.d0.loss_cls: 5.9026, decode.d0.loss_mask: 0.5452, decode.d0.loss_dice: 0.8825, decode.d1.loss_cls: 0.4901, decode.d1.loss_mask: 0.5762, decode.d1.loss_dice: 0.8675, decode.d2.loss_cls: 0.4277, decode.d2.loss_mask: 0.5609, decode.d2.loss_dice: 0.8361, decode.d3.loss_cls: 0.3961, decode.d3.loss_mask: 0.5579, decode.d3.loss_dice: 0.8206, decode.d4.loss_cls: 0.3890, decode.d4.loss_mask: 0.5537, decode.d4.loss_dice: 0.8199, decode.d5.loss_cls: 0.3766, decode.d5.loss_mask: 0.5548, decode.d5.loss_dice: 0.8188, decode.d6.loss_cls: 0.3732, decode.d6.loss_mask: 0.5561, decode.d6.loss_dice: 0.8167, decode.d7.loss_cls: 0.3719, decode.d7.loss_mask: 0.5550, decode.d7.loss_dice: 0.8156, decode.d8.loss_cls: 0.3705, decode.d8.loss_mask: 0.5547, decode.d8.loss_dice: 0.8171, loss: 23.3460
2022-11-30 23:42:21,143 - mmseg - INFO - Iter [22400/40000]	lr: 5.854e-08, eta: 21:21:56, time: 4.123, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3800, decode.loss_mask: 0.5447, decode.loss_dice: 0.8270, decode.d0.loss_cls: 5.9246, decode.d0.loss_mask: 0.5286, decode.d0.loss_dice: 0.8880, decode.d1.loss_cls: 0.5001, decode.d1.loss_mask: 0.5716, decode.d1.loss_dice: 0.8812, decode.d2.loss_cls: 0.4384, decode.d2.loss_mask: 0.5593, decode.d2.loss_dice: 0.8477, decode.d3.loss_cls: 0.4071, decode.d3.loss_mask: 0.5492, decode.d3.loss_dice: 0.8317, decode.d4.loss_cls: 0.3994, decode.d4.loss_mask: 0.5478, decode.d4.loss_dice: 0.8286, decode.d5.loss_cls: 0.3878, decode.d5.loss_mask: 0.5450, decode.d5.loss_dice: 0.8279, decode.d6.loss_cls: 0.3898, decode.d6.loss_mask: 0.5452, decode.d6.loss_dice: 0.8263, decode.d7.loss_cls: 0.3812, decode.d7.loss_mask: 0.5477, decode.d7.loss_dice: 0.8257, decode.d8.loss_cls: 0.3813, decode.d8.loss_mask: 0.5457, decode.d8.loss_dice: 0.8253, loss: 23.4841
2022-11-30 23:45:47,121 - mmseg - INFO - Iter [22450/40000]	lr: 5.837e-08, eta: 21:18:07, time: 4.120, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3764, decode.loss_mask: 0.5591, decode.loss_dice: 0.8102, decode.d0.loss_cls: 5.8980, decode.d0.loss_mask: 0.5469, decode.d0.loss_dice: 0.8716, decode.d1.loss_cls: 0.4877, decode.d1.loss_mask: 0.5906, decode.d1.loss_dice: 0.8680, decode.d2.loss_cls: 0.4321, decode.d2.loss_mask: 0.5743, decode.d2.loss_dice: 0.8336, decode.d3.loss_cls: 0.3989, decode.d3.loss_mask: 0.5653, decode.d3.loss_dice: 0.8244, decode.d4.loss_cls: 0.3885, decode.d4.loss_mask: 0.5642, decode.d4.loss_dice: 0.8226, decode.d5.loss_cls: 0.3803, decode.d5.loss_mask: 0.5598, decode.d5.loss_dice: 0.8179, decode.d6.loss_cls: 0.3774, decode.d6.loss_mask: 0.5591, decode.d6.loss_dice: 0.8094, decode.d7.loss_cls: 0.3743, decode.d7.loss_mask: 0.5594, decode.d7.loss_dice: 0.8126, decode.d8.loss_cls: 0.3760, decode.d8.loss_mask: 0.5592, decode.d8.loss_dice: 0.8147, loss: 23.4124
2022-11-30 23:49:12,520 - mmseg - INFO - Iter [22500/40000]	lr: 5.820e-08, eta: 21:14:19, time: 4.108, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3820, decode.loss_mask: 0.5617, decode.loss_dice: 0.8162, decode.d0.loss_cls: 5.8993, decode.d0.loss_mask: 0.5453, decode.d0.loss_dice: 0.8852, decode.d1.loss_cls: 0.5071, decode.d1.loss_mask: 0.5824, decode.d1.loss_dice: 0.8815, decode.d2.loss_cls: 0.4361, decode.d2.loss_mask: 0.5731, decode.d2.loss_dice: 0.8420, decode.d3.loss_cls: 0.4048, decode.d3.loss_mask: 0.5670, decode.d3.loss_dice: 0.8266, decode.d4.loss_cls: 0.3976, decode.d4.loss_mask: 0.5637, decode.d4.loss_dice: 0.8257, decode.d5.loss_cls: 0.3850, decode.d5.loss_mask: 0.5640, decode.d5.loss_dice: 0.8215, decode.d6.loss_cls: 0.3827, decode.d6.loss_mask: 0.5638, decode.d6.loss_dice: 0.8180, decode.d7.loss_cls: 0.3816, decode.d7.loss_mask: 0.5641, decode.d7.loss_dice: 0.8187, decode.d8.loss_cls: 0.3792, decode.d8.loss_mask: 0.5625, decode.d8.loss_dice: 0.8176, loss: 23.5560
2022-11-30 23:52:38,324 - mmseg - INFO - Iter [22550/40000]	lr: 5.804e-08, eta: 21:10:30, time: 4.116, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3779, decode.loss_mask: 0.5369, decode.loss_dice: 0.8151, decode.d0.loss_cls: 5.9023, decode.d0.loss_mask: 0.5267, decode.d0.loss_dice: 0.8866, decode.d1.loss_cls: 0.4885, decode.d1.loss_mask: 0.5616, decode.d1.loss_dice: 0.8765, decode.d2.loss_cls: 0.4363, decode.d2.loss_mask: 0.5484, decode.d2.loss_dice: 0.8359, decode.d3.loss_cls: 0.4017, decode.d3.loss_mask: 0.5438, decode.d3.loss_dice: 0.8276, decode.d4.loss_cls: 0.3955, decode.d4.loss_mask: 0.5410, decode.d4.loss_dice: 0.8250, decode.d5.loss_cls: 0.3866, decode.d5.loss_mask: 0.5380, decode.d5.loss_dice: 0.8188, decode.d6.loss_cls: 0.3824, decode.d6.loss_mask: 0.5372, decode.d6.loss_dice: 0.8157, decode.d7.loss_cls: 0.3826, decode.d7.loss_mask: 0.5354, decode.d7.loss_dice: 0.8166, decode.d8.loss_cls: 0.3794, decode.d8.loss_mask: 0.5380, decode.d8.loss_dice: 0.8154, loss: 23.2736
2022-11-30 23:56:04,579 - mmseg - INFO - Iter [22600/40000]	lr: 5.787e-08, eta: 21:06:43, time: 4.125, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3954, decode.loss_mask: 0.5564, decode.loss_dice: 0.8178, decode.d0.loss_cls: 5.8906, decode.d0.loss_mask: 0.5418, decode.d0.loss_dice: 0.8872, decode.d1.loss_cls: 0.4968, decode.d1.loss_mask: 0.5867, decode.d1.loss_dice: 0.8773, decode.d2.loss_cls: 0.4447, decode.d2.loss_mask: 0.5747, decode.d2.loss_dice: 0.8410, decode.d3.loss_cls: 0.4178, decode.d3.loss_mask: 0.5645, decode.d3.loss_dice: 0.8277, decode.d4.loss_cls: 0.4079, decode.d4.loss_mask: 0.5604, decode.d4.loss_dice: 0.8252, decode.d5.loss_cls: 0.3942, decode.d5.loss_mask: 0.5620, decode.d5.loss_dice: 0.8247, decode.d6.loss_cls: 0.3936, decode.d6.loss_mask: 0.5580, decode.d6.loss_dice: 0.8215, decode.d7.loss_cls: 0.3948, decode.d7.loss_mask: 0.5571, decode.d7.loss_dice: 0.8177, decode.d8.loss_cls: 0.3955, decode.d8.loss_mask: 0.5572, decode.d8.loss_dice: 0.8160, loss: 23.6060
2022-11-30 23:59:29,962 - mmseg - INFO - Iter [22650/40000]	lr: 5.770e-08, eta: 21:02:54, time: 4.108, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3837, decode.loss_mask: 0.5443, decode.loss_dice: 0.8008, decode.d0.loss_cls: 5.8732, decode.d0.loss_mask: 0.5286, decode.d0.loss_dice: 0.8561, decode.d1.loss_cls: 0.4961, decode.d1.loss_mask: 0.5709, decode.d1.loss_dice: 0.8599, decode.d2.loss_cls: 0.4398, decode.d2.loss_mask: 0.5564, decode.d2.loss_dice: 0.8240, decode.d3.loss_cls: 0.4054, decode.d3.loss_mask: 0.5525, decode.d3.loss_dice: 0.8100, decode.d4.loss_cls: 0.3975, decode.d4.loss_mask: 0.5502, decode.d4.loss_dice: 0.8077, decode.d5.loss_cls: 0.3915, decode.d5.loss_mask: 0.5463, decode.d5.loss_dice: 0.8071, decode.d6.loss_cls: 0.3867, decode.d6.loss_mask: 0.5477, decode.d6.loss_dice: 0.8024, decode.d7.loss_cls: 0.3860, decode.d7.loss_mask: 0.5469, decode.d7.loss_dice: 0.7987, decode.d8.loss_cls: 0.3832, decode.d8.loss_mask: 0.5454, decode.d8.loss_dice: 0.8015, loss: 23.2006
2022-12-01 00:02:55,613 - mmseg - INFO - Iter [22700/40000]	lr: 5.754e-08, eta: 20:59:06, time: 4.113, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3579, decode.loss_mask: 0.5663, decode.loss_dice: 0.8235, decode.d0.loss_cls: 5.8658, decode.d0.loss_mask: 0.5534, decode.d0.loss_dice: 0.8934, decode.d1.loss_cls: 0.4797, decode.d1.loss_mask: 0.5898, decode.d1.loss_dice: 0.8831, decode.d2.loss_cls: 0.4178, decode.d2.loss_mask: 0.5779, decode.d2.loss_dice: 0.8467, decode.d3.loss_cls: 0.3844, decode.d3.loss_mask: 0.5738, decode.d3.loss_dice: 0.8354, decode.d4.loss_cls: 0.3785, decode.d4.loss_mask: 0.5707, decode.d4.loss_dice: 0.8332, decode.d5.loss_cls: 0.3665, decode.d5.loss_mask: 0.5667, decode.d5.loss_dice: 0.8296, decode.d6.loss_cls: 0.3658, decode.d6.loss_mask: 0.5644, decode.d6.loss_dice: 0.8279, decode.d7.loss_cls: 0.3620, decode.d7.loss_mask: 0.5637, decode.d7.loss_dice: 0.8239, decode.d8.loss_cls: 0.3587, decode.d8.loss_mask: 0.5642, decode.d8.loss_dice: 0.8262, loss: 23.4510
2022-12-01 00:06:21,415 - mmseg - INFO - Iter [22750/40000]	lr: 5.737e-08, eta: 20:55:18, time: 4.116, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3730, decode.loss_mask: 0.5545, decode.loss_dice: 0.8186, decode.d0.loss_cls: 5.8800, decode.d0.loss_mask: 0.5318, decode.d0.loss_dice: 0.8801, decode.d1.loss_cls: 0.4954, decode.d1.loss_mask: 0.5751, decode.d1.loss_dice: 0.8759, decode.d2.loss_cls: 0.4321, decode.d2.loss_mask: 0.5611, decode.d2.loss_dice: 0.8427, decode.d3.loss_cls: 0.4003, decode.d3.loss_mask: 0.5555, decode.d3.loss_dice: 0.8274, decode.d4.loss_cls: 0.3911, decode.d4.loss_mask: 0.5568, decode.d4.loss_dice: 0.8208, decode.d5.loss_cls: 0.3814, decode.d5.loss_mask: 0.5547, decode.d5.loss_dice: 0.8228, decode.d6.loss_cls: 0.3793, decode.d6.loss_mask: 0.5535, decode.d6.loss_dice: 0.8158, decode.d7.loss_cls: 0.3723, decode.d7.loss_mask: 0.5522, decode.d7.loss_dice: 0.8184, decode.d8.loss_cls: 0.3724, decode.d8.loss_mask: 0.5546, decode.d8.loss_dice: 0.8205, loss: 23.3700
2022-12-01 00:09:49,675 - mmseg - INFO - Iter [22800/40000]	lr: 5.721e-08, eta: 20:51:32, time: 4.165, data_time: 0.066, memory: 51902, decode.loss_cls: 0.3830, decode.loss_mask: 0.5612, decode.loss_dice: 0.8212, decode.d0.loss_cls: 5.8757, decode.d0.loss_mask: 0.5433, decode.d0.loss_dice: 0.8888, decode.d1.loss_cls: 0.4995, decode.d1.loss_mask: 0.5893, decode.d1.loss_dice: 0.8816, decode.d2.loss_cls: 0.4429, decode.d2.loss_mask: 0.5749, decode.d2.loss_dice: 0.8494, decode.d3.loss_cls: 0.4076, decode.d3.loss_mask: 0.5673, decode.d3.loss_dice: 0.8332, decode.d4.loss_cls: 0.3975, decode.d4.loss_mask: 0.5662, decode.d4.loss_dice: 0.8300, decode.d5.loss_cls: 0.3935, decode.d5.loss_mask: 0.5611, decode.d5.loss_dice: 0.8235, decode.d6.loss_cls: 0.3883, decode.d6.loss_mask: 0.5580, decode.d6.loss_dice: 0.8217, decode.d7.loss_cls: 0.3832, decode.d7.loss_mask: 0.5593, decode.d7.loss_dice: 0.8212, decode.d8.loss_cls: 0.3871, decode.d8.loss_mask: 0.5607, decode.d8.loss_dice: 0.8220, loss: 23.5924
2022-12-01 00:13:15,227 - mmseg - INFO - Iter [22850/40000]	lr: 5.704e-08, eta: 20:47:45, time: 4.111, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3582, decode.loss_mask: 0.5697, decode.loss_dice: 0.8106, decode.d0.loss_cls: 5.8332, decode.d0.loss_mask: 0.5488, decode.d0.loss_dice: 0.8776, decode.d1.loss_cls: 0.4824, decode.d1.loss_mask: 0.5926, decode.d1.loss_dice: 0.8728, decode.d2.loss_cls: 0.4154, decode.d2.loss_mask: 0.5801, decode.d2.loss_dice: 0.8408, decode.d3.loss_cls: 0.3797, decode.d3.loss_mask: 0.5738, decode.d3.loss_dice: 0.8256, decode.d4.loss_cls: 0.3762, decode.d4.loss_mask: 0.5703, decode.d4.loss_dice: 0.8193, decode.d5.loss_cls: 0.3652, decode.d5.loss_mask: 0.5674, decode.d5.loss_dice: 0.8185, decode.d6.loss_cls: 0.3600, decode.d6.loss_mask: 0.5677, decode.d6.loss_dice: 0.8180, decode.d7.loss_cls: 0.3595, decode.d7.loss_mask: 0.5680, decode.d7.loss_dice: 0.8139, decode.d8.loss_cls: 0.3576, decode.d8.loss_mask: 0.5679, decode.d8.loss_dice: 0.8159, loss: 23.3067
2022-12-01 00:16:40,875 - mmseg - INFO - Iter [22900/40000]	lr: 5.687e-08, eta: 20:43:57, time: 4.113, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3653, decode.loss_mask: 0.5566, decode.loss_dice: 0.8112, decode.d0.loss_cls: 5.8261, decode.d0.loss_mask: 0.5391, decode.d0.loss_dice: 0.8724, decode.d1.loss_cls: 0.4832, decode.d1.loss_mask: 0.5739, decode.d1.loss_dice: 0.8700, decode.d2.loss_cls: 0.4248, decode.d2.loss_mask: 0.5625, decode.d2.loss_dice: 0.8335, decode.d3.loss_cls: 0.3930, decode.d3.loss_mask: 0.5581, decode.d3.loss_dice: 0.8186, decode.d4.loss_cls: 0.3812, decode.d4.loss_mask: 0.5553, decode.d4.loss_dice: 0.8175, decode.d5.loss_cls: 0.3763, decode.d5.loss_mask: 0.5542, decode.d5.loss_dice: 0.8115, decode.d6.loss_cls: 0.3709, decode.d6.loss_mask: 0.5534, decode.d6.loss_dice: 0.8097, decode.d7.loss_cls: 0.3715, decode.d7.loss_mask: 0.5540, decode.d7.loss_dice: 0.8108, decode.d8.loss_cls: 0.3670, decode.d8.loss_mask: 0.5520, decode.d8.loss_dice: 0.8124, loss: 23.1858
2022-12-01 00:20:06,519 - mmseg - INFO - Iter [22950/40000]	lr: 5.671e-08, eta: 20:40:09, time: 4.113, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3764, decode.loss_mask: 0.5562, decode.loss_dice: 0.8136, decode.d0.loss_cls: 5.8439, decode.d0.loss_mask: 0.5395, decode.d0.loss_dice: 0.8785, decode.d1.loss_cls: 0.4906, decode.d1.loss_mask: 0.5801, decode.d1.loss_dice: 0.8679, decode.d2.loss_cls: 0.4347, decode.d2.loss_mask: 0.5694, decode.d2.loss_dice: 0.8331, decode.d3.loss_cls: 0.4005, decode.d3.loss_mask: 0.5643, decode.d3.loss_dice: 0.8158, decode.d4.loss_cls: 0.3925, decode.d4.loss_mask: 0.5598, decode.d4.loss_dice: 0.8205, decode.d5.loss_cls: 0.3818, decode.d5.loss_mask: 0.5595, decode.d5.loss_dice: 0.8133, decode.d6.loss_cls: 0.3774, decode.d6.loss_mask: 0.5577, decode.d6.loss_dice: 0.8158, decode.d7.loss_cls: 0.3729, decode.d7.loss_mask: 0.5554, decode.d7.loss_dice: 0.8147, decode.d8.loss_cls: 0.3740, decode.d8.loss_mask: 0.5564, decode.d8.loss_dice: 0.8141, loss: 23.3302
2022-12-01 00:23:32,334 - mmseg - INFO - Saving checkpoint at 23000 iterations
2022-12-01 00:24:18,927 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 00:24:18,927 - mmseg - INFO - Iter [23000/40000]	lr: 5.654e-08, eta: 20:36:56, time: 5.048, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3740, decode.loss_mask: 0.5517, decode.loss_dice: 0.8195, decode.d0.loss_cls: 5.8424, decode.d0.loss_mask: 0.5379, decode.d0.loss_dice: 0.8789, decode.d1.loss_cls: 0.4834, decode.d1.loss_mask: 0.5765, decode.d1.loss_dice: 0.8775, decode.d2.loss_cls: 0.4312, decode.d2.loss_mask: 0.5647, decode.d2.loss_dice: 0.8431, decode.d3.loss_cls: 0.3945, decode.d3.loss_mask: 0.5583, decode.d3.loss_dice: 0.8309, decode.d4.loss_cls: 0.3883, decode.d4.loss_mask: 0.5548, decode.d4.loss_dice: 0.8257, decode.d5.loss_cls: 0.3803, decode.d5.loss_mask: 0.5532, decode.d5.loss_dice: 0.8213, decode.d6.loss_cls: 0.3716, decode.d6.loss_mask: 0.5513, decode.d6.loss_dice: 0.8207, decode.d7.loss_cls: 0.3721, decode.d7.loss_mask: 0.5509, decode.d7.loss_dice: 0.8195, decode.d8.loss_cls: 0.3721, decode.d8.loss_mask: 0.5530, decode.d8.loss_dice: 0.8193, loss: 23.3188
2022-12-01 00:27:16,990 - mmseg - INFO - per class results:
2022-12-01 00:27:16,995 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 83.02 | 89.15 |
|       building      | 85.32 | 91.81 |
|         sky         |  95.1 | 97.58 |
|        floor        | 85.21 | 90.51 |
|         tree        | 78.49 | 89.24 |
|       ceiling       | 86.85 | 92.82 |
|         road        | 87.84 | 92.05 |
|         bed         | 93.66 | 96.99 |
|      windowpane     | 69.03 | 81.54 |
|        grass        | 72.84 | 85.53 |
|       cabinet       | 62.58 | 75.15 |
|       sidewalk      | 73.82 | 87.02 |
|        person       | 88.23 | 93.49 |
|        earth        | 43.88 | 60.64 |
|         door        | 63.41 | 84.13 |
|        table        | 71.46 | 81.56 |
|       mountain      | 62.42 | 72.32 |
|        plant        | 55.41 |  69.8 |
|       curtain       | 81.65 | 92.31 |
|        chair        |  67.4 | 77.32 |
|         car         | 89.79 | 95.14 |
|        water        | 71.56 | 85.34 |
|       painting      | 81.59 | 92.01 |
|         sofa        | 85.39 |  91.1 |
|        shelf        | 45.56 | 55.71 |
|        house        |  50.3 | 66.58 |
|         sea         |  78.7 |  87.9 |
|        mirror       | 81.15 | 91.14 |
|         rug         | 71.44 | 85.39 |
|        field        | 36.82 | 58.81 |
|       armchair      | 61.08 | 80.64 |
|         seat        |  67.5 |  89.3 |
|        fence        | 54.97 | 70.98 |
|         desk        | 57.93 | 80.46 |
|         rock        |  61.9 | 76.23 |
|       wardrobe      | 58.75 |  87.1 |
|         lamp        | 80.74 | 90.11 |
|       bathtub       | 92.03 | 93.69 |
|       railing       | 46.02 | 66.71 |
|       cushion       | 75.94 | 90.39 |
|         base        |  48.3 | 70.19 |
|         box         | 42.76 | 59.74 |
|        column       | 62.47 |  82.2 |
|      signboard      | 45.94 | 66.51 |
|   chest of drawers  | 45.55 | 65.27 |
|       counter       | 58.14 | 69.44 |
|         sand        |  62.7 | 87.93 |
|         sink        | 82.97 | 86.92 |
|      skyscraper     | 43.72 | 55.84 |
|      fireplace      | 83.09 | 95.71 |
|     refrigerator    |  85.2 | 95.46 |
|      grandstand     | 46.86 | 74.97 |
|         path        | 32.38 | 40.29 |
|        stairs       | 35.61 | 47.94 |
|        runway       | 74.51 | 93.87 |
|         case        | 68.22 | 87.01 |
|      pool table     | 95.83 | 98.68 |
|        pillow       | 72.25 | 83.31 |
|     screen door     |  84.5 | 93.98 |
|       stairway      |  57.0 |  76.3 |
|        river        | 25.06 | 29.46 |
|        bridge       | 78.79 | 87.14 |
|       bookcase      | 31.61 |  56.2 |
|        blind        | 48.79 | 58.61 |
|     coffee table    | 72.43 | 91.15 |
|        toilet       | 93.17 | 96.79 |
|        flower       | 43.36 | 64.85 |
|         book        | 60.63 | 82.34 |
|         hill        | 14.55 | 27.31 |
|        bench        | 71.84 | 82.13 |
|      countertop     | 73.67 | 92.65 |
|        stove        | 85.74 | 89.64 |
|         palm        | 55.02 | 81.64 |
|    kitchen island   | 40.46 | 82.09 |
|       computer      | 77.72 | 86.27 |
|     swivel chair    | 55.39 | 87.27 |
|         boat        | 58.78 |  89.7 |
|         bar         |  64.5 | 70.24 |
|    arcade machine   | 91.47 | 98.69 |
|        hovel        |  38.0 | 42.39 |
|         bus         | 94.06 | 96.05 |
|        towel        | 81.94 | 95.12 |
|        light        | 65.37 |  79.0 |
|        truck        | 53.27 | 73.33 |
|        tower        | 33.38 | 62.17 |
|      chandelier     | 76.67 | 86.52 |
|        awning       | 32.85 | 59.14 |
|     streetlight     | 45.69 | 71.77 |
|        booth        | 59.23 | 82.73 |
| television receiver | 76.78 | 91.76 |
|       airplane      | 88.01 |  96.1 |
|      dirt track     |  7.78 | 13.84 |
|       apparel       | 51.98 | 90.62 |
|         pole        | 34.14 | 51.85 |
|         land        |  1.31 |  1.91 |
|      bannister      | 20.57 | 35.42 |
|      escalator      | 62.73 | 84.59 |
|       ottoman       | 56.55 | 78.21 |
|        bottle       | 52.44 | 82.68 |
|        buffet       | 39.36 | 49.16 |
|        poster       | 40.88 | 60.05 |
|        stage        | 29.06 | 61.17 |
|         van         | 55.31 | 77.21 |
|         ship        | 18.01 | 19.03 |
|       fountain      | 56.84 |  64.9 |
|    conveyer belt    |  79.2 | 97.69 |
|        canopy       | 57.82 |  92.4 |
|        washer       | 90.49 |  93.3 |
|      plaything      |  38.9 | 58.77 |
|    swimming pool    | 49.17 | 74.99 |
|        stool        | 54.78 | 86.31 |
|        barrel       |  64.7 |  94.0 |
|        basket       | 47.82 | 75.92 |
|      waterfall      |  46.8 | 58.41 |
|         tent        | 96.23 | 98.08 |
|         bag         |  35.3 |  49.1 |
|       minibike      | 81.78 | 93.29 |
|        cradle       | 91.34 | 97.16 |
|         oven        | 65.46 | 82.54 |
|         ball        | 41.38 | 44.75 |
|         food        | 64.07 | 75.11 |
|         step        | 25.58 | 46.15 |
|         tank        | 58.97 | 67.52 |
|      trade name     | 34.43 | 45.61 |
|      microwave      | 89.77 | 94.44 |
|         pot         | 62.72 | 75.01 |
|        animal       | 82.96 | 84.93 |
|       bicycle       | 63.16 | 84.04 |
|         lake        | 44.04 | 68.66 |
|      dishwasher     | 80.05 | 90.51 |
|        screen       |  61.9 | 96.08 |
|       blanket       | 42.82 |  61.1 |
|      sculpture      | 73.04 | 90.46 |
|         hood        | 80.85 |  88.7 |
|        sconce       | 68.35 | 82.96 |
|         vase        | 58.58 | 81.22 |
|    traffic light    | 52.19 | 73.41 |
|         tray        | 31.55 | 49.74 |
|        ashcan       | 56.05 | 80.35 |
|         fan         | 73.72 |  87.0 |
|         pier        | 37.74 |  41.8 |
|      crt screen     |  1.5  |  3.83 |
|        plate        | 68.61 | 85.98 |
|       monitor       |  6.65 |  9.73 |
|    bulletin board   | 62.57 | 85.01 |
|        shower       |  15.3 | 30.28 |
|       radiator      | 73.13 | 93.22 |
|        glass        | 29.37 | 32.92 |
|        clock        | 64.18 | 77.04 |
|         flag        | 68.69 | 88.31 |
+---------------------+-------+-------+
2022-12-01 00:27:16,995 - mmseg - INFO - Summary:
2022-12-01 00:27:16,995 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 86.96 | 60.49 | 75.31 |
+-------+-------+-------+
2022-12-01 00:27:17,001 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 00:27:17,002 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8696, mIoU: 0.6049, mAcc: 0.7531, IoU.wall: 0.8302, IoU.building: 0.8532, IoU.sky: 0.9510, IoU.floor: 0.8521, IoU.tree: 0.7849, IoU.ceiling: 0.8685, IoU.road: 0.8784, IoU.bed : 0.9366, IoU.windowpane: 0.6903, IoU.grass: 0.7284, IoU.cabinet: 0.6258, IoU.sidewalk: 0.7382, IoU.person: 0.8823, IoU.earth: 0.4388, IoU.door: 0.6341, IoU.table: 0.7146, IoU.mountain: 0.6242, IoU.plant: 0.5541, IoU.curtain: 0.8165, IoU.chair: 0.6740, IoU.car: 0.8979, IoU.water: 0.7156, IoU.painting: 0.8159, IoU.sofa: 0.8539, IoU.shelf: 0.4556, IoU.house: 0.5030, IoU.sea: 0.7870, IoU.mirror: 0.8115, IoU.rug: 0.7144, IoU.field: 0.3682, IoU.armchair: 0.6108, IoU.seat: 0.6750, IoU.fence: 0.5497, IoU.desk: 0.5793, IoU.rock: 0.6190, IoU.wardrobe: 0.5875, IoU.lamp: 0.8074, IoU.bathtub: 0.9203, IoU.railing: 0.4602, IoU.cushion: 0.7594, IoU.base: 0.4830, IoU.box: 0.4276, IoU.column: 0.6247, IoU.signboard: 0.4594, IoU.chest of drawers: 0.4555, IoU.counter: 0.5814, IoU.sand: 0.6270, IoU.sink: 0.8297, IoU.skyscraper: 0.4372, IoU.fireplace: 0.8309, IoU.refrigerator: 0.8520, IoU.grandstand: 0.4686, IoU.path: 0.3238, IoU.stairs: 0.3561, IoU.runway: 0.7451, IoU.case: 0.6822, IoU.pool table: 0.9583, IoU.pillow: 0.7225, IoU.screen door: 0.8450, IoU.stairway: 0.5700, IoU.river: 0.2506, IoU.bridge: 0.7879, IoU.bookcase: 0.3161, IoU.blind: 0.4879, IoU.coffee table: 0.7243, IoU.toilet: 0.9317, IoU.flower: 0.4336, IoU.book: 0.6063, IoU.hill: 0.1455, IoU.bench: 0.7184, IoU.countertop: 0.7367, IoU.stove: 0.8574, IoU.palm: 0.5502, IoU.kitchen island: 0.4046, IoU.computer: 0.7772, IoU.swivel chair: 0.5539, IoU.boat: 0.5878, IoU.bar: 0.6450, IoU.arcade machine: 0.9147, IoU.hovel: 0.3800, IoU.bus: 0.9406, IoU.towel: 0.8194, IoU.light: 0.6537, IoU.truck: 0.5327, IoU.tower: 0.3338, IoU.chandelier: 0.7667, IoU.awning: 0.3285, IoU.streetlight: 0.4569, IoU.booth: 0.5923, IoU.television receiver: 0.7678, IoU.airplane: 0.8801, IoU.dirt track: 0.0778, IoU.apparel: 0.5198, IoU.pole: 0.3414, IoU.land: 0.0131, IoU.bannister: 0.2057, IoU.escalator: 0.6273, IoU.ottoman: 0.5655, IoU.bottle: 0.5244, IoU.buffet: 0.3936, IoU.poster: 0.4088, IoU.stage: 0.2906, IoU.van: 0.5531, IoU.ship: 0.1801, IoU.fountain: 0.5684, IoU.conveyer belt: 0.7920, IoU.canopy: 0.5782, IoU.washer: 0.9049, IoU.plaything: 0.3890, IoU.swimming pool: 0.4917, IoU.stool: 0.5478, IoU.barrel: 0.6470, IoU.basket: 0.4782, IoU.waterfall: 0.4680, IoU.tent: 0.9623, IoU.bag: 0.3530, IoU.minibike: 0.8178, IoU.cradle: 0.9134, IoU.oven: 0.6546, IoU.ball: 0.4138, IoU.food: 0.6407, IoU.step: 0.2558, IoU.tank: 0.5897, IoU.trade name: 0.3443, IoU.microwave: 0.8977, IoU.pot: 0.6272, IoU.animal: 0.8296, IoU.bicycle: 0.6316, IoU.lake: 0.4404, IoU.dishwasher: 0.8005, IoU.screen: 0.6190, IoU.blanket: 0.4282, IoU.sculpture: 0.7304, IoU.hood: 0.8085, IoU.sconce: 0.6835, IoU.vase: 0.5858, IoU.traffic light: 0.5219, IoU.tray: 0.3155, IoU.ashcan: 0.5605, IoU.fan: 0.7372, IoU.pier: 0.3774, IoU.crt screen: 0.0150, IoU.plate: 0.6861, IoU.monitor: 0.0665, IoU.bulletin board: 0.6257, IoU.shower: 0.1530, IoU.radiator: 0.7313, IoU.glass: 0.2937, IoU.clock: 0.6418, IoU.flag: 0.6869, Acc.wall: 0.8915, Acc.building: 0.9181, Acc.sky: 0.9758, Acc.floor: 0.9051, Acc.tree: 0.8924, Acc.ceiling: 0.9282, Acc.road: 0.9205, Acc.bed : 0.9699, Acc.windowpane: 0.8154, Acc.grass: 0.8553, Acc.cabinet: 0.7515, Acc.sidewalk: 0.8702, Acc.person: 0.9349, Acc.earth: 0.6064, Acc.door: 0.8413, Acc.table: 0.8156, Acc.mountain: 0.7232, Acc.plant: 0.6980, Acc.curtain: 0.9231, Acc.chair: 0.7732, Acc.car: 0.9514, Acc.water: 0.8534, Acc.painting: 0.9201, Acc.sofa: 0.9110, Acc.shelf: 0.5571, Acc.house: 0.6658, Acc.sea: 0.8790, Acc.mirror: 0.9114, Acc.rug: 0.8539, Acc.field: 0.5881, Acc.armchair: 0.8064, Acc.seat: 0.8930, Acc.fence: 0.7098, Acc.desk: 0.8046, Acc.rock: 0.7623, Acc.wardrobe: 0.8710, Acc.lamp: 0.9011, Acc.bathtub: 0.9369, Acc.railing: 0.6671, Acc.cushion: 0.9039, Acc.base: 0.7019, Acc.box: 0.5974, Acc.column: 0.8220, Acc.signboard: 0.6651, Acc.chest of drawers: 0.6527, Acc.counter: 0.6944, Acc.sand: 0.8793, Acc.sink: 0.8692, Acc.skyscraper: 0.5584, Acc.fireplace: 0.9571, Acc.refrigerator: 0.9546, Acc.grandstand: 0.7497, Acc.path: 0.4029, Acc.stairs: 0.4794, Acc.runway: 0.9387, Acc.case: 0.8701, Acc.pool table: 0.9868, Acc.pillow: 0.8331, Acc.screen door: 0.9398, Acc.stairway: 0.7630, Acc.river: 0.2946, Acc.bridge: 0.8714, Acc.bookcase: 0.5620, Acc.blind: 0.5861, Acc.coffee table: 0.9115, Acc.toilet: 0.9679, Acc.flower: 0.6485, Acc.book: 0.8234, Acc.hill: 0.2731, Acc.bench: 0.8213, Acc.countertop: 0.9265, Acc.stove: 0.8964, Acc.palm: 0.8164, Acc.kitchen island: 0.8209, Acc.computer: 0.8627, Acc.swivel chair: 0.8727, Acc.boat: 0.8970, Acc.bar: 0.7024, Acc.arcade machine: 0.9869, Acc.hovel: 0.4239, Acc.bus: 0.9605, Acc.towel: 0.9512, Acc.light: 0.7900, Acc.truck: 0.7333, Acc.tower: 0.6217, Acc.chandelier: 0.8652, Acc.awning: 0.5914, Acc.streetlight: 0.7177, Acc.booth: 0.8273, Acc.television receiver: 0.9176, Acc.airplane: 0.9610, Acc.dirt track: 0.1384, Acc.apparel: 0.9062, Acc.pole: 0.5185, Acc.land: 0.0191, Acc.bannister: 0.3542, Acc.escalator: 0.8459, Acc.ottoman: 0.7821, Acc.bottle: 0.8268, Acc.buffet: 0.4916, Acc.poster: 0.6005, Acc.stage: 0.6117, Acc.van: 0.7721, Acc.ship: 0.1903, Acc.fountain: 0.6490, Acc.conveyer belt: 0.9769, Acc.canopy: 0.9240, Acc.washer: 0.9330, Acc.plaything: 0.5877, Acc.swimming pool: 0.7499, Acc.stool: 0.8631, Acc.barrel: 0.9400, Acc.basket: 0.7592, Acc.waterfall: 0.5841, Acc.tent: 0.9808, Acc.bag: 0.4910, Acc.minibike: 0.9329, Acc.cradle: 0.9716, Acc.oven: 0.8254, Acc.ball: 0.4475, Acc.food: 0.7511, Acc.step: 0.4615, Acc.tank: 0.6752, Acc.trade name: 0.4561, Acc.microwave: 0.9444, Acc.pot: 0.7501, Acc.animal: 0.8493, Acc.bicycle: 0.8404, Acc.lake: 0.6866, Acc.dishwasher: 0.9051, Acc.screen: 0.9608, Acc.blanket: 0.6110, Acc.sculpture: 0.9046, Acc.hood: 0.8870, Acc.sconce: 0.8296, Acc.vase: 0.8122, Acc.traffic light: 0.7341, Acc.tray: 0.4974, Acc.ashcan: 0.8035, Acc.fan: 0.8700, Acc.pier: 0.4180, Acc.crt screen: 0.0383, Acc.plate: 0.8598, Acc.monitor: 0.0973, Acc.bulletin board: 0.8501, Acc.shower: 0.3028, Acc.radiator: 0.9322, Acc.glass: 0.3292, Acc.clock: 0.7704, Acc.flag: 0.8831
2022-12-01 00:30:43,344 - mmseg - INFO - Iter [23050/40000]	lr: 5.637e-08, eta: 20:35:20, time: 7.688, data_time: 3.581, memory: 51902, decode.loss_cls: 0.3732, decode.loss_mask: 0.5459, decode.loss_dice: 0.8090, decode.d0.loss_cls: 5.8462, decode.d0.loss_mask: 0.5259, decode.d0.loss_dice: 0.8754, decode.d1.loss_cls: 0.4905, decode.d1.loss_mask: 0.5727, decode.d1.loss_dice: 0.8638, decode.d2.loss_cls: 0.4258, decode.d2.loss_mask: 0.5611, decode.d2.loss_dice: 0.8339, decode.d3.loss_cls: 0.3954, decode.d3.loss_mask: 0.5501, decode.d3.loss_dice: 0.8218, decode.d4.loss_cls: 0.3848, decode.d4.loss_mask: 0.5473, decode.d4.loss_dice: 0.8177, decode.d5.loss_cls: 0.3782, decode.d5.loss_mask: 0.5459, decode.d5.loss_dice: 0.8122, decode.d6.loss_cls: 0.3772, decode.d6.loss_mask: 0.5427, decode.d6.loss_dice: 0.8073, decode.d7.loss_cls: 0.3708, decode.d7.loss_mask: 0.5426, decode.d7.loss_dice: 0.8071, decode.d8.loss_cls: 0.3691, decode.d8.loss_mask: 0.5446, decode.d8.loss_dice: 0.8082, loss: 23.1463
2022-12-01 00:34:08,738 - mmseg - INFO - Iter [23100/40000]	lr: 5.621e-08, eta: 20:31:32, time: 4.108, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3723, decode.loss_mask: 0.5429, decode.loss_dice: 0.8145, decode.d0.loss_cls: 5.8350, decode.d0.loss_mask: 0.5281, decode.d0.loss_dice: 0.8823, decode.d1.loss_cls: 0.4837, decode.d1.loss_mask: 0.5678, decode.d1.loss_dice: 0.8725, decode.d2.loss_cls: 0.4318, decode.d2.loss_mask: 0.5575, decode.d2.loss_dice: 0.8385, decode.d3.loss_cls: 0.4015, decode.d3.loss_mask: 0.5510, decode.d3.loss_dice: 0.8230, decode.d4.loss_cls: 0.3927, decode.d4.loss_mask: 0.5491, decode.d4.loss_dice: 0.8232, decode.d5.loss_cls: 0.3843, decode.d5.loss_mask: 0.5448, decode.d5.loss_dice: 0.8155, decode.d6.loss_cls: 0.3772, decode.d6.loss_mask: 0.5435, decode.d6.loss_dice: 0.8146, decode.d7.loss_cls: 0.3758, decode.d7.loss_mask: 0.5455, decode.d7.loss_dice: 0.8185, decode.d8.loss_cls: 0.3712, decode.d8.loss_mask: 0.5438, decode.d8.loss_dice: 0.8141, loss: 23.2163
2022-12-01 00:37:34,923 - mmseg - INFO - Iter [23150/40000]	lr: 5.604e-08, eta: 20:27:44, time: 4.124, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3856, decode.loss_mask: 0.5519, decode.loss_dice: 0.8260, decode.d0.loss_cls: 5.8484, decode.d0.loss_mask: 0.5381, decode.d0.loss_dice: 0.8845, decode.d1.loss_cls: 0.5023, decode.d1.loss_mask: 0.5731, decode.d1.loss_dice: 0.8772, decode.d2.loss_cls: 0.4438, decode.d2.loss_mask: 0.5599, decode.d2.loss_dice: 0.8460, decode.d3.loss_cls: 0.4118, decode.d3.loss_mask: 0.5558, decode.d3.loss_dice: 0.8349, decode.d4.loss_cls: 0.3991, decode.d4.loss_mask: 0.5559, decode.d4.loss_dice: 0.8284, decode.d5.loss_cls: 0.3917, decode.d5.loss_mask: 0.5539, decode.d5.loss_dice: 0.8249, decode.d6.loss_cls: 0.3886, decode.d6.loss_mask: 0.5521, decode.d6.loss_dice: 0.8241, decode.d7.loss_cls: 0.3874, decode.d7.loss_mask: 0.5490, decode.d7.loss_dice: 0.8246, decode.d8.loss_cls: 0.3866, decode.d8.loss_mask: 0.5511, decode.d8.loss_dice: 0.8219, loss: 23.4786
2022-12-01 00:41:00,544 - mmseg - INFO - Iter [23200/40000]	lr: 5.588e-08, eta: 20:23:56, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3778, decode.loss_mask: 0.5616, decode.loss_dice: 0.8240, decode.d0.loss_cls: 5.8140, decode.d0.loss_mask: 0.5431, decode.d0.loss_dice: 0.8843, decode.d1.loss_cls: 0.4884, decode.d1.loss_mask: 0.5851, decode.d1.loss_dice: 0.8766, decode.d2.loss_cls: 0.4295, decode.d2.loss_mask: 0.5730, decode.d2.loss_dice: 0.8467, decode.d3.loss_cls: 0.3987, decode.d3.loss_mask: 0.5695, decode.d3.loss_dice: 0.8335, decode.d4.loss_cls: 0.3913, decode.d4.loss_mask: 0.5649, decode.d4.loss_dice: 0.8343, decode.d5.loss_cls: 0.3852, decode.d5.loss_mask: 0.5626, decode.d5.loss_dice: 0.8297, decode.d6.loss_cls: 0.3796, decode.d6.loss_mask: 0.5611, decode.d6.loss_dice: 0.8246, decode.d7.loss_cls: 0.3777, decode.d7.loss_mask: 0.5616, decode.d7.loss_dice: 0.8247, decode.d8.loss_cls: 0.3771, decode.d8.loss_mask: 0.5614, decode.d8.loss_dice: 0.8234, loss: 23.4647
2022-12-01 00:44:25,909 - mmseg - INFO - Iter [23250/40000]	lr: 5.571e-08, eta: 20:20:08, time: 4.107, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3657, decode.loss_mask: 0.5462, decode.loss_dice: 0.8192, decode.d0.loss_cls: 5.8048, decode.d0.loss_mask: 0.5301, decode.d0.loss_dice: 0.8799, decode.d1.loss_cls: 0.4804, decode.d1.loss_mask: 0.5676, decode.d1.loss_dice: 0.8750, decode.d2.loss_cls: 0.4208, decode.d2.loss_mask: 0.5589, decode.d2.loss_dice: 0.8474, decode.d3.loss_cls: 0.3931, decode.d3.loss_mask: 0.5531, decode.d3.loss_dice: 0.8259, decode.d4.loss_cls: 0.3849, decode.d4.loss_mask: 0.5493, decode.d4.loss_dice: 0.8275, decode.d5.loss_cls: 0.3731, decode.d5.loss_mask: 0.5481, decode.d5.loss_dice: 0.8241, decode.d6.loss_cls: 0.3698, decode.d6.loss_mask: 0.5480, decode.d6.loss_dice: 0.8202, decode.d7.loss_cls: 0.3664, decode.d7.loss_mask: 0.5464, decode.d7.loss_dice: 0.8176, decode.d8.loss_cls: 0.3667, decode.d8.loss_mask: 0.5456, decode.d8.loss_dice: 0.8169, loss: 23.1728
2022-12-01 00:47:51,611 - mmseg - INFO - Iter [23300/40000]	lr: 5.554e-08, eta: 20:16:20, time: 4.114, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3782, decode.loss_mask: 0.5524, decode.loss_dice: 0.8012, decode.d0.loss_cls: 5.8029, decode.d0.loss_mask: 0.5388, decode.d0.loss_dice: 0.8684, decode.d1.loss_cls: 0.4877, decode.d1.loss_mask: 0.5758, decode.d1.loss_dice: 0.8600, decode.d2.loss_cls: 0.4343, decode.d2.loss_mask: 0.5635, decode.d2.loss_dice: 0.8224, decode.d3.loss_cls: 0.4016, decode.d3.loss_mask: 0.5580, decode.d3.loss_dice: 0.8134, decode.d4.loss_cls: 0.3921, decode.d4.loss_mask: 0.5569, decode.d4.loss_dice: 0.8109, decode.d5.loss_cls: 0.3867, decode.d5.loss_mask: 0.5519, decode.d5.loss_dice: 0.8047, decode.d6.loss_cls: 0.3829, decode.d6.loss_mask: 0.5520, decode.d6.loss_dice: 0.8036, decode.d7.loss_cls: 0.3835, decode.d7.loss_mask: 0.5517, decode.d7.loss_dice: 0.8044, decode.d8.loss_cls: 0.3783, decode.d8.loss_mask: 0.5522, decode.d8.loss_dice: 0.8016, loss: 23.1719
2022-12-01 00:51:17,671 - mmseg - INFO - Iter [23350/40000]	lr: 5.538e-08, eta: 20:12:33, time: 4.121, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3729, decode.loss_mask: 0.5479, decode.loss_dice: 0.8167, decode.d0.loss_cls: 5.8131, decode.d0.loss_mask: 0.5339, decode.d0.loss_dice: 0.8851, decode.d1.loss_cls: 0.4940, decode.d1.loss_mask: 0.5712, decode.d1.loss_dice: 0.8717, decode.d2.loss_cls: 0.4315, decode.d2.loss_mask: 0.5617, decode.d2.loss_dice: 0.8407, decode.d3.loss_cls: 0.4021, decode.d3.loss_mask: 0.5564, decode.d3.loss_dice: 0.8266, decode.d4.loss_cls: 0.3908, decode.d4.loss_mask: 0.5526, decode.d4.loss_dice: 0.8239, decode.d5.loss_cls: 0.3835, decode.d5.loss_mask: 0.5508, decode.d5.loss_dice: 0.8238, decode.d6.loss_cls: 0.3830, decode.d6.loss_mask: 0.5485, decode.d6.loss_dice: 0.8194, decode.d7.loss_cls: 0.3801, decode.d7.loss_mask: 0.5476, decode.d7.loss_dice: 0.8172, decode.d8.loss_cls: 0.3764, decode.d8.loss_mask: 0.5486, decode.d8.loss_dice: 0.8191, loss: 23.2908
2022-12-01 00:54:45,570 - mmseg - INFO - Iter [23400/40000]	lr: 5.521e-08, eta: 20:08:47, time: 4.158, data_time: 0.067, memory: 51902, decode.loss_cls: 0.3788, decode.loss_mask: 0.5567, decode.loss_dice: 0.8161, decode.d0.loss_cls: 5.8035, decode.d0.loss_mask: 0.5447, decode.d0.loss_dice: 0.8856, decode.d1.loss_cls: 0.4927, decode.d1.loss_mask: 0.5865, decode.d1.loss_dice: 0.8915, decode.d2.loss_cls: 0.4369, decode.d2.loss_mask: 0.5742, decode.d2.loss_dice: 0.8490, decode.d3.loss_cls: 0.4077, decode.d3.loss_mask: 0.5635, decode.d3.loss_dice: 0.8294, decode.d4.loss_cls: 0.4005, decode.d4.loss_mask: 0.5611, decode.d4.loss_dice: 0.8225, decode.d5.loss_cls: 0.3922, decode.d5.loss_mask: 0.5586, decode.d5.loss_dice: 0.8204, decode.d6.loss_cls: 0.3850, decode.d6.loss_mask: 0.5577, decode.d6.loss_dice: 0.8171, decode.d7.loss_cls: 0.3828, decode.d7.loss_mask: 0.5558, decode.d7.loss_dice: 0.8159, decode.d8.loss_cls: 0.3804, decode.d8.loss_mask: 0.5569, decode.d8.loss_dice: 0.8173, loss: 23.4410
2022-12-01 00:58:11,317 - mmseg - INFO - Iter [23450/40000]	lr: 5.504e-08, eta: 20:05:00, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3630, decode.loss_mask: 0.5581, decode.loss_dice: 0.8093, decode.d0.loss_cls: 5.7770, decode.d0.loss_mask: 0.5420, decode.d0.loss_dice: 0.8677, decode.d1.loss_cls: 0.4821, decode.d1.loss_mask: 0.5806, decode.d1.loss_dice: 0.8637, decode.d2.loss_cls: 0.4242, decode.d2.loss_mask: 0.5724, decode.d2.loss_dice: 0.8317, decode.d3.loss_cls: 0.3877, decode.d3.loss_mask: 0.5661, decode.d3.loss_dice: 0.8168, decode.d4.loss_cls: 0.3785, decode.d4.loss_mask: 0.5644, decode.d4.loss_dice: 0.8160, decode.d5.loss_cls: 0.3712, decode.d5.loss_mask: 0.5619, decode.d5.loss_dice: 0.8122, decode.d6.loss_cls: 0.3683, decode.d6.loss_mask: 0.5597, decode.d6.loss_dice: 0.8085, decode.d7.loss_cls: 0.3668, decode.d7.loss_mask: 0.5593, decode.d7.loss_dice: 0.8080, decode.d8.loss_cls: 0.3610, decode.d8.loss_mask: 0.5601, decode.d8.loss_dice: 0.8087, loss: 23.1467
2022-12-01 01:01:37,007 - mmseg - INFO - Iter [23500/40000]	lr: 5.488e-08, eta: 20:01:12, time: 4.114, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3621, decode.loss_mask: 0.5423, decode.loss_dice: 0.8107, decode.d0.loss_cls: 5.7945, decode.d0.loss_mask: 0.5357, decode.d0.loss_dice: 0.8781, decode.d1.loss_cls: 0.4852, decode.d1.loss_mask: 0.5664, decode.d1.loss_dice: 0.8677, decode.d2.loss_cls: 0.4220, decode.d2.loss_mask: 0.5537, decode.d2.loss_dice: 0.8368, decode.d3.loss_cls: 0.3938, decode.d3.loss_mask: 0.5478, decode.d3.loss_dice: 0.8158, decode.d4.loss_cls: 0.3812, decode.d4.loss_mask: 0.5473, decode.d4.loss_dice: 0.8204, decode.d5.loss_cls: 0.3692, decode.d5.loss_mask: 0.5457, decode.d5.loss_dice: 0.8155, decode.d6.loss_cls: 0.3648, decode.d6.loss_mask: 0.5447, decode.d6.loss_dice: 0.8086, decode.d7.loss_cls: 0.3604, decode.d7.loss_mask: 0.5454, decode.d7.loss_dice: 0.8119, decode.d8.loss_cls: 0.3615, decode.d8.loss_mask: 0.5443, decode.d8.loss_dice: 0.8104, loss: 23.0441
2022-12-01 01:05:02,618 - mmseg - INFO - Iter [23550/40000]	lr: 5.471e-08, eta: 19:57:25, time: 4.112, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3693, decode.loss_mask: 0.5523, decode.loss_dice: 0.7971, decode.d0.loss_cls: 5.7753, decode.d0.loss_mask: 0.5428, decode.d0.loss_dice: 0.8648, decode.d1.loss_cls: 0.4810, decode.d1.loss_mask: 0.5783, decode.d1.loss_dice: 0.8571, decode.d2.loss_cls: 0.4257, decode.d2.loss_mask: 0.5681, decode.d2.loss_dice: 0.8252, decode.d3.loss_cls: 0.3913, decode.d3.loss_mask: 0.5596, decode.d3.loss_dice: 0.8081, decode.d4.loss_cls: 0.3842, decode.d4.loss_mask: 0.5572, decode.d4.loss_dice: 0.8049, decode.d5.loss_cls: 0.3756, decode.d5.loss_mask: 0.5531, decode.d5.loss_dice: 0.8006, decode.d6.loss_cls: 0.3730, decode.d6.loss_mask: 0.5541, decode.d6.loss_dice: 0.8000, decode.d7.loss_cls: 0.3705, decode.d7.loss_mask: 0.5546, decode.d7.loss_dice: 0.8024, decode.d8.loss_cls: 0.3677, decode.d8.loss_mask: 0.5529, decode.d8.loss_dice: 0.7988, loss: 23.0459
2022-12-01 01:08:28,323 - mmseg - INFO - Iter [23600/40000]	lr: 5.454e-08, eta: 19:53:38, time: 4.114, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3540, decode.loss_mask: 0.5387, decode.loss_dice: 0.8086, decode.d0.loss_cls: 5.7652, decode.d0.loss_mask: 0.5247, decode.d0.loss_dice: 0.8725, decode.d1.loss_cls: 0.4678, decode.d1.loss_mask: 0.5651, decode.d1.loss_dice: 0.8656, decode.d2.loss_cls: 0.4124, decode.d2.loss_mask: 0.5504, decode.d2.loss_dice: 0.8329, decode.d3.loss_cls: 0.3773, decode.d3.loss_mask: 0.5471, decode.d3.loss_dice: 0.8194, decode.d4.loss_cls: 0.3701, decode.d4.loss_mask: 0.5446, decode.d4.loss_dice: 0.8167, decode.d5.loss_cls: 0.3609, decode.d5.loss_mask: 0.5416, decode.d5.loss_dice: 0.8115, decode.d6.loss_cls: 0.3556, decode.d6.loss_mask: 0.5408, decode.d6.loss_dice: 0.8127, decode.d7.loss_cls: 0.3556, decode.d7.loss_mask: 0.5417, decode.d7.loss_dice: 0.8133, decode.d8.loss_cls: 0.3552, decode.d8.loss_mask: 0.5403, decode.d8.loss_dice: 0.8107, loss: 22.8732
2022-12-01 01:11:54,050 - mmseg - INFO - Iter [23650/40000]	lr: 5.438e-08, eta: 19:49:51, time: 4.115, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3952, decode.loss_mask: 0.5605, decode.loss_dice: 0.8270, decode.d0.loss_cls: 5.7668, decode.d0.loss_mask: 0.5445, decode.d0.loss_dice: 0.8961, decode.d1.loss_cls: 0.5131, decode.d1.loss_mask: 0.5868, decode.d1.loss_dice: 0.8869, decode.d2.loss_cls: 0.4510, decode.d2.loss_mask: 0.5733, decode.d2.loss_dice: 0.8549, decode.d3.loss_cls: 0.4176, decode.d3.loss_mask: 0.5684, decode.d3.loss_dice: 0.8358, decode.d4.loss_cls: 0.4091, decode.d4.loss_mask: 0.5653, decode.d4.loss_dice: 0.8397, decode.d5.loss_cls: 0.3994, decode.d5.loss_mask: 0.5625, decode.d5.loss_dice: 0.8308, decode.d6.loss_cls: 0.3931, decode.d6.loss_mask: 0.5612, decode.d6.loss_dice: 0.8320, decode.d7.loss_cls: 0.3936, decode.d7.loss_mask: 0.5600, decode.d7.loss_dice: 0.8288, decode.d8.loss_cls: 0.3922, decode.d8.loss_mask: 0.5605, decode.d8.loss_dice: 0.8288, loss: 23.6350
2022-12-01 01:15:19,958 - mmseg - INFO - Iter [23700/40000]	lr: 5.421e-08, eta: 19:46:04, time: 4.118, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3583, decode.loss_mask: 0.5541, decode.loss_dice: 0.8011, decode.d0.loss_cls: 5.7406, decode.d0.loss_mask: 0.5369, decode.d0.loss_dice: 0.8547, decode.d1.loss_cls: 0.4727, decode.d1.loss_mask: 0.5766, decode.d1.loss_dice: 0.8569, decode.d2.loss_cls: 0.4180, decode.d2.loss_mask: 0.5669, decode.d2.loss_dice: 0.8248, decode.d3.loss_cls: 0.3863, decode.d3.loss_mask: 0.5594, decode.d3.loss_dice: 0.8070, decode.d4.loss_cls: 0.3742, decode.d4.loss_mask: 0.5590, decode.d4.loss_dice: 0.8110, decode.d5.loss_cls: 0.3659, decode.d5.loss_mask: 0.5544, decode.d5.loss_dice: 0.8061, decode.d6.loss_cls: 0.3605, decode.d6.loss_mask: 0.5534, decode.d6.loss_dice: 0.8065, decode.d7.loss_cls: 0.3580, decode.d7.loss_mask: 0.5539, decode.d7.loss_dice: 0.8029, decode.d8.loss_cls: 0.3571, decode.d8.loss_mask: 0.5528, decode.d8.loss_dice: 0.8012, loss: 22.9311
2022-12-01 01:18:45,625 - mmseg - INFO - Iter [23750/40000]	lr: 5.405e-08, eta: 19:42:17, time: 4.113, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3702, decode.loss_mask: 0.5566, decode.loss_dice: 0.8080, decode.d0.loss_cls: 5.7492, decode.d0.loss_mask: 0.5398, decode.d0.loss_dice: 0.8663, decode.d1.loss_cls: 0.4810, decode.d1.loss_mask: 0.5831, decode.d1.loss_dice: 0.8616, decode.d2.loss_cls: 0.4298, decode.d2.loss_mask: 0.5740, decode.d2.loss_dice: 0.8310, decode.d3.loss_cls: 0.3969, decode.d3.loss_mask: 0.5635, decode.d3.loss_dice: 0.8165, decode.d4.loss_cls: 0.3904, decode.d4.loss_mask: 0.5591, decode.d4.loss_dice: 0.8107, decode.d5.loss_cls: 0.3754, decode.d5.loss_mask: 0.5606, decode.d5.loss_dice: 0.8143, decode.d6.loss_cls: 0.3746, decode.d6.loss_mask: 0.5588, decode.d6.loss_dice: 0.8133, decode.d7.loss_cls: 0.3741, decode.d7.loss_mask: 0.5580, decode.d7.loss_dice: 0.8062, decode.d8.loss_cls: 0.3695, decode.d8.loss_mask: 0.5584, decode.d8.loss_dice: 0.8051, loss: 23.1559
2022-12-01 01:22:11,442 - mmseg - INFO - Iter [23800/40000]	lr: 5.388e-08, eta: 19:38:30, time: 4.116, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3697, decode.loss_mask: 0.5351, decode.loss_dice: 0.8057, decode.d0.loss_cls: 5.7468, decode.d0.loss_mask: 0.5260, decode.d0.loss_dice: 0.8694, decode.d1.loss_cls: 0.4831, decode.d1.loss_mask: 0.5629, decode.d1.loss_dice: 0.8611, decode.d2.loss_cls: 0.4298, decode.d2.loss_mask: 0.5504, decode.d2.loss_dice: 0.8261, decode.d3.loss_cls: 0.4043, decode.d3.loss_mask: 0.5425, decode.d3.loss_dice: 0.8114, decode.d4.loss_cls: 0.3922, decode.d4.loss_mask: 0.5394, decode.d4.loss_dice: 0.8088, decode.d5.loss_cls: 0.3791, decode.d5.loss_mask: 0.5395, decode.d5.loss_dice: 0.8071, decode.d6.loss_cls: 0.3771, decode.d6.loss_mask: 0.5383, decode.d6.loss_dice: 0.8039, decode.d7.loss_cls: 0.3704, decode.d7.loss_mask: 0.5395, decode.d7.loss_dice: 0.8011, decode.d8.loss_cls: 0.3686, decode.d8.loss_mask: 0.5383, decode.d8.loss_dice: 0.8034, loss: 22.9312
2022-12-01 01:25:37,002 - mmseg - INFO - Iter [23850/40000]	lr: 5.371e-08, eta: 19:34:43, time: 4.111, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3739, decode.loss_mask: 0.5526, decode.loss_dice: 0.8152, decode.d0.loss_cls: 5.7549, decode.d0.loss_mask: 0.5401, decode.d0.loss_dice: 0.8818, decode.d1.loss_cls: 0.4895, decode.d1.loss_mask: 0.5813, decode.d1.loss_dice: 0.8760, decode.d2.loss_cls: 0.4350, decode.d2.loss_mask: 0.5668, decode.d2.loss_dice: 0.8400, decode.d3.loss_cls: 0.3996, decode.d3.loss_mask: 0.5613, decode.d3.loss_dice: 0.8277, decode.d4.loss_cls: 0.3916, decode.d4.loss_mask: 0.5597, decode.d4.loss_dice: 0.8239, decode.d5.loss_cls: 0.3857, decode.d5.loss_mask: 0.5539, decode.d5.loss_dice: 0.8185, decode.d6.loss_cls: 0.3804, decode.d6.loss_mask: 0.5529, decode.d6.loss_dice: 0.8140, decode.d7.loss_cls: 0.3762, decode.d7.loss_mask: 0.5542, decode.d7.loss_dice: 0.8198, decode.d8.loss_cls: 0.3761, decode.d8.loss_mask: 0.5526, decode.d8.loss_dice: 0.8176, loss: 23.2730
2022-12-01 01:29:02,775 - mmseg - INFO - Iter [23900/40000]	lr: 5.355e-08, eta: 19:30:57, time: 4.115, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3698, decode.loss_mask: 0.5484, decode.loss_dice: 0.8128, decode.d0.loss_cls: 5.7345, decode.d0.loss_mask: 0.5385, decode.d0.loss_dice: 0.8806, decode.d1.loss_cls: 0.4863, decode.d1.loss_mask: 0.5761, decode.d1.loss_dice: 0.8754, decode.d2.loss_cls: 0.4219, decode.d2.loss_mask: 0.5634, decode.d2.loss_dice: 0.8400, decode.d3.loss_cls: 0.3930, decode.d3.loss_mask: 0.5578, decode.d3.loss_dice: 0.8234, decode.d4.loss_cls: 0.3842, decode.d4.loss_mask: 0.5542, decode.d4.loss_dice: 0.8220, decode.d5.loss_cls: 0.3721, decode.d5.loss_mask: 0.5524, decode.d5.loss_dice: 0.8185, decode.d6.loss_cls: 0.3693, decode.d6.loss_mask: 0.5500, decode.d6.loss_dice: 0.8151, decode.d7.loss_cls: 0.3701, decode.d7.loss_mask: 0.5494, decode.d7.loss_dice: 0.8153, decode.d8.loss_cls: 0.3678, decode.d8.loss_mask: 0.5494, decode.d8.loss_dice: 0.8143, loss: 23.1260
2022-12-01 01:32:28,523 - mmseg - INFO - Iter [23950/40000]	lr: 5.338e-08, eta: 19:27:10, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3603, decode.loss_mask: 0.5444, decode.loss_dice: 0.7962, decode.d0.loss_cls: 5.7442, decode.d0.loss_mask: 0.5307, decode.d0.loss_dice: 0.8571, decode.d1.loss_cls: 0.4756, decode.d1.loss_mask: 0.5756, decode.d1.loss_dice: 0.8583, decode.d2.loss_cls: 0.4216, decode.d2.loss_mask: 0.5588, decode.d2.loss_dice: 0.8199, decode.d3.loss_cls: 0.3870, decode.d3.loss_mask: 0.5541, decode.d3.loss_dice: 0.8071, decode.d4.loss_cls: 0.3794, decode.d4.loss_mask: 0.5483, decode.d4.loss_dice: 0.8014, decode.d5.loss_cls: 0.3723, decode.d5.loss_mask: 0.5455, decode.d5.loss_dice: 0.7965, decode.d6.loss_cls: 0.3627, decode.d6.loss_mask: 0.5457, decode.d6.loss_dice: 0.7956, decode.d7.loss_cls: 0.3628, decode.d7.loss_mask: 0.5443, decode.d7.loss_dice: 0.7945, decode.d8.loss_cls: 0.3635, decode.d8.loss_mask: 0.5437, decode.d8.loss_dice: 0.7929, loss: 22.8399
2022-12-01 01:35:54,243 - mmseg - INFO - Saving checkpoint at 24000 iterations
2022-12-01 01:36:38,181 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 01:36:38,182 - mmseg - INFO - Iter [24000/40000]	lr: 5.321e-08, eta: 19:23:53, time: 4.993, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3598, decode.loss_mask: 0.5437, decode.loss_dice: 0.7920, decode.d0.loss_cls: 5.7109, decode.d0.loss_mask: 0.5322, decode.d0.loss_dice: 0.8538, decode.d1.loss_cls: 0.4770, decode.d1.loss_mask: 0.5668, decode.d1.loss_dice: 0.8459, decode.d2.loss_cls: 0.4239, decode.d2.loss_mask: 0.5551, decode.d2.loss_dice: 0.8134, decode.d3.loss_cls: 0.3897, decode.d3.loss_mask: 0.5502, decode.d3.loss_dice: 0.7972, decode.d4.loss_cls: 0.3767, decode.d4.loss_mask: 0.5477, decode.d4.loss_dice: 0.7992, decode.d5.loss_cls: 0.3709, decode.d5.loss_mask: 0.5430, decode.d5.loss_dice: 0.7915, decode.d6.loss_cls: 0.3661, decode.d6.loss_mask: 0.5448, decode.d6.loss_dice: 0.7905, decode.d7.loss_cls: 0.3632, decode.d7.loss_mask: 0.5418, decode.d7.loss_dice: 0.7889, decode.d8.loss_cls: 0.3627, decode.d8.loss_mask: 0.5417, decode.d8.loss_dice: 0.7884, loss: 22.7287
2022-12-01 01:39:36,183 - mmseg - INFO - per class results:
2022-12-01 01:39:36,188 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 83.94 | 90.24 |
|       building      | 85.57 |  91.8 |
|         sky         | 95.16 | 97.36 |
|        floor        | 85.05 | 90.37 |
|         tree        | 78.84 | 89.67 |
|       ceiling       | 86.59 | 92.09 |
|         road        | 88.42 | 91.69 |
|         bed         | 93.67 | 96.99 |
|      windowpane     |  69.3 | 82.01 |
|        grass        | 68.85 | 79.78 |
|       cabinet       | 61.02 | 71.12 |
|       sidewalk      | 72.15 | 84.24 |
|        person       |  88.4 | 93.92 |
|        earth        | 43.83 | 59.56 |
|         door        | 64.69 | 83.34 |
|        table        |  72.9 | 82.81 |
|       mountain      | 65.56 | 75.22 |
|        plant        | 57.22 | 71.33 |
|       curtain       | 82.54 | 92.13 |
|        chair        | 68.52 | 78.75 |
|         car         |  89.6 | 94.98 |
|        water        | 66.47 | 85.31 |
|       painting      | 82.44 | 92.41 |
|         sofa        | 84.95 | 90.09 |
|        shelf        | 49.54 | 61.75 |
|        house        | 52.63 | 68.87 |
|         sea         | 75.68 |  84.5 |
|        mirror       | 81.22 | 90.73 |
|         rug         | 71.15 | 85.01 |
|        field        | 37.41 | 70.66 |
|       armchair      | 63.94 | 82.46 |
|         seat        | 66.34 |  89.4 |
|        fence        | 57.94 | 76.15 |
|         desk        | 60.51 | 82.01 |
|         rock        | 58.41 | 80.93 |
|       wardrobe      | 57.57 | 84.94 |
|         lamp        | 80.77 | 90.06 |
|       bathtub       | 90.97 | 92.67 |
|       railing       | 44.36 | 64.48 |
|       cushion       | 76.19 | 89.65 |
|         base        | 46.18 | 77.05 |
|         box         | 44.03 | 63.35 |
|        column       | 62.29 | 74.29 |
|      signboard      | 43.97 | 68.42 |
|   chest of drawers  | 43.83 | 75.57 |
|       counter       | 58.25 | 65.21 |
|         sand        | 59.24 | 89.55 |
|         sink        | 83.27 | 87.24 |
|      skyscraper     | 42.99 | 51.33 |
|      fireplace      | 81.75 | 95.65 |
|     refrigerator    | 84.45 | 93.31 |
|      grandstand     | 46.71 | 76.17 |
|         path        | 28.37 | 42.25 |
|        stairs       | 33.18 | 42.56 |
|        runway       | 74.36 | 93.76 |
|         case        | 70.71 |  86.7 |
|      pool table     | 95.74 | 98.77 |
|        pillow       | 72.03 | 82.97 |
|     screen door     | 85.72 | 92.15 |
|       stairway      | 53.73 | 76.31 |
|        river        | 25.04 | 29.17 |
|        bridge       | 67.07 | 86.68 |
|       bookcase      | 44.55 | 66.56 |
|        blind        | 51.36 | 62.65 |
|     coffee table    | 73.31 | 89.27 |
|        toilet       | 92.31 | 95.39 |
|        flower       | 45.88 | 72.92 |
|         book        | 61.93 | 83.41 |
|         hill        | 13.67 | 28.88 |
|        bench        | 74.12 | 80.89 |
|      countertop     | 73.89 |  89.2 |
|        stove        | 86.47 | 90.42 |
|         palm        | 56.96 | 80.81 |
|    kitchen island   | 37.98 | 86.02 |
|       computer      | 82.57 | 89.36 |
|     swivel chair    | 55.51 | 87.47 |
|         boat        | 62.58 | 87.68 |
|         bar         | 70.34 | 77.31 |
|    arcade machine   | 92.03 | 98.41 |
|        hovel        | 46.79 | 68.53 |
|         bus         | 92.99 | 96.05 |
|        towel        | 84.06 | 93.81 |
|        light        |  64.9 | 80.22 |
|        truck        | 50.23 | 70.84 |
|        tower        |  33.6 | 63.68 |
|      chandelier     | 76.33 |  84.2 |
|        awning       | 33.69 | 54.56 |
|     streetlight     | 45.88 | 71.03 |
|        booth        | 56.84 | 71.45 |
| television receiver | 75.22 | 89.65 |
|       airplane      | 88.73 |  96.1 |
|      dirt track     | 14.96 | 39.07 |
|       apparel       | 52.75 | 88.83 |
|         pole        | 35.18 | 49.66 |
|         land        |  5.37 |  8.18 |
|      bannister      |  20.4 |  37.2 |
|      escalator      | 63.32 | 84.27 |
|       ottoman       | 57.96 | 79.52 |
|        bottle       | 52.63 |  80.4 |
|        buffet       | 39.73 | 51.43 |
|        poster       | 39.78 | 59.38 |
|        stage        | 30.98 | 64.77 |
|         van         | 53.04 | 76.22 |
|         ship        | 15.06 | 16.31 |
|       fountain      | 47.31 | 54.64 |
|    conveyer belt    | 77.08 | 97.58 |
|        canopy       | 54.16 |  92.5 |
|        washer       | 90.54 | 93.33 |
|      plaything      | 39.48 | 62.39 |
|    swimming pool    | 49.19 | 76.29 |
|        stool        | 60.22 | 84.81 |
|        barrel       | 68.08 | 93.99 |
|        basket       | 47.01 | 76.69 |
|      waterfall      | 45.41 | 55.87 |
|         tent        | 96.09 | 97.88 |
|         bag         | 35.34 | 49.82 |
|       minibike      | 81.41 | 93.73 |
|        cradle       | 91.38 | 97.37 |
|         oven        | 66.55 | 83.44 |
|         ball        | 42.62 | 46.19 |
|         food        |  68.3 | 81.67 |
|         step        | 27.89 |  36.8 |
|         tank        | 64.72 | 67.33 |
|      trade name     | 18.34 | 22.81 |
|      microwave      | 89.73 | 94.31 |
|         pot         | 62.77 |  74.5 |
|        animal       | 84.03 | 87.15 |
|       bicycle       | 62.81 | 81.36 |
|         lake        |  0.19 |  0.26 |
|      dishwasher     | 79.84 | 90.53 |
|        screen       | 58.07 | 91.41 |
|       blanket       | 44.11 | 60.38 |
|      sculpture      | 73.26 | 90.36 |
|         hood        | 69.49 | 74.44 |
|        sconce       | 67.65 | 81.69 |
|         vase        | 58.25 | 81.75 |
|    traffic light    | 51.88 | 70.51 |
|         tray        | 32.42 | 53.31 |
|        ashcan       | 50.47 | 76.55 |
|         fan         | 72.81 | 85.81 |
|         pier        |  37.4 | 41.94 |
|      crt screen     |  5.37 | 15.23 |
|        plate        | 70.01 | 84.97 |
|       monitor       |  3.99 |  5.1  |
|    bulletin board   | 65.41 | 91.54 |
|        shower       | 13.59 | 28.64 |
|       radiator      | 76.19 | 91.89 |
|        glass        | 28.64 | 31.49 |
|        clock        |  63.6 | 76.63 |
|         flag        | 68.91 | 87.22 |
+---------------------+-------+-------+
2022-12-01 01:39:36,188 - mmseg - INFO - Summary:
2022-12-01 01:39:36,188 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 86.98 | 60.21 | 75.04 |
+-------+-------+-------+
2022-12-01 01:39:36,193 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 01:39:36,194 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8698, mIoU: 0.6021, mAcc: 0.7504, IoU.wall: 0.8394, IoU.building: 0.8557, IoU.sky: 0.9516, IoU.floor: 0.8505, IoU.tree: 0.7884, IoU.ceiling: 0.8659, IoU.road: 0.8842, IoU.bed : 0.9367, IoU.windowpane: 0.6930, IoU.grass: 0.6885, IoU.cabinet: 0.6102, IoU.sidewalk: 0.7215, IoU.person: 0.8840, IoU.earth: 0.4383, IoU.door: 0.6469, IoU.table: 0.7290, IoU.mountain: 0.6556, IoU.plant: 0.5722, IoU.curtain: 0.8254, IoU.chair: 0.6852, IoU.car: 0.8960, IoU.water: 0.6647, IoU.painting: 0.8244, IoU.sofa: 0.8495, IoU.shelf: 0.4954, IoU.house: 0.5263, IoU.sea: 0.7568, IoU.mirror: 0.8122, IoU.rug: 0.7115, IoU.field: 0.3741, IoU.armchair: 0.6394, IoU.seat: 0.6634, IoU.fence: 0.5794, IoU.desk: 0.6051, IoU.rock: 0.5841, IoU.wardrobe: 0.5757, IoU.lamp: 0.8077, IoU.bathtub: 0.9097, IoU.railing: 0.4436, IoU.cushion: 0.7619, IoU.base: 0.4618, IoU.box: 0.4403, IoU.column: 0.6229, IoU.signboard: 0.4397, IoU.chest of drawers: 0.4383, IoU.counter: 0.5825, IoU.sand: 0.5924, IoU.sink: 0.8327, IoU.skyscraper: 0.4299, IoU.fireplace: 0.8175, IoU.refrigerator: 0.8445, IoU.grandstand: 0.4671, IoU.path: 0.2837, IoU.stairs: 0.3318, IoU.runway: 0.7436, IoU.case: 0.7071, IoU.pool table: 0.9574, IoU.pillow: 0.7203, IoU.screen door: 0.8572, IoU.stairway: 0.5373, IoU.river: 0.2504, IoU.bridge: 0.6707, IoU.bookcase: 0.4455, IoU.blind: 0.5136, IoU.coffee table: 0.7331, IoU.toilet: 0.9231, IoU.flower: 0.4588, IoU.book: 0.6193, IoU.hill: 0.1367, IoU.bench: 0.7412, IoU.countertop: 0.7389, IoU.stove: 0.8647, IoU.palm: 0.5696, IoU.kitchen island: 0.3798, IoU.computer: 0.8257, IoU.swivel chair: 0.5551, IoU.boat: 0.6258, IoU.bar: 0.7034, IoU.arcade machine: 0.9203, IoU.hovel: 0.4679, IoU.bus: 0.9299, IoU.towel: 0.8406, IoU.light: 0.6490, IoU.truck: 0.5023, IoU.tower: 0.3360, IoU.chandelier: 0.7633, IoU.awning: 0.3369, IoU.streetlight: 0.4588, IoU.booth: 0.5684, IoU.television receiver: 0.7522, IoU.airplane: 0.8873, IoU.dirt track: 0.1496, IoU.apparel: 0.5275, IoU.pole: 0.3518, IoU.land: 0.0537, IoU.bannister: 0.2040, IoU.escalator: 0.6332, IoU.ottoman: 0.5796, IoU.bottle: 0.5263, IoU.buffet: 0.3973, IoU.poster: 0.3978, IoU.stage: 0.3098, IoU.van: 0.5304, IoU.ship: 0.1506, IoU.fountain: 0.4731, IoU.conveyer belt: 0.7708, IoU.canopy: 0.5416, IoU.washer: 0.9054, IoU.plaything: 0.3948, IoU.swimming pool: 0.4919, IoU.stool: 0.6022, IoU.barrel: 0.6808, IoU.basket: 0.4701, IoU.waterfall: 0.4541, IoU.tent: 0.9609, IoU.bag: 0.3534, IoU.minibike: 0.8141, IoU.cradle: 0.9138, IoU.oven: 0.6655, IoU.ball: 0.4262, IoU.food: 0.6830, IoU.step: 0.2789, IoU.tank: 0.6472, IoU.trade name: 0.1834, IoU.microwave: 0.8973, IoU.pot: 0.6277, IoU.animal: 0.8403, IoU.bicycle: 0.6281, IoU.lake: 0.0019, IoU.dishwasher: 0.7984, IoU.screen: 0.5807, IoU.blanket: 0.4411, IoU.sculpture: 0.7326, IoU.hood: 0.6949, IoU.sconce: 0.6765, IoU.vase: 0.5825, IoU.traffic light: 0.5188, IoU.tray: 0.3242, IoU.ashcan: 0.5047, IoU.fan: 0.7281, IoU.pier: 0.3740, IoU.crt screen: 0.0537, IoU.plate: 0.7001, IoU.monitor: 0.0399, IoU.bulletin board: 0.6541, IoU.shower: 0.1359, IoU.radiator: 0.7619, IoU.glass: 0.2864, IoU.clock: 0.6360, IoU.flag: 0.6891, Acc.wall: 0.9024, Acc.building: 0.9180, Acc.sky: 0.9736, Acc.floor: 0.9037, Acc.tree: 0.8967, Acc.ceiling: 0.9209, Acc.road: 0.9169, Acc.bed : 0.9699, Acc.windowpane: 0.8201, Acc.grass: 0.7978, Acc.cabinet: 0.7112, Acc.sidewalk: 0.8424, Acc.person: 0.9392, Acc.earth: 0.5956, Acc.door: 0.8334, Acc.table: 0.8281, Acc.mountain: 0.7522, Acc.plant: 0.7133, Acc.curtain: 0.9213, Acc.chair: 0.7875, Acc.car: 0.9498, Acc.water: 0.8531, Acc.painting: 0.9241, Acc.sofa: 0.9009, Acc.shelf: 0.6175, Acc.house: 0.6887, Acc.sea: 0.8450, Acc.mirror: 0.9073, Acc.rug: 0.8501, Acc.field: 0.7066, Acc.armchair: 0.8246, Acc.seat: 0.8940, Acc.fence: 0.7615, Acc.desk: 0.8201, Acc.rock: 0.8093, Acc.wardrobe: 0.8494, Acc.lamp: 0.9006, Acc.bathtub: 0.9267, Acc.railing: 0.6448, Acc.cushion: 0.8965, Acc.base: 0.7705, Acc.box: 0.6335, Acc.column: 0.7429, Acc.signboard: 0.6842, Acc.chest of drawers: 0.7557, Acc.counter: 0.6521, Acc.sand: 0.8955, Acc.sink: 0.8724, Acc.skyscraper: 0.5133, Acc.fireplace: 0.9565, Acc.refrigerator: 0.9331, Acc.grandstand: 0.7617, Acc.path: 0.4225, Acc.stairs: 0.4256, Acc.runway: 0.9376, Acc.case: 0.8670, Acc.pool table: 0.9877, Acc.pillow: 0.8297, Acc.screen door: 0.9215, Acc.stairway: 0.7631, Acc.river: 0.2917, Acc.bridge: 0.8668, Acc.bookcase: 0.6656, Acc.blind: 0.6265, Acc.coffee table: 0.8927, Acc.toilet: 0.9539, Acc.flower: 0.7292, Acc.book: 0.8341, Acc.hill: 0.2888, Acc.bench: 0.8089, Acc.countertop: 0.8920, Acc.stove: 0.9042, Acc.palm: 0.8081, Acc.kitchen island: 0.8602, Acc.computer: 0.8936, Acc.swivel chair: 0.8747, Acc.boat: 0.8768, Acc.bar: 0.7731, Acc.arcade machine: 0.9841, Acc.hovel: 0.6853, Acc.bus: 0.9605, Acc.towel: 0.9381, Acc.light: 0.8022, Acc.truck: 0.7084, Acc.tower: 0.6368, Acc.chandelier: 0.8420, Acc.awning: 0.5456, Acc.streetlight: 0.7103, Acc.booth: 0.7145, Acc.television receiver: 0.8965, Acc.airplane: 0.9610, Acc.dirt track: 0.3907, Acc.apparel: 0.8883, Acc.pole: 0.4966, Acc.land: 0.0818, Acc.bannister: 0.3720, Acc.escalator: 0.8427, Acc.ottoman: 0.7952, Acc.bottle: 0.8040, Acc.buffet: 0.5143, Acc.poster: 0.5938, Acc.stage: 0.6477, Acc.van: 0.7622, Acc.ship: 0.1631, Acc.fountain: 0.5464, Acc.conveyer belt: 0.9758, Acc.canopy: 0.9250, Acc.washer: 0.9333, Acc.plaything: 0.6239, Acc.swimming pool: 0.7629, Acc.stool: 0.8481, Acc.barrel: 0.9399, Acc.basket: 0.7669, Acc.waterfall: 0.5587, Acc.tent: 0.9788, Acc.bag: 0.4982, Acc.minibike: 0.9373, Acc.cradle: 0.9737, Acc.oven: 0.8344, Acc.ball: 0.4619, Acc.food: 0.8167, Acc.step: 0.3680, Acc.tank: 0.6733, Acc.trade name: 0.2281, Acc.microwave: 0.9431, Acc.pot: 0.7450, Acc.animal: 0.8715, Acc.bicycle: 0.8136, Acc.lake: 0.0026, Acc.dishwasher: 0.9053, Acc.screen: 0.9141, Acc.blanket: 0.6038, Acc.sculpture: 0.9036, Acc.hood: 0.7444, Acc.sconce: 0.8169, Acc.vase: 0.8175, Acc.traffic light: 0.7051, Acc.tray: 0.5331, Acc.ashcan: 0.7655, Acc.fan: 0.8581, Acc.pier: 0.4194, Acc.crt screen: 0.1523, Acc.plate: 0.8497, Acc.monitor: 0.0510, Acc.bulletin board: 0.9154, Acc.shower: 0.2864, Acc.radiator: 0.9189, Acc.glass: 0.3149, Acc.clock: 0.7663, Acc.flag: 0.8722
2022-12-01 01:43:04,564 - mmseg - INFO - Iter [24050/40000]	lr: 5.305e-08, eta: 19:22:06, time: 7.728, data_time: 3.627, memory: 51902, decode.loss_cls: 0.3786, decode.loss_mask: 0.5430, decode.loss_dice: 0.8087, decode.d0.loss_cls: 5.7348, decode.d0.loss_mask: 0.5282, decode.d0.loss_dice: 0.8825, decode.d1.loss_cls: 0.5023, decode.d1.loss_mask: 0.5654, decode.d1.loss_dice: 0.8698, decode.d2.loss_cls: 0.4418, decode.d2.loss_mask: 0.5543, decode.d2.loss_dice: 0.8309, decode.d3.loss_cls: 0.4050, decode.d3.loss_mask: 0.5481, decode.d3.loss_dice: 0.8225, decode.d4.loss_cls: 0.3939, decode.d4.loss_mask: 0.5476, decode.d4.loss_dice: 0.8219, decode.d5.loss_cls: 0.3875, decode.d5.loss_mask: 0.5441, decode.d5.loss_dice: 0.8146, decode.d6.loss_cls: 0.3859, decode.d6.loss_mask: 0.5430, decode.d6.loss_dice: 0.8113, decode.d7.loss_cls: 0.3797, decode.d7.loss_mask: 0.5451, decode.d7.loss_dice: 0.8129, decode.d8.loss_cls: 0.3783, decode.d8.loss_mask: 0.5432, decode.d8.loss_dice: 0.8102, loss: 23.1349
2022-12-01 01:46:30,656 - mmseg - INFO - Iter [24100/40000]	lr: 5.288e-08, eta: 19:18:20, time: 4.122, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3710, decode.loss_mask: 0.5506, decode.loss_dice: 0.7942, decode.d0.loss_cls: 5.6980, decode.d0.loss_mask: 0.5413, decode.d0.loss_dice: 0.8618, decode.d1.loss_cls: 0.4802, decode.d1.loss_mask: 0.5771, decode.d1.loss_dice: 0.8496, decode.d2.loss_cls: 0.4244, decode.d2.loss_mask: 0.5657, decode.d2.loss_dice: 0.8171, decode.d3.loss_cls: 0.3911, decode.d3.loss_mask: 0.5592, decode.d3.loss_dice: 0.8065, decode.d4.loss_cls: 0.3805, decode.d4.loss_mask: 0.5567, decode.d4.loss_dice: 0.8019, decode.d5.loss_cls: 0.3731, decode.d5.loss_mask: 0.5554, decode.d5.loss_dice: 0.7964, decode.d6.loss_cls: 0.3698, decode.d6.loss_mask: 0.5527, decode.d6.loss_dice: 0.7948, decode.d7.loss_cls: 0.3651, decode.d7.loss_mask: 0.5534, decode.d7.loss_dice: 0.7976, decode.d8.loss_cls: 0.3684, decode.d8.loss_mask: 0.5511, decode.d8.loss_dice: 0.7969, loss: 22.9016
2022-12-01 01:49:56,322 - mmseg - INFO - Iter [24150/40000]	lr: 5.272e-08, eta: 19:14:33, time: 4.113, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3785, decode.loss_mask: 0.5551, decode.loss_dice: 0.8185, decode.d0.loss_cls: 5.7273, decode.d0.loss_mask: 0.5432, decode.d0.loss_dice: 0.8822, decode.d1.loss_cls: 0.5036, decode.d1.loss_mask: 0.5808, decode.d1.loss_dice: 0.8772, decode.d2.loss_cls: 0.4380, decode.d2.loss_mask: 0.5683, decode.d2.loss_dice: 0.8440, decode.d3.loss_cls: 0.4036, decode.d3.loss_mask: 0.5618, decode.d3.loss_dice: 0.8315, decode.d4.loss_cls: 0.3932, decode.d4.loss_mask: 0.5583, decode.d4.loss_dice: 0.8246, decode.d5.loss_cls: 0.3854, decode.d5.loss_mask: 0.5581, decode.d5.loss_dice: 0.8184, decode.d6.loss_cls: 0.3812, decode.d6.loss_mask: 0.5567, decode.d6.loss_dice: 0.8168, decode.d7.loss_cls: 0.3768, decode.d7.loss_mask: 0.5565, decode.d7.loss_dice: 0.8163, decode.d8.loss_cls: 0.3793, decode.d8.loss_mask: 0.5538, decode.d8.loss_dice: 0.8155, loss: 23.3048
2022-12-01 01:53:21,761 - mmseg - INFO - Iter [24200/40000]	lr: 5.255e-08, eta: 19:10:45, time: 4.109, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3772, decode.loss_mask: 0.5388, decode.loss_dice: 0.7890, decode.d0.loss_cls: 5.7022, decode.d0.loss_mask: 0.5284, decode.d0.loss_dice: 0.8673, decode.d1.loss_cls: 0.4913, decode.d1.loss_mask: 0.5651, decode.d1.loss_dice: 0.8544, decode.d2.loss_cls: 0.4352, decode.d2.loss_mask: 0.5511, decode.d2.loss_dice: 0.8206, decode.d3.loss_cls: 0.4013, decode.d3.loss_mask: 0.5454, decode.d3.loss_dice: 0.8062, decode.d4.loss_cls: 0.3898, decode.d4.loss_mask: 0.5441, decode.d4.loss_dice: 0.8022, decode.d5.loss_cls: 0.3811, decode.d5.loss_mask: 0.5401, decode.d5.loss_dice: 0.7964, decode.d6.loss_cls: 0.3769, decode.d6.loss_mask: 0.5400, decode.d6.loss_dice: 0.7914, decode.d7.loss_cls: 0.3773, decode.d7.loss_mask: 0.5383, decode.d7.loss_dice: 0.7911, decode.d8.loss_cls: 0.3726, decode.d8.loss_mask: 0.5398, decode.d8.loss_dice: 0.7931, loss: 22.8480
2022-12-01 01:56:47,862 - mmseg - INFO - Iter [24250/40000]	lr: 5.238e-08, eta: 19:06:59, time: 4.122, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3604, decode.loss_mask: 0.5503, decode.loss_dice: 0.7930, decode.d0.loss_cls: 5.7029, decode.d0.loss_mask: 0.5365, decode.d0.loss_dice: 0.8538, decode.d1.loss_cls: 0.4731, decode.d1.loss_mask: 0.5726, decode.d1.loss_dice: 0.8530, decode.d2.loss_cls: 0.4184, decode.d2.loss_mask: 0.5615, decode.d2.loss_dice: 0.8157, decode.d3.loss_cls: 0.3834, decode.d3.loss_mask: 0.5578, decode.d3.loss_dice: 0.8042, decode.d4.loss_cls: 0.3757, decode.d4.loss_mask: 0.5536, decode.d4.loss_dice: 0.8016, decode.d5.loss_cls: 0.3686, decode.d5.loss_mask: 0.5540, decode.d5.loss_dice: 0.7955, decode.d6.loss_cls: 0.3603, decode.d6.loss_mask: 0.5521, decode.d6.loss_dice: 0.7945, decode.d7.loss_cls: 0.3542, decode.d7.loss_mask: 0.5511, decode.d7.loss_dice: 0.7958, decode.d8.loss_cls: 0.3588, decode.d8.loss_mask: 0.5519, decode.d8.loss_dice: 0.7957, loss: 22.8000
2022-12-01 02:00:13,518 - mmseg - INFO - Iter [24300/40000]	lr: 5.222e-08, eta: 19:03:12, time: 4.113, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3668, decode.loss_mask: 0.5665, decode.loss_dice: 0.8371, decode.d0.loss_cls: 5.6882, decode.d0.loss_mask: 0.5546, decode.d0.loss_dice: 0.8925, decode.d1.loss_cls: 0.4818, decode.d1.loss_mask: 0.5943, decode.d1.loss_dice: 0.8859, decode.d2.loss_cls: 0.4248, decode.d2.loss_mask: 0.5809, decode.d2.loss_dice: 0.8596, decode.d3.loss_cls: 0.3972, decode.d3.loss_mask: 0.5732, decode.d3.loss_dice: 0.8470, decode.d4.loss_cls: 0.3892, decode.d4.loss_mask: 0.5707, decode.d4.loss_dice: 0.8440, decode.d5.loss_cls: 0.3773, decode.d5.loss_mask: 0.5678, decode.d5.loss_dice: 0.8408, decode.d6.loss_cls: 0.3736, decode.d6.loss_mask: 0.5676, decode.d6.loss_dice: 0.8391, decode.d7.loss_cls: 0.3690, decode.d7.loss_mask: 0.5643, decode.d7.loss_dice: 0.8357, decode.d8.loss_cls: 0.3704, decode.d8.loss_mask: 0.5662, decode.d8.loss_dice: 0.8389, loss: 23.4647
2022-12-01 02:03:39,380 - mmseg - INFO - Iter [24350/40000]	lr: 5.205e-08, eta: 18:59:26, time: 4.117, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3741, decode.loss_mask: 0.5523, decode.loss_dice: 0.8049, decode.d0.loss_cls: 5.6810, decode.d0.loss_mask: 0.5404, decode.d0.loss_dice: 0.8667, decode.d1.loss_cls: 0.4842, decode.d1.loss_mask: 0.5817, decode.d1.loss_dice: 0.8677, decode.d2.loss_cls: 0.4302, decode.d2.loss_mask: 0.5651, decode.d2.loss_dice: 0.8290, decode.d3.loss_cls: 0.4011, decode.d3.loss_mask: 0.5579, decode.d3.loss_dice: 0.8195, decode.d4.loss_cls: 0.3960, decode.d4.loss_mask: 0.5532, decode.d4.loss_dice: 0.8098, decode.d5.loss_cls: 0.3801, decode.d5.loss_mask: 0.5528, decode.d5.loss_dice: 0.8082, decode.d6.loss_cls: 0.3817, decode.d6.loss_mask: 0.5503, decode.d6.loss_dice: 0.8036, decode.d7.loss_cls: 0.3757, decode.d7.loss_mask: 0.5521, decode.d7.loss_dice: 0.8050, decode.d8.loss_cls: 0.3760, decode.d8.loss_mask: 0.5517, decode.d8.loss_dice: 0.8020, loss: 23.0536
2022-12-01 02:07:04,973 - mmseg - INFO - Iter [24400/40000]	lr: 5.188e-08, eta: 18:55:39, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3638, decode.loss_mask: 0.5418, decode.loss_dice: 0.8099, decode.d0.loss_cls: 5.6895, decode.d0.loss_mask: 0.5222, decode.d0.loss_dice: 0.8656, decode.d1.loss_cls: 0.4784, decode.d1.loss_mask: 0.5679, decode.d1.loss_dice: 0.8682, decode.d2.loss_cls: 0.4196, decode.d2.loss_mask: 0.5532, decode.d2.loss_dice: 0.8314, decode.d3.loss_cls: 0.3871, decode.d3.loss_mask: 0.5477, decode.d3.loss_dice: 0.8164, decode.d4.loss_cls: 0.3823, decode.d4.loss_mask: 0.5465, decode.d4.loss_dice: 0.8123, decode.d5.loss_cls: 0.3729, decode.d5.loss_mask: 0.5438, decode.d5.loss_dice: 0.8127, decode.d6.loss_cls: 0.3657, decode.d6.loss_mask: 0.5431, decode.d6.loss_dice: 0.8064, decode.d7.loss_cls: 0.3645, decode.d7.loss_mask: 0.5411, decode.d7.loss_dice: 0.8101, decode.d8.loss_cls: 0.3638, decode.d8.loss_mask: 0.5412, decode.d8.loss_dice: 0.8071, loss: 22.8758
2022-12-01 02:10:30,897 - mmseg - INFO - Iter [24450/40000]	lr: 5.172e-08, eta: 18:51:53, time: 4.118, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3743, decode.loss_mask: 0.5210, decode.loss_dice: 0.7820, decode.d0.loss_cls: 5.6790, decode.d0.loss_mask: 0.5124, decode.d0.loss_dice: 0.8490, decode.d1.loss_cls: 0.4766, decode.d1.loss_mask: 0.5483, decode.d1.loss_dice: 0.8380, decode.d2.loss_cls: 0.4228, decode.d2.loss_mask: 0.5358, decode.d2.loss_dice: 0.8088, decode.d3.loss_cls: 0.3922, decode.d3.loss_mask: 0.5323, decode.d3.loss_dice: 0.7956, decode.d4.loss_cls: 0.3854, decode.d4.loss_mask: 0.5308, decode.d4.loss_dice: 0.7926, decode.d5.loss_cls: 0.3767, decode.d5.loss_mask: 0.5267, decode.d5.loss_dice: 0.7869, decode.d6.loss_cls: 0.3717, decode.d6.loss_mask: 0.5244, decode.d6.loss_dice: 0.7870, decode.d7.loss_cls: 0.3709, decode.d7.loss_mask: 0.5240, decode.d7.loss_dice: 0.7867, decode.d8.loss_cls: 0.3753, decode.d8.loss_mask: 0.5226, decode.d8.loss_dice: 0.7832, loss: 22.5129
2022-12-01 02:13:56,354 - mmseg - INFO - Iter [24500/40000]	lr: 5.155e-08, eta: 18:48:06, time: 4.110, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3551, decode.loss_mask: 0.5644, decode.loss_dice: 0.8220, decode.d0.loss_cls: 5.6656, decode.d0.loss_mask: 0.5477, decode.d0.loss_dice: 0.8833, decode.d1.loss_cls: 0.4665, decode.d1.loss_mask: 0.5872, decode.d1.loss_dice: 0.8772, decode.d2.loss_cls: 0.4150, decode.d2.loss_mask: 0.5756, decode.d2.loss_dice: 0.8444, decode.d3.loss_cls: 0.3809, decode.d3.loss_mask: 0.5705, decode.d3.loss_dice: 0.8285, decode.d4.loss_cls: 0.3709, decode.d4.loss_mask: 0.5686, decode.d4.loss_dice: 0.8291, decode.d5.loss_cls: 0.3631, decode.d5.loss_mask: 0.5661, decode.d5.loss_dice: 0.8258, decode.d6.loss_cls: 0.3573, decode.d6.loss_mask: 0.5643, decode.d6.loss_dice: 0.8260, decode.d7.loss_cls: 0.3576, decode.d7.loss_mask: 0.5641, decode.d7.loss_dice: 0.8200, decode.d8.loss_cls: 0.3536, decode.d8.loss_mask: 0.5635, decode.d8.loss_dice: 0.8201, loss: 23.1339
2022-12-01 02:17:22,090 - mmseg - INFO - Iter [24550/40000]	lr: 5.139e-08, eta: 18:44:20, time: 4.115, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3720, decode.loss_mask: 0.5388, decode.loss_dice: 0.7997, decode.d0.loss_cls: 5.6801, decode.d0.loss_mask: 0.5252, decode.d0.loss_dice: 0.8648, decode.d1.loss_cls: 0.4827, decode.d1.loss_mask: 0.5657, decode.d1.loss_dice: 0.8579, decode.d2.loss_cls: 0.4325, decode.d2.loss_mask: 0.5516, decode.d2.loss_dice: 0.8264, decode.d3.loss_cls: 0.3956, decode.d3.loss_mask: 0.5480, decode.d3.loss_dice: 0.8099, decode.d4.loss_cls: 0.3893, decode.d4.loss_mask: 0.5433, decode.d4.loss_dice: 0.8071, decode.d5.loss_cls: 0.3773, decode.d5.loss_mask: 0.5430, decode.d5.loss_dice: 0.8041, decode.d6.loss_cls: 0.3721, decode.d6.loss_mask: 0.5398, decode.d6.loss_dice: 0.8022, decode.d7.loss_cls: 0.3689, decode.d7.loss_mask: 0.5397, decode.d7.loss_dice: 0.8074, decode.d8.loss_cls: 0.3711, decode.d8.loss_mask: 0.5370, decode.d8.loss_dice: 0.7995, loss: 22.8528
2022-12-01 02:20:47,843 - mmseg - INFO - Iter [24600/40000]	lr: 5.122e-08, eta: 18:40:34, time: 4.115, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3713, decode.loss_mask: 0.5464, decode.loss_dice: 0.8200, decode.d0.loss_cls: 5.6708, decode.d0.loss_mask: 0.5359, decode.d0.loss_dice: 0.8938, decode.d1.loss_cls: 0.4922, decode.d1.loss_mask: 0.5726, decode.d1.loss_dice: 0.8796, decode.d2.loss_cls: 0.4388, decode.d2.loss_mask: 0.5605, decode.d2.loss_dice: 0.8447, decode.d3.loss_cls: 0.4026, decode.d3.loss_mask: 0.5558, decode.d3.loss_dice: 0.8305, decode.d4.loss_cls: 0.3936, decode.d4.loss_mask: 0.5509, decode.d4.loss_dice: 0.8280, decode.d5.loss_cls: 0.3824, decode.d5.loss_mask: 0.5504, decode.d5.loss_dice: 0.8258, decode.d6.loss_cls: 0.3787, decode.d6.loss_mask: 0.5470, decode.d6.loss_dice: 0.8202, decode.d7.loss_cls: 0.3776, decode.d7.loss_mask: 0.5477, decode.d7.loss_dice: 0.8210, decode.d8.loss_cls: 0.3726, decode.d8.loss_mask: 0.5455, decode.d8.loss_dice: 0.8214, loss: 23.1785
2022-12-01 02:24:15,820 - mmseg - INFO - Iter [24650/40000]	lr: 5.105e-08, eta: 18:36:49, time: 4.159, data_time: 0.066, memory: 51902, decode.loss_cls: 0.3535, decode.loss_mask: 0.5482, decode.loss_dice: 0.8046, decode.d0.loss_cls: 5.6609, decode.d0.loss_mask: 0.5324, decode.d0.loss_dice: 0.8686, decode.d1.loss_cls: 0.4705, decode.d1.loss_mask: 0.5705, decode.d1.loss_dice: 0.8579, decode.d2.loss_cls: 0.4120, decode.d2.loss_mask: 0.5596, decode.d2.loss_dice: 0.8264, decode.d3.loss_cls: 0.3815, decode.d3.loss_mask: 0.5548, decode.d3.loss_dice: 0.8102, decode.d4.loss_cls: 0.3733, decode.d4.loss_mask: 0.5501, decode.d4.loss_dice: 0.8089, decode.d5.loss_cls: 0.3639, decode.d5.loss_mask: 0.5490, decode.d5.loss_dice: 0.8087, decode.d6.loss_cls: 0.3543, decode.d6.loss_mask: 0.5501, decode.d6.loss_dice: 0.8061, decode.d7.loss_cls: 0.3534, decode.d7.loss_mask: 0.5482, decode.d7.loss_dice: 0.8042, decode.d8.loss_cls: 0.3571, decode.d8.loss_mask: 0.5474, decode.d8.loss_dice: 0.8020, loss: 22.7880
2022-12-01 02:27:41,656 - mmseg - INFO - Iter [24700/40000]	lr: 5.089e-08, eta: 18:33:03, time: 4.117, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3706, decode.loss_mask: 0.5365, decode.loss_dice: 0.8106, decode.d0.loss_cls: 5.6748, decode.d0.loss_mask: 0.5279, decode.d0.loss_dice: 0.8769, decode.d1.loss_cls: 0.4936, decode.d1.loss_mask: 0.5612, decode.d1.loss_dice: 0.8670, decode.d2.loss_cls: 0.4312, decode.d2.loss_mask: 0.5485, decode.d2.loss_dice: 0.8351, decode.d3.loss_cls: 0.3996, decode.d3.loss_mask: 0.5441, decode.d3.loss_dice: 0.8187, decode.d4.loss_cls: 0.3909, decode.d4.loss_mask: 0.5399, decode.d4.loss_dice: 0.8188, decode.d5.loss_cls: 0.3816, decode.d5.loss_mask: 0.5395, decode.d5.loss_dice: 0.8168, decode.d6.loss_cls: 0.3754, decode.d6.loss_mask: 0.5391, decode.d6.loss_dice: 0.8141, decode.d7.loss_cls: 0.3709, decode.d7.loss_mask: 0.5387, decode.d7.loss_dice: 0.8167, decode.d8.loss_cls: 0.3737, decode.d8.loss_mask: 0.5380, decode.d8.loss_dice: 0.8122, loss: 22.9629
2022-12-01 02:31:07,428 - mmseg - INFO - Iter [24750/40000]	lr: 5.072e-08, eta: 18:29:17, time: 4.115, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3685, decode.loss_mask: 0.5489, decode.loss_dice: 0.8217, decode.d0.loss_cls: 5.6512, decode.d0.loss_mask: 0.5359, decode.d0.loss_dice: 0.8831, decode.d1.loss_cls: 0.4925, decode.d1.loss_mask: 0.5723, decode.d1.loss_dice: 0.8727, decode.d2.loss_cls: 0.4269, decode.d2.loss_mask: 0.5576, decode.d2.loss_dice: 0.8416, decode.d3.loss_cls: 0.3965, decode.d3.loss_mask: 0.5539, decode.d3.loss_dice: 0.8305, decode.d4.loss_cls: 0.3861, decode.d4.loss_mask: 0.5540, decode.d4.loss_dice: 0.8286, decode.d5.loss_cls: 0.3752, decode.d5.loss_mask: 0.5516, decode.d5.loss_dice: 0.8248, decode.d6.loss_cls: 0.3722, decode.d6.loss_mask: 0.5508, decode.d6.loss_dice: 0.8170, decode.d7.loss_cls: 0.3670, decode.d7.loss_mask: 0.5515, decode.d7.loss_dice: 0.8193, decode.d8.loss_cls: 0.3706, decode.d8.loss_mask: 0.5479, decode.d8.loss_dice: 0.8204, loss: 23.0908
2022-12-01 02:34:32,941 - mmseg - INFO - Iter [24800/40000]	lr: 5.055e-08, eta: 18:25:31, time: 4.110, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3772, decode.loss_mask: 0.5563, decode.loss_dice: 0.8287, decode.d0.loss_cls: 5.6637, decode.d0.loss_mask: 0.5384, decode.d0.loss_dice: 0.8924, decode.d1.loss_cls: 0.4902, decode.d1.loss_mask: 0.5789, decode.d1.loss_dice: 0.8844, decode.d2.loss_cls: 0.4358, decode.d2.loss_mask: 0.5685, decode.d2.loss_dice: 0.8506, decode.d3.loss_cls: 0.4046, decode.d3.loss_mask: 0.5622, decode.d3.loss_dice: 0.8385, decode.d4.loss_cls: 0.3923, decode.d4.loss_mask: 0.5587, decode.d4.loss_dice: 0.8358, decode.d5.loss_cls: 0.3833, decode.d5.loss_mask: 0.5594, decode.d5.loss_dice: 0.8286, decode.d6.loss_cls: 0.3742, decode.d6.loss_mask: 0.5578, decode.d6.loss_dice: 0.8304, decode.d7.loss_cls: 0.3745, decode.d7.loss_mask: 0.5586, decode.d7.loss_dice: 0.8283, decode.d8.loss_cls: 0.3743, decode.d8.loss_mask: 0.5561, decode.d8.loss_dice: 0.8296, loss: 23.3121
2022-12-01 02:37:58,805 - mmseg - INFO - Iter [24850/40000]	lr: 5.039e-08, eta: 18:21:45, time: 4.117, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3488, decode.loss_mask: 0.5446, decode.loss_dice: 0.7851, decode.d0.loss_cls: 5.5961, decode.d0.loss_mask: 0.5292, decode.d0.loss_dice: 0.8503, decode.d1.loss_cls: 0.4558, decode.d1.loss_mask: 0.5685, decode.d1.loss_dice: 0.8421, decode.d2.loss_cls: 0.3999, decode.d2.loss_mask: 0.5602, decode.d2.loss_dice: 0.8114, decode.d3.loss_cls: 0.3746, decode.d3.loss_mask: 0.5501, decode.d3.loss_dice: 0.7963, decode.d4.loss_cls: 0.3670, decode.d4.loss_mask: 0.5461, decode.d4.loss_dice: 0.7955, decode.d5.loss_cls: 0.3590, decode.d5.loss_mask: 0.5420, decode.d5.loss_dice: 0.7867, decode.d6.loss_cls: 0.3525, decode.d6.loss_mask: 0.5428, decode.d6.loss_dice: 0.7824, decode.d7.loss_cls: 0.3493, decode.d7.loss_mask: 0.5446, decode.d7.loss_dice: 0.7865, decode.d8.loss_cls: 0.3493, decode.d8.loss_mask: 0.5433, decode.d8.loss_dice: 0.7832, loss: 22.4433
2022-12-01 02:41:24,758 - mmseg - INFO - Iter [24900/40000]	lr: 5.022e-08, eta: 18:18:00, time: 4.119, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3599, decode.loss_mask: 0.5299, decode.loss_dice: 0.8029, decode.d0.loss_cls: 5.6617, decode.d0.loss_mask: 0.5206, decode.d0.loss_dice: 0.8744, decode.d1.loss_cls: 0.4790, decode.d1.loss_mask: 0.5557, decode.d1.loss_dice: 0.8668, decode.d2.loss_cls: 0.4188, decode.d2.loss_mask: 0.5451, decode.d2.loss_dice: 0.8265, decode.d3.loss_cls: 0.3861, decode.d3.loss_mask: 0.5371, decode.d3.loss_dice: 0.8165, decode.d4.loss_cls: 0.3758, decode.d4.loss_mask: 0.5339, decode.d4.loss_dice: 0.8125, decode.d5.loss_cls: 0.3653, decode.d5.loss_mask: 0.5321, decode.d5.loss_dice: 0.8081, decode.d6.loss_cls: 0.3615, decode.d6.loss_mask: 0.5319, decode.d6.loss_dice: 0.8050, decode.d7.loss_cls: 0.3557, decode.d7.loss_mask: 0.5295, decode.d7.loss_dice: 0.8054, decode.d8.loss_cls: 0.3545, decode.d8.loss_mask: 0.5306, decode.d8.loss_dice: 0.8025, loss: 22.6854
2022-12-01 02:44:50,212 - mmseg - INFO - Iter [24950/40000]	lr: 5.006e-08, eta: 18:14:14, time: 4.109, data_time: 0.022, memory: 51902, decode.loss_cls: 0.3470, decode.loss_mask: 0.5401, decode.loss_dice: 0.7961, decode.d0.loss_cls: 5.6253, decode.d0.loss_mask: 0.5252, decode.d0.loss_dice: 0.8628, decode.d1.loss_cls: 0.4607, decode.d1.loss_mask: 0.5639, decode.d1.loss_dice: 0.8525, decode.d2.loss_cls: 0.4046, decode.d2.loss_mask: 0.5512, decode.d2.loss_dice: 0.8175, decode.d3.loss_cls: 0.3724, decode.d3.loss_mask: 0.5454, decode.d3.loss_dice: 0.8114, decode.d4.loss_cls: 0.3637, decode.d4.loss_mask: 0.5436, decode.d4.loss_dice: 0.8059, decode.d5.loss_cls: 0.3507, decode.d5.loss_mask: 0.5409, decode.d5.loss_dice: 0.8053, decode.d6.loss_cls: 0.3489, decode.d6.loss_mask: 0.5422, decode.d6.loss_dice: 0.8019, decode.d7.loss_cls: 0.3459, decode.d7.loss_mask: 0.5404, decode.d7.loss_dice: 0.8014, decode.d8.loss_cls: 0.3451, decode.d8.loss_mask: 0.5405, decode.d8.loss_dice: 0.8001, loss: 22.5528
2022-12-01 02:48:16,178 - mmseg - INFO - Saving checkpoint at 25000 iterations
2022-12-01 02:48:58,890 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 02:48:58,891 - mmseg - INFO - Iter [25000/40000]	lr: 4.989e-08, eta: 18:10:54, time: 4.974, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3824, decode.loss_mask: 0.5287, decode.loss_dice: 0.8097, decode.d0.loss_cls: 5.6435, decode.d0.loss_mask: 0.5191, decode.d0.loss_dice: 0.8760, decode.d1.loss_cls: 0.4901, decode.d1.loss_mask: 0.5531, decode.d1.loss_dice: 0.8725, decode.d2.loss_cls: 0.4392, decode.d2.loss_mask: 0.5383, decode.d2.loss_dice: 0.8343, decode.d3.loss_cls: 0.4061, decode.d3.loss_mask: 0.5327, decode.d3.loss_dice: 0.8211, decode.d4.loss_cls: 0.3958, decode.d4.loss_mask: 0.5320, decode.d4.loss_dice: 0.8171, decode.d5.loss_cls: 0.3898, decode.d5.loss_mask: 0.5306, decode.d5.loss_dice: 0.8123, decode.d6.loss_cls: 0.3815, decode.d6.loss_mask: 0.5314, decode.d6.loss_dice: 0.8097, decode.d7.loss_cls: 0.3825, decode.d7.loss_mask: 0.5283, decode.d7.loss_dice: 0.8131, decode.d8.loss_cls: 0.3820, decode.d8.loss_mask: 0.5300, decode.d8.loss_dice: 0.8126, loss: 22.8956
2022-12-01 02:51:56,924 - mmseg - INFO - per class results:
2022-12-01 02:51:56,929 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 83.55 | 89.31 |
|       building      | 85.18 | 91.58 |
|         sky         | 95.13 | 97.58 |
|        floor        | 85.35 | 90.39 |
|         tree        | 78.48 | 88.91 |
|       ceiling       | 87.75 |  94.1 |
|         road        |  88.2 | 91.31 |
|         bed         | 93.66 | 96.93 |
|      windowpane     | 69.12 | 82.15 |
|        grass        | 69.46 |  81.7 |
|       cabinet       | 62.35 | 70.74 |
|       sidewalk      |  72.6 | 86.77 |
|        person       | 88.41 | 93.98 |
|        earth        | 43.22 | 57.75 |
|         door        |  65.7 | 82.64 |
|        table        | 72.25 | 82.48 |
|       mountain      | 65.64 | 76.23 |
|        plant        | 57.99 | 70.79 |
|       curtain       | 83.02 | 91.31 |
|        chair        | 69.93 | 79.96 |
|         car         | 89.06 | 94.88 |
|        water        | 68.09 | 85.12 |
|       painting      | 80.09 | 90.95 |
|         sofa        | 85.16 | 90.88 |
|        shelf        | 46.29 | 56.42 |
|        house        |  53.3 | 70.13 |
|         sea         | 80.17 |  89.5 |
|        mirror       | 81.34 |  91.5 |
|         rug         | 73.62 | 87.51 |
|        field        | 37.52 | 72.06 |
|       armchair      | 64.59 | 79.26 |
|         seat        | 68.93 | 92.31 |
|        fence        | 57.73 | 79.76 |
|         desk        | 59.21 | 81.59 |
|         rock        | 61.42 | 75.68 |
|       wardrobe      | 56.65 | 87.43 |
|         lamp        | 80.58 | 89.47 |
|       bathtub       | 91.49 | 93.82 |
|       railing       | 48.01 | 72.45 |
|       cushion       | 76.21 | 89.33 |
|         base        | 48.12 | 78.77 |
|         box         | 40.75 | 57.21 |
|        column       | 59.61 | 75.79 |
|      signboard      | 44.48 | 64.97 |
|   chest of drawers  | 43.81 | 76.12 |
|       counter       | 58.86 |  68.8 |
|         sand        | 58.39 | 88.26 |
|         sink        | 83.11 | 87.11 |
|      skyscraper     | 44.04 | 56.02 |
|      fireplace      | 80.68 | 96.18 |
|     refrigerator    | 85.27 | 96.19 |
|      grandstand     | 48.75 | 81.31 |
|         path        |  30.4 | 43.38 |
|        stairs       | 37.73 | 52.26 |
|        runway       | 74.45 | 94.23 |
|         case        |  68.5 | 84.86 |
|      pool table     | 95.84 | 98.66 |
|        pillow       | 72.26 | 84.44 |
|     screen door     | 86.07 | 94.88 |
|       stairway      | 56.35 | 71.57 |
|        river        |  31.2 | 37.99 |
|        bridge       | 71.77 | 86.69 |
|       bookcase      | 39.26 | 68.77 |
|        blind        | 48.83 | 63.11 |
|     coffee table    | 73.72 | 91.89 |
|        toilet       | 93.17 | 96.74 |
|        flower       | 43.29 | 65.22 |
|         book        | 60.72 | 80.85 |
|         hill        | 15.74 | 27.65 |
|        bench        | 75.47 |  84.6 |
|      countertop     | 74.02 |  89.6 |
|        stove        | 86.74 | 90.78 |
|         palm        | 55.41 | 83.06 |
|    kitchen island   | 45.07 | 95.25 |
|       computer      | 82.61 | 90.19 |
|     swivel chair    | 55.37 |  85.7 |
|         boat        | 56.36 | 88.26 |
|         bar         | 70.99 | 78.27 |
|    arcade machine   | 91.64 | 98.63 |
|        hovel        | 49.54 | 68.25 |
|         bus         | 95.15 | 97.45 |
|        towel        | 82.42 |  92.0 |
|        light        | 64.43 | 80.66 |
|        truck        | 55.46 | 70.39 |
|        tower        | 33.38 | 63.05 |
|      chandelier     | 76.48 | 87.96 |
|        awning       | 31.83 | 53.37 |
|     streetlight     | 45.64 | 70.54 |
|        booth        | 67.16 | 80.64 |
| television receiver | 77.78 | 91.84 |
|       airplane      | 88.81 | 96.56 |
|      dirt track     | 20.13 | 47.41 |
|       apparel       | 50.49 | 88.23 |
|         pole        | 35.72 | 52.56 |
|         land        |  7.1  | 10.85 |
|      bannister      | 21.32 |  33.3 |
|      escalator      | 67.02 | 84.11 |
|       ottoman       | 56.47 | 87.55 |
|        bottle       |  53.1 | 82.96 |
|        buffet       | 46.17 | 65.53 |
|        poster       | 31.58 | 62.48 |
|        stage        | 26.96 | 65.79 |
|         van         | 48.33 | 72.45 |
|         ship        | 20.64 |  21.8 |
|       fountain      | 46.75 | 54.57 |
|    conveyer belt    | 81.81 | 97.15 |
|        canopy       | 56.54 | 73.84 |
|        washer       | 90.69 | 93.68 |
|      plaything      | 37.29 | 59.01 |
|    swimming pool    | 46.28 |  76.4 |
|        stool        | 60.26 | 81.64 |
|        barrel       | 66.37 | 95.64 |
|        basket       |  49.3 | 78.55 |
|      waterfall      | 46.47 | 57.41 |
|         tent        | 95.57 | 98.19 |
|         bag         | 35.44 | 49.65 |
|       minibike      | 81.21 | 93.93 |
|        cradle       |  91.4 | 97.36 |
|         oven        | 66.98 |  84.1 |
|         ball        | 42.75 | 47.16 |
|         food        | 68.33 | 85.87 |
|         step        | 32.07 | 49.83 |
|         tank        | 62.02 | 67.62 |
|      trade name     | 34.79 | 49.39 |
|      microwave      | 90.19 | 94.91 |
|         pot         | 62.39 | 74.91 |
|        animal       | 82.77 | 86.02 |
|       bicycle       | 64.35 | 84.82 |
|         lake        | 16.97 |  19.3 |
|      dishwasher     | 78.69 |  90.7 |
|        screen       | 62.02 | 91.62 |
|       blanket       | 43.27 | 61.78 |
|      sculpture      | 72.94 | 90.42 |
|         hood        | 80.65 | 90.68 |
|        sconce       | 65.65 | 82.53 |
|         vase        | 57.63 | 81.52 |
|    traffic light    | 52.84 | 72.78 |
|         tray        | 30.01 | 47.79 |
|        ashcan       | 55.37 | 78.99 |
|         fan         | 73.62 | 87.11 |
|         pier        | 38.51 |  41.7 |
|      crt screen     | 11.02 | 31.58 |
|        plate        | 69.01 |  86.1 |
|       monitor       |  3.53 |  4.35 |
|    bulletin board   | 64.35 | 84.37 |
|        shower       | 18.52 | 30.08 |
|       radiator      | 71.53 | 93.69 |
|        glass        | 29.35 | 32.63 |
|        clock        | 63.07 | 77.49 |
|         flag        | 70.36 | 87.88 |
+---------------------+-------+-------+
2022-12-01 02:51:56,929 - mmseg - INFO - Summary:
2022-12-01 02:51:56,929 - mmseg - INFO - 
+-------+-------+------+
|  aAcc |  mIoU | mAcc |
+-------+-------+------+
| 87.08 | 60.93 | 76.3 |
+-------+-------+------+
2022-12-01 02:51:56,932 - mmseg - INFO - The previous best checkpoint /mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune/lr1.0_lrd0.9/best_mIoU_iter_18000.pth was removed
2022-12-01 02:52:40,648 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_25000.pth.
2022-12-01 02:52:40,649 - mmseg - INFO - Best mIoU is 0.6093 at 25000 iter.
2022-12-01 02:52:40,660 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 02:52:40,661 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8708, mIoU: 0.6093, mAcc: 0.7630, IoU.wall: 0.8355, IoU.building: 0.8518, IoU.sky: 0.9513, IoU.floor: 0.8535, IoU.tree: 0.7848, IoU.ceiling: 0.8775, IoU.road: 0.8820, IoU.bed : 0.9366, IoU.windowpane: 0.6912, IoU.grass: 0.6946, IoU.cabinet: 0.6235, IoU.sidewalk: 0.7260, IoU.person: 0.8841, IoU.earth: 0.4322, IoU.door: 0.6570, IoU.table: 0.7225, IoU.mountain: 0.6564, IoU.plant: 0.5799, IoU.curtain: 0.8302, IoU.chair: 0.6993, IoU.car: 0.8906, IoU.water: 0.6809, IoU.painting: 0.8009, IoU.sofa: 0.8516, IoU.shelf: 0.4629, IoU.house: 0.5330, IoU.sea: 0.8017, IoU.mirror: 0.8134, IoU.rug: 0.7362, IoU.field: 0.3752, IoU.armchair: 0.6459, IoU.seat: 0.6893, IoU.fence: 0.5773, IoU.desk: 0.5921, IoU.rock: 0.6142, IoU.wardrobe: 0.5665, IoU.lamp: 0.8058, IoU.bathtub: 0.9149, IoU.railing: 0.4801, IoU.cushion: 0.7621, IoU.base: 0.4812, IoU.box: 0.4075, IoU.column: 0.5961, IoU.signboard: 0.4448, IoU.chest of drawers: 0.4381, IoU.counter: 0.5886, IoU.sand: 0.5839, IoU.sink: 0.8311, IoU.skyscraper: 0.4404, IoU.fireplace: 0.8068, IoU.refrigerator: 0.8527, IoU.grandstand: 0.4875, IoU.path: 0.3040, IoU.stairs: 0.3773, IoU.runway: 0.7445, IoU.case: 0.6850, IoU.pool table: 0.9584, IoU.pillow: 0.7226, IoU.screen door: 0.8607, IoU.stairway: 0.5635, IoU.river: 0.3120, IoU.bridge: 0.7177, IoU.bookcase: 0.3926, IoU.blind: 0.4883, IoU.coffee table: 0.7372, IoU.toilet: 0.9317, IoU.flower: 0.4329, IoU.book: 0.6072, IoU.hill: 0.1574, IoU.bench: 0.7547, IoU.countertop: 0.7402, IoU.stove: 0.8674, IoU.palm: 0.5541, IoU.kitchen island: 0.4507, IoU.computer: 0.8261, IoU.swivel chair: 0.5537, IoU.boat: 0.5636, IoU.bar: 0.7099, IoU.arcade machine: 0.9164, IoU.hovel: 0.4954, IoU.bus: 0.9515, IoU.towel: 0.8242, IoU.light: 0.6443, IoU.truck: 0.5546, IoU.tower: 0.3338, IoU.chandelier: 0.7648, IoU.awning: 0.3183, IoU.streetlight: 0.4564, IoU.booth: 0.6716, IoU.television receiver: 0.7778, IoU.airplane: 0.8881, IoU.dirt track: 0.2013, IoU.apparel: 0.5049, IoU.pole: 0.3572, IoU.land: 0.0710, IoU.bannister: 0.2132, IoU.escalator: 0.6702, IoU.ottoman: 0.5647, IoU.bottle: 0.5310, IoU.buffet: 0.4617, IoU.poster: 0.3158, IoU.stage: 0.2696, IoU.van: 0.4833, IoU.ship: 0.2064, IoU.fountain: 0.4675, IoU.conveyer belt: 0.8181, IoU.canopy: 0.5654, IoU.washer: 0.9069, IoU.plaything: 0.3729, IoU.swimming pool: 0.4628, IoU.stool: 0.6026, IoU.barrel: 0.6637, IoU.basket: 0.4930, IoU.waterfall: 0.4647, IoU.tent: 0.9557, IoU.bag: 0.3544, IoU.minibike: 0.8121, IoU.cradle: 0.9140, IoU.oven: 0.6698, IoU.ball: 0.4275, IoU.food: 0.6833, IoU.step: 0.3207, IoU.tank: 0.6202, IoU.trade name: 0.3479, IoU.microwave: 0.9019, IoU.pot: 0.6239, IoU.animal: 0.8277, IoU.bicycle: 0.6435, IoU.lake: 0.1697, IoU.dishwasher: 0.7869, IoU.screen: 0.6202, IoU.blanket: 0.4327, IoU.sculpture: 0.7294, IoU.hood: 0.8065, IoU.sconce: 0.6565, IoU.vase: 0.5763, IoU.traffic light: 0.5284, IoU.tray: 0.3001, IoU.ashcan: 0.5537, IoU.fan: 0.7362, IoU.pier: 0.3851, IoU.crt screen: 0.1102, IoU.plate: 0.6901, IoU.monitor: 0.0353, IoU.bulletin board: 0.6435, IoU.shower: 0.1852, IoU.radiator: 0.7153, IoU.glass: 0.2935, IoU.clock: 0.6307, IoU.flag: 0.7036, Acc.wall: 0.8931, Acc.building: 0.9158, Acc.sky: 0.9758, Acc.floor: 0.9039, Acc.tree: 0.8891, Acc.ceiling: 0.9410, Acc.road: 0.9131, Acc.bed : 0.9693, Acc.windowpane: 0.8215, Acc.grass: 0.8170, Acc.cabinet: 0.7074, Acc.sidewalk: 0.8677, Acc.person: 0.9398, Acc.earth: 0.5775, Acc.door: 0.8264, Acc.table: 0.8248, Acc.mountain: 0.7623, Acc.plant: 0.7079, Acc.curtain: 0.9131, Acc.chair: 0.7996, Acc.car: 0.9488, Acc.water: 0.8512, Acc.painting: 0.9095, Acc.sofa: 0.9088, Acc.shelf: 0.5642, Acc.house: 0.7013, Acc.sea: 0.8950, Acc.mirror: 0.9150, Acc.rug: 0.8751, Acc.field: 0.7206, Acc.armchair: 0.7926, Acc.seat: 0.9231, Acc.fence: 0.7976, Acc.desk: 0.8159, Acc.rock: 0.7568, Acc.wardrobe: 0.8743, Acc.lamp: 0.8947, Acc.bathtub: 0.9382, Acc.railing: 0.7245, Acc.cushion: 0.8933, Acc.base: 0.7877, Acc.box: 0.5721, Acc.column: 0.7579, Acc.signboard: 0.6497, Acc.chest of drawers: 0.7612, Acc.counter: 0.6880, Acc.sand: 0.8826, Acc.sink: 0.8711, Acc.skyscraper: 0.5602, Acc.fireplace: 0.9618, Acc.refrigerator: 0.9619, Acc.grandstand: 0.8131, Acc.path: 0.4338, Acc.stairs: 0.5226, Acc.runway: 0.9423, Acc.case: 0.8486, Acc.pool table: 0.9866, Acc.pillow: 0.8444, Acc.screen door: 0.9488, Acc.stairway: 0.7157, Acc.river: 0.3799, Acc.bridge: 0.8669, Acc.bookcase: 0.6877, Acc.blind: 0.6311, Acc.coffee table: 0.9189, Acc.toilet: 0.9674, Acc.flower: 0.6522, Acc.book: 0.8085, Acc.hill: 0.2765, Acc.bench: 0.8460, Acc.countertop: 0.8960, Acc.stove: 0.9078, Acc.palm: 0.8306, Acc.kitchen island: 0.9525, Acc.computer: 0.9019, Acc.swivel chair: 0.8570, Acc.boat: 0.8826, Acc.bar: 0.7827, Acc.arcade machine: 0.9863, Acc.hovel: 0.6825, Acc.bus: 0.9745, Acc.towel: 0.9200, Acc.light: 0.8066, Acc.truck: 0.7039, Acc.tower: 0.6305, Acc.chandelier: 0.8796, Acc.awning: 0.5337, Acc.streetlight: 0.7054, Acc.booth: 0.8064, Acc.television receiver: 0.9184, Acc.airplane: 0.9656, Acc.dirt track: 0.4741, Acc.apparel: 0.8823, Acc.pole: 0.5256, Acc.land: 0.1085, Acc.bannister: 0.3330, Acc.escalator: 0.8411, Acc.ottoman: 0.8755, Acc.bottle: 0.8296, Acc.buffet: 0.6553, Acc.poster: 0.6248, Acc.stage: 0.6579, Acc.van: 0.7245, Acc.ship: 0.2180, Acc.fountain: 0.5457, Acc.conveyer belt: 0.9715, Acc.canopy: 0.7384, Acc.washer: 0.9368, Acc.plaything: 0.5901, Acc.swimming pool: 0.7640, Acc.stool: 0.8164, Acc.barrel: 0.9564, Acc.basket: 0.7855, Acc.waterfall: 0.5741, Acc.tent: 0.9819, Acc.bag: 0.4965, Acc.minibike: 0.9393, Acc.cradle: 0.9736, Acc.oven: 0.8410, Acc.ball: 0.4716, Acc.food: 0.8587, Acc.step: 0.4983, Acc.tank: 0.6762, Acc.trade name: 0.4939, Acc.microwave: 0.9491, Acc.pot: 0.7491, Acc.animal: 0.8602, Acc.bicycle: 0.8482, Acc.lake: 0.1930, Acc.dishwasher: 0.9070, Acc.screen: 0.9162, Acc.blanket: 0.6178, Acc.sculpture: 0.9042, Acc.hood: 0.9068, Acc.sconce: 0.8253, Acc.vase: 0.8152, Acc.traffic light: 0.7278, Acc.tray: 0.4779, Acc.ashcan: 0.7899, Acc.fan: 0.8711, Acc.pier: 0.4170, Acc.crt screen: 0.3158, Acc.plate: 0.8610, Acc.monitor: 0.0435, Acc.bulletin board: 0.8437, Acc.shower: 0.3008, Acc.radiator: 0.9369, Acc.glass: 0.3263, Acc.clock: 0.7749, Acc.flag: 0.8788
2022-12-01 02:56:06,953 - mmseg - INFO - Iter [25050/40000]	lr: 4.972e-08, eta: 18:09:21, time: 8.561, data_time: 4.455, memory: 51902, decode.loss_cls: 0.3634, decode.loss_mask: 0.5534, decode.loss_dice: 0.7982, decode.d0.loss_cls: 5.6135, decode.d0.loss_mask: 0.5436, decode.d0.loss_dice: 0.8670, decode.d1.loss_cls: 0.4711, decode.d1.loss_mask: 0.5788, decode.d1.loss_dice: 0.8521, decode.d2.loss_cls: 0.4124, decode.d2.loss_mask: 0.5689, decode.d2.loss_dice: 0.8264, decode.d3.loss_cls: 0.3842, decode.d3.loss_mask: 0.5619, decode.d3.loss_dice: 0.8085, decode.d4.loss_cls: 0.3793, decode.d4.loss_mask: 0.5567, decode.d4.loss_dice: 0.8044, decode.d5.loss_cls: 0.3698, decode.d5.loss_mask: 0.5544, decode.d5.loss_dice: 0.8017, decode.d6.loss_cls: 0.3630, decode.d6.loss_mask: 0.5535, decode.d6.loss_dice: 0.7970, decode.d7.loss_cls: 0.3631, decode.d7.loss_mask: 0.5518, decode.d7.loss_dice: 0.7949, decode.d8.loss_cls: 0.3643, decode.d8.loss_mask: 0.5517, decode.d8.loss_dice: 0.7958, loss: 22.8047
2022-12-01 02:59:32,531 - mmseg - INFO - Iter [25100/40000]	lr: 4.956e-08, eta: 18:05:35, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3707, decode.loss_mask: 0.5454, decode.loss_dice: 0.7911, decode.d0.loss_cls: 5.6114, decode.d0.loss_mask: 0.5319, decode.d0.loss_dice: 0.8621, decode.d1.loss_cls: 0.4777, decode.d1.loss_mask: 0.5732, decode.d1.loss_dice: 0.8533, decode.d2.loss_cls: 0.4244, decode.d2.loss_mask: 0.5610, decode.d2.loss_dice: 0.8202, decode.d3.loss_cls: 0.3935, decode.d3.loss_mask: 0.5518, decode.d3.loss_dice: 0.8035, decode.d4.loss_cls: 0.3872, decode.d4.loss_mask: 0.5490, decode.d4.loss_dice: 0.8029, decode.d5.loss_cls: 0.3771, decode.d5.loss_mask: 0.5467, decode.d5.loss_dice: 0.8001, decode.d6.loss_cls: 0.3699, decode.d6.loss_mask: 0.5465, decode.d6.loss_dice: 0.7975, decode.d7.loss_cls: 0.3684, decode.d7.loss_mask: 0.5484, decode.d7.loss_dice: 0.7936, decode.d8.loss_cls: 0.3671, decode.d8.loss_mask: 0.5471, decode.d8.loss_dice: 0.7930, loss: 22.7655
2022-12-01 03:02:58,018 - mmseg - INFO - Iter [25150/40000]	lr: 4.939e-08, eta: 18:01:49, time: 4.110, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3563, decode.loss_mask: 0.5448, decode.loss_dice: 0.7926, decode.d0.loss_cls: 5.5959, decode.d0.loss_mask: 0.5287, decode.d0.loss_dice: 0.8551, decode.d1.loss_cls: 0.4686, decode.d1.loss_mask: 0.5686, decode.d1.loss_dice: 0.8507, decode.d2.loss_cls: 0.4099, decode.d2.loss_mask: 0.5562, decode.d2.loss_dice: 0.8161, decode.d3.loss_cls: 0.3821, decode.d3.loss_mask: 0.5494, decode.d3.loss_dice: 0.8003, decode.d4.loss_cls: 0.3708, decode.d4.loss_mask: 0.5488, decode.d4.loss_dice: 0.7990, decode.d5.loss_cls: 0.3656, decode.d5.loss_mask: 0.5442, decode.d5.loss_dice: 0.7971, decode.d6.loss_cls: 0.3568, decode.d6.loss_mask: 0.5437, decode.d6.loss_dice: 0.7965, decode.d7.loss_cls: 0.3579, decode.d7.loss_mask: 0.5435, decode.d7.loss_dice: 0.7973, decode.d8.loss_cls: 0.3562, decode.d8.loss_mask: 0.5439, decode.d8.loss_dice: 0.7923, loss: 22.5890
2022-12-01 03:06:24,091 - mmseg - INFO - Iter [25200/40000]	lr: 4.922e-08, eta: 17:58:03, time: 4.121, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3661, decode.loss_mask: 0.5552, decode.loss_dice: 0.7921, decode.d0.loss_cls: 5.5844, decode.d0.loss_mask: 0.5475, decode.d0.loss_dice: 0.8656, decode.d1.loss_cls: 0.4834, decode.d1.loss_mask: 0.5830, decode.d1.loss_dice: 0.8575, decode.d2.loss_cls: 0.4208, decode.d2.loss_mask: 0.5700, decode.d2.loss_dice: 0.8191, decode.d3.loss_cls: 0.3942, decode.d3.loss_mask: 0.5623, decode.d3.loss_dice: 0.8077, decode.d4.loss_cls: 0.3806, decode.d4.loss_mask: 0.5625, decode.d4.loss_dice: 0.8012, decode.d5.loss_cls: 0.3713, decode.d5.loss_mask: 0.5591, decode.d5.loss_dice: 0.7976, decode.d6.loss_cls: 0.3658, decode.d6.loss_mask: 0.5571, decode.d6.loss_dice: 0.7961, decode.d7.loss_cls: 0.3645, decode.d7.loss_mask: 0.5571, decode.d7.loss_dice: 0.7947, decode.d8.loss_cls: 0.3633, decode.d8.loss_mask: 0.5569, decode.d8.loss_dice: 0.7954, loss: 22.8322
2022-12-01 03:09:49,455 - mmseg - INFO - Iter [25250/40000]	lr: 4.906e-08, eta: 17:54:16, time: 4.107, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3502, decode.loss_mask: 0.5579, decode.loss_dice: 0.8040, decode.d0.loss_cls: 5.5787, decode.d0.loss_mask: 0.5432, decode.d0.loss_dice: 0.8619, decode.d1.loss_cls: 0.4525, decode.d1.loss_mask: 0.5834, decode.d1.loss_dice: 0.8558, decode.d2.loss_cls: 0.4030, decode.d2.loss_mask: 0.5694, decode.d2.loss_dice: 0.8263, decode.d3.loss_cls: 0.3729, decode.d3.loss_mask: 0.5652, decode.d3.loss_dice: 0.8190, decode.d4.loss_cls: 0.3665, decode.d4.loss_mask: 0.5640, decode.d4.loss_dice: 0.8143, decode.d5.loss_cls: 0.3562, decode.d5.loss_mask: 0.5604, decode.d5.loss_dice: 0.8074, decode.d6.loss_cls: 0.3577, decode.d6.loss_mask: 0.5569, decode.d6.loss_dice: 0.8039, decode.d7.loss_cls: 0.3514, decode.d7.loss_mask: 0.5564, decode.d7.loss_dice: 0.8037, decode.d8.loss_cls: 0.3511, decode.d8.loss_mask: 0.5572, decode.d8.loss_dice: 0.8054, loss: 22.7559
2022-12-01 03:13:17,909 - mmseg - INFO - Iter [25300/40000]	lr: 4.889e-08, eta: 17:50:32, time: 4.169, data_time: 0.064, memory: 51902, decode.loss_cls: 0.3742, decode.loss_mask: 0.5520, decode.loss_dice: 0.8171, decode.d0.loss_cls: 5.6055, decode.d0.loss_mask: 0.5472, decode.d0.loss_dice: 0.8892, decode.d1.loss_cls: 0.4867, decode.d1.loss_mask: 0.5821, decode.d1.loss_dice: 0.8847, decode.d2.loss_cls: 0.4307, decode.d2.loss_mask: 0.5682, decode.d2.loss_dice: 0.8468, decode.d3.loss_cls: 0.4000, decode.d3.loss_mask: 0.5609, decode.d3.loss_dice: 0.8282, decode.d4.loss_cls: 0.3937, decode.d4.loss_mask: 0.5594, decode.d4.loss_dice: 0.8269, decode.d5.loss_cls: 0.3840, decode.d5.loss_mask: 0.5554, decode.d5.loss_dice: 0.8196, decode.d6.loss_cls: 0.3774, decode.d6.loss_mask: 0.5541, decode.d6.loss_dice: 0.8209, decode.d7.loss_cls: 0.3770, decode.d7.loss_mask: 0.5538, decode.d7.loss_dice: 0.8184, decode.d8.loss_cls: 0.3782, decode.d8.loss_mask: 0.5531, decode.d8.loss_dice: 0.8168, loss: 23.1624
2022-12-01 03:16:43,522 - mmseg - INFO - Iter [25350/40000]	lr: 4.872e-08, eta: 17:46:46, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3538, decode.loss_mask: 0.5436, decode.loss_dice: 0.7903, decode.d0.loss_cls: 5.5991, decode.d0.loss_mask: 0.5307, decode.d0.loss_dice: 0.8524, decode.d1.loss_cls: 0.4689, decode.d1.loss_mask: 0.5703, decode.d1.loss_dice: 0.8497, decode.d2.loss_cls: 0.4125, decode.d2.loss_mask: 0.5587, decode.d2.loss_dice: 0.8161, decode.d3.loss_cls: 0.3794, decode.d3.loss_mask: 0.5516, decode.d3.loss_dice: 0.8011, decode.d4.loss_cls: 0.3727, decode.d4.loss_mask: 0.5508, decode.d4.loss_dice: 0.7980, decode.d5.loss_cls: 0.3608, decode.d5.loss_mask: 0.5460, decode.d5.loss_dice: 0.7946, decode.d6.loss_cls: 0.3565, decode.d6.loss_mask: 0.5436, decode.d6.loss_dice: 0.7957, decode.d7.loss_cls: 0.3547, decode.d7.loss_mask: 0.5437, decode.d7.loss_dice: 0.7937, decode.d8.loss_cls: 0.3520, decode.d8.loss_mask: 0.5418, decode.d8.loss_dice: 0.7950, loss: 22.5777
2022-12-01 03:20:09,339 - mmseg - INFO - Iter [25400/40000]	lr: 4.856e-08, eta: 17:43:01, time: 4.116, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3466, decode.loss_mask: 0.5503, decode.loss_dice: 0.7889, decode.d0.loss_cls: 5.5525, decode.d0.loss_mask: 0.5402, decode.d0.loss_dice: 0.8537, decode.d1.loss_cls: 0.4606, decode.d1.loss_mask: 0.5737, decode.d1.loss_dice: 0.8456, decode.d2.loss_cls: 0.4043, decode.d2.loss_mask: 0.5624, decode.d2.loss_dice: 0.8170, decode.d3.loss_cls: 0.3698, decode.d3.loss_mask: 0.5539, decode.d3.loss_dice: 0.7978, decode.d4.loss_cls: 0.3647, decode.d4.loss_mask: 0.5518, decode.d4.loss_dice: 0.7950, decode.d5.loss_cls: 0.3558, decode.d5.loss_mask: 0.5497, decode.d5.loss_dice: 0.7880, decode.d6.loss_cls: 0.3514, decode.d6.loss_mask: 0.5490, decode.d6.loss_dice: 0.7867, decode.d7.loss_cls: 0.3473, decode.d7.loss_mask: 0.5486, decode.d7.loss_dice: 0.7879, decode.d8.loss_cls: 0.3467, decode.d8.loss_mask: 0.5501, decode.d8.loss_dice: 0.7898, loss: 22.4797
2022-12-01 03:23:35,031 - mmseg - INFO - Iter [25450/40000]	lr: 4.839e-08, eta: 17:39:15, time: 4.114, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3631, decode.loss_mask: 0.5420, decode.loss_dice: 0.8025, decode.d0.loss_cls: 5.5885, decode.d0.loss_mask: 0.5300, decode.d0.loss_dice: 0.8703, decode.d1.loss_cls: 0.4776, decode.d1.loss_mask: 0.5693, decode.d1.loss_dice: 0.8616, decode.d2.loss_cls: 0.4198, decode.d2.loss_mask: 0.5554, decode.d2.loss_dice: 0.8309, decode.d3.loss_cls: 0.3859, decode.d3.loss_mask: 0.5496, decode.d3.loss_dice: 0.8186, decode.d4.loss_cls: 0.3795, decode.d4.loss_mask: 0.5452, decode.d4.loss_dice: 0.8140, decode.d5.loss_cls: 0.3703, decode.d5.loss_mask: 0.5426, decode.d5.loss_dice: 0.8110, decode.d6.loss_cls: 0.3645, decode.d6.loss_mask: 0.5419, decode.d6.loss_dice: 0.8070, decode.d7.loss_cls: 0.3617, decode.d7.loss_mask: 0.5432, decode.d7.loss_dice: 0.8075, decode.d8.loss_cls: 0.3620, decode.d8.loss_mask: 0.5426, decode.d8.loss_dice: 0.8071, loss: 22.7651
2022-12-01 03:27:00,712 - mmseg - INFO - Iter [25500/40000]	lr: 4.823e-08, eta: 17:35:29, time: 4.114, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3863, decode.loss_mask: 0.5422, decode.loss_dice: 0.8150, decode.d0.loss_cls: 5.5642, decode.d0.loss_mask: 0.5367, decode.d0.loss_dice: 0.8871, decode.d1.loss_cls: 0.4998, decode.d1.loss_mask: 0.5710, decode.d1.loss_dice: 0.8718, decode.d2.loss_cls: 0.4486, decode.d2.loss_mask: 0.5562, decode.d2.loss_dice: 0.8347, decode.d3.loss_cls: 0.4099, decode.d3.loss_mask: 0.5510, decode.d3.loss_dice: 0.8188, decode.d4.loss_cls: 0.4052, decode.d4.loss_mask: 0.5489, decode.d4.loss_dice: 0.8201, decode.d5.loss_cls: 0.3972, decode.d5.loss_mask: 0.5446, decode.d5.loss_dice: 0.8177, decode.d6.loss_cls: 0.3908, decode.d6.loss_mask: 0.5455, decode.d6.loss_dice: 0.8154, decode.d7.loss_cls: 0.3869, decode.d7.loss_mask: 0.5437, decode.d7.loss_dice: 0.8133, decode.d8.loss_cls: 0.3865, decode.d8.loss_mask: 0.5433, decode.d8.loss_dice: 0.8123, loss: 23.0647
2022-12-01 03:30:26,300 - mmseg - INFO - Iter [25550/40000]	lr: 4.806e-08, eta: 17:31:44, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3583, decode.loss_mask: 0.5449, decode.loss_dice: 0.8129, decode.d0.loss_cls: 5.5601, decode.d0.loss_mask: 0.5336, decode.d0.loss_dice: 0.8774, decode.d1.loss_cls: 0.4755, decode.d1.loss_mask: 0.5696, decode.d1.loss_dice: 0.8682, decode.d2.loss_cls: 0.4167, decode.d2.loss_mask: 0.5566, decode.d2.loss_dice: 0.8348, decode.d3.loss_cls: 0.3816, decode.d3.loss_mask: 0.5541, decode.d3.loss_dice: 0.8179, decode.d4.loss_cls: 0.3756, decode.d4.loss_mask: 0.5505, decode.d4.loss_dice: 0.8144, decode.d5.loss_cls: 0.3649, decode.d5.loss_mask: 0.5486, decode.d5.loss_dice: 0.8158, decode.d6.loss_cls: 0.3598, decode.d6.loss_mask: 0.5469, decode.d6.loss_dice: 0.8085, decode.d7.loss_cls: 0.3575, decode.d7.loss_mask: 0.5460, decode.d7.loss_dice: 0.8125, decode.d8.loss_cls: 0.3597, decode.d8.loss_mask: 0.5449, decode.d8.loss_dice: 0.8122, loss: 22.7798
2022-12-01 03:33:52,278 - mmseg - INFO - Iter [25600/40000]	lr: 4.789e-08, eta: 17:27:58, time: 4.120, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3548, decode.loss_mask: 0.5521, decode.loss_dice: 0.8040, decode.d0.loss_cls: 5.5425, decode.d0.loss_mask: 0.5402, decode.d0.loss_dice: 0.8673, decode.d1.loss_cls: 0.4693, decode.d1.loss_mask: 0.5763, decode.d1.loss_dice: 0.8693, decode.d2.loss_cls: 0.4121, decode.d2.loss_mask: 0.5643, decode.d2.loss_dice: 0.8268, decode.d3.loss_cls: 0.3835, decode.d3.loss_mask: 0.5559, decode.d3.loss_dice: 0.8119, decode.d4.loss_cls: 0.3757, decode.d4.loss_mask: 0.5514, decode.d4.loss_dice: 0.8100, decode.d5.loss_cls: 0.3618, decode.d5.loss_mask: 0.5525, decode.d5.loss_dice: 0.8061, decode.d6.loss_cls: 0.3620, decode.d6.loss_mask: 0.5501, decode.d6.loss_dice: 0.8005, decode.d7.loss_cls: 0.3580, decode.d7.loss_mask: 0.5510, decode.d7.loss_dice: 0.8023, decode.d8.loss_cls: 0.3583, decode.d8.loss_mask: 0.5511, decode.d8.loss_dice: 0.8029, loss: 22.7238
2022-12-01 03:37:18,068 - mmseg - INFO - Iter [25650/40000]	lr: 4.773e-08, eta: 17:24:13, time: 4.116, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3497, decode.loss_mask: 0.5489, decode.loss_dice: 0.7994, decode.d0.loss_cls: 5.5523, decode.d0.loss_mask: 0.5376, decode.d0.loss_dice: 0.8608, decode.d1.loss_cls: 0.4698, decode.d1.loss_mask: 0.5721, decode.d1.loss_dice: 0.8557, decode.d2.loss_cls: 0.4073, decode.d2.loss_mask: 0.5620, decode.d2.loss_dice: 0.8209, decode.d3.loss_cls: 0.3797, decode.d3.loss_mask: 0.5537, decode.d3.loss_dice: 0.8075, decode.d4.loss_cls: 0.3673, decode.d4.loss_mask: 0.5503, decode.d4.loss_dice: 0.8066, decode.d5.loss_cls: 0.3553, decode.d5.loss_mask: 0.5518, decode.d5.loss_dice: 0.8020, decode.d6.loss_cls: 0.3541, decode.d6.loss_mask: 0.5491, decode.d6.loss_dice: 0.7989, decode.d7.loss_cls: 0.3500, decode.d7.loss_mask: 0.5488, decode.d7.loss_dice: 0.8013, decode.d8.loss_cls: 0.3484, decode.d8.loss_mask: 0.5491, decode.d8.loss_dice: 0.7985, loss: 22.6089
2022-12-01 03:40:43,837 - mmseg - INFO - Iter [25700/40000]	lr: 4.756e-08, eta: 17:20:28, time: 4.115, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3595, decode.loss_mask: 0.5328, decode.loss_dice: 0.7889, decode.d0.loss_cls: 5.5637, decode.d0.loss_mask: 0.5177, decode.d0.loss_dice: 0.8582, decode.d1.loss_cls: 0.4729, decode.d1.loss_mask: 0.5569, decode.d1.loss_dice: 0.8509, decode.d2.loss_cls: 0.4242, decode.d2.loss_mask: 0.5436, decode.d2.loss_dice: 0.8121, decode.d3.loss_cls: 0.3864, decode.d3.loss_mask: 0.5375, decode.d3.loss_dice: 0.7989, decode.d4.loss_cls: 0.3790, decode.d4.loss_mask: 0.5333, decode.d4.loss_dice: 0.7959, decode.d5.loss_cls: 0.3683, decode.d5.loss_mask: 0.5332, decode.d5.loss_dice: 0.7937, decode.d6.loss_cls: 0.3622, decode.d6.loss_mask: 0.5327, decode.d6.loss_dice: 0.7910, decode.d7.loss_cls: 0.3612, decode.d7.loss_mask: 0.5328, decode.d7.loss_dice: 0.7907, decode.d8.loss_cls: 0.3613, decode.d8.loss_mask: 0.5307, decode.d8.loss_dice: 0.7909, loss: 22.4613
2022-12-01 03:44:09,454 - mmseg - INFO - Iter [25750/40000]	lr: 4.739e-08, eta: 17:16:42, time: 4.112, data_time: 0.022, memory: 51902, decode.loss_cls: 0.3507, decode.loss_mask: 0.5386, decode.loss_dice: 0.7861, decode.d0.loss_cls: 5.5439, decode.d0.loss_mask: 0.5272, decode.d0.loss_dice: 0.8554, decode.d1.loss_cls: 0.4587, decode.d1.loss_mask: 0.5626, decode.d1.loss_dice: 0.8452, decode.d2.loss_cls: 0.4071, decode.d2.loss_mask: 0.5502, decode.d2.loss_dice: 0.8122, decode.d3.loss_cls: 0.3746, decode.d3.loss_mask: 0.5439, decode.d3.loss_dice: 0.8006, decode.d4.loss_cls: 0.3711, decode.d4.loss_mask: 0.5403, decode.d4.loss_dice: 0.7947, decode.d5.loss_cls: 0.3575, decode.d5.loss_mask: 0.5386, decode.d5.loss_dice: 0.7956, decode.d6.loss_cls: 0.3525, decode.d6.loss_mask: 0.5373, decode.d6.loss_dice: 0.7884, decode.d7.loss_cls: 0.3514, decode.d7.loss_mask: 0.5383, decode.d7.loss_dice: 0.7878, decode.d8.loss_cls: 0.3477, decode.d8.loss_mask: 0.5380, decode.d8.loss_dice: 0.7858, loss: 22.3821
2022-12-01 03:47:35,379 - mmseg - INFO - Iter [25800/40000]	lr: 4.723e-08, eta: 17:12:57, time: 4.118, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3561, decode.loss_mask: 0.5338, decode.loss_dice: 0.8160, decode.d0.loss_cls: 5.5610, decode.d0.loss_mask: 0.5194, decode.d0.loss_dice: 0.8724, decode.d1.loss_cls: 0.4764, decode.d1.loss_mask: 0.5600, decode.d1.loss_dice: 0.8714, decode.d2.loss_cls: 0.4168, decode.d2.loss_mask: 0.5460, decode.d2.loss_dice: 0.8396, decode.d3.loss_cls: 0.3821, decode.d3.loss_mask: 0.5420, decode.d3.loss_dice: 0.8241, decode.d4.loss_cls: 0.3732, decode.d4.loss_mask: 0.5380, decode.d4.loss_dice: 0.8216, decode.d5.loss_cls: 0.3623, decode.d5.loss_mask: 0.5368, decode.d5.loss_dice: 0.8170, decode.d6.loss_cls: 0.3585, decode.d6.loss_mask: 0.5349, decode.d6.loss_dice: 0.8160, decode.d7.loss_cls: 0.3582, decode.d7.loss_mask: 0.5361, decode.d7.loss_dice: 0.8153, decode.d8.loss_cls: 0.3560, decode.d8.loss_mask: 0.5340, decode.d8.loss_dice: 0.8139, loss: 22.6890
2022-12-01 03:51:01,255 - mmseg - INFO - Iter [25850/40000]	lr: 4.706e-08, eta: 17:09:12, time: 4.118, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3572, decode.loss_mask: 0.5497, decode.loss_dice: 0.8041, decode.d0.loss_cls: 5.5331, decode.d0.loss_mask: 0.5374, decode.d0.loss_dice: 0.8668, decode.d1.loss_cls: 0.4727, decode.d1.loss_mask: 0.5757, decode.d1.loss_dice: 0.8640, decode.d2.loss_cls: 0.4135, decode.d2.loss_mask: 0.5641, decode.d2.loss_dice: 0.8321, decode.d3.loss_cls: 0.3852, decode.d3.loss_mask: 0.5581, decode.d3.loss_dice: 0.8166, decode.d4.loss_cls: 0.3726, decode.d4.loss_mask: 0.5577, decode.d4.loss_dice: 0.8130, decode.d5.loss_cls: 0.3673, decode.d5.loss_mask: 0.5532, decode.d5.loss_dice: 0.8085, decode.d6.loss_cls: 0.3614, decode.d6.loss_mask: 0.5508, decode.d6.loss_dice: 0.8061, decode.d7.loss_cls: 0.3632, decode.d7.loss_mask: 0.5500, decode.d7.loss_dice: 0.8056, decode.d8.loss_cls: 0.3560, decode.d8.loss_mask: 0.5512, decode.d8.loss_dice: 0.8052, loss: 22.7523
2022-12-01 03:54:26,666 - mmseg - INFO - Iter [25900/40000]	lr: 4.690e-08, eta: 17:05:27, time: 4.108, data_time: 0.022, memory: 51902, decode.loss_cls: 0.3768, decode.loss_mask: 0.5611, decode.loss_dice: 0.8191, decode.d0.loss_cls: 5.5414, decode.d0.loss_mask: 0.5500, decode.d0.loss_dice: 0.8821, decode.d1.loss_cls: 0.4884, decode.d1.loss_mask: 0.5909, decode.d1.loss_dice: 0.8776, decode.d2.loss_cls: 0.4309, decode.d2.loss_mask: 0.5795, decode.d2.loss_dice: 0.8446, decode.d3.loss_cls: 0.3989, decode.d3.loss_mask: 0.5700, decode.d3.loss_dice: 0.8288, decode.d4.loss_cls: 0.3901, decode.d4.loss_mask: 0.5671, decode.d4.loss_dice: 0.8251, decode.d5.loss_cls: 0.3821, decode.d5.loss_mask: 0.5648, decode.d5.loss_dice: 0.8196, decode.d6.loss_cls: 0.3787, decode.d6.loss_mask: 0.5652, decode.d6.loss_dice: 0.8183, decode.d7.loss_cls: 0.3738, decode.d7.loss_mask: 0.5638, decode.d7.loss_dice: 0.8203, decode.d8.loss_cls: 0.3738, decode.d8.loss_mask: 0.5620, decode.d8.loss_dice: 0.8181, loss: 23.1627
2022-12-01 03:57:54,560 - mmseg - INFO - Iter [25950/40000]	lr: 4.673e-08, eta: 17:01:43, time: 4.158, data_time: 0.069, memory: 51902, decode.loss_cls: 0.3469, decode.loss_mask: 0.5396, decode.loss_dice: 0.7931, decode.d0.loss_cls: 5.5325, decode.d0.loss_mask: 0.5304, decode.d0.loss_dice: 0.8514, decode.d1.loss_cls: 0.4584, decode.d1.loss_mask: 0.5698, decode.d1.loss_dice: 0.8462, decode.d2.loss_cls: 0.4031, decode.d2.loss_mask: 0.5539, decode.d2.loss_dice: 0.8159, decode.d3.loss_cls: 0.3673, decode.d3.loss_mask: 0.5492, decode.d3.loss_dice: 0.8017, decode.d4.loss_cls: 0.3616, decode.d4.loss_mask: 0.5452, decode.d4.loss_dice: 0.7965, decode.d5.loss_cls: 0.3546, decode.d5.loss_mask: 0.5446, decode.d5.loss_dice: 0.7964, decode.d6.loss_cls: 0.3499, decode.d6.loss_mask: 0.5420, decode.d6.loss_dice: 0.7926, decode.d7.loss_cls: 0.3464, decode.d7.loss_mask: 0.5401, decode.d7.loss_dice: 0.7931, decode.d8.loss_cls: 0.3464, decode.d8.loss_mask: 0.5393, decode.d8.loss_dice: 0.7914, loss: 22.3993
2022-12-01 04:01:20,605 - mmseg - INFO - Saving checkpoint at 26000 iterations
2022-12-01 04:02:03,677 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 04:02:03,677 - mmseg - INFO - Iter [26000/40000]	lr: 4.656e-08, eta: 16:58:22, time: 4.982, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3497, decode.loss_mask: 0.5489, decode.loss_dice: 0.8011, decode.d0.loss_cls: 5.5161, decode.d0.loss_mask: 0.5346, decode.d0.loss_dice: 0.8611, decode.d1.loss_cls: 0.4515, decode.d1.loss_mask: 0.5761, decode.d1.loss_dice: 0.8589, decode.d2.loss_cls: 0.4053, decode.d2.loss_mask: 0.5637, decode.d2.loss_dice: 0.8288, decode.d3.loss_cls: 0.3709, decode.d3.loss_mask: 0.5547, decode.d3.loss_dice: 0.8098, decode.d4.loss_cls: 0.3636, decode.d4.loss_mask: 0.5534, decode.d4.loss_dice: 0.8036, decode.d5.loss_cls: 0.3582, decode.d5.loss_mask: 0.5511, decode.d5.loss_dice: 0.8014, decode.d6.loss_cls: 0.3565, decode.d6.loss_mask: 0.5505, decode.d6.loss_dice: 0.7985, decode.d7.loss_cls: 0.3471, decode.d7.loss_mask: 0.5505, decode.d7.loss_dice: 0.8045, decode.d8.loss_cls: 0.3496, decode.d8.loss_mask: 0.5497, decode.d8.loss_dice: 0.7999, loss: 22.5689
2022-12-01 04:05:01,744 - mmseg - INFO - per class results:
2022-12-01 04:05:01,749 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 83.06 | 88.98 |
|       building      | 85.32 | 91.56 |
|         sky         | 95.08 | 97.19 |
|        floor        | 85.01 | 89.69 |
|         tree        | 78.68 | 90.61 |
|       ceiling       | 87.36 | 93.56 |
|         road        | 88.36 | 92.06 |
|         bed         | 93.73 | 97.01 |
|      windowpane     | 67.54 | 81.47 |
|        grass        | 70.96 | 84.12 |
|       cabinet       |  61.9 | 70.78 |
|       sidewalk      | 73.17 | 86.03 |
|        person       | 88.26 | 94.45 |
|        earth        |  44.1 | 59.61 |
|         door        | 64.03 | 85.15 |
|        table        | 73.03 |  82.3 |
|       mountain      | 60.06 | 69.78 |
|        plant        | 58.01 | 70.14 |
|       curtain       | 82.71 | 91.48 |
|        chair        | 68.88 | 79.54 |
|         car         | 89.25 | 95.03 |
|        water        | 69.03 | 85.16 |
|       painting      | 81.49 | 92.33 |
|         sofa        | 83.76 | 89.95 |
|        shelf        | 49.67 | 64.66 |
|        house        | 55.88 | 70.77 |
|         sea         | 79.52 | 88.97 |
|        mirror       | 81.16 | 92.36 |
|         rug         | 74.34 | 89.58 |
|        field        |  39.9 | 72.01 |
|       armchair      | 63.05 | 78.37 |
|         seat        | 65.01 | 88.33 |
|        fence        | 55.54 | 72.95 |
|         desk        | 60.77 | 85.02 |
|         rock        | 57.44 | 75.19 |
|       wardrobe      | 55.81 | 85.69 |
|         lamp        |  80.9 | 90.58 |
|       bathtub       | 92.05 | 93.76 |
|       railing       | 46.96 | 70.81 |
|       cushion       | 75.68 | 89.99 |
|         base        | 44.96 | 70.61 |
|         box         | 42.23 | 57.72 |
|        column       | 60.61 | 71.43 |
|      signboard      | 46.08 |  66.9 |
|   chest of drawers  | 46.04 | 77.13 |
|       counter       | 57.46 | 66.35 |
|         sand        |  62.0 | 87.84 |
|         sink        | 82.56 | 87.11 |
|      skyscraper     | 42.15 | 54.23 |
|      fireplace      | 77.96 | 95.15 |
|     refrigerator    | 84.67 | 94.93 |
|      grandstand     | 51.13 | 84.72 |
|         path        | 31.64 | 42.41 |
|        stairs       | 36.85 | 48.78 |
|        runway       | 73.78 | 94.07 |
|         case        | 68.84 | 86.56 |
|      pool table     | 95.85 | 98.78 |
|        pillow       | 73.19 | 83.46 |
|     screen door     | 85.18 | 95.55 |
|       stairway      | 55.23 | 70.87 |
|        river        | 25.05 | 28.77 |
|        bridge       | 77.02 | 88.46 |
|       bookcase      | 44.97 | 60.77 |
|        blind        | 43.42 | 53.94 |
|     coffee table    | 74.09 |  90.6 |
|        toilet       | 93.26 | 96.79 |
|        flower       | 45.02 | 68.78 |
|         book        |  60.6 | 84.37 |
|         hill        | 14.53 | 29.75 |
|        bench        | 74.65 | 83.71 |
|      countertop     | 71.28 | 89.16 |
|        stove        | 86.16 |  90.3 |
|         palm        | 54.98 | 82.58 |
|    kitchen island   | 48.43 | 93.63 |
|       computer      | 79.21 | 86.05 |
|     swivel chair    | 56.59 | 83.82 |
|         boat        | 55.26 | 89.99 |
|         bar         | 65.32 | 73.23 |
|    arcade machine   | 91.14 | 98.71 |
|        hovel        | 54.36 | 81.26 |
|         bus         |  95.8 |  97.7 |
|        towel        | 83.61 | 94.97 |
|        light        | 65.46 | 80.33 |
|        truck        |  52.4 | 71.06 |
|        tower        | 33.11 |  63.3 |
|      chandelier     | 77.62 | 87.89 |
|        awning       | 33.18 | 56.06 |
|     streetlight     | 45.17 | 69.64 |
|        booth        | 62.93 |  75.6 |
| television receiver |  77.2 | 91.78 |
|       airplane      | 87.32 | 96.68 |
|      dirt track     |  7.7  | 13.39 |
|       apparel       | 54.76 | 93.46 |
|         pole        | 36.06 | 49.49 |
|         land        |  3.22 |  4.64 |
|      bannister      | 20.03 | 35.36 |
|      escalator      | 66.52 | 83.88 |
|       ottoman       | 56.91 | 83.11 |
|        bottle       |  51.2 | 84.53 |
|        buffet       | 45.16 | 66.03 |
|        poster       |  40.5 | 61.41 |
|        stage        | 31.19 | 82.05 |
|         van         | 49.63 | 73.39 |
|         ship        | 27.22 |  28.7 |
|       fountain      | 47.47 |  54.9 |
|    conveyer belt    | 77.98 | 97.26 |
|        canopy       | 65.85 | 89.64 |
|        washer       | 91.06 | 93.58 |
|      plaything      | 36.74 |  60.1 |
|    swimming pool    | 45.79 | 75.55 |
|        stool        | 51.81 | 86.33 |
|        barrel       |  66.2 | 97.02 |
|        basket       | 47.66 | 73.04 |
|      waterfall      |  47.2 | 58.16 |
|         tent        | 95.31 | 98.12 |
|         bag         | 34.33 | 48.65 |
|       minibike      | 81.12 | 94.17 |
|        cradle       | 91.37 | 97.29 |
|         oven        | 66.49 | 83.97 |
|         ball        | 42.28 | 45.98 |
|         food        | 69.27 | 83.42 |
|         step        |  28.3 | 43.95 |
|         tank        | 61.99 | 67.61 |
|      trade name     | 34.92 | 46.81 |
|      microwave      | 89.89 | 94.66 |
|         pot         | 62.55 | 75.36 |
|        animal       | 79.29 | 81.51 |
|       bicycle       |  63.4 | 85.38 |
|         lake        | 16.73 | 25.25 |
|      dishwasher     | 80.71 | 90.55 |
|        screen       | 59.15 | 91.46 |
|       blanket       | 44.71 | 62.54 |
|      sculpture      | 73.06 | 90.72 |
|         hood        | 77.86 | 87.89 |
|        sconce       |  67.3 | 83.89 |
|         vase        | 58.78 | 81.48 |
|    traffic light    | 52.51 | 74.26 |
|         tray        | 32.21 | 48.72 |
|        ashcan       | 54.93 | 75.39 |
|         fan         | 73.79 | 86.73 |
|         pier        |  38.9 | 42.06 |
|      crt screen     |  5.07 | 13.77 |
|        plate        |  70.9 | 85.43 |
|       monitor       |  3.37 |  4.84 |
|    bulletin board   | 63.13 | 83.23 |
|        shower       | 16.92 | 29.35 |
|       radiator      | 75.44 | 92.92 |
|        glass        |  29.9 | 32.94 |
|        clock        | 64.44 | 76.84 |
|         flag        | 68.97 | 88.59 |
+---------------------+-------+-------+
2022-12-01 04:05:01,749 - mmseg - INFO - Summary:
2022-12-01 04:05:01,749 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 86.98 | 60.74 | 75.88 |
+-------+-------+-------+
2022-12-01 04:05:01,754 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 04:05:01,755 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8698, mIoU: 0.6074, mAcc: 0.7588, IoU.wall: 0.8306, IoU.building: 0.8532, IoU.sky: 0.9508, IoU.floor: 0.8501, IoU.tree: 0.7868, IoU.ceiling: 0.8736, IoU.road: 0.8836, IoU.bed : 0.9373, IoU.windowpane: 0.6754, IoU.grass: 0.7096, IoU.cabinet: 0.6190, IoU.sidewalk: 0.7317, IoU.person: 0.8826, IoU.earth: 0.4410, IoU.door: 0.6403, IoU.table: 0.7303, IoU.mountain: 0.6006, IoU.plant: 0.5801, IoU.curtain: 0.8271, IoU.chair: 0.6888, IoU.car: 0.8925, IoU.water: 0.6903, IoU.painting: 0.8149, IoU.sofa: 0.8376, IoU.shelf: 0.4967, IoU.house: 0.5588, IoU.sea: 0.7952, IoU.mirror: 0.8116, IoU.rug: 0.7434, IoU.field: 0.3990, IoU.armchair: 0.6305, IoU.seat: 0.6501, IoU.fence: 0.5554, IoU.desk: 0.6077, IoU.rock: 0.5744, IoU.wardrobe: 0.5581, IoU.lamp: 0.8090, IoU.bathtub: 0.9205, IoU.railing: 0.4696, IoU.cushion: 0.7568, IoU.base: 0.4496, IoU.box: 0.4223, IoU.column: 0.6061, IoU.signboard: 0.4608, IoU.chest of drawers: 0.4604, IoU.counter: 0.5746, IoU.sand: 0.6200, IoU.sink: 0.8256, IoU.skyscraper: 0.4215, IoU.fireplace: 0.7796, IoU.refrigerator: 0.8467, IoU.grandstand: 0.5113, IoU.path: 0.3164, IoU.stairs: 0.3685, IoU.runway: 0.7378, IoU.case: 0.6884, IoU.pool table: 0.9585, IoU.pillow: 0.7319, IoU.screen door: 0.8518, IoU.stairway: 0.5523, IoU.river: 0.2505, IoU.bridge: 0.7702, IoU.bookcase: 0.4497, IoU.blind: 0.4342, IoU.coffee table: 0.7409, IoU.toilet: 0.9326, IoU.flower: 0.4502, IoU.book: 0.6060, IoU.hill: 0.1453, IoU.bench: 0.7465, IoU.countertop: 0.7128, IoU.stove: 0.8616, IoU.palm: 0.5498, IoU.kitchen island: 0.4843, IoU.computer: 0.7921, IoU.swivel chair: 0.5659, IoU.boat: 0.5526, IoU.bar: 0.6532, IoU.arcade machine: 0.9114, IoU.hovel: 0.5436, IoU.bus: 0.9580, IoU.towel: 0.8361, IoU.light: 0.6546, IoU.truck: 0.5240, IoU.tower: 0.3311, IoU.chandelier: 0.7762, IoU.awning: 0.3318, IoU.streetlight: 0.4517, IoU.booth: 0.6293, IoU.television receiver: 0.7720, IoU.airplane: 0.8732, IoU.dirt track: 0.0770, IoU.apparel: 0.5476, IoU.pole: 0.3606, IoU.land: 0.0322, IoU.bannister: 0.2003, IoU.escalator: 0.6652, IoU.ottoman: 0.5691, IoU.bottle: 0.5120, IoU.buffet: 0.4516, IoU.poster: 0.4050, IoU.stage: 0.3119, IoU.van: 0.4963, IoU.ship: 0.2722, IoU.fountain: 0.4747, IoU.conveyer belt: 0.7798, IoU.canopy: 0.6585, IoU.washer: 0.9106, IoU.plaything: 0.3674, IoU.swimming pool: 0.4579, IoU.stool: 0.5181, IoU.barrel: 0.6620, IoU.basket: 0.4766, IoU.waterfall: 0.4720, IoU.tent: 0.9531, IoU.bag: 0.3433, IoU.minibike: 0.8112, IoU.cradle: 0.9137, IoU.oven: 0.6649, IoU.ball: 0.4228, IoU.food: 0.6927, IoU.step: 0.2830, IoU.tank: 0.6199, IoU.trade name: 0.3492, IoU.microwave: 0.8989, IoU.pot: 0.6255, IoU.animal: 0.7929, IoU.bicycle: 0.6340, IoU.lake: 0.1673, IoU.dishwasher: 0.8071, IoU.screen: 0.5915, IoU.blanket: 0.4471, IoU.sculpture: 0.7306, IoU.hood: 0.7786, IoU.sconce: 0.6730, IoU.vase: 0.5878, IoU.traffic light: 0.5251, IoU.tray: 0.3221, IoU.ashcan: 0.5493, IoU.fan: 0.7379, IoU.pier: 0.3890, IoU.crt screen: 0.0507, IoU.plate: 0.7090, IoU.monitor: 0.0337, IoU.bulletin board: 0.6313, IoU.shower: 0.1692, IoU.radiator: 0.7544, IoU.glass: 0.2990, IoU.clock: 0.6444, IoU.flag: 0.6897, Acc.wall: 0.8898, Acc.building: 0.9156, Acc.sky: 0.9719, Acc.floor: 0.8969, Acc.tree: 0.9061, Acc.ceiling: 0.9356, Acc.road: 0.9206, Acc.bed : 0.9701, Acc.windowpane: 0.8147, Acc.grass: 0.8412, Acc.cabinet: 0.7078, Acc.sidewalk: 0.8603, Acc.person: 0.9445, Acc.earth: 0.5961, Acc.door: 0.8515, Acc.table: 0.8230, Acc.mountain: 0.6978, Acc.plant: 0.7014, Acc.curtain: 0.9148, Acc.chair: 0.7954, Acc.car: 0.9503, Acc.water: 0.8516, Acc.painting: 0.9233, Acc.sofa: 0.8995, Acc.shelf: 0.6466, Acc.house: 0.7077, Acc.sea: 0.8897, Acc.mirror: 0.9236, Acc.rug: 0.8958, Acc.field: 0.7201, Acc.armchair: 0.7837, Acc.seat: 0.8833, Acc.fence: 0.7295, Acc.desk: 0.8502, Acc.rock: 0.7519, Acc.wardrobe: 0.8569, Acc.lamp: 0.9058, Acc.bathtub: 0.9376, Acc.railing: 0.7081, Acc.cushion: 0.8999, Acc.base: 0.7061, Acc.box: 0.5772, Acc.column: 0.7143, Acc.signboard: 0.6690, Acc.chest of drawers: 0.7713, Acc.counter: 0.6635, Acc.sand: 0.8784, Acc.sink: 0.8711, Acc.skyscraper: 0.5423, Acc.fireplace: 0.9515, Acc.refrigerator: 0.9493, Acc.grandstand: 0.8472, Acc.path: 0.4241, Acc.stairs: 0.4878, Acc.runway: 0.9407, Acc.case: 0.8656, Acc.pool table: 0.9878, Acc.pillow: 0.8346, Acc.screen door: 0.9555, Acc.stairway: 0.7087, Acc.river: 0.2877, Acc.bridge: 0.8846, Acc.bookcase: 0.6077, Acc.blind: 0.5394, Acc.coffee table: 0.9060, Acc.toilet: 0.9679, Acc.flower: 0.6878, Acc.book: 0.8437, Acc.hill: 0.2975, Acc.bench: 0.8371, Acc.countertop: 0.8916, Acc.stove: 0.9030, Acc.palm: 0.8258, Acc.kitchen island: 0.9363, Acc.computer: 0.8605, Acc.swivel chair: 0.8382, Acc.boat: 0.8999, Acc.bar: 0.7323, Acc.arcade machine: 0.9871, Acc.hovel: 0.8126, Acc.bus: 0.9770, Acc.towel: 0.9497, Acc.light: 0.8033, Acc.truck: 0.7106, Acc.tower: 0.6330, Acc.chandelier: 0.8789, Acc.awning: 0.5606, Acc.streetlight: 0.6964, Acc.booth: 0.7560, Acc.television receiver: 0.9178, Acc.airplane: 0.9668, Acc.dirt track: 0.1339, Acc.apparel: 0.9346, Acc.pole: 0.4949, Acc.land: 0.0464, Acc.bannister: 0.3536, Acc.escalator: 0.8388, Acc.ottoman: 0.8311, Acc.bottle: 0.8453, Acc.buffet: 0.6603, Acc.poster: 0.6141, Acc.stage: 0.8205, Acc.van: 0.7339, Acc.ship: 0.2870, Acc.fountain: 0.5490, Acc.conveyer belt: 0.9726, Acc.canopy: 0.8964, Acc.washer: 0.9358, Acc.plaything: 0.6010, Acc.swimming pool: 0.7555, Acc.stool: 0.8633, Acc.barrel: 0.9702, Acc.basket: 0.7304, Acc.waterfall: 0.5816, Acc.tent: 0.9812, Acc.bag: 0.4865, Acc.minibike: 0.9417, Acc.cradle: 0.9729, Acc.oven: 0.8397, Acc.ball: 0.4598, Acc.food: 0.8342, Acc.step: 0.4395, Acc.tank: 0.6761, Acc.trade name: 0.4681, Acc.microwave: 0.9466, Acc.pot: 0.7536, Acc.animal: 0.8151, Acc.bicycle: 0.8538, Acc.lake: 0.2525, Acc.dishwasher: 0.9055, Acc.screen: 0.9146, Acc.blanket: 0.6254, Acc.sculpture: 0.9072, Acc.hood: 0.8789, Acc.sconce: 0.8389, Acc.vase: 0.8148, Acc.traffic light: 0.7426, Acc.tray: 0.4872, Acc.ashcan: 0.7539, Acc.fan: 0.8673, Acc.pier: 0.4206, Acc.crt screen: 0.1377, Acc.plate: 0.8543, Acc.monitor: 0.0484, Acc.bulletin board: 0.8323, Acc.shower: 0.2935, Acc.radiator: 0.9292, Acc.glass: 0.3294, Acc.clock: 0.7684, Acc.flag: 0.8859
2022-12-01 04:08:27,838 - mmseg - INFO - Iter [26050/40000]	lr: 4.640e-08, eta: 16:56:13, time: 7.683, data_time: 3.582, memory: 51902, decode.loss_cls: 0.3454, decode.loss_mask: 0.5450, decode.loss_dice: 0.7922, decode.d0.loss_cls: 5.5220, decode.d0.loss_mask: 0.5376, decode.d0.loss_dice: 0.8561, decode.d1.loss_cls: 0.4638, decode.d1.loss_mask: 0.5706, decode.d1.loss_dice: 0.8515, decode.d2.loss_cls: 0.4092, decode.d2.loss_mask: 0.5578, decode.d2.loss_dice: 0.8173, decode.d3.loss_cls: 0.3702, decode.d3.loss_mask: 0.5517, decode.d3.loss_dice: 0.8013, decode.d4.loss_cls: 0.3600, decode.d4.loss_mask: 0.5475, decode.d4.loss_dice: 0.7979, decode.d5.loss_cls: 0.3550, decode.d5.loss_mask: 0.5460, decode.d5.loss_dice: 0.7916, decode.d6.loss_cls: 0.3486, decode.d6.loss_mask: 0.5459, decode.d6.loss_dice: 0.7915, decode.d7.loss_cls: 0.3477, decode.d7.loss_mask: 0.5440, decode.d7.loss_dice: 0.7916, decode.d8.loss_cls: 0.3453, decode.d8.loss_mask: 0.5456, decode.d8.loss_dice: 0.7928, loss: 22.4430
2022-12-01 04:11:53,703 - mmseg - INFO - Iter [26100/40000]	lr: 4.623e-08, eta: 16:52:27, time: 4.117, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3592, decode.loss_mask: 0.5437, decode.loss_dice: 0.8089, decode.d0.loss_cls: 5.5079, decode.d0.loss_mask: 0.5329, decode.d0.loss_dice: 0.8759, decode.d1.loss_cls: 0.4786, decode.d1.loss_mask: 0.5660, decode.d1.loss_dice: 0.8609, decode.d2.loss_cls: 0.4219, decode.d2.loss_mask: 0.5553, decode.d2.loss_dice: 0.8287, decode.d3.loss_cls: 0.3870, decode.d3.loss_mask: 0.5482, decode.d3.loss_dice: 0.8136, decode.d4.loss_cls: 0.3781, decode.d4.loss_mask: 0.5480, decode.d4.loss_dice: 0.8146, decode.d5.loss_cls: 0.3691, decode.d5.loss_mask: 0.5453, decode.d5.loss_dice: 0.8121, decode.d6.loss_cls: 0.3613, decode.d6.loss_mask: 0.5441, decode.d6.loss_dice: 0.8090, decode.d7.loss_cls: 0.3580, decode.d7.loss_mask: 0.5421, decode.d7.loss_dice: 0.8102, decode.d8.loss_cls: 0.3584, decode.d8.loss_mask: 0.5429, decode.d8.loss_dice: 0.8067, loss: 22.6886
2022-12-01 04:15:19,404 - mmseg - INFO - Iter [26150/40000]	lr: 4.606e-08, eta: 16:48:42, time: 4.114, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3599, decode.loss_mask: 0.5470, decode.loss_dice: 0.7954, decode.d0.loss_cls: 5.5159, decode.d0.loss_mask: 0.5367, decode.d0.loss_dice: 0.8695, decode.d1.loss_cls: 0.4840, decode.d1.loss_mask: 0.5735, decode.d1.loss_dice: 0.8522, decode.d2.loss_cls: 0.4209, decode.d2.loss_mask: 0.5623, decode.d2.loss_dice: 0.8192, decode.d3.loss_cls: 0.3904, decode.d3.loss_mask: 0.5522, decode.d3.loss_dice: 0.8032, decode.d4.loss_cls: 0.3834, decode.d4.loss_mask: 0.5494, decode.d4.loss_dice: 0.8006, decode.d5.loss_cls: 0.3690, decode.d5.loss_mask: 0.5470, decode.d5.loss_dice: 0.7952, decode.d6.loss_cls: 0.3647, decode.d6.loss_mask: 0.5473, decode.d6.loss_dice: 0.7948, decode.d7.loss_cls: 0.3634, decode.d7.loss_mask: 0.5458, decode.d7.loss_dice: 0.7935, decode.d8.loss_cls: 0.3620, decode.d8.loss_mask: 0.5460, decode.d8.loss_dice: 0.7911, loss: 22.6354
2022-12-01 04:18:45,198 - mmseg - INFO - Iter [26200/40000]	lr: 4.590e-08, eta: 16:44:57, time: 4.116, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3521, decode.loss_mask: 0.5518, decode.loss_dice: 0.8101, decode.d0.loss_cls: 5.5021, decode.d0.loss_mask: 0.5428, decode.d0.loss_dice: 0.8725, decode.d1.loss_cls: 0.4603, decode.d1.loss_mask: 0.5771, decode.d1.loss_dice: 0.8624, decode.d2.loss_cls: 0.4047, decode.d2.loss_mask: 0.5659, decode.d2.loss_dice: 0.8351, decode.d3.loss_cls: 0.3821, decode.d3.loss_mask: 0.5577, decode.d3.loss_dice: 0.8168, decode.d4.loss_cls: 0.3703, decode.d4.loss_mask: 0.5546, decode.d4.loss_dice: 0.8127, decode.d5.loss_cls: 0.3594, decode.d5.loss_mask: 0.5542, decode.d5.loss_dice: 0.8125, decode.d6.loss_cls: 0.3551, decode.d6.loss_mask: 0.5552, decode.d6.loss_dice: 0.8104, decode.d7.loss_cls: 0.3553, decode.d7.loss_mask: 0.5541, decode.d7.loss_dice: 0.8068, decode.d8.loss_cls: 0.3545, decode.d8.loss_mask: 0.5528, decode.d8.loss_dice: 0.8055, loss: 22.7068
2022-12-01 04:22:10,809 - mmseg - INFO - Iter [26250/40000]	lr: 4.573e-08, eta: 16:41:12, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3593, decode.loss_mask: 0.5298, decode.loss_dice: 0.7852, decode.d0.loss_cls: 5.4960, decode.d0.loss_mask: 0.5188, decode.d0.loss_dice: 0.8484, decode.d1.loss_cls: 0.4750, decode.d1.loss_mask: 0.5582, decode.d1.loss_dice: 0.8403, decode.d2.loss_cls: 0.4225, decode.d2.loss_mask: 0.5445, decode.d2.loss_dice: 0.8123, decode.d3.loss_cls: 0.3848, decode.d3.loss_mask: 0.5367, decode.d3.loss_dice: 0.7965, decode.d4.loss_cls: 0.3770, decode.d4.loss_mask: 0.5360, decode.d4.loss_dice: 0.7933, decode.d5.loss_cls: 0.3677, decode.d5.loss_mask: 0.5332, decode.d5.loss_dice: 0.7925, decode.d6.loss_cls: 0.3623, decode.d6.loss_mask: 0.5326, decode.d6.loss_dice: 0.7884, decode.d7.loss_cls: 0.3622, decode.d7.loss_mask: 0.5328, decode.d7.loss_dice: 0.7873, decode.d8.loss_cls: 0.3571, decode.d8.loss_mask: 0.5318, decode.d8.loss_dice: 0.7858, loss: 22.3485
2022-12-01 04:25:36,877 - mmseg - INFO - Iter [26300/40000]	lr: 4.557e-08, eta: 16:37:27, time: 4.121, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3556, decode.loss_mask: 0.5419, decode.loss_dice: 0.7980, decode.d0.loss_cls: 5.4870, decode.d0.loss_mask: 0.5283, decode.d0.loss_dice: 0.8583, decode.d1.loss_cls: 0.4661, decode.d1.loss_mask: 0.5654, decode.d1.loss_dice: 0.8544, decode.d2.loss_cls: 0.4141, decode.d2.loss_mask: 0.5518, decode.d2.loss_dice: 0.8202, decode.d3.loss_cls: 0.3871, decode.d3.loss_mask: 0.5449, decode.d3.loss_dice: 0.8012, decode.d4.loss_cls: 0.3703, decode.d4.loss_mask: 0.5465, decode.d4.loss_dice: 0.7987, decode.d5.loss_cls: 0.3651, decode.d5.loss_mask: 0.5424, decode.d5.loss_dice: 0.7976, decode.d6.loss_cls: 0.3606, decode.d6.loss_mask: 0.5416, decode.d6.loss_dice: 0.7978, decode.d7.loss_cls: 0.3587, decode.d7.loss_mask: 0.5417, decode.d7.loss_dice: 0.7978, decode.d8.loss_cls: 0.3541, decode.d8.loss_mask: 0.5414, decode.d8.loss_dice: 0.7967, loss: 22.4855
2022-12-01 04:29:02,268 - mmseg - INFO - Iter [26350/40000]	lr: 4.540e-08, eta: 16:33:41, time: 4.108, data_time: 0.022, memory: 51902, decode.loss_cls: 0.3500, decode.loss_mask: 0.5387, decode.loss_dice: 0.7897, decode.d0.loss_cls: 5.4905, decode.d0.loss_mask: 0.5252, decode.d0.loss_dice: 0.8524, decode.d1.loss_cls: 0.4665, decode.d1.loss_mask: 0.5637, decode.d1.loss_dice: 0.8431, decode.d2.loss_cls: 0.4140, decode.d2.loss_mask: 0.5516, decode.d2.loss_dice: 0.8134, decode.d3.loss_cls: 0.3818, decode.d3.loss_mask: 0.5460, decode.d3.loss_dice: 0.7986, decode.d4.loss_cls: 0.3726, decode.d4.loss_mask: 0.5438, decode.d4.loss_dice: 0.7915, decode.d5.loss_cls: 0.3643, decode.d5.loss_mask: 0.5407, decode.d5.loss_dice: 0.7913, decode.d6.loss_cls: 0.3616, decode.d6.loss_mask: 0.5375, decode.d6.loss_dice: 0.7883, decode.d7.loss_cls: 0.3552, decode.d7.loss_mask: 0.5403, decode.d7.loss_dice: 0.7866, decode.d8.loss_cls: 0.3545, decode.d8.loss_mask: 0.5390, decode.d8.loss_dice: 0.7871, loss: 22.3794
2022-12-01 04:32:28,094 - mmseg - INFO - Iter [26400/40000]	lr: 4.523e-08, eta: 16:29:57, time: 4.117, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3682, decode.loss_mask: 0.5257, decode.loss_dice: 0.7906, decode.d0.loss_cls: 5.4876, decode.d0.loss_mask: 0.5119, decode.d0.loss_dice: 0.8553, decode.d1.loss_cls: 0.4700, decode.d1.loss_mask: 0.5520, decode.d1.loss_dice: 0.8480, decode.d2.loss_cls: 0.4242, decode.d2.loss_mask: 0.5377, decode.d2.loss_dice: 0.8102, decode.d3.loss_cls: 0.3962, decode.d3.loss_mask: 0.5306, decode.d3.loss_dice: 0.7949, decode.d4.loss_cls: 0.3850, decode.d4.loss_mask: 0.5296, decode.d4.loss_dice: 0.7951, decode.d5.loss_cls: 0.3744, decode.d5.loss_mask: 0.5278, decode.d5.loss_dice: 0.7905, decode.d6.loss_cls: 0.3682, decode.d6.loss_mask: 0.5268, decode.d6.loss_dice: 0.7885, decode.d7.loss_cls: 0.3690, decode.d7.loss_mask: 0.5241, decode.d7.loss_dice: 0.7921, decode.d8.loss_cls: 0.3687, decode.d8.loss_mask: 0.5259, decode.d8.loss_dice: 0.7917, loss: 22.3605
2022-12-01 04:35:54,040 - mmseg - INFO - Iter [26450/40000]	lr: 4.507e-08, eta: 16:26:12, time: 4.119, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3616, decode.loss_mask: 0.5650, decode.loss_dice: 0.8178, decode.d0.loss_cls: 5.4787, decode.d0.loss_mask: 0.5564, decode.d0.loss_dice: 0.8749, decode.d1.loss_cls: 0.4749, decode.d1.loss_mask: 0.5955, decode.d1.loss_dice: 0.8742, decode.d2.loss_cls: 0.4216, decode.d2.loss_mask: 0.5802, decode.d2.loss_dice: 0.8385, decode.d3.loss_cls: 0.3866, decode.d3.loss_mask: 0.5710, decode.d3.loss_dice: 0.8244, decode.d4.loss_cls: 0.3775, decode.d4.loss_mask: 0.5719, decode.d4.loss_dice: 0.8203, decode.d5.loss_cls: 0.3701, decode.d5.loss_mask: 0.5691, decode.d5.loss_dice: 0.8179, decode.d6.loss_cls: 0.3621, decode.d6.loss_mask: 0.5686, decode.d6.loss_dice: 0.8139, decode.d7.loss_cls: 0.3632, decode.d7.loss_mask: 0.5675, decode.d7.loss_dice: 0.8162, decode.d8.loss_cls: 0.3595, decode.d8.loss_mask: 0.5674, decode.d8.loss_dice: 0.8160, loss: 22.9825
2022-12-01 04:39:19,653 - mmseg - INFO - Iter [26500/40000]	lr: 4.490e-08, eta: 16:22:27, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3312, decode.loss_mask: 0.5450, decode.loss_dice: 0.7921, decode.d0.loss_cls: 5.4776, decode.d0.loss_mask: 0.5305, decode.d0.loss_dice: 0.8563, decode.d1.loss_cls: 0.4479, decode.d1.loss_mask: 0.5720, decode.d1.loss_dice: 0.8499, decode.d2.loss_cls: 0.3923, decode.d2.loss_mask: 0.5573, decode.d2.loss_dice: 0.8155, decode.d3.loss_cls: 0.3578, decode.d3.loss_mask: 0.5497, decode.d3.loss_dice: 0.8009, decode.d4.loss_cls: 0.3495, decode.d4.loss_mask: 0.5475, decode.d4.loss_dice: 0.7982, decode.d5.loss_cls: 0.3400, decode.d5.loss_mask: 0.5457, decode.d5.loss_dice: 0.7955, decode.d6.loss_cls: 0.3369, decode.d6.loss_mask: 0.5422, decode.d6.loss_dice: 0.7878, decode.d7.loss_cls: 0.3321, decode.d7.loss_mask: 0.5447, decode.d7.loss_dice: 0.7903, decode.d8.loss_cls: 0.3312, decode.d8.loss_mask: 0.5428, decode.d8.loss_dice: 0.7911, loss: 22.2514
2022-12-01 04:42:48,116 - mmseg - INFO - Iter [26550/40000]	lr: 4.473e-08, eta: 16:18:44, time: 4.169, data_time: 0.068, memory: 51902, decode.loss_cls: 0.3799, decode.loss_mask: 0.5347, decode.loss_dice: 0.8199, decode.d0.loss_cls: 5.5076, decode.d0.loss_mask: 0.5230, decode.d0.loss_dice: 0.8949, decode.d1.loss_cls: 0.5011, decode.d1.loss_mask: 0.5580, decode.d1.loss_dice: 0.8741, decode.d2.loss_cls: 0.4398, decode.d2.loss_mask: 0.5476, decode.d2.loss_dice: 0.8411, decode.d3.loss_cls: 0.4116, decode.d3.loss_mask: 0.5388, decode.d3.loss_dice: 0.8283, decode.d4.loss_cls: 0.4045, decode.d4.loss_mask: 0.5384, decode.d4.loss_dice: 0.8278, decode.d5.loss_cls: 0.3959, decode.d5.loss_mask: 0.5346, decode.d5.loss_dice: 0.8234, decode.d6.loss_cls: 0.3893, decode.d6.loss_mask: 0.5360, decode.d6.loss_dice: 0.8253, decode.d7.loss_cls: 0.3869, decode.d7.loss_mask: 0.5346, decode.d7.loss_dice: 0.8219, decode.d8.loss_cls: 0.3836, decode.d8.loss_mask: 0.5359, decode.d8.loss_dice: 0.8221, loss: 22.9606
2022-12-01 04:46:13,873 - mmseg - INFO - Iter [26600/40000]	lr: 4.457e-08, eta: 16:14:59, time: 4.115, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3533, decode.loss_mask: 0.5320, decode.loss_dice: 0.7896, decode.d0.loss_cls: 5.4761, decode.d0.loss_mask: 0.5239, decode.d0.loss_dice: 0.8659, decode.d1.loss_cls: 0.4692, decode.d1.loss_mask: 0.5546, decode.d1.loss_dice: 0.8493, decode.d2.loss_cls: 0.4087, decode.d2.loss_mask: 0.5438, decode.d2.loss_dice: 0.8146, decode.d3.loss_cls: 0.3791, decode.d3.loss_mask: 0.5397, decode.d3.loss_dice: 0.7973, decode.d4.loss_cls: 0.3681, decode.d4.loss_mask: 0.5373, decode.d4.loss_dice: 0.7973, decode.d5.loss_cls: 0.3610, decode.d5.loss_mask: 0.5335, decode.d5.loss_dice: 0.7934, decode.d6.loss_cls: 0.3551, decode.d6.loss_mask: 0.5324, decode.d6.loss_dice: 0.7881, decode.d7.loss_cls: 0.3516, decode.d7.loss_mask: 0.5326, decode.d7.loss_dice: 0.7916, decode.d8.loss_cls: 0.3526, decode.d8.loss_mask: 0.5325, decode.d8.loss_dice: 0.7890, loss: 22.3131
2022-12-01 04:49:39,633 - mmseg - INFO - Iter [26650/40000]	lr: 4.440e-08, eta: 16:11:15, time: 4.115, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3452, decode.loss_mask: 0.5435, decode.loss_dice: 0.7808, decode.d0.loss_cls: 5.4463, decode.d0.loss_mask: 0.5300, decode.d0.loss_dice: 0.8456, decode.d1.loss_cls: 0.4598, decode.d1.loss_mask: 0.5673, decode.d1.loss_dice: 0.8381, decode.d2.loss_cls: 0.4008, decode.d2.loss_mask: 0.5554, decode.d2.loss_dice: 0.8042, decode.d3.loss_cls: 0.3700, decode.d3.loss_mask: 0.5515, decode.d3.loss_dice: 0.7906, decode.d4.loss_cls: 0.3607, decode.d4.loss_mask: 0.5475, decode.d4.loss_dice: 0.7870, decode.d5.loss_cls: 0.3487, decode.d5.loss_mask: 0.5462, decode.d5.loss_dice: 0.7878, decode.d6.loss_cls: 0.3471, decode.d6.loss_mask: 0.5457, decode.d6.loss_dice: 0.7813, decode.d7.loss_cls: 0.3469, decode.d7.loss_mask: 0.5451, decode.d7.loss_dice: 0.7841, decode.d8.loss_cls: 0.3442, decode.d8.loss_mask: 0.5433, decode.d8.loss_dice: 0.7850, loss: 22.2297
2022-12-01 04:53:05,367 - mmseg - INFO - Iter [26700/40000]	lr: 4.424e-08, eta: 16:07:30, time: 4.115, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3557, decode.loss_mask: 0.5412, decode.loss_dice: 0.7961, decode.d0.loss_cls: 5.4524, decode.d0.loss_mask: 0.5337, decode.d0.loss_dice: 0.8687, decode.d1.loss_cls: 0.4734, decode.d1.loss_mask: 0.5664, decode.d1.loss_dice: 0.8606, decode.d2.loss_cls: 0.4111, decode.d2.loss_mask: 0.5525, decode.d2.loss_dice: 0.8279, decode.d3.loss_cls: 0.3813, decode.d3.loss_mask: 0.5470, decode.d3.loss_dice: 0.8113, decode.d4.loss_cls: 0.3741, decode.d4.loss_mask: 0.5425, decode.d4.loss_dice: 0.8062, decode.d5.loss_cls: 0.3647, decode.d5.loss_mask: 0.5410, decode.d5.loss_dice: 0.8033, decode.d6.loss_cls: 0.3596, decode.d6.loss_mask: 0.5434, decode.d6.loss_dice: 0.8023, decode.d7.loss_cls: 0.3567, decode.d7.loss_mask: 0.5413, decode.d7.loss_dice: 0.8000, decode.d8.loss_cls: 0.3535, decode.d8.loss_mask: 0.5400, decode.d8.loss_dice: 0.8023, loss: 22.5103
2022-12-01 04:56:31,368 - mmseg - INFO - Iter [26750/40000]	lr: 4.407e-08, eta: 16:03:46, time: 4.119, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3493, decode.loss_mask: 0.5448, decode.loss_dice: 0.8058, decode.d0.loss_cls: 5.4692, decode.d0.loss_mask: 0.5327, decode.d0.loss_dice: 0.8656, decode.d1.loss_cls: 0.4663, decode.d1.loss_mask: 0.5677, decode.d1.loss_dice: 0.8555, decode.d2.loss_cls: 0.4084, decode.d2.loss_mask: 0.5560, decode.d2.loss_dice: 0.8207, decode.d3.loss_cls: 0.3773, decode.d3.loss_mask: 0.5494, decode.d3.loss_dice: 0.8097, decode.d4.loss_cls: 0.3678, decode.d4.loss_mask: 0.5461, decode.d4.loss_dice: 0.8097, decode.d5.loss_cls: 0.3588, decode.d5.loss_mask: 0.5458, decode.d5.loss_dice: 0.8062, decode.d6.loss_cls: 0.3524, decode.d6.loss_mask: 0.5433, decode.d6.loss_dice: 0.8024, decode.d7.loss_cls: 0.3528, decode.d7.loss_mask: 0.5440, decode.d7.loss_dice: 0.8023, decode.d8.loss_cls: 0.3500, decode.d8.loss_mask: 0.5428, decode.d8.loss_dice: 0.8009, loss: 22.5040
2022-12-01 04:59:56,842 - mmseg - INFO - Iter [26800/40000]	lr: 4.390e-08, eta: 16:00:01, time: 4.110, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3647, decode.loss_mask: 0.5560, decode.loss_dice: 0.8110, decode.d0.loss_cls: 5.4584, decode.d0.loss_mask: 0.5472, decode.d0.loss_dice: 0.8816, decode.d1.loss_cls: 0.4790, decode.d1.loss_mask: 0.5849, decode.d1.loss_dice: 0.8785, decode.d2.loss_cls: 0.4240, decode.d2.loss_mask: 0.5702, decode.d2.loss_dice: 0.8416, decode.d3.loss_cls: 0.3981, decode.d3.loss_mask: 0.5617, decode.d3.loss_dice: 0.8225, decode.d4.loss_cls: 0.3846, decode.d4.loss_mask: 0.5621, decode.d4.loss_dice: 0.8203, decode.d5.loss_cls: 0.3730, decode.d5.loss_mask: 0.5575, decode.d5.loss_dice: 0.8167, decode.d6.loss_cls: 0.3718, decode.d6.loss_mask: 0.5561, decode.d6.loss_dice: 0.8160, decode.d7.loss_cls: 0.3681, decode.d7.loss_mask: 0.5578, decode.d7.loss_dice: 0.8154, decode.d8.loss_cls: 0.3661, decode.d8.loss_mask: 0.5541, decode.d8.loss_dice: 0.8124, loss: 22.9115
2022-12-01 05:03:22,891 - mmseg - INFO - Iter [26850/40000]	lr: 4.374e-08, eta: 15:56:17, time: 4.121, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3679, decode.loss_mask: 0.5387, decode.loss_dice: 0.8134, decode.d0.loss_cls: 5.4717, decode.d0.loss_mask: 0.5300, decode.d0.loss_dice: 0.8835, decode.d1.loss_cls: 0.4882, decode.d1.loss_mask: 0.5643, decode.d1.loss_dice: 0.8711, decode.d2.loss_cls: 0.4264, decode.d2.loss_mask: 0.5506, decode.d2.loss_dice: 0.8356, decode.d3.loss_cls: 0.3960, decode.d3.loss_mask: 0.5454, decode.d3.loss_dice: 0.8212, decode.d4.loss_cls: 0.3835, decode.d4.loss_mask: 0.5426, decode.d4.loss_dice: 0.8187, decode.d5.loss_cls: 0.3743, decode.d5.loss_mask: 0.5412, decode.d5.loss_dice: 0.8155, decode.d6.loss_cls: 0.3726, decode.d6.loss_mask: 0.5393, decode.d6.loss_dice: 0.8140, decode.d7.loss_cls: 0.3708, decode.d7.loss_mask: 0.5393, decode.d7.loss_dice: 0.8125, decode.d8.loss_cls: 0.3694, decode.d8.loss_mask: 0.5393, decode.d8.loss_dice: 0.8168, loss: 22.7538
2022-12-01 05:06:48,735 - mmseg - INFO - Iter [26900/40000]	lr: 4.357e-08, eta: 15:52:33, time: 4.117, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3717, decode.loss_mask: 0.5372, decode.loss_dice: 0.8088, decode.d0.loss_cls: 5.4633, decode.d0.loss_mask: 0.5249, decode.d0.loss_dice: 0.8755, decode.d1.loss_cls: 0.4868, decode.d1.loss_mask: 0.5631, decode.d1.loss_dice: 0.8683, decode.d2.loss_cls: 0.4271, decode.d2.loss_mask: 0.5503, decode.d2.loss_dice: 0.8347, decode.d3.loss_cls: 0.3954, decode.d3.loss_mask: 0.5455, decode.d3.loss_dice: 0.8187, decode.d4.loss_cls: 0.3890, decode.d4.loss_mask: 0.5437, decode.d4.loss_dice: 0.8161, decode.d5.loss_cls: 0.3779, decode.d5.loss_mask: 0.5408, decode.d5.loss_dice: 0.8122, decode.d6.loss_cls: 0.3766, decode.d6.loss_mask: 0.5388, decode.d6.loss_dice: 0.8078, decode.d7.loss_cls: 0.3684, decode.d7.loss_mask: 0.5384, decode.d7.loss_dice: 0.8125, decode.d8.loss_cls: 0.3698, decode.d8.loss_mask: 0.5371, decode.d8.loss_dice: 0.8140, loss: 22.7146
2022-12-01 05:10:14,475 - mmseg - INFO - Iter [26950/40000]	lr: 4.340e-08, eta: 15:48:49, time: 4.115, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3455, decode.loss_mask: 0.5525, decode.loss_dice: 0.8009, decode.d0.loss_cls: 5.4296, decode.d0.loss_mask: 0.5397, decode.d0.loss_dice: 0.8717, decode.d1.loss_cls: 0.4554, decode.d1.loss_mask: 0.5782, decode.d1.loss_dice: 0.8643, decode.d2.loss_cls: 0.4021, decode.d2.loss_mask: 0.5676, decode.d2.loss_dice: 0.8293, decode.d3.loss_cls: 0.3721, decode.d3.loss_mask: 0.5588, decode.d3.loss_dice: 0.8168, decode.d4.loss_cls: 0.3613, decode.d4.loss_mask: 0.5554, decode.d4.loss_dice: 0.8117, decode.d5.loss_cls: 0.3482, decode.d5.loss_mask: 0.5554, decode.d5.loss_dice: 0.8098, decode.d6.loss_cls: 0.3463, decode.d6.loss_mask: 0.5524, decode.d6.loss_dice: 0.8080, decode.d7.loss_cls: 0.3442, decode.d7.loss_mask: 0.5541, decode.d7.loss_dice: 0.8041, decode.d8.loss_cls: 0.3451, decode.d8.loss_mask: 0.5525, decode.d8.loss_dice: 0.8035, loss: 22.5364
2022-12-01 05:13:40,135 - mmseg - INFO - Saving checkpoint at 27000 iterations
2022-12-01 05:14:22,614 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 05:14:22,614 - mmseg - INFO - Iter [27000/40000]	lr: 4.324e-08, eta: 15:45:25, time: 4.963, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3628, decode.loss_mask: 0.5468, decode.loss_dice: 0.8046, decode.d0.loss_cls: 5.4204, decode.d0.loss_mask: 0.5384, decode.d0.loss_dice: 0.8702, decode.d1.loss_cls: 0.4713, decode.d1.loss_mask: 0.5728, decode.d1.loss_dice: 0.8608, decode.d2.loss_cls: 0.4182, decode.d2.loss_mask: 0.5581, decode.d2.loss_dice: 0.8266, decode.d3.loss_cls: 0.3873, decode.d3.loss_mask: 0.5546, decode.d3.loss_dice: 0.8149, decode.d4.loss_cls: 0.3805, decode.d4.loss_mask: 0.5518, decode.d4.loss_dice: 0.8035, decode.d5.loss_cls: 0.3704, decode.d5.loss_mask: 0.5495, decode.d5.loss_dice: 0.8053, decode.d6.loss_cls: 0.3692, decode.d6.loss_mask: 0.5481, decode.d6.loss_dice: 0.8005, decode.d7.loss_cls: 0.3666, decode.d7.loss_mask: 0.5469, decode.d7.loss_dice: 0.8045, decode.d8.loss_cls: 0.3630, decode.d8.loss_mask: 0.5478, decode.d8.loss_dice: 0.8038, loss: 22.6196
2022-12-01 05:17:20,609 - mmseg - INFO - per class results:
2022-12-01 05:17:20,614 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 82.96 |  89.1 |
|       building      | 85.22 | 91.63 |
|         sky         | 95.17 | 97.32 |
|        floor        | 85.15 |  90.4 |
|         tree        | 78.21 | 89.24 |
|       ceiling       | 87.32 | 92.98 |
|         road        | 88.12 | 91.38 |
|         bed         | 93.84 | 97.33 |
|      windowpane     |  68.1 | 81.48 |
|        grass        | 69.34 | 81.16 |
|       cabinet       | 63.13 |  71.8 |
|       sidewalk      | 71.31 | 85.91 |
|        person       | 88.34 | 94.08 |
|        earth        | 45.21 | 61.99 |
|         door        | 64.81 | 83.06 |
|        table        | 72.65 | 82.42 |
|       mountain      | 61.24 | 70.87 |
|        plant        | 57.71 | 72.18 |
|       curtain       | 82.88 | 91.27 |
|        chair        | 69.23 | 80.08 |
|         car         | 89.34 | 94.52 |
|        water        | 66.24 | 84.68 |
|       painting      | 81.47 | 92.59 |
|         sofa        | 84.81 | 90.34 |
|        shelf        | 49.63 | 61.74 |
|        house        |  53.2 | 70.73 |
|         sea         | 80.34 |  89.6 |
|        mirror       | 81.05 | 93.09 |
|         rug         |  72.6 | 84.46 |
|        field        | 34.67 | 65.31 |
|       armchair      | 64.32 | 80.24 |
|         seat        |  66.6 | 90.72 |
|        fence        | 57.26 | 76.79 |
|         desk        |  59.2 | 83.49 |
|         rock        | 60.14 | 75.94 |
|       wardrobe      | 59.42 | 87.44 |
|         lamp        | 80.93 | 89.65 |
|       bathtub       | 91.07 | 92.64 |
|       railing       | 47.53 |  71.3 |
|       cushion       | 77.39 | 90.16 |
|         base        | 46.67 | 76.28 |
|         box         | 44.34 | 64.23 |
|        column       | 57.87 | 74.04 |
|      signboard      |  44.5 | 68.18 |
|   chest of drawers  | 49.25 | 74.91 |
|       counter       | 54.29 | 68.14 |
|         sand        | 62.35 | 87.37 |
|         sink        |  82.5 | 86.82 |
|      skyscraper     | 42.45 | 52.04 |
|      fireplace      | 80.74 | 93.95 |
|     refrigerator    | 82.43 | 90.75 |
|      grandstand     | 49.23 | 79.75 |
|         path        |  32.6 | 41.81 |
|        stairs       | 37.89 | 51.59 |
|        runway       | 74.35 | 93.75 |
|         case        | 68.03 | 85.06 |
|      pool table     | 95.61 | 98.36 |
|        pillow       | 72.27 | 83.61 |
|     screen door     | 85.48 | 94.75 |
|       stairway      | 57.73 |  75.3 |
|        river        | 25.39 | 29.37 |
|        bridge       | 68.62 | 86.94 |
|       bookcase      | 44.76 | 67.89 |
|        blind        | 47.65 | 58.84 |
|     coffee table    | 73.59 | 92.46 |
|        toilet       | 92.22 |  95.3 |
|        flower       | 46.63 | 69.29 |
|         book        | 60.65 |  81.9 |
|         hill        | 14.51 | 28.86 |
|        bench        | 74.61 | 82.89 |
|      countertop     | 68.76 | 90.68 |
|        stove        | 86.27 | 90.23 |
|         palm        | 55.29 | 81.94 |
|    kitchen island   | 48.94 | 96.12 |
|       computer      | 79.35 | 85.81 |
|     swivel chair    | 55.29 | 82.92 |
|         boat        | 53.96 | 89.68 |
|         bar         | 67.17 | 76.84 |
|    arcade machine   | 91.28 | 98.59 |
|        hovel        | 55.05 | 85.27 |
|         bus         | 94.34 | 96.63 |
|        towel        | 83.45 | 94.26 |
|        light        | 65.64 | 79.66 |
|        truck        | 50.98 | 72.95 |
|        tower        | 32.86 | 63.21 |
|      chandelier     | 76.73 | 86.45 |
|        awning       | 33.36 | 54.12 |
|     streetlight     | 45.66 | 68.36 |
|        booth        | 56.33 | 73.85 |
| television receiver | 77.54 | 92.03 |
|       airplane      | 88.88 | 96.67 |
|      dirt track     | 23.78 | 47.12 |
|       apparel       | 52.73 | 89.38 |
|         pole        | 31.13 | 43.98 |
|         land        |  2.35 |  3.33 |
|      bannister      | 23.43 | 34.51 |
|      escalator      |  64.1 | 86.05 |
|       ottoman       | 55.37 | 77.57 |
|        bottle       | 52.77 | 82.76 |
|        buffet       |  45.6 | 66.21 |
|        poster       | 41.97 | 59.73 |
|        stage        |  30.3 |  79.6 |
|         van         | 49.69 | 76.18 |
|         ship        | 24.74 | 25.94 |
|       fountain      | 48.84 | 58.07 |
|    conveyer belt    | 76.98 | 97.27 |
|        canopy       | 48.84 |  64.1 |
|        washer       | 90.27 | 93.13 |
|      plaything      | 39.83 | 62.49 |
|    swimming pool    | 46.97 | 75.39 |
|        stool        | 58.13 | 85.12 |
|        barrel       |  62.6 | 91.34 |
|        basket       | 49.04 | 76.58 |
|      waterfall      | 46.07 | 56.54 |
|         tent        | 95.11 | 98.07 |
|         bag         | 35.08 | 50.93 |
|       minibike      | 81.06 | 94.22 |
|        cradle       | 91.55 |  97.8 |
|         oven        |  65.4 | 83.71 |
|         ball        | 40.77 | 44.43 |
|         food        |  69.4 | 84.41 |
|         step        | 28.81 |  45.8 |
|         tank        | 62.12 | 67.34 |
|      trade name     | 31.98 | 41.61 |
|      microwave      | 89.84 |  94.5 |
|         pot         | 62.02 |  75.4 |
|        animal       | 82.82 | 85.57 |
|       bicycle       | 63.11 | 84.25 |
|         lake        |  0.03 |  0.03 |
|      dishwasher     | 80.53 | 90.33 |
|        screen       | 60.43 | 92.91 |
|       blanket       | 45.66 | 60.32 |
|      sculpture      | 72.45 | 90.59 |
|         hood        | 76.21 | 85.72 |
|        sconce       | 66.84 |  83.1 |
|         vase        | 60.18 |  80.9 |
|    traffic light    | 52.14 | 71.14 |
|         tray        | 33.58 | 52.36 |
|        ashcan       | 52.78 | 76.65 |
|         fan         | 73.73 | 86.79 |
|         pier        | 37.55 | 42.04 |
|      crt screen     |  3.2  |  8.47 |
|        plate        | 68.97 | 84.51 |
|       monitor       |  4.58 |  6.67 |
|    bulletin board   | 58.51 | 82.85 |
|        shower       |  13.1 | 28.76 |
|       radiator      | 73.73 | 88.92 |
|        glass        | 28.93 | 31.62 |
|        clock        |  62.6 | 78.32 |
|         flag        | 66.48 | 88.38 |
+---------------------+-------+-------+
2022-12-01 05:17:20,614 - mmseg - INFO - Summary:
2022-12-01 05:17:20,614 - mmseg - INFO - 
+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 86.92 | 60.4 | 75.62 |
+-------+------+-------+
2022-12-01 05:17:20,620 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 05:17:20,620 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8692, mIoU: 0.6040, mAcc: 0.7562, IoU.wall: 0.8296, IoU.building: 0.8522, IoU.sky: 0.9517, IoU.floor: 0.8515, IoU.tree: 0.7821, IoU.ceiling: 0.8732, IoU.road: 0.8812, IoU.bed : 0.9384, IoU.windowpane: 0.6810, IoU.grass: 0.6934, IoU.cabinet: 0.6313, IoU.sidewalk: 0.7131, IoU.person: 0.8834, IoU.earth: 0.4521, IoU.door: 0.6481, IoU.table: 0.7265, IoU.mountain: 0.6124, IoU.plant: 0.5771, IoU.curtain: 0.8288, IoU.chair: 0.6923, IoU.car: 0.8934, IoU.water: 0.6624, IoU.painting: 0.8147, IoU.sofa: 0.8481, IoU.shelf: 0.4963, IoU.house: 0.5320, IoU.sea: 0.8034, IoU.mirror: 0.8105, IoU.rug: 0.7260, IoU.field: 0.3467, IoU.armchair: 0.6432, IoU.seat: 0.6660, IoU.fence: 0.5726, IoU.desk: 0.5920, IoU.rock: 0.6014, IoU.wardrobe: 0.5942, IoU.lamp: 0.8093, IoU.bathtub: 0.9107, IoU.railing: 0.4753, IoU.cushion: 0.7739, IoU.base: 0.4667, IoU.box: 0.4434, IoU.column: 0.5787, IoU.signboard: 0.4450, IoU.chest of drawers: 0.4925, IoU.counter: 0.5429, IoU.sand: 0.6235, IoU.sink: 0.8250, IoU.skyscraper: 0.4245, IoU.fireplace: 0.8074, IoU.refrigerator: 0.8243, IoU.grandstand: 0.4923, IoU.path: 0.3260, IoU.stairs: 0.3789, IoU.runway: 0.7435, IoU.case: 0.6803, IoU.pool table: 0.9561, IoU.pillow: 0.7227, IoU.screen door: 0.8548, IoU.stairway: 0.5773, IoU.river: 0.2539, IoU.bridge: 0.6862, IoU.bookcase: 0.4476, IoU.blind: 0.4765, IoU.coffee table: 0.7359, IoU.toilet: 0.9222, IoU.flower: 0.4663, IoU.book: 0.6065, IoU.hill: 0.1451, IoU.bench: 0.7461, IoU.countertop: 0.6876, IoU.stove: 0.8627, IoU.palm: 0.5529, IoU.kitchen island: 0.4894, IoU.computer: 0.7935, IoU.swivel chair: 0.5529, IoU.boat: 0.5396, IoU.bar: 0.6717, IoU.arcade machine: 0.9128, IoU.hovel: 0.5505, IoU.bus: 0.9434, IoU.towel: 0.8345, IoU.light: 0.6564, IoU.truck: 0.5098, IoU.tower: 0.3286, IoU.chandelier: 0.7673, IoU.awning: 0.3336, IoU.streetlight: 0.4566, IoU.booth: 0.5633, IoU.television receiver: 0.7754, IoU.airplane: 0.8888, IoU.dirt track: 0.2378, IoU.apparel: 0.5273, IoU.pole: 0.3113, IoU.land: 0.0235, IoU.bannister: 0.2343, IoU.escalator: 0.6410, IoU.ottoman: 0.5537, IoU.bottle: 0.5277, IoU.buffet: 0.4560, IoU.poster: 0.4197, IoU.stage: 0.3030, IoU.van: 0.4969, IoU.ship: 0.2474, IoU.fountain: 0.4884, IoU.conveyer belt: 0.7698, IoU.canopy: 0.4884, IoU.washer: 0.9027, IoU.plaything: 0.3983, IoU.swimming pool: 0.4697, IoU.stool: 0.5813, IoU.barrel: 0.6260, IoU.basket: 0.4904, IoU.waterfall: 0.4607, IoU.tent: 0.9511, IoU.bag: 0.3508, IoU.minibike: 0.8106, IoU.cradle: 0.9155, IoU.oven: 0.6540, IoU.ball: 0.4077, IoU.food: 0.6940, IoU.step: 0.2881, IoU.tank: 0.6212, IoU.trade name: 0.3198, IoU.microwave: 0.8984, IoU.pot: 0.6202, IoU.animal: 0.8282, IoU.bicycle: 0.6311, IoU.lake: 0.0003, IoU.dishwasher: 0.8053, IoU.screen: 0.6043, IoU.blanket: 0.4566, IoU.sculpture: 0.7245, IoU.hood: 0.7621, IoU.sconce: 0.6684, IoU.vase: 0.6018, IoU.traffic light: 0.5214, IoU.tray: 0.3358, IoU.ashcan: 0.5278, IoU.fan: 0.7373, IoU.pier: 0.3755, IoU.crt screen: 0.0320, IoU.plate: 0.6897, IoU.monitor: 0.0458, IoU.bulletin board: 0.5851, IoU.shower: 0.1310, IoU.radiator: 0.7373, IoU.glass: 0.2893, IoU.clock: 0.6260, IoU.flag: 0.6648, Acc.wall: 0.8910, Acc.building: 0.9163, Acc.sky: 0.9732, Acc.floor: 0.9040, Acc.tree: 0.8924, Acc.ceiling: 0.9298, Acc.road: 0.9138, Acc.bed : 0.9733, Acc.windowpane: 0.8148, Acc.grass: 0.8116, Acc.cabinet: 0.7180, Acc.sidewalk: 0.8591, Acc.person: 0.9408, Acc.earth: 0.6199, Acc.door: 0.8306, Acc.table: 0.8242, Acc.mountain: 0.7087, Acc.plant: 0.7218, Acc.curtain: 0.9127, Acc.chair: 0.8008, Acc.car: 0.9452, Acc.water: 0.8468, Acc.painting: 0.9259, Acc.sofa: 0.9034, Acc.shelf: 0.6174, Acc.house: 0.7073, Acc.sea: 0.8960, Acc.mirror: 0.9309, Acc.rug: 0.8446, Acc.field: 0.6531, Acc.armchair: 0.8024, Acc.seat: 0.9072, Acc.fence: 0.7679, Acc.desk: 0.8349, Acc.rock: 0.7594, Acc.wardrobe: 0.8744, Acc.lamp: 0.8965, Acc.bathtub: 0.9264, Acc.railing: 0.7130, Acc.cushion: 0.9016, Acc.base: 0.7628, Acc.box: 0.6423, Acc.column: 0.7404, Acc.signboard: 0.6818, Acc.chest of drawers: 0.7491, Acc.counter: 0.6814, Acc.sand: 0.8737, Acc.sink: 0.8682, Acc.skyscraper: 0.5204, Acc.fireplace: 0.9395, Acc.refrigerator: 0.9075, Acc.grandstand: 0.7975, Acc.path: 0.4181, Acc.stairs: 0.5159, Acc.runway: 0.9375, Acc.case: 0.8506, Acc.pool table: 0.9836, Acc.pillow: 0.8361, Acc.screen door: 0.9475, Acc.stairway: 0.7530, Acc.river: 0.2937, Acc.bridge: 0.8694, Acc.bookcase: 0.6789, Acc.blind: 0.5884, Acc.coffee table: 0.9246, Acc.toilet: 0.9530, Acc.flower: 0.6929, Acc.book: 0.8190, Acc.hill: 0.2886, Acc.bench: 0.8289, Acc.countertop: 0.9068, Acc.stove: 0.9023, Acc.palm: 0.8194, Acc.kitchen island: 0.9612, Acc.computer: 0.8581, Acc.swivel chair: 0.8292, Acc.boat: 0.8968, Acc.bar: 0.7684, Acc.arcade machine: 0.9859, Acc.hovel: 0.8527, Acc.bus: 0.9663, Acc.towel: 0.9426, Acc.light: 0.7966, Acc.truck: 0.7295, Acc.tower: 0.6321, Acc.chandelier: 0.8645, Acc.awning: 0.5412, Acc.streetlight: 0.6836, Acc.booth: 0.7385, Acc.television receiver: 0.9203, Acc.airplane: 0.9667, Acc.dirt track: 0.4712, Acc.apparel: 0.8938, Acc.pole: 0.4398, Acc.land: 0.0333, Acc.bannister: 0.3451, Acc.escalator: 0.8605, Acc.ottoman: 0.7757, Acc.bottle: 0.8276, Acc.buffet: 0.6621, Acc.poster: 0.5973, Acc.stage: 0.7960, Acc.van: 0.7618, Acc.ship: 0.2594, Acc.fountain: 0.5807, Acc.conveyer belt: 0.9727, Acc.canopy: 0.6410, Acc.washer: 0.9313, Acc.plaything: 0.6249, Acc.swimming pool: 0.7539, Acc.stool: 0.8512, Acc.barrel: 0.9134, Acc.basket: 0.7658, Acc.waterfall: 0.5654, Acc.tent: 0.9807, Acc.bag: 0.5093, Acc.minibike: 0.9422, Acc.cradle: 0.9780, Acc.oven: 0.8371, Acc.ball: 0.4443, Acc.food: 0.8441, Acc.step: 0.4580, Acc.tank: 0.6734, Acc.trade name: 0.4161, Acc.microwave: 0.9450, Acc.pot: 0.7540, Acc.animal: 0.8557, Acc.bicycle: 0.8425, Acc.lake: 0.0003, Acc.dishwasher: 0.9033, Acc.screen: 0.9291, Acc.blanket: 0.6032, Acc.sculpture: 0.9059, Acc.hood: 0.8572, Acc.sconce: 0.8310, Acc.vase: 0.8090, Acc.traffic light: 0.7114, Acc.tray: 0.5236, Acc.ashcan: 0.7665, Acc.fan: 0.8679, Acc.pier: 0.4204, Acc.crt screen: 0.0847, Acc.plate: 0.8451, Acc.monitor: 0.0667, Acc.bulletin board: 0.8285, Acc.shower: 0.2876, Acc.radiator: 0.8892, Acc.glass: 0.3162, Acc.clock: 0.7832, Acc.flag: 0.8838
2022-12-01 05:20:47,189 - mmseg - INFO - Iter [27050/40000]	lr: 4.307e-08, eta: 15:43:07, time: 7.691, data_time: 3.580, memory: 51902, decode.loss_cls: 0.3588, decode.loss_mask: 0.5429, decode.loss_dice: 0.7930, decode.d0.loss_cls: 5.4279, decode.d0.loss_mask: 0.5281, decode.d0.loss_dice: 0.8603, decode.d1.loss_cls: 0.4687, decode.d1.loss_mask: 0.5642, decode.d1.loss_dice: 0.8523, decode.d2.loss_cls: 0.4117, decode.d2.loss_mask: 0.5554, decode.d2.loss_dice: 0.8214, decode.d3.loss_cls: 0.3793, decode.d3.loss_mask: 0.5492, decode.d3.loss_dice: 0.8035, decode.d4.loss_cls: 0.3734, decode.d4.loss_mask: 0.5459, decode.d4.loss_dice: 0.8020, decode.d5.loss_cls: 0.3621, decode.d5.loss_mask: 0.5448, decode.d5.loss_dice: 0.8010, decode.d6.loss_cls: 0.3631, decode.d6.loss_mask: 0.5414, decode.d6.loss_dice: 0.7936, decode.d7.loss_cls: 0.3539, decode.d7.loss_mask: 0.5426, decode.d7.loss_dice: 0.7989, decode.d8.loss_cls: 0.3584, decode.d8.loss_mask: 0.5410, decode.d8.loss_dice: 0.7959, loss: 22.4349
2022-12-01 05:24:12,794 - mmseg - INFO - Iter [27100/40000]	lr: 4.290e-08, eta: 15:39:22, time: 4.112, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3532, decode.loss_mask: 0.5251, decode.loss_dice: 0.7873, decode.d0.loss_cls: 5.4362, decode.d0.loss_mask: 0.5161, decode.d0.loss_dice: 0.8490, decode.d1.loss_cls: 0.4715, decode.d1.loss_mask: 0.5488, decode.d1.loss_dice: 0.8372, decode.d2.loss_cls: 0.4178, decode.d2.loss_mask: 0.5340, decode.d2.loss_dice: 0.8041, decode.d3.loss_cls: 0.3825, decode.d3.loss_mask: 0.5298, decode.d3.loss_dice: 0.7924, decode.d4.loss_cls: 0.3760, decode.d4.loss_mask: 0.5272, decode.d4.loss_dice: 0.7909, decode.d5.loss_cls: 0.3651, decode.d5.loss_mask: 0.5257, decode.d5.loss_dice: 0.7893, decode.d6.loss_cls: 0.3626, decode.d6.loss_mask: 0.5261, decode.d6.loss_dice: 0.7820, decode.d7.loss_cls: 0.3601, decode.d7.loss_mask: 0.5246, decode.d7.loss_dice: 0.7840, decode.d8.loss_cls: 0.3567, decode.d8.loss_mask: 0.5225, decode.d8.loss_dice: 0.7843, loss: 22.1619
2022-12-01 05:27:38,676 - mmseg - INFO - Iter [27150/40000]	lr: 4.274e-08, eta: 15:35:38, time: 4.118, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3727, decode.loss_mask: 0.5360, decode.loss_dice: 0.8081, decode.d0.loss_cls: 5.4407, decode.d0.loss_mask: 0.5270, decode.d0.loss_dice: 0.8785, decode.d1.loss_cls: 0.4866, decode.d1.loss_mask: 0.5661, decode.d1.loss_dice: 0.8729, decode.d2.loss_cls: 0.4288, decode.d2.loss_mask: 0.5518, decode.d2.loss_dice: 0.8376, decode.d3.loss_cls: 0.3946, decode.d3.loss_mask: 0.5442, decode.d3.loss_dice: 0.8192, decode.d4.loss_cls: 0.3875, decode.d4.loss_mask: 0.5436, decode.d4.loss_dice: 0.8174, decode.d5.loss_cls: 0.3783, decode.d5.loss_mask: 0.5404, decode.d5.loss_dice: 0.8151, decode.d6.loss_cls: 0.3739, decode.d6.loss_mask: 0.5379, decode.d6.loss_dice: 0.8116, decode.d7.loss_cls: 0.3745, decode.d7.loss_mask: 0.5353, decode.d7.loss_dice: 0.8108, decode.d8.loss_cls: 0.3700, decode.d8.loss_mask: 0.5372, decode.d8.loss_dice: 0.8096, loss: 22.7082
2022-12-01 05:31:06,853 - mmseg - INFO - Iter [27200/40000]	lr: 4.257e-08, eta: 15:31:54, time: 4.164, data_time: 0.070, memory: 51902, decode.loss_cls: 0.3536, decode.loss_mask: 0.5534, decode.loss_dice: 0.8171, decode.d0.loss_cls: 5.3976, decode.d0.loss_mask: 0.5386, decode.d0.loss_dice: 0.8776, decode.d1.loss_cls: 0.4715, decode.d1.loss_mask: 0.5760, decode.d1.loss_dice: 0.8739, decode.d2.loss_cls: 0.4179, decode.d2.loss_mask: 0.5632, decode.d2.loss_dice: 0.8349, decode.d3.loss_cls: 0.3802, decode.d3.loss_mask: 0.5600, decode.d3.loss_dice: 0.8220, decode.d4.loss_cls: 0.3746, decode.d4.loss_mask: 0.5566, decode.d4.loss_dice: 0.8201, decode.d5.loss_cls: 0.3609, decode.d5.loss_mask: 0.5538, decode.d5.loss_dice: 0.8134, decode.d6.loss_cls: 0.3620, decode.d6.loss_mask: 0.5534, decode.d6.loss_dice: 0.8111, decode.d7.loss_cls: 0.3559, decode.d7.loss_mask: 0.5532, decode.d7.loss_dice: 0.8171, decode.d8.loss_cls: 0.3549, decode.d8.loss_mask: 0.5535, decode.d8.loss_dice: 0.8159, loss: 22.6936
2022-12-01 05:34:32,713 - mmseg - INFO - Iter [27250/40000]	lr: 4.241e-08, eta: 15:28:10, time: 4.117, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3539, decode.loss_mask: 0.5307, decode.loss_dice: 0.7992, decode.d0.loss_cls: 5.4326, decode.d0.loss_mask: 0.5226, decode.d0.loss_dice: 0.8677, decode.d1.loss_cls: 0.4700, decode.d1.loss_mask: 0.5549, decode.d1.loss_dice: 0.8529, decode.d2.loss_cls: 0.4146, decode.d2.loss_mask: 0.5460, decode.d2.loss_dice: 0.8229, decode.d3.loss_cls: 0.3801, decode.d3.loss_mask: 0.5401, decode.d3.loss_dice: 0.8073, decode.d4.loss_cls: 0.3743, decode.d4.loss_mask: 0.5350, decode.d4.loss_dice: 0.8019, decode.d5.loss_cls: 0.3625, decode.d5.loss_mask: 0.5340, decode.d5.loss_dice: 0.7990, decode.d6.loss_cls: 0.3606, decode.d6.loss_mask: 0.5316, decode.d6.loss_dice: 0.7947, decode.d7.loss_cls: 0.3561, decode.d7.loss_mask: 0.5311, decode.d7.loss_dice: 0.7950, decode.d8.loss_cls: 0.3562, decode.d8.loss_mask: 0.5317, decode.d8.loss_dice: 0.7992, loss: 22.3582
2022-12-01 05:37:58,710 - mmseg - INFO - Iter [27300/40000]	lr: 4.224e-08, eta: 15:24:26, time: 4.120, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3453, decode.loss_mask: 0.5342, decode.loss_dice: 0.7981, decode.d0.loss_cls: 5.4204, decode.d0.loss_mask: 0.5258, decode.d0.loss_dice: 0.8655, decode.d1.loss_cls: 0.4587, decode.d1.loss_mask: 0.5621, decode.d1.loss_dice: 0.8576, decode.d2.loss_cls: 0.4009, decode.d2.loss_mask: 0.5477, decode.d2.loss_dice: 0.8225, decode.d3.loss_cls: 0.3699, decode.d3.loss_mask: 0.5426, decode.d3.loss_dice: 0.8124, decode.d4.loss_cls: 0.3599, decode.d4.loss_mask: 0.5392, decode.d4.loss_dice: 0.8072, decode.d5.loss_cls: 0.3496, decode.d5.loss_mask: 0.5379, decode.d5.loss_dice: 0.8047, decode.d6.loss_cls: 0.3470, decode.d6.loss_mask: 0.5366, decode.d6.loss_dice: 0.8028, decode.d7.loss_cls: 0.3451, decode.d7.loss_mask: 0.5356, decode.d7.loss_dice: 0.8003, decode.d8.loss_cls: 0.3431, decode.d8.loss_mask: 0.5353, decode.d8.loss_dice: 0.7960, loss: 22.3038
2022-12-01 05:41:24,285 - mmseg - INFO - Iter [27350/40000]	lr: 4.207e-08, eta: 15:20:42, time: 4.111, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3454, decode.loss_mask: 0.5287, decode.loss_dice: 0.7792, decode.d0.loss_cls: 5.4217, decode.d0.loss_mask: 0.5201, decode.d0.loss_dice: 0.8548, decode.d1.loss_cls: 0.4708, decode.d1.loss_mask: 0.5548, decode.d1.loss_dice: 0.8436, decode.d2.loss_cls: 0.4065, decode.d2.loss_mask: 0.5437, decode.d2.loss_dice: 0.8091, decode.d3.loss_cls: 0.3712, decode.d3.loss_mask: 0.5355, decode.d3.loss_dice: 0.7914, decode.d4.loss_cls: 0.3626, decode.d4.loss_mask: 0.5327, decode.d4.loss_dice: 0.7901, decode.d5.loss_cls: 0.3545, decode.d5.loss_mask: 0.5312, decode.d5.loss_dice: 0.7841, decode.d6.loss_cls: 0.3513, decode.d6.loss_mask: 0.5297, decode.d6.loss_dice: 0.7861, decode.d7.loss_cls: 0.3424, decode.d7.loss_mask: 0.5302, decode.d7.loss_dice: 0.7817, decode.d8.loss_cls: 0.3428, decode.d8.loss_mask: 0.5288, decode.d8.loss_dice: 0.7811, loss: 22.1058
2022-12-01 05:44:50,084 - mmseg - INFO - Iter [27400/40000]	lr: 4.191e-08, eta: 15:16:57, time: 4.115, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3731, decode.loss_mask: 0.5399, decode.loss_dice: 0.8088, decode.d0.loss_cls: 5.3981, decode.d0.loss_mask: 0.5335, decode.d0.loss_dice: 0.8783, decode.d1.loss_cls: 0.4917, decode.d1.loss_mask: 0.5672, decode.d1.loss_dice: 0.8701, decode.d2.loss_cls: 0.4370, decode.d2.loss_mask: 0.5528, decode.d2.loss_dice: 0.8328, decode.d3.loss_cls: 0.3996, decode.d3.loss_mask: 0.5466, decode.d3.loss_dice: 0.8219, decode.d4.loss_cls: 0.3905, decode.d4.loss_mask: 0.5461, decode.d4.loss_dice: 0.8175, decode.d5.loss_cls: 0.3791, decode.d5.loss_mask: 0.5438, decode.d5.loss_dice: 0.8137, decode.d6.loss_cls: 0.3763, decode.d6.loss_mask: 0.5420, decode.d6.loss_dice: 0.8117, decode.d7.loss_cls: 0.3735, decode.d7.loss_mask: 0.5430, decode.d7.loss_dice: 0.8088, decode.d8.loss_cls: 0.3690, decode.d8.loss_mask: 0.5417, decode.d8.loss_dice: 0.8130, loss: 22.7214
2022-12-01 05:48:16,127 - mmseg - INFO - Iter [27450/40000]	lr: 4.174e-08, eta: 15:13:13, time: 4.121, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3564, decode.loss_mask: 0.5386, decode.loss_dice: 0.8012, decode.d0.loss_cls: 5.4107, decode.d0.loss_mask: 0.5304, decode.d0.loss_dice: 0.8716, decode.d1.loss_cls: 0.4681, decode.d1.loss_mask: 0.5683, decode.d1.loss_dice: 0.8629, decode.d2.loss_cls: 0.4118, decode.d2.loss_mask: 0.5537, decode.d2.loss_dice: 0.8223, decode.d3.loss_cls: 0.3802, decode.d3.loss_mask: 0.5468, decode.d3.loss_dice: 0.8126, decode.d4.loss_cls: 0.3776, decode.d4.loss_mask: 0.5437, decode.d4.loss_dice: 0.8055, decode.d5.loss_cls: 0.3642, decode.d5.loss_mask: 0.5410, decode.d5.loss_dice: 0.8039, decode.d6.loss_cls: 0.3593, decode.d6.loss_mask: 0.5415, decode.d6.loss_dice: 0.8004, decode.d7.loss_cls: 0.3591, decode.d7.loss_mask: 0.5381, decode.d7.loss_dice: 0.8001, decode.d8.loss_cls: 0.3566, decode.d8.loss_mask: 0.5386, decode.d8.loss_dice: 0.8027, loss: 22.4676
2022-12-01 05:51:42,102 - mmseg - INFO - Iter [27500/40000]	lr: 4.157e-08, eta: 15:09:30, time: 4.120, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3497, decode.loss_mask: 0.5438, decode.loss_dice: 0.7979, decode.d0.loss_cls: 5.3886, decode.d0.loss_mask: 0.5319, decode.d0.loss_dice: 0.8612, decode.d1.loss_cls: 0.4648, decode.d1.loss_mask: 0.5694, decode.d1.loss_dice: 0.8600, decode.d2.loss_cls: 0.4109, decode.d2.loss_mask: 0.5573, decode.d2.loss_dice: 0.8227, decode.d3.loss_cls: 0.3772, decode.d3.loss_mask: 0.5496, decode.d3.loss_dice: 0.8063, decode.d4.loss_cls: 0.3646, decode.d4.loss_mask: 0.5476, decode.d4.loss_dice: 0.8018, decode.d5.loss_cls: 0.3565, decode.d5.loss_mask: 0.5452, decode.d5.loss_dice: 0.8036, decode.d6.loss_cls: 0.3518, decode.d6.loss_mask: 0.5438, decode.d6.loss_dice: 0.8003, decode.d7.loss_cls: 0.3508, decode.d7.loss_mask: 0.5439, decode.d7.loss_dice: 0.7981, decode.d8.loss_cls: 0.3469, decode.d8.loss_mask: 0.5442, decode.d8.loss_dice: 0.7990, loss: 22.3892
2022-12-01 05:55:07,492 - mmseg - INFO - Iter [27550/40000]	lr: 4.141e-08, eta: 15:05:45, time: 4.108, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3468, decode.loss_mask: 0.5582, decode.loss_dice: 0.8155, decode.d0.loss_cls: 5.3593, decode.d0.loss_mask: 0.5491, decode.d0.loss_dice: 0.8804, decode.d1.loss_cls: 0.4573, decode.d1.loss_mask: 0.5862, decode.d1.loss_dice: 0.8713, decode.d2.loss_cls: 0.4080, decode.d2.loss_mask: 0.5719, decode.d2.loss_dice: 0.8338, decode.d3.loss_cls: 0.3758, decode.d3.loss_mask: 0.5669, decode.d3.loss_dice: 0.8225, decode.d4.loss_cls: 0.3657, decode.d4.loss_mask: 0.5615, decode.d4.loss_dice: 0.8218, decode.d5.loss_cls: 0.3592, decode.d5.loss_mask: 0.5580, decode.d5.loss_dice: 0.8189, decode.d6.loss_cls: 0.3516, decode.d6.loss_mask: 0.5594, decode.d6.loss_dice: 0.8172, decode.d7.loss_cls: 0.3516, decode.d7.loss_mask: 0.5597, decode.d7.loss_dice: 0.8171, decode.d8.loss_cls: 0.3516, decode.d8.loss_mask: 0.5581, decode.d8.loss_dice: 0.8131, loss: 22.6674
2022-12-01 05:58:33,515 - mmseg - INFO - Iter [27600/40000]	lr: 4.124e-08, eta: 15:02:02, time: 4.120, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3500, decode.loss_mask: 0.5545, decode.loss_dice: 0.7899, decode.d0.loss_cls: 5.3805, decode.d0.loss_mask: 0.5379, decode.d0.loss_dice: 0.8532, decode.d1.loss_cls: 0.4594, decode.d1.loss_mask: 0.5772, decode.d1.loss_dice: 0.8465, decode.d2.loss_cls: 0.4130, decode.d2.loss_mask: 0.5673, decode.d2.loss_dice: 0.8113, decode.d3.loss_cls: 0.3795, decode.d3.loss_mask: 0.5591, decode.d3.loss_dice: 0.7988, decode.d4.loss_cls: 0.3719, decode.d4.loss_mask: 0.5564, decode.d4.loss_dice: 0.7976, decode.d5.loss_cls: 0.3618, decode.d5.loss_mask: 0.5562, decode.d5.loss_dice: 0.7968, decode.d6.loss_cls: 0.3555, decode.d6.loss_mask: 0.5551, decode.d6.loss_dice: 0.7928, decode.d7.loss_cls: 0.3504, decode.d7.loss_mask: 0.5546, decode.d7.loss_dice: 0.7935, decode.d8.loss_cls: 0.3514, decode.d8.loss_mask: 0.5533, decode.d8.loss_dice: 0.7938, loss: 22.4190
2022-12-01 06:01:59,410 - mmseg - INFO - Iter [27650/40000]	lr: 4.108e-08, eta: 14:58:18, time: 4.118, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3466, decode.loss_mask: 0.5452, decode.loss_dice: 0.8052, decode.d0.loss_cls: 5.3845, decode.d0.loss_mask: 0.5338, decode.d0.loss_dice: 0.8684, decode.d1.loss_cls: 0.4717, decode.d1.loss_mask: 0.5719, decode.d1.loss_dice: 0.8621, decode.d2.loss_cls: 0.4078, decode.d2.loss_mask: 0.5615, decode.d2.loss_dice: 0.8304, decode.d3.loss_cls: 0.3740, decode.d3.loss_mask: 0.5528, decode.d3.loss_dice: 0.8151, decode.d4.loss_cls: 0.3638, decode.d4.loss_mask: 0.5519, decode.d4.loss_dice: 0.8140, decode.d5.loss_cls: 0.3566, decode.d5.loss_mask: 0.5473, decode.d5.loss_dice: 0.8124, decode.d6.loss_cls: 0.3525, decode.d6.loss_mask: 0.5460, decode.d6.loss_dice: 0.8066, decode.d7.loss_cls: 0.3489, decode.d7.loss_mask: 0.5456, decode.d7.loss_dice: 0.8094, decode.d8.loss_cls: 0.3490, decode.d8.loss_mask: 0.5430, decode.d8.loss_dice: 0.8085, loss: 22.4867
2022-12-01 06:05:25,174 - mmseg - INFO - Iter [27700/40000]	lr: 4.091e-08, eta: 14:54:34, time: 4.115, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3741, decode.loss_mask: 0.5503, decode.loss_dice: 0.8025, decode.d0.loss_cls: 5.3952, decode.d0.loss_mask: 0.5372, decode.d0.loss_dice: 0.8758, decode.d1.loss_cls: 0.4953, decode.d1.loss_mask: 0.5744, decode.d1.loss_dice: 0.8636, decode.d2.loss_cls: 0.4357, decode.d2.loss_mask: 0.5589, decode.d2.loss_dice: 0.8252, decode.d3.loss_cls: 0.4007, decode.d3.loss_mask: 0.5541, decode.d3.loss_dice: 0.8096, decode.d4.loss_cls: 0.3928, decode.d4.loss_mask: 0.5530, decode.d4.loss_dice: 0.8094, decode.d5.loss_cls: 0.3822, decode.d5.loss_mask: 0.5525, decode.d5.loss_dice: 0.8080, decode.d6.loss_cls: 0.3758, decode.d6.loss_mask: 0.5514, decode.d6.loss_dice: 0.8033, decode.d7.loss_cls: 0.3710, decode.d7.loss_mask: 0.5498, decode.d7.loss_dice: 0.8034, decode.d8.loss_cls: 0.3718, decode.d8.loss_mask: 0.5513, decode.d8.loss_dice: 0.8040, loss: 22.7327
2022-12-01 06:08:50,779 - mmseg - INFO - Iter [27750/40000]	lr: 4.074e-08, eta: 14:50:51, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3523, decode.loss_mask: 0.5292, decode.loss_dice: 0.7808, decode.d0.loss_cls: 5.3740, decode.d0.loss_mask: 0.5211, decode.d0.loss_dice: 0.8410, decode.d1.loss_cls: 0.4604, decode.d1.loss_mask: 0.5560, decode.d1.loss_dice: 0.8398, decode.d2.loss_cls: 0.4050, decode.d2.loss_mask: 0.5430, decode.d2.loss_dice: 0.8082, decode.d3.loss_cls: 0.3747, decode.d3.loss_mask: 0.5354, decode.d3.loss_dice: 0.7951, decode.d4.loss_cls: 0.3674, decode.d4.loss_mask: 0.5351, decode.d4.loss_dice: 0.7908, decode.d5.loss_cls: 0.3600, decode.d5.loss_mask: 0.5312, decode.d5.loss_dice: 0.7871, decode.d6.loss_cls: 0.3578, decode.d6.loss_mask: 0.5296, decode.d6.loss_dice: 0.7827, decode.d7.loss_cls: 0.3515, decode.d7.loss_mask: 0.5305, decode.d7.loss_dice: 0.7795, decode.d8.loss_cls: 0.3515, decode.d8.loss_mask: 0.5289, decode.d8.loss_dice: 0.7822, loss: 22.0820
2022-12-01 06:12:16,454 - mmseg - INFO - Iter [27800/40000]	lr: 4.058e-08, eta: 14:47:07, time: 4.113, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3605, decode.loss_mask: 0.5338, decode.loss_dice: 0.7788, decode.d0.loss_cls: 5.3725, decode.d0.loss_mask: 0.5247, decode.d0.loss_dice: 0.8498, decode.d1.loss_cls: 0.4733, decode.d1.loss_mask: 0.5609, decode.d1.loss_dice: 0.8406, decode.d2.loss_cls: 0.4139, decode.d2.loss_mask: 0.5496, decode.d2.loss_dice: 0.8057, decode.d3.loss_cls: 0.3832, decode.d3.loss_mask: 0.5411, decode.d3.loss_dice: 0.7935, decode.d4.loss_cls: 0.3716, decode.d4.loss_mask: 0.5400, decode.d4.loss_dice: 0.7923, decode.d5.loss_cls: 0.3626, decode.d5.loss_mask: 0.5354, decode.d5.loss_dice: 0.7854, decode.d6.loss_cls: 0.3577, decode.d6.loss_mask: 0.5371, decode.d6.loss_dice: 0.7828, decode.d7.loss_cls: 0.3589, decode.d7.loss_mask: 0.5355, decode.d7.loss_dice: 0.7834, decode.d8.loss_cls: 0.3540, decode.d8.loss_mask: 0.5340, decode.d8.loss_dice: 0.7837, loss: 22.1961
2022-12-01 06:15:44,619 - mmseg - INFO - Iter [27850/40000]	lr: 4.041e-08, eta: 14:43:24, time: 4.163, data_time: 0.066, memory: 51902, decode.loss_cls: 0.3539, decode.loss_mask: 0.5374, decode.loss_dice: 0.7958, decode.d0.loss_cls: 5.3653, decode.d0.loss_mask: 0.5326, decode.d0.loss_dice: 0.8653, decode.d1.loss_cls: 0.4682, decode.d1.loss_mask: 0.5657, decode.d1.loss_dice: 0.8504, decode.d2.loss_cls: 0.4114, decode.d2.loss_mask: 0.5523, decode.d2.loss_dice: 0.8217, decode.d3.loss_cls: 0.3770, decode.d3.loss_mask: 0.5451, decode.d3.loss_dice: 0.8037, decode.d4.loss_cls: 0.3702, decode.d4.loss_mask: 0.5447, decode.d4.loss_dice: 0.8010, decode.d5.loss_cls: 0.3571, decode.d5.loss_mask: 0.5413, decode.d5.loss_dice: 0.7982, decode.d6.loss_cls: 0.3539, decode.d6.loss_mask: 0.5406, decode.d6.loss_dice: 0.7967, decode.d7.loss_cls: 0.3499, decode.d7.loss_mask: 0.5375, decode.d7.loss_dice: 0.7951, decode.d8.loss_cls: 0.3520, decode.d8.loss_mask: 0.5370, decode.d8.loss_dice: 0.7963, loss: 22.3171
2022-12-01 06:19:10,148 - mmseg - INFO - Iter [27900/40000]	lr: 4.024e-08, eta: 14:39:41, time: 4.111, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3383, decode.loss_mask: 0.5425, decode.loss_dice: 0.8066, decode.d0.loss_cls: 5.3511, decode.d0.loss_mask: 0.5348, decode.d0.loss_dice: 0.8694, decode.d1.loss_cls: 0.4524, decode.d1.loss_mask: 0.5663, decode.d1.loss_dice: 0.8634, decode.d2.loss_cls: 0.3995, decode.d2.loss_mask: 0.5561, decode.d2.loss_dice: 0.8328, decode.d3.loss_cls: 0.3674, decode.d3.loss_mask: 0.5484, decode.d3.loss_dice: 0.8124, decode.d4.loss_cls: 0.3593, decode.d4.loss_mask: 0.5448, decode.d4.loss_dice: 0.8087, decode.d5.loss_cls: 0.3455, decode.d5.loss_mask: 0.5443, decode.d5.loss_dice: 0.8079, decode.d6.loss_cls: 0.3427, decode.d6.loss_mask: 0.5429, decode.d6.loss_dice: 0.8041, decode.d7.loss_cls: 0.3389, decode.d7.loss_mask: 0.5421, decode.d7.loss_dice: 0.8062, decode.d8.loss_cls: 0.3380, decode.d8.loss_mask: 0.5408, decode.d8.loss_dice: 0.8032, loss: 22.3107
2022-12-01 06:22:36,183 - mmseg - INFO - Iter [27950/40000]	lr: 4.008e-08, eta: 14:35:57, time: 4.121, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3353, decode.loss_mask: 0.5290, decode.loss_dice: 0.7747, decode.d0.loss_cls: 5.3218, decode.d0.loss_mask: 0.5221, decode.d0.loss_dice: 0.8358, decode.d1.loss_cls: 0.4516, decode.d1.loss_mask: 0.5568, decode.d1.loss_dice: 0.8313, decode.d2.loss_cls: 0.3895, decode.d2.loss_mask: 0.5441, decode.d2.loss_dice: 0.7979, decode.d3.loss_cls: 0.3607, decode.d3.loss_mask: 0.5387, decode.d3.loss_dice: 0.7827, decode.d4.loss_cls: 0.3467, decode.d4.loss_mask: 0.5338, decode.d4.loss_dice: 0.7818, decode.d5.loss_cls: 0.3383, decode.d5.loss_mask: 0.5320, decode.d5.loss_dice: 0.7788, decode.d6.loss_cls: 0.3378, decode.d6.loss_mask: 0.5313, decode.d6.loss_dice: 0.7760, decode.d7.loss_cls: 0.3359, decode.d7.loss_mask: 0.5304, decode.d7.loss_dice: 0.7752, decode.d8.loss_cls: 0.3346, decode.d8.loss_mask: 0.5304, decode.d8.loss_dice: 0.7762, loss: 21.8113
2022-12-01 06:26:02,000 - mmseg - INFO - Saving checkpoint at 28000 iterations
2022-12-01 06:26:45,016 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 06:26:45,016 - mmseg - INFO - Iter [28000/40000]	lr: 3.991e-08, eta: 14:32:33, time: 4.977, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3609, decode.loss_mask: 0.5369, decode.loss_dice: 0.7963, decode.d0.loss_cls: 5.3855, decode.d0.loss_mask: 0.5306, decode.d0.loss_dice: 0.8629, decode.d1.loss_cls: 0.4784, decode.d1.loss_mask: 0.5656, decode.d1.loss_dice: 0.8568, decode.d2.loss_cls: 0.4224, decode.d2.loss_mask: 0.5533, decode.d2.loss_dice: 0.8232, decode.d3.loss_cls: 0.3885, decode.d3.loss_mask: 0.5461, decode.d3.loss_dice: 0.8065, decode.d4.loss_cls: 0.3807, decode.d4.loss_mask: 0.5438, decode.d4.loss_dice: 0.8032, decode.d5.loss_cls: 0.3706, decode.d5.loss_mask: 0.5402, decode.d5.loss_dice: 0.8012, decode.d6.loss_cls: 0.3687, decode.d6.loss_mask: 0.5398, decode.d6.loss_dice: 0.7959, decode.d7.loss_cls: 0.3677, decode.d7.loss_mask: 0.5382, decode.d7.loss_dice: 0.7954, decode.d8.loss_cls: 0.3630, decode.d8.loss_mask: 0.5372, decode.d8.loss_dice: 0.7947, loss: 22.4540
2022-12-01 06:29:43,016 - mmseg - INFO - per class results:
2022-12-01 06:29:43,021 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 82.89 | 88.95 |
|       building      | 85.48 | 92.19 |
|         sky         | 95.21 |  97.2 |
|        floor        |  85.1 | 90.06 |
|         tree        | 77.65 | 89.59 |
|       ceiling       | 86.98 | 93.33 |
|         road        | 88.41 | 91.53 |
|         bed         | 93.77 | 97.35 |
|      windowpane     | 69.31 | 84.73 |
|        grass        | 68.86 | 79.27 |
|       cabinet       | 63.36 | 72.95 |
|       sidewalk      | 72.97 | 85.78 |
|        person       | 88.41 | 93.99 |
|        earth        | 46.23 | 67.52 |
|         door        | 64.53 |  80.4 |
|        table        | 71.98 | 81.34 |
|       mountain      | 60.35 | 69.28 |
|        plant        | 56.93 |  68.7 |
|       curtain       | 83.31 | 90.68 |
|        chair        | 67.63 | 76.87 |
|         car         | 89.46 | 94.74 |
|        water        | 71.12 | 85.76 |
|       painting      |  80.8 | 92.52 |
|         sofa        | 84.96 | 90.37 |
|        shelf        | 50.09 | 62.25 |
|        house        | 57.14 | 73.54 |
|         sea         | 78.57 | 87.63 |
|        mirror       |  79.9 | 91.19 |
|         rug         | 71.22 | 85.83 |
|        field        | 36.02 | 63.86 |
|       armchair      | 60.83 | 81.03 |
|         seat        | 66.75 |  89.4 |
|        fence        | 55.74 | 75.34 |
|         desk        | 59.38 | 83.63 |
|         rock        | 56.26 | 75.96 |
|       wardrobe      | 57.88 | 86.01 |
|         lamp        |  80.8 | 90.87 |
|       bathtub       | 91.77 | 93.59 |
|       railing       | 45.28 | 66.54 |
|       cushion       | 76.73 | 90.89 |
|         base        | 46.97 | 76.07 |
|         box         | 45.17 | 63.66 |
|        column       | 56.39 | 73.82 |
|      signboard      | 45.24 | 68.17 |
|   chest of drawers  | 48.63 |  76.2 |
|       counter       | 56.93 | 64.99 |
|         sand        | 61.95 |  88.0 |
|         sink        | 88.72 | 92.56 |
|      skyscraper     | 41.88 | 49.19 |
|      fireplace      | 79.66 |  95.5 |
|     refrigerator    | 83.35 | 92.79 |
|      grandstand     | 49.84 | 83.27 |
|         path        | 32.56 | 41.68 |
|        stairs       | 30.34 | 40.15 |
|        runway       | 74.54 | 93.73 |
|         case        |  67.0 | 87.39 |
|      pool table     | 95.85 | 98.61 |
|        pillow       | 72.61 | 83.09 |
|     screen door     | 85.59 | 93.95 |
|       stairway      | 51.27 |  75.8 |
|        river        | 30.19 | 35.31 |
|        bridge       | 66.75 | 84.51 |
|       bookcase      | 43.49 |  67.1 |
|        blind        | 46.08 | 56.17 |
|     coffee table    | 72.67 | 92.33 |
|        toilet       | 92.08 | 95.35 |
|        flower       | 46.26 | 73.28 |
|         book        | 60.69 | 82.73 |
|         hill        | 16.86 | 28.87 |
|        bench        | 73.18 | 84.32 |
|      countertop     | 71.53 | 88.37 |
|        stove        | 85.68 | 89.62 |
|         palm        | 56.01 | 82.09 |
|    kitchen island   | 44.21 | 96.03 |
|       computer      |  81.9 | 91.21 |
|     swivel chair    | 55.49 | 85.66 |
|         boat        | 54.74 | 87.99 |
|         bar         |  69.2 | 78.09 |
|    arcade machine   | 91.75 | 98.65 |
|        hovel        | 61.81 | 73.33 |
|         bus         | 95.77 | 97.56 |
|        towel        | 83.25 | 94.12 |
|        light        | 65.52 | 78.23 |
|        truck        | 51.31 | 73.07 |
|        tower        | 32.82 | 63.33 |
|      chandelier     | 77.44 | 87.39 |
|        awning       | 31.53 | 52.67 |
|     streetlight     | 45.84 | 71.76 |
|        booth        | 52.29 | 78.19 |
| television receiver | 77.62 | 92.36 |
|       airplane      | 88.48 | 96.22 |
|      dirt track     | 12.82 | 22.95 |
|       apparel       | 55.52 | 89.08 |
|         pole        | 31.68 | 44.74 |
|         land        |  3.67 |  4.8  |
|      bannister      | 21.32 | 32.47 |
|      escalator      | 66.65 | 86.06 |
|       ottoman       | 55.55 | 77.06 |
|        bottle       | 52.79 | 81.21 |
|        buffet       | 41.27 | 58.55 |
|        poster       | 36.78 | 50.76 |
|        stage        | 31.85 | 66.16 |
|         van         | 50.65 |  75.7 |
|         ship        | 25.63 | 28.04 |
|       fountain      | 50.82 | 52.97 |
|    conveyer belt    |  78.3 | 97.39 |
|        canopy       | 55.22 | 73.81 |
|        washer       | 90.81 | 93.77 |
|      plaything      | 36.76 | 58.03 |
|    swimming pool    | 51.78 | 75.85 |
|        stool        | 56.05 | 85.69 |
|        barrel       | 65.74 | 97.05 |
|        basket       | 48.65 | 76.56 |
|      waterfall      | 47.33 | 59.26 |
|         tent        | 95.45 | 98.09 |
|         bag         | 35.16 | 48.46 |
|       minibike      | 81.27 |  93.7 |
|        cradle       | 91.41 | 97.45 |
|         oven        | 66.54 | 86.61 |
|         ball        | 38.77 |  42.0 |
|         food        | 65.55 |  80.2 |
|         step        | 31.65 | 47.14 |
|         tank        | 59.28 |  67.9 |
|      trade name     | 32.42 |  44.9 |
|      microwave      | 89.83 | 94.59 |
|         pot         | 62.74 | 75.01 |
|        animal       | 82.43 | 84.99 |
|       bicycle       | 62.42 | 83.41 |
|         lake        | 51.89 | 68.79 |
|      dishwasher     | 80.34 | 90.66 |
|        screen       | 59.37 | 91.16 |
|       blanket       | 41.01 | 52.13 |
|      sculpture      | 66.96 | 90.66 |
|         hood        | 86.72 | 91.67 |
|        sconce       | 66.95 | 84.25 |
|         vase        | 59.28 | 81.41 |
|    traffic light    | 52.14 | 73.82 |
|         tray        | 32.69 | 53.56 |
|        ashcan       | 54.79 | 76.79 |
|         fan         | 73.42 | 88.92 |
|         pier        | 37.15 | 41.38 |
|      crt screen     |  4.49 |  12.3 |
|        plate        | 70.05 | 84.22 |
|       monitor       |  3.85 |  4.5  |
|    bulletin board   | 61.44 | 83.66 |
|        shower       | 15.03 | 28.72 |
|       radiator      | 72.81 | 93.37 |
|        glass        | 29.12 | 32.44 |
|        clock        |  63.0 | 77.27 |
|         flag        | 68.24 | 89.23 |
+---------------------+-------+-------+
2022-12-01 06:29:43,021 - mmseg - INFO - Summary:
2022-12-01 06:29:43,021 - mmseg - INFO - 
+-------+-------+------+
|  aAcc |  mIoU | mAcc |
+-------+-------+------+
| 86.97 | 60.73 | 75.8 |
+-------+-------+------+
2022-12-01 06:29:43,026 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 06:29:43,026 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8697, mIoU: 0.6073, mAcc: 0.7580, IoU.wall: 0.8289, IoU.building: 0.8548, IoU.sky: 0.9521, IoU.floor: 0.8510, IoU.tree: 0.7765, IoU.ceiling: 0.8698, IoU.road: 0.8841, IoU.bed : 0.9377, IoU.windowpane: 0.6931, IoU.grass: 0.6886, IoU.cabinet: 0.6336, IoU.sidewalk: 0.7297, IoU.person: 0.8841, IoU.earth: 0.4623, IoU.door: 0.6453, IoU.table: 0.7198, IoU.mountain: 0.6035, IoU.plant: 0.5693, IoU.curtain: 0.8331, IoU.chair: 0.6763, IoU.car: 0.8946, IoU.water: 0.7112, IoU.painting: 0.8080, IoU.sofa: 0.8496, IoU.shelf: 0.5009, IoU.house: 0.5714, IoU.sea: 0.7857, IoU.mirror: 0.7990, IoU.rug: 0.7122, IoU.field: 0.3602, IoU.armchair: 0.6083, IoU.seat: 0.6675, IoU.fence: 0.5574, IoU.desk: 0.5938, IoU.rock: 0.5626, IoU.wardrobe: 0.5788, IoU.lamp: 0.8080, IoU.bathtub: 0.9177, IoU.railing: 0.4528, IoU.cushion: 0.7673, IoU.base: 0.4697, IoU.box: 0.4517, IoU.column: 0.5639, IoU.signboard: 0.4524, IoU.chest of drawers: 0.4863, IoU.counter: 0.5693, IoU.sand: 0.6195, IoU.sink: 0.8872, IoU.skyscraper: 0.4188, IoU.fireplace: 0.7966, IoU.refrigerator: 0.8335, IoU.grandstand: 0.4984, IoU.path: 0.3256, IoU.stairs: 0.3034, IoU.runway: 0.7454, IoU.case: 0.6700, IoU.pool table: 0.9585, IoU.pillow: 0.7261, IoU.screen door: 0.8559, IoU.stairway: 0.5127, IoU.river: 0.3019, IoU.bridge: 0.6675, IoU.bookcase: 0.4349, IoU.blind: 0.4608, IoU.coffee table: 0.7267, IoU.toilet: 0.9208, IoU.flower: 0.4626, IoU.book: 0.6069, IoU.hill: 0.1686, IoU.bench: 0.7318, IoU.countertop: 0.7153, IoU.stove: 0.8568, IoU.palm: 0.5601, IoU.kitchen island: 0.4421, IoU.computer: 0.8190, IoU.swivel chair: 0.5549, IoU.boat: 0.5474, IoU.bar: 0.6920, IoU.arcade machine: 0.9175, IoU.hovel: 0.6181, IoU.bus: 0.9577, IoU.towel: 0.8325, IoU.light: 0.6552, IoU.truck: 0.5131, IoU.tower: 0.3282, IoU.chandelier: 0.7744, IoU.awning: 0.3153, IoU.streetlight: 0.4584, IoU.booth: 0.5229, IoU.television receiver: 0.7762, IoU.airplane: 0.8848, IoU.dirt track: 0.1282, IoU.apparel: 0.5552, IoU.pole: 0.3168, IoU.land: 0.0367, IoU.bannister: 0.2132, IoU.escalator: 0.6665, IoU.ottoman: 0.5555, IoU.bottle: 0.5279, IoU.buffet: 0.4127, IoU.poster: 0.3678, IoU.stage: 0.3185, IoU.van: 0.5065, IoU.ship: 0.2563, IoU.fountain: 0.5082, IoU.conveyer belt: 0.7830, IoU.canopy: 0.5522, IoU.washer: 0.9081, IoU.plaything: 0.3676, IoU.swimming pool: 0.5178, IoU.stool: 0.5605, IoU.barrel: 0.6574, IoU.basket: 0.4865, IoU.waterfall: 0.4733, IoU.tent: 0.9545, IoU.bag: 0.3516, IoU.minibike: 0.8127, IoU.cradle: 0.9141, IoU.oven: 0.6654, IoU.ball: 0.3877, IoU.food: 0.6555, IoU.step: 0.3165, IoU.tank: 0.5928, IoU.trade name: 0.3242, IoU.microwave: 0.8983, IoU.pot: 0.6274, IoU.animal: 0.8243, IoU.bicycle: 0.6242, IoU.lake: 0.5189, IoU.dishwasher: 0.8034, IoU.screen: 0.5937, IoU.blanket: 0.4101, IoU.sculpture: 0.6696, IoU.hood: 0.8672, IoU.sconce: 0.6695, IoU.vase: 0.5928, IoU.traffic light: 0.5214, IoU.tray: 0.3269, IoU.ashcan: 0.5479, IoU.fan: 0.7342, IoU.pier: 0.3715, IoU.crt screen: 0.0449, IoU.plate: 0.7005, IoU.monitor: 0.0385, IoU.bulletin board: 0.6144, IoU.shower: 0.1503, IoU.radiator: 0.7281, IoU.glass: 0.2912, IoU.clock: 0.6300, IoU.flag: 0.6824, Acc.wall: 0.8895, Acc.building: 0.9219, Acc.sky: 0.9720, Acc.floor: 0.9006, Acc.tree: 0.8959, Acc.ceiling: 0.9333, Acc.road: 0.9153, Acc.bed : 0.9735, Acc.windowpane: 0.8473, Acc.grass: 0.7927, Acc.cabinet: 0.7295, Acc.sidewalk: 0.8578, Acc.person: 0.9399, Acc.earth: 0.6752, Acc.door: 0.8040, Acc.table: 0.8134, Acc.mountain: 0.6928, Acc.plant: 0.6870, Acc.curtain: 0.9068, Acc.chair: 0.7687, Acc.car: 0.9474, Acc.water: 0.8576, Acc.painting: 0.9252, Acc.sofa: 0.9037, Acc.shelf: 0.6225, Acc.house: 0.7354, Acc.sea: 0.8763, Acc.mirror: 0.9119, Acc.rug: 0.8583, Acc.field: 0.6386, Acc.armchair: 0.8103, Acc.seat: 0.8940, Acc.fence: 0.7534, Acc.desk: 0.8363, Acc.rock: 0.7596, Acc.wardrobe: 0.8601, Acc.lamp: 0.9087, Acc.bathtub: 0.9359, Acc.railing: 0.6654, Acc.cushion: 0.9089, Acc.base: 0.7607, Acc.box: 0.6366, Acc.column: 0.7382, Acc.signboard: 0.6817, Acc.chest of drawers: 0.7620, Acc.counter: 0.6499, Acc.sand: 0.8800, Acc.sink: 0.9256, Acc.skyscraper: 0.4919, Acc.fireplace: 0.9550, Acc.refrigerator: 0.9279, Acc.grandstand: 0.8327, Acc.path: 0.4168, Acc.stairs: 0.4015, Acc.runway: 0.9373, Acc.case: 0.8739, Acc.pool table: 0.9861, Acc.pillow: 0.8309, Acc.screen door: 0.9395, Acc.stairway: 0.7580, Acc.river: 0.3531, Acc.bridge: 0.8451, Acc.bookcase: 0.6710, Acc.blind: 0.5617, Acc.coffee table: 0.9233, Acc.toilet: 0.9535, Acc.flower: 0.7328, Acc.book: 0.8273, Acc.hill: 0.2887, Acc.bench: 0.8432, Acc.countertop: 0.8837, Acc.stove: 0.8962, Acc.palm: 0.8209, Acc.kitchen island: 0.9603, Acc.computer: 0.9121, Acc.swivel chair: 0.8566, Acc.boat: 0.8799, Acc.bar: 0.7809, Acc.arcade machine: 0.9865, Acc.hovel: 0.7333, Acc.bus: 0.9756, Acc.towel: 0.9412, Acc.light: 0.7823, Acc.truck: 0.7307, Acc.tower: 0.6333, Acc.chandelier: 0.8739, Acc.awning: 0.5267, Acc.streetlight: 0.7176, Acc.booth: 0.7819, Acc.television receiver: 0.9236, Acc.airplane: 0.9622, Acc.dirt track: 0.2295, Acc.apparel: 0.8908, Acc.pole: 0.4474, Acc.land: 0.0480, Acc.bannister: 0.3247, Acc.escalator: 0.8606, Acc.ottoman: 0.7706, Acc.bottle: 0.8121, Acc.buffet: 0.5855, Acc.poster: 0.5076, Acc.stage: 0.6616, Acc.van: 0.7570, Acc.ship: 0.2804, Acc.fountain: 0.5297, Acc.conveyer belt: 0.9739, Acc.canopy: 0.7381, Acc.washer: 0.9377, Acc.plaything: 0.5803, Acc.swimming pool: 0.7585, Acc.stool: 0.8569, Acc.barrel: 0.9705, Acc.basket: 0.7656, Acc.waterfall: 0.5926, Acc.tent: 0.9809, Acc.bag: 0.4846, Acc.minibike: 0.9370, Acc.cradle: 0.9745, Acc.oven: 0.8661, Acc.ball: 0.4200, Acc.food: 0.8020, Acc.step: 0.4714, Acc.tank: 0.6790, Acc.trade name: 0.4490, Acc.microwave: 0.9459, Acc.pot: 0.7501, Acc.animal: 0.8499, Acc.bicycle: 0.8341, Acc.lake: 0.6879, Acc.dishwasher: 0.9066, Acc.screen: 0.9116, Acc.blanket: 0.5213, Acc.sculpture: 0.9066, Acc.hood: 0.9167, Acc.sconce: 0.8425, Acc.vase: 0.8141, Acc.traffic light: 0.7382, Acc.tray: 0.5356, Acc.ashcan: 0.7679, Acc.fan: 0.8892, Acc.pier: 0.4138, Acc.crt screen: 0.1230, Acc.plate: 0.8422, Acc.monitor: 0.0450, Acc.bulletin board: 0.8366, Acc.shower: 0.2872, Acc.radiator: 0.9337, Acc.glass: 0.3244, Acc.clock: 0.7727, Acc.flag: 0.8923
2022-12-01 06:33:08,808 - mmseg - INFO - Iter [28050/40000]	lr: 3.975e-08, eta: 14:30:05, time: 7.676, data_time: 3.580, memory: 51902, decode.loss_cls: 0.3594, decode.loss_mask: 0.5289, decode.loss_dice: 0.7984, decode.d0.loss_cls: 5.3786, decode.d0.loss_mask: 0.5235, decode.d0.loss_dice: 0.8661, decode.d1.loss_cls: 0.4766, decode.d1.loss_mask: 0.5548, decode.d1.loss_dice: 0.8581, decode.d2.loss_cls: 0.4183, decode.d2.loss_mask: 0.5450, decode.d2.loss_dice: 0.8254, decode.d3.loss_cls: 0.3899, decode.d3.loss_mask: 0.5359, decode.d3.loss_dice: 0.8068, decode.d4.loss_cls: 0.3758, decode.d4.loss_mask: 0.5333, decode.d4.loss_dice: 0.8061, decode.d5.loss_cls: 0.3706, decode.d5.loss_mask: 0.5320, decode.d5.loss_dice: 0.7999, decode.d6.loss_cls: 0.3656, decode.d6.loss_mask: 0.5302, decode.d6.loss_dice: 0.7970, decode.d7.loss_cls: 0.3626, decode.d7.loss_mask: 0.5279, decode.d7.loss_dice: 0.7976, decode.d8.loss_cls: 0.3616, decode.d8.loss_mask: 0.5286, decode.d8.loss_dice: 0.7979, loss: 22.3523
2022-12-01 06:36:34,737 - mmseg - INFO - Iter [28100/40000]	lr: 3.958e-08, eta: 14:26:21, time: 4.119, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3486, decode.loss_mask: 0.5333, decode.loss_dice: 0.7890, decode.d0.loss_cls: 5.3468, decode.d0.loss_mask: 0.5262, decode.d0.loss_dice: 0.8601, decode.d1.loss_cls: 0.4621, decode.d1.loss_mask: 0.5597, decode.d1.loss_dice: 0.8489, decode.d2.loss_cls: 0.4030, decode.d2.loss_mask: 0.5491, decode.d2.loss_dice: 0.8190, decode.d3.loss_cls: 0.3741, decode.d3.loss_mask: 0.5410, decode.d3.loss_dice: 0.8008, decode.d4.loss_cls: 0.3642, decode.d4.loss_mask: 0.5378, decode.d4.loss_dice: 0.7992, decode.d5.loss_cls: 0.3516, decode.d5.loss_mask: 0.5354, decode.d5.loss_dice: 0.7963, decode.d6.loss_cls: 0.3500, decode.d6.loss_mask: 0.5353, decode.d6.loss_dice: 0.7916, decode.d7.loss_cls: 0.3488, decode.d7.loss_mask: 0.5336, decode.d7.loss_dice: 0.7883, decode.d8.loss_cls: 0.3482, decode.d8.loss_mask: 0.5340, decode.d8.loss_dice: 0.7878, loss: 22.1639
2022-12-01 06:40:00,565 - mmseg - INFO - Iter [28150/40000]	lr: 3.941e-08, eta: 14:22:38, time: 4.117, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3629, decode.loss_mask: 0.5300, decode.loss_dice: 0.8034, decode.d0.loss_cls: 5.3461, decode.d0.loss_mask: 0.5207, decode.d0.loss_dice: 0.8642, decode.d1.loss_cls: 0.4806, decode.d1.loss_mask: 0.5593, decode.d1.loss_dice: 0.8603, decode.d2.loss_cls: 0.4195, decode.d2.loss_mask: 0.5423, decode.d2.loss_dice: 0.8257, decode.d3.loss_cls: 0.3906, decode.d3.loss_mask: 0.5373, decode.d3.loss_dice: 0.8116, decode.d4.loss_cls: 0.3809, decode.d4.loss_mask: 0.5349, decode.d4.loss_dice: 0.8081, decode.d5.loss_cls: 0.3708, decode.d5.loss_mask: 0.5336, decode.d5.loss_dice: 0.8063, decode.d6.loss_cls: 0.3674, decode.d6.loss_mask: 0.5307, decode.d6.loss_dice: 0.8001, decode.d7.loss_cls: 0.3639, decode.d7.loss_mask: 0.5290, decode.d7.loss_dice: 0.8017, decode.d8.loss_cls: 0.3617, decode.d8.loss_mask: 0.5293, decode.d8.loss_dice: 0.8033, loss: 22.3762
2022-12-01 06:43:26,425 - mmseg - INFO - Iter [28200/40000]	lr: 3.925e-08, eta: 14:18:54, time: 4.117, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3421, decode.loss_mask: 0.5255, decode.loss_dice: 0.7733, decode.d0.loss_cls: 5.3349, decode.d0.loss_mask: 0.5138, decode.d0.loss_dice: 0.8404, decode.d1.loss_cls: 0.4515, decode.d1.loss_mask: 0.5509, decode.d1.loss_dice: 0.8322, decode.d2.loss_cls: 0.3950, decode.d2.loss_mask: 0.5372, decode.d2.loss_dice: 0.7983, decode.d3.loss_cls: 0.3624, decode.d3.loss_mask: 0.5292, decode.d3.loss_dice: 0.7869, decode.d4.loss_cls: 0.3565, decode.d4.loss_mask: 0.5267, decode.d4.loss_dice: 0.7835, decode.d5.loss_cls: 0.3481, decode.d5.loss_mask: 0.5259, decode.d5.loss_dice: 0.7765, decode.d6.loss_cls: 0.3435, decode.d6.loss_mask: 0.5245, decode.d6.loss_dice: 0.7755, decode.d7.loss_cls: 0.3440, decode.d7.loss_mask: 0.5234, decode.d7.loss_dice: 0.7717, decode.d8.loss_cls: 0.3410, decode.d8.loss_mask: 0.5234, decode.d8.loss_dice: 0.7740, loss: 21.8116
2022-12-01 06:46:51,885 - mmseg - INFO - Iter [28250/40000]	lr: 3.908e-08, eta: 14:15:10, time: 4.109, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3625, decode.loss_mask: 0.5645, decode.loss_dice: 0.8182, decode.d0.loss_cls: 5.3324, decode.d0.loss_mask: 0.5550, decode.d0.loss_dice: 0.8769, decode.d1.loss_cls: 0.4685, decode.d1.loss_mask: 0.5938, decode.d1.loss_dice: 0.8740, decode.d2.loss_cls: 0.4180, decode.d2.loss_mask: 0.5807, decode.d2.loss_dice: 0.8446, decode.d3.loss_cls: 0.3866, decode.d3.loss_mask: 0.5694, decode.d3.loss_dice: 0.8297, decode.d4.loss_cls: 0.3802, decode.d4.loss_mask: 0.5681, decode.d4.loss_dice: 0.8245, decode.d5.loss_cls: 0.3675, decode.d5.loss_mask: 0.5657, decode.d5.loss_dice: 0.8205, decode.d6.loss_cls: 0.3637, decode.d6.loss_mask: 0.5633, decode.d6.loss_dice: 0.8166, decode.d7.loss_cls: 0.3635, decode.d7.loss_mask: 0.5652, decode.d7.loss_dice: 0.8196, decode.d8.loss_cls: 0.3629, decode.d8.loss_mask: 0.5645, decode.d8.loss_dice: 0.8153, loss: 22.8359
2022-12-01 06:50:17,741 - mmseg - INFO - Iter [28300/40000]	lr: 3.891e-08, eta: 14:11:27, time: 4.117, data_time: 0.022, memory: 51902, decode.loss_cls: 0.3386, decode.loss_mask: 0.5347, decode.loss_dice: 0.7878, decode.d0.loss_cls: 5.3464, decode.d0.loss_mask: 0.5253, decode.d0.loss_dice: 0.8530, decode.d1.loss_cls: 0.4493, decode.d1.loss_mask: 0.5617, decode.d1.loss_dice: 0.8426, decode.d2.loss_cls: 0.3948, decode.d2.loss_mask: 0.5492, decode.d2.loss_dice: 0.8156, decode.d3.loss_cls: 0.3655, decode.d3.loss_mask: 0.5425, decode.d3.loss_dice: 0.7987, decode.d4.loss_cls: 0.3555, decode.d4.loss_mask: 0.5401, decode.d4.loss_dice: 0.7924, decode.d5.loss_cls: 0.3480, decode.d5.loss_mask: 0.5393, decode.d5.loss_dice: 0.7918, decode.d6.loss_cls: 0.3442, decode.d6.loss_mask: 0.5379, decode.d6.loss_dice: 0.7858, decode.d7.loss_cls: 0.3439, decode.d7.loss_mask: 0.5355, decode.d7.loss_dice: 0.7857, decode.d8.loss_cls: 0.3434, decode.d8.loss_mask: 0.5357, decode.d8.loss_dice: 0.7837, loss: 22.0687
2022-12-01 06:53:43,460 - mmseg - INFO - Iter [28350/40000]	lr: 3.875e-08, eta: 14:07:43, time: 4.114, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3383, decode.loss_mask: 0.5447, decode.loss_dice: 0.7941, decode.d0.loss_cls: 5.3194, decode.d0.loss_mask: 0.5316, decode.d0.loss_dice: 0.8560, decode.d1.loss_cls: 0.4568, decode.d1.loss_mask: 0.5722, decode.d1.loss_dice: 0.8491, decode.d2.loss_cls: 0.3978, decode.d2.loss_mask: 0.5592, decode.d2.loss_dice: 0.8183, decode.d3.loss_cls: 0.3672, decode.d3.loss_mask: 0.5514, decode.d3.loss_dice: 0.8026, decode.d4.loss_cls: 0.3583, decode.d4.loss_mask: 0.5490, decode.d4.loss_dice: 0.8008, decode.d5.loss_cls: 0.3500, decode.d5.loss_mask: 0.5474, decode.d5.loss_dice: 0.7985, decode.d6.loss_cls: 0.3446, decode.d6.loss_mask: 0.5484, decode.d6.loss_dice: 0.7953, decode.d7.loss_cls: 0.3430, decode.d7.loss_mask: 0.5454, decode.d7.loss_dice: 0.7979, decode.d8.loss_cls: 0.3409, decode.d8.loss_mask: 0.5442, decode.d8.loss_dice: 0.7922, loss: 22.2146
2022-12-01 06:57:09,252 - mmseg - INFO - Iter [28400/40000]	lr: 3.858e-08, eta: 14:04:00, time: 4.116, data_time: 0.022, memory: 51902, decode.loss_cls: 0.3628, decode.loss_mask: 0.5375, decode.loss_dice: 0.8113, decode.d0.loss_cls: 5.3397, decode.d0.loss_mask: 0.5269, decode.d0.loss_dice: 0.8816, decode.d1.loss_cls: 0.4832, decode.d1.loss_mask: 0.5626, decode.d1.loss_dice: 0.8733, decode.d2.loss_cls: 0.4222, decode.d2.loss_mask: 0.5498, decode.d2.loss_dice: 0.8411, decode.d3.loss_cls: 0.3892, decode.d3.loss_mask: 0.5416, decode.d3.loss_dice: 0.8238, decode.d4.loss_cls: 0.3763, decode.d4.loss_mask: 0.5413, decode.d4.loss_dice: 0.8195, decode.d5.loss_cls: 0.3648, decode.d5.loss_mask: 0.5410, decode.d5.loss_dice: 0.8187, decode.d6.loss_cls: 0.3640, decode.d6.loss_mask: 0.5356, decode.d6.loss_dice: 0.8141, decode.d7.loss_cls: 0.3586, decode.d7.loss_mask: 0.5381, decode.d7.loss_dice: 0.8166, decode.d8.loss_cls: 0.3590, decode.d8.loss_mask: 0.5379, decode.d8.loss_dice: 0.8174, loss: 22.5491
2022-12-01 07:00:37,385 - mmseg - INFO - Iter [28450/40000]	lr: 3.842e-08, eta: 14:00:17, time: 4.163, data_time: 0.067, memory: 51902, decode.loss_cls: 0.3395, decode.loss_mask: 0.5393, decode.loss_dice: 0.7940, decode.d0.loss_cls: 5.3195, decode.d0.loss_mask: 0.5282, decode.d0.loss_dice: 0.8619, decode.d1.loss_cls: 0.4539, decode.d1.loss_mask: 0.5614, decode.d1.loss_dice: 0.8529, decode.d2.loss_cls: 0.3963, decode.d2.loss_mask: 0.5527, decode.d2.loss_dice: 0.8181, decode.d3.loss_cls: 0.3677, decode.d3.loss_mask: 0.5457, decode.d3.loss_dice: 0.8029, decode.d4.loss_cls: 0.3609, decode.d4.loss_mask: 0.5429, decode.d4.loss_dice: 0.8011, decode.d5.loss_cls: 0.3517, decode.d5.loss_mask: 0.5411, decode.d5.loss_dice: 0.7994, decode.d6.loss_cls: 0.3478, decode.d6.loss_mask: 0.5392, decode.d6.loss_dice: 0.7930, decode.d7.loss_cls: 0.3424, decode.d7.loss_mask: 0.5402, decode.d7.loss_dice: 0.8001, decode.d8.loss_cls: 0.3392, decode.d8.loss_mask: 0.5389, decode.d8.loss_dice: 0.7967, loss: 22.1687
2022-12-01 07:04:02,991 - mmseg - INFO - Iter [28500/40000]	lr: 3.825e-08, eta: 13:56:34, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3467, decode.loss_mask: 0.5267, decode.loss_dice: 0.7831, decode.d0.loss_cls: 5.3020, decode.d0.loss_mask: 0.5198, decode.d0.loss_dice: 0.8428, decode.d1.loss_cls: 0.4603, decode.d1.loss_mask: 0.5525, decode.d1.loss_dice: 0.8390, decode.d2.loss_cls: 0.4051, decode.d2.loss_mask: 0.5423, decode.d2.loss_dice: 0.8056, decode.d3.loss_cls: 0.3714, decode.d3.loss_mask: 0.5370, decode.d3.loss_dice: 0.7958, decode.d4.loss_cls: 0.3609, decode.d4.loss_mask: 0.5331, decode.d4.loss_dice: 0.7942, decode.d5.loss_cls: 0.3512, decode.d5.loss_mask: 0.5323, decode.d5.loss_dice: 0.7908, decode.d6.loss_cls: 0.3472, decode.d6.loss_mask: 0.5311, decode.d6.loss_dice: 0.7858, decode.d7.loss_cls: 0.3455, decode.d7.loss_mask: 0.5269, decode.d7.loss_dice: 0.7818, decode.d8.loss_cls: 0.3468, decode.d8.loss_mask: 0.5281, decode.d8.loss_dice: 0.7830, loss: 21.9688
2022-12-01 07:07:29,026 - mmseg - INFO - Iter [28550/40000]	lr: 3.808e-08, eta: 13:52:51, time: 4.121, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3321, decode.loss_mask: 0.5443, decode.loss_dice: 0.7979, decode.d0.loss_cls: 5.2928, decode.d0.loss_mask: 0.5347, decode.d0.loss_dice: 0.8546, decode.d1.loss_cls: 0.4378, decode.d1.loss_mask: 0.5696, decode.d1.loss_dice: 0.8523, decode.d2.loss_cls: 0.3898, decode.d2.loss_mask: 0.5580, decode.d2.loss_dice: 0.8197, decode.d3.loss_cls: 0.3535, decode.d3.loss_mask: 0.5542, decode.d3.loss_dice: 0.8050, decode.d4.loss_cls: 0.3464, decode.d4.loss_mask: 0.5489, decode.d4.loss_dice: 0.8021, decode.d5.loss_cls: 0.3362, decode.d5.loss_mask: 0.5489, decode.d5.loss_dice: 0.8004, decode.d6.loss_cls: 0.3326, decode.d6.loss_mask: 0.5469, decode.d6.loss_dice: 0.7961, decode.d7.loss_cls: 0.3320, decode.d7.loss_mask: 0.5461, decode.d7.loss_dice: 0.7990, decode.d8.loss_cls: 0.3308, decode.d8.loss_mask: 0.5465, decode.d8.loss_dice: 0.7975, loss: 22.1067
2022-12-01 07:10:55,009 - mmseg - INFO - Iter [28600/40000]	lr: 3.792e-08, eta: 13:49:08, time: 4.120, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3497, decode.loss_mask: 0.5490, decode.loss_dice: 0.8022, decode.d0.loss_cls: 5.3050, decode.d0.loss_mask: 0.5417, decode.d0.loss_dice: 0.8665, decode.d1.loss_cls: 0.4640, decode.d1.loss_mask: 0.5707, decode.d1.loss_dice: 0.8572, decode.d2.loss_cls: 0.4040, decode.d2.loss_mask: 0.5594, decode.d2.loss_dice: 0.8240, decode.d3.loss_cls: 0.3740, decode.d3.loss_mask: 0.5559, decode.d3.loss_dice: 0.8108, decode.d4.loss_cls: 0.3633, decode.d4.loss_mask: 0.5535, decode.d4.loss_dice: 0.8093, decode.d5.loss_cls: 0.3519, decode.d5.loss_mask: 0.5512, decode.d5.loss_dice: 0.8053, decode.d6.loss_cls: 0.3521, decode.d6.loss_mask: 0.5509, decode.d6.loss_dice: 0.7981, decode.d7.loss_cls: 0.3481, decode.d7.loss_mask: 0.5477, decode.d7.loss_dice: 0.7994, decode.d8.loss_cls: 0.3488, decode.d8.loss_mask: 0.5493, decode.d8.loss_dice: 0.7981, loss: 22.3609
2022-12-01 07:14:20,699 - mmseg - INFO - Iter [28650/40000]	lr: 3.775e-08, eta: 13:45:25, time: 4.114, data_time: 0.022, memory: 51902, decode.loss_cls: 0.3592, decode.loss_mask: 0.5279, decode.loss_dice: 0.7898, decode.d0.loss_cls: 5.3205, decode.d0.loss_mask: 0.5173, decode.d0.loss_dice: 0.8555, decode.d1.loss_cls: 0.4760, decode.d1.loss_mask: 0.5562, decode.d1.loss_dice: 0.8433, decode.d2.loss_cls: 0.4162, decode.d2.loss_mask: 0.5417, decode.d2.loss_dice: 0.8124, decode.d3.loss_cls: 0.3829, decode.d3.loss_mask: 0.5340, decode.d3.loss_dice: 0.7992, decode.d4.loss_cls: 0.3765, decode.d4.loss_mask: 0.5314, decode.d4.loss_dice: 0.7981, decode.d5.loss_cls: 0.3619, decode.d5.loss_mask: 0.5305, decode.d5.loss_dice: 0.7977, decode.d6.loss_cls: 0.3598, decode.d6.loss_mask: 0.5287, decode.d6.loss_dice: 0.7906, decode.d7.loss_cls: 0.3584, decode.d7.loss_mask: 0.5277, decode.d7.loss_dice: 0.7905, decode.d8.loss_cls: 0.3585, decode.d8.loss_mask: 0.5265, decode.d8.loss_dice: 0.7921, loss: 22.1611
2022-12-01 07:17:46,690 - mmseg - INFO - Iter [28700/40000]	lr: 3.758e-08, eta: 13:41:42, time: 4.120, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3664, decode.loss_mask: 0.5388, decode.loss_dice: 0.8133, decode.d0.loss_cls: 5.3182, decode.d0.loss_mask: 0.5320, decode.d0.loss_dice: 0.8768, decode.d1.loss_cls: 0.4846, decode.d1.loss_mask: 0.5654, decode.d1.loss_dice: 0.8672, decode.d2.loss_cls: 0.4212, decode.d2.loss_mask: 0.5542, decode.d2.loss_dice: 0.8332, decode.d3.loss_cls: 0.3930, decode.d3.loss_mask: 0.5477, decode.d3.loss_dice: 0.8204, decode.d4.loss_cls: 0.3852, decode.d4.loss_mask: 0.5419, decode.d4.loss_dice: 0.8190, decode.d5.loss_cls: 0.3731, decode.d5.loss_mask: 0.5419, decode.d5.loss_dice: 0.8151, decode.d6.loss_cls: 0.3697, decode.d6.loss_mask: 0.5418, decode.d6.loss_dice: 0.8132, decode.d7.loss_cls: 0.3677, decode.d7.loss_mask: 0.5397, decode.d7.loss_dice: 0.8128, decode.d8.loss_cls: 0.3696, decode.d8.loss_mask: 0.5390, decode.d8.loss_dice: 0.8138, loss: 22.5760
2022-12-01 07:21:12,595 - mmseg - INFO - Iter [28750/40000]	lr: 3.742e-08, eta: 13:37:59, time: 4.118, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3487, decode.loss_mask: 0.5501, decode.loss_dice: 0.7985, decode.d0.loss_cls: 5.3001, decode.d0.loss_mask: 0.5414, decode.d0.loss_dice: 0.8766, decode.d1.loss_cls: 0.4736, decode.d1.loss_mask: 0.5734, decode.d1.loss_dice: 0.8610, decode.d2.loss_cls: 0.4098, decode.d2.loss_mask: 0.5608, decode.d2.loss_dice: 0.8233, decode.d3.loss_cls: 0.3761, decode.d3.loss_mask: 0.5573, decode.d3.loss_dice: 0.8087, decode.d4.loss_cls: 0.3706, decode.d4.loss_mask: 0.5532, decode.d4.loss_dice: 0.8059, decode.d5.loss_cls: 0.3582, decode.d5.loss_mask: 0.5508, decode.d5.loss_dice: 0.8008, decode.d6.loss_cls: 0.3509, decode.d6.loss_mask: 0.5512, decode.d6.loss_dice: 0.7980, decode.d7.loss_cls: 0.3457, decode.d7.loss_mask: 0.5517, decode.d7.loss_dice: 0.8011, decode.d8.loss_cls: 0.3472, decode.d8.loss_mask: 0.5517, decode.d8.loss_dice: 0.7991, loss: 22.3951
2022-12-01 07:24:38,250 - mmseg - INFO - Iter [28800/40000]	lr: 3.725e-08, eta: 13:34:16, time: 4.113, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3366, decode.loss_mask: 0.5344, decode.loss_dice: 0.8047, decode.d0.loss_cls: 5.2939, decode.d0.loss_mask: 0.5229, decode.d0.loss_dice: 0.8667, decode.d1.loss_cls: 0.4613, decode.d1.loss_mask: 0.5620, decode.d1.loss_dice: 0.8557, decode.d2.loss_cls: 0.4009, decode.d2.loss_mask: 0.5522, decode.d2.loss_dice: 0.8250, decode.d3.loss_cls: 0.3643, decode.d3.loss_mask: 0.5445, decode.d3.loss_dice: 0.8139, decode.d4.loss_cls: 0.3562, decode.d4.loss_mask: 0.5417, decode.d4.loss_dice: 0.8098, decode.d5.loss_cls: 0.3491, decode.d5.loss_mask: 0.5378, decode.d5.loss_dice: 0.8099, decode.d6.loss_cls: 0.3443, decode.d6.loss_mask: 0.5343, decode.d6.loss_dice: 0.8044, decode.d7.loss_cls: 0.3440, decode.d7.loss_mask: 0.5345, decode.d7.loss_dice: 0.8041, decode.d8.loss_cls: 0.3384, decode.d8.loss_mask: 0.5339, decode.d8.loss_dice: 0.8072, loss: 22.1886
2022-12-01 07:28:04,106 - mmseg - INFO - Iter [28850/40000]	lr: 3.708e-08, eta: 13:30:33, time: 4.117, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3480, decode.loss_mask: 0.5471, decode.loss_dice: 0.8012, decode.d0.loss_cls: 5.3176, decode.d0.loss_mask: 0.5390, decode.d0.loss_dice: 0.8715, decode.d1.loss_cls: 0.4584, decode.d1.loss_mask: 0.5738, decode.d1.loss_dice: 0.8648, decode.d2.loss_cls: 0.4070, decode.d2.loss_mask: 0.5600, decode.d2.loss_dice: 0.8274, decode.d3.loss_cls: 0.3763, decode.d3.loss_mask: 0.5535, decode.d3.loss_dice: 0.8116, decode.d4.loss_cls: 0.3622, decode.d4.loss_mask: 0.5536, decode.d4.loss_dice: 0.8067, decode.d5.loss_cls: 0.3545, decode.d5.loss_mask: 0.5522, decode.d5.loss_dice: 0.8048, decode.d6.loss_cls: 0.3529, decode.d6.loss_mask: 0.5489, decode.d6.loss_dice: 0.8030, decode.d7.loss_cls: 0.3508, decode.d7.loss_mask: 0.5491, decode.d7.loss_dice: 0.8045, decode.d8.loss_cls: 0.3470, decode.d8.loss_mask: 0.5472, decode.d8.loss_dice: 0.8004, loss: 22.3948
2022-12-01 07:31:30,140 - mmseg - INFO - Iter [28900/40000]	lr: 3.692e-08, eta: 13:26:50, time: 4.121, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3502, decode.loss_mask: 0.5452, decode.loss_dice: 0.7890, decode.d0.loss_cls: 5.2572, decode.d0.loss_mask: 0.5382, decode.d0.loss_dice: 0.8599, decode.d1.loss_cls: 0.4549, decode.d1.loss_mask: 0.5737, decode.d1.loss_dice: 0.8529, decode.d2.loss_cls: 0.4044, decode.d2.loss_mask: 0.5590, decode.d2.loss_dice: 0.8180, decode.d3.loss_cls: 0.3741, decode.d3.loss_mask: 0.5536, decode.d3.loss_dice: 0.8017, decode.d4.loss_cls: 0.3646, decode.d4.loss_mask: 0.5500, decode.d4.loss_dice: 0.7978, decode.d5.loss_cls: 0.3560, decode.d5.loss_mask: 0.5472, decode.d5.loss_dice: 0.7925, decode.d6.loss_cls: 0.3537, decode.d6.loss_mask: 0.5460, decode.d6.loss_dice: 0.7926, decode.d7.loss_cls: 0.3482, decode.d7.loss_mask: 0.5469, decode.d7.loss_dice: 0.7938, decode.d8.loss_cls: 0.3484, decode.d8.loss_mask: 0.5444, decode.d8.loss_dice: 0.7911, loss: 22.2051
2022-12-01 07:34:55,529 - mmseg - INFO - Iter [28950/40000]	lr: 3.675e-08, eta: 13:23:07, time: 4.108, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3433, decode.loss_mask: 0.5470, decode.loss_dice: 0.8038, decode.d0.loss_cls: 5.2711, decode.d0.loss_mask: 0.5336, decode.d0.loss_dice: 0.8662, decode.d1.loss_cls: 0.4642, decode.d1.loss_mask: 0.5696, decode.d1.loss_dice: 0.8527, decode.d2.loss_cls: 0.4065, decode.d2.loss_mask: 0.5609, decode.d2.loss_dice: 0.8230, decode.d3.loss_cls: 0.3722, decode.d3.loss_mask: 0.5542, decode.d3.loss_dice: 0.8105, decode.d4.loss_cls: 0.3638, decode.d4.loss_mask: 0.5490, decode.d4.loss_dice: 0.8076, decode.d5.loss_cls: 0.3509, decode.d5.loss_mask: 0.5503, decode.d5.loss_dice: 0.8068, decode.d6.loss_cls: 0.3478, decode.d6.loss_mask: 0.5490, decode.d6.loss_dice: 0.8002, decode.d7.loss_cls: 0.3460, decode.d7.loss_mask: 0.5469, decode.d7.loss_dice: 0.8013, decode.d8.loss_cls: 0.3457, decode.d8.loss_mask: 0.5466, decode.d8.loss_dice: 0.8009, loss: 22.2916
2022-12-01 07:38:21,454 - mmseg - INFO - Saving checkpoint at 29000 iterations
2022-12-01 07:39:05,638 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 07:39:05,638 - mmseg - INFO - Iter [29000/40000]	lr: 3.659e-08, eta: 13:19:41, time: 5.002, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3565, decode.loss_mask: 0.5370, decode.loss_dice: 0.7996, decode.d0.loss_cls: 5.2775, decode.d0.loss_mask: 0.5246, decode.d0.loss_dice: 0.8574, decode.d1.loss_cls: 0.4685, decode.d1.loss_mask: 0.5643, decode.d1.loss_dice: 0.8518, decode.d2.loss_cls: 0.4125, decode.d2.loss_mask: 0.5502, decode.d2.loss_dice: 0.8235, decode.d3.loss_cls: 0.3810, decode.d3.loss_mask: 0.5439, decode.d3.loss_dice: 0.8101, decode.d4.loss_cls: 0.3746, decode.d4.loss_mask: 0.5431, decode.d4.loss_dice: 0.8058, decode.d5.loss_cls: 0.3625, decode.d5.loss_mask: 0.5410, decode.d5.loss_dice: 0.8023, decode.d6.loss_cls: 0.3569, decode.d6.loss_mask: 0.5393, decode.d6.loss_dice: 0.7995, decode.d7.loss_cls: 0.3548, decode.d7.loss_mask: 0.5400, decode.d7.loss_dice: 0.7999, decode.d8.loss_cls: 0.3547, decode.d8.loss_mask: 0.5391, decode.d8.loss_dice: 0.7984, loss: 22.2702
2022-12-01 07:42:03,715 - mmseg - INFO - per class results:
2022-12-01 07:42:03,720 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 83.29 |  89.4 |
|       building      | 85.77 | 92.25 |
|         sky         | 95.21 | 97.27 |
|        floor        | 85.63 | 90.63 |
|         tree        |  78.3 |  89.7 |
|       ceiling       | 87.34 | 93.55 |
|         road        | 88.38 | 92.32 |
|         bed         | 93.77 | 97.37 |
|      windowpane     | 68.96 | 81.81 |
|        grass        | 69.77 | 82.02 |
|       cabinet       | 64.48 | 74.39 |
|       sidewalk      | 73.01 | 85.73 |
|        person       | 88.48 | 94.46 |
|        earth        | 43.79 | 61.08 |
|         door        | 65.19 | 83.72 |
|        table        | 72.14 | 82.16 |
|       mountain      | 60.43 | 70.19 |
|        plant        | 57.85 | 68.45 |
|       curtain       | 82.77 | 91.97 |
|        chair        | 68.82 |  78.2 |
|         car         | 89.51 | 94.85 |
|        water        | 69.38 | 86.84 |
|       painting      | 80.56 | 92.06 |
|         sofa        | 85.81 | 92.22 |
|        shelf        | 48.65 | 61.07 |
|        house        | 52.34 | 71.22 |
|         sea         | 75.71 | 84.45 |
|        mirror       | 80.34 | 90.97 |
|         rug         | 71.32 | 83.96 |
|        field        | 36.21 | 64.83 |
|       armchair      | 64.03 | 82.02 |
|         seat        | 65.95 | 89.96 |
|        fence        | 56.87 | 74.76 |
|         desk        | 58.46 | 82.06 |
|         rock        | 58.05 | 75.82 |
|       wardrobe      | 59.99 |  86.3 |
|         lamp        | 80.74 | 91.04 |
|       bathtub       | 91.26 | 93.02 |
|       railing       | 45.62 | 65.07 |
|       cushion       |  78.1 | 90.25 |
|         base        | 43.72 | 68.15 |
|         box         | 43.13 | 60.42 |
|        column       | 58.97 | 72.69 |
|      signboard      | 45.32 | 68.35 |
|   chest of drawers  | 49.12 |  70.9 |
|       counter       | 60.24 | 69.57 |
|         sand        | 62.47 | 87.69 |
|         sink        | 82.36 | 87.12 |
|      skyscraper     | 47.92 | 55.37 |
|      fireplace      | 82.21 | 96.41 |
|     refrigerator    | 83.58 | 93.98 |
|      grandstand     | 52.73 | 80.96 |
|         path        | 32.05 | 41.91 |
|        stairs       | 37.38 | 50.99 |
|        runway       | 73.81 | 94.15 |
|         case        | 68.57 | 87.87 |
|      pool table     | 95.97 | 98.69 |
|        pillow       | 73.04 |  84.1 |
|     screen door     | 84.75 | 92.53 |
|       stairway      | 58.64 | 72.36 |
|        river        | 32.68 | 38.38 |
|        bridge       | 64.61 | 85.67 |
|       bookcase      | 42.09 | 63.07 |
|        blind        | 46.97 | 58.43 |
|     coffee table    |  74.0 | 92.75 |
|        toilet       | 93.26 | 96.86 |
|        flower       | 45.55 | 71.64 |
|         book        | 60.85 | 82.01 |
|         hill        | 11.37 | 20.43 |
|        bench        | 75.55 | 85.92 |
|      countertop     | 70.78 | 90.05 |
|        stove        | 86.69 |  90.9 |
|         palm        | 55.48 | 83.68 |
|    kitchen island   |  46.7 | 96.56 |
|       computer      | 80.38 | 87.74 |
|     swivel chair    | 55.43 | 88.37 |
|         boat        | 60.13 | 89.53 |
|         bar         | 70.97 | 78.22 |
|    arcade machine   | 92.11 | 98.58 |
|        hovel        |  49.9 | 74.75 |
|         bus         | 95.51 | 97.74 |
|        towel        | 84.72 | 94.65 |
|        light        | 67.17 | 79.83 |
|        truck        | 51.99 | 71.09 |
|        tower        | 34.25 | 62.74 |
|      chandelier     | 76.71 | 86.65 |
|        awning       | 32.76 | 54.87 |
|     streetlight     | 45.23 | 71.68 |
|        booth        | 56.35 | 68.84 |
| television receiver | 80.52 | 92.36 |
|       airplane      | 89.02 | 96.56 |
|      dirt track     | 14.73 | 26.17 |
|       apparel       | 52.45 | 85.37 |
|         pole        | 34.41 | 48.72 |
|         land        |  6.22 |  8.7  |
|      bannister      | 22.21 | 37.26 |
|      escalator      |  64.4 | 82.44 |
|       ottoman       | 58.81 | 77.27 |
|        bottle       | 52.01 | 83.25 |
|        buffet       | 41.44 | 57.56 |
|        poster       | 41.18 | 60.92 |
|        stage        | 28.72 | 62.12 |
|         van         | 50.58 | 77.17 |
|         ship        | 29.17 | 30.82 |
|       fountain      | 46.99 | 54.49 |
|    conveyer belt    | 77.56 | 97.11 |
|        canopy       | 47.22 | 62.09 |
|        washer       | 91.24 | 93.82 |
|      plaything      | 37.26 | 59.84 |
|    swimming pool    | 51.49 | 76.07 |
|        stool        | 52.84 | 85.04 |
|        barrel       | 66.48 | 96.79 |
|        basket       | 47.45 | 70.59 |
|      waterfall      | 46.35 | 56.68 |
|         tent        | 95.64 | 98.02 |
|         bag         | 33.99 | 48.91 |
|       minibike      | 80.96 | 94.16 |
|        cradle       | 91.44 | 97.37 |
|         oven        |  66.6 | 84.13 |
|         ball        | 43.42 | 46.94 |
|         food        | 66.88 | 81.72 |
|         step        | 30.88 | 44.69 |
|         tank        |  64.7 | 67.42 |
|      trade name     | 32.97 | 42.95 |
|      microwave      | 89.75 | 94.78 |
|         pot         | 62.11 | 75.02 |
|        animal       | 84.11 | 86.86 |
|       bicycle       | 62.58 | 85.06 |
|         lake        |  63.1 | 63.29 |
|      dishwasher     | 79.08 | 90.68 |
|        screen       |  59.2 | 91.45 |
|       blanket       | 47.48 | 60.56 |
|      sculpture      | 72.91 | 90.91 |
|         hood        | 80.84 |  91.7 |
|        sconce       | 67.65 | 83.92 |
|         vase        | 59.93 | 81.06 |
|    traffic light    | 52.98 |  75.3 |
|         tray        |  34.3 | 51.27 |
|        ashcan       | 50.85 | 75.58 |
|         fan         |  73.8 | 87.43 |
|         pier        | 37.53 |  41.9 |
|      crt screen     |  1.36 |  3.77 |
|        plate        | 70.74 | 85.06 |
|       monitor       |  8.93 | 12.45 |
|    bulletin board   | 59.78 | 84.83 |
|        shower       | 13.48 |  29.5 |
|       radiator      | 72.54 | 93.68 |
|        glass        | 29.03 | 31.85 |
|        clock        | 63.53 | 77.62 |
|         flag        | 68.43 | 87.82 |
+---------------------+-------+-------+
2022-12-01 07:42:03,720 - mmseg - INFO - Summary:
2022-12-01 07:42:03,720 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 87.14 | 61.08 | 75.76 |
+-------+-------+-------+
2022-12-01 07:42:03,724 - mmseg - INFO - The previous best checkpoint /mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune/lr1.0_lrd0.9/best_mIoU_iter_25000.pth was removed
2022-12-01 07:42:48,439 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_29000.pth.
2022-12-01 07:42:48,439 - mmseg - INFO - Best mIoU is 0.6108 at 29000 iter.
2022-12-01 07:42:48,447 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 07:42:48,447 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8714, mIoU: 0.6108, mAcc: 0.7576, IoU.wall: 0.8329, IoU.building: 0.8577, IoU.sky: 0.9521, IoU.floor: 0.8563, IoU.tree: 0.7830, IoU.ceiling: 0.8734, IoU.road: 0.8838, IoU.bed : 0.9377, IoU.windowpane: 0.6896, IoU.grass: 0.6977, IoU.cabinet: 0.6448, IoU.sidewalk: 0.7301, IoU.person: 0.8848, IoU.earth: 0.4379, IoU.door: 0.6519, IoU.table: 0.7214, IoU.mountain: 0.6043, IoU.plant: 0.5785, IoU.curtain: 0.8277, IoU.chair: 0.6882, IoU.car: 0.8951, IoU.water: 0.6938, IoU.painting: 0.8056, IoU.sofa: 0.8581, IoU.shelf: 0.4865, IoU.house: 0.5234, IoU.sea: 0.7571, IoU.mirror: 0.8034, IoU.rug: 0.7132, IoU.field: 0.3621, IoU.armchair: 0.6403, IoU.seat: 0.6595, IoU.fence: 0.5687, IoU.desk: 0.5846, IoU.rock: 0.5805, IoU.wardrobe: 0.5999, IoU.lamp: 0.8074, IoU.bathtub: 0.9126, IoU.railing: 0.4562, IoU.cushion: 0.7810, IoU.base: 0.4372, IoU.box: 0.4313, IoU.column: 0.5897, IoU.signboard: 0.4532, IoU.chest of drawers: 0.4912, IoU.counter: 0.6024, IoU.sand: 0.6247, IoU.sink: 0.8236, IoU.skyscraper: 0.4792, IoU.fireplace: 0.8221, IoU.refrigerator: 0.8358, IoU.grandstand: 0.5273, IoU.path: 0.3205, IoU.stairs: 0.3738, IoU.runway: 0.7381, IoU.case: 0.6857, IoU.pool table: 0.9597, IoU.pillow: 0.7304, IoU.screen door: 0.8475, IoU.stairway: 0.5864, IoU.river: 0.3268, IoU.bridge: 0.6461, IoU.bookcase: 0.4209, IoU.blind: 0.4697, IoU.coffee table: 0.7400, IoU.toilet: 0.9326, IoU.flower: 0.4555, IoU.book: 0.6085, IoU.hill: 0.1137, IoU.bench: 0.7555, IoU.countertop: 0.7078, IoU.stove: 0.8669, IoU.palm: 0.5548, IoU.kitchen island: 0.4670, IoU.computer: 0.8038, IoU.swivel chair: 0.5543, IoU.boat: 0.6013, IoU.bar: 0.7097, IoU.arcade machine: 0.9211, IoU.hovel: 0.4990, IoU.bus: 0.9551, IoU.towel: 0.8472, IoU.light: 0.6717, IoU.truck: 0.5199, IoU.tower: 0.3425, IoU.chandelier: 0.7671, IoU.awning: 0.3276, IoU.streetlight: 0.4523, IoU.booth: 0.5635, IoU.television receiver: 0.8052, IoU.airplane: 0.8902, IoU.dirt track: 0.1473, IoU.apparel: 0.5245, IoU.pole: 0.3441, IoU.land: 0.0622, IoU.bannister: 0.2221, IoU.escalator: 0.6440, IoU.ottoman: 0.5881, IoU.bottle: 0.5201, IoU.buffet: 0.4144, IoU.poster: 0.4118, IoU.stage: 0.2872, IoU.van: 0.5058, IoU.ship: 0.2917, IoU.fountain: 0.4699, IoU.conveyer belt: 0.7756, IoU.canopy: 0.4722, IoU.washer: 0.9124, IoU.plaything: 0.3726, IoU.swimming pool: 0.5149, IoU.stool: 0.5284, IoU.barrel: 0.6648, IoU.basket: 0.4745, IoU.waterfall: 0.4635, IoU.tent: 0.9564, IoU.bag: 0.3399, IoU.minibike: 0.8096, IoU.cradle: 0.9144, IoU.oven: 0.6660, IoU.ball: 0.4342, IoU.food: 0.6688, IoU.step: 0.3088, IoU.tank: 0.6470, IoU.trade name: 0.3297, IoU.microwave: 0.8975, IoU.pot: 0.6211, IoU.animal: 0.8411, IoU.bicycle: 0.6258, IoU.lake: 0.6310, IoU.dishwasher: 0.7908, IoU.screen: 0.5920, IoU.blanket: 0.4748, IoU.sculpture: 0.7291, IoU.hood: 0.8084, IoU.sconce: 0.6765, IoU.vase: 0.5993, IoU.traffic light: 0.5298, IoU.tray: 0.3430, IoU.ashcan: 0.5085, IoU.fan: 0.7380, IoU.pier: 0.3753, IoU.crt screen: 0.0136, IoU.plate: 0.7074, IoU.monitor: 0.0893, IoU.bulletin board: 0.5978, IoU.shower: 0.1348, IoU.radiator: 0.7254, IoU.glass: 0.2903, IoU.clock: 0.6353, IoU.flag: 0.6843, Acc.wall: 0.8940, Acc.building: 0.9225, Acc.sky: 0.9727, Acc.floor: 0.9063, Acc.tree: 0.8970, Acc.ceiling: 0.9355, Acc.road: 0.9232, Acc.bed : 0.9737, Acc.windowpane: 0.8181, Acc.grass: 0.8202, Acc.cabinet: 0.7439, Acc.sidewalk: 0.8573, Acc.person: 0.9446, Acc.earth: 0.6108, Acc.door: 0.8372, Acc.table: 0.8216, Acc.mountain: 0.7019, Acc.plant: 0.6845, Acc.curtain: 0.9197, Acc.chair: 0.7820, Acc.car: 0.9485, Acc.water: 0.8684, Acc.painting: 0.9206, Acc.sofa: 0.9222, Acc.shelf: 0.6107, Acc.house: 0.7122, Acc.sea: 0.8445, Acc.mirror: 0.9097, Acc.rug: 0.8396, Acc.field: 0.6483, Acc.armchair: 0.8202, Acc.seat: 0.8996, Acc.fence: 0.7476, Acc.desk: 0.8206, Acc.rock: 0.7582, Acc.wardrobe: 0.8630, Acc.lamp: 0.9104, Acc.bathtub: 0.9302, Acc.railing: 0.6507, Acc.cushion: 0.9025, Acc.base: 0.6815, Acc.box: 0.6042, Acc.column: 0.7269, Acc.signboard: 0.6835, Acc.chest of drawers: 0.7090, Acc.counter: 0.6957, Acc.sand: 0.8769, Acc.sink: 0.8712, Acc.skyscraper: 0.5537, Acc.fireplace: 0.9641, Acc.refrigerator: 0.9398, Acc.grandstand: 0.8096, Acc.path: 0.4191, Acc.stairs: 0.5099, Acc.runway: 0.9415, Acc.case: 0.8787, Acc.pool table: 0.9869, Acc.pillow: 0.8410, Acc.screen door: 0.9253, Acc.stairway: 0.7236, Acc.river: 0.3838, Acc.bridge: 0.8567, Acc.bookcase: 0.6307, Acc.blind: 0.5843, Acc.coffee table: 0.9275, Acc.toilet: 0.9686, Acc.flower: 0.7164, Acc.book: 0.8201, Acc.hill: 0.2043, Acc.bench: 0.8592, Acc.countertop: 0.9005, Acc.stove: 0.9090, Acc.palm: 0.8368, Acc.kitchen island: 0.9656, Acc.computer: 0.8774, Acc.swivel chair: 0.8837, Acc.boat: 0.8953, Acc.bar: 0.7822, Acc.arcade machine: 0.9858, Acc.hovel: 0.7475, Acc.bus: 0.9774, Acc.towel: 0.9465, Acc.light: 0.7983, Acc.truck: 0.7109, Acc.tower: 0.6274, Acc.chandelier: 0.8665, Acc.awning: 0.5487, Acc.streetlight: 0.7168, Acc.booth: 0.6884, Acc.television receiver: 0.9236, Acc.airplane: 0.9656, Acc.dirt track: 0.2617, Acc.apparel: 0.8537, Acc.pole: 0.4872, Acc.land: 0.0870, Acc.bannister: 0.3726, Acc.escalator: 0.8244, Acc.ottoman: 0.7727, Acc.bottle: 0.8325, Acc.buffet: 0.5756, Acc.poster: 0.6092, Acc.stage: 0.6212, Acc.van: 0.7717, Acc.ship: 0.3082, Acc.fountain: 0.5449, Acc.conveyer belt: 0.9711, Acc.canopy: 0.6209, Acc.washer: 0.9382, Acc.plaything: 0.5984, Acc.swimming pool: 0.7607, Acc.stool: 0.8504, Acc.barrel: 0.9679, Acc.basket: 0.7059, Acc.waterfall: 0.5668, Acc.tent: 0.9802, Acc.bag: 0.4891, Acc.minibike: 0.9416, Acc.cradle: 0.9737, Acc.oven: 0.8413, Acc.ball: 0.4694, Acc.food: 0.8172, Acc.step: 0.4469, Acc.tank: 0.6742, Acc.trade name: 0.4295, Acc.microwave: 0.9478, Acc.pot: 0.7502, Acc.animal: 0.8686, Acc.bicycle: 0.8506, Acc.lake: 0.6329, Acc.dishwasher: 0.9068, Acc.screen: 0.9145, Acc.blanket: 0.6056, Acc.sculpture: 0.9091, Acc.hood: 0.9170, Acc.sconce: 0.8392, Acc.vase: 0.8106, Acc.traffic light: 0.7530, Acc.tray: 0.5127, Acc.ashcan: 0.7558, Acc.fan: 0.8743, Acc.pier: 0.4190, Acc.crt screen: 0.0377, Acc.plate: 0.8506, Acc.monitor: 0.1245, Acc.bulletin board: 0.8483, Acc.shower: 0.2950, Acc.radiator: 0.9368, Acc.glass: 0.3185, Acc.clock: 0.7762, Acc.flag: 0.8782
2022-12-01 07:46:14,987 - mmseg - INFO - Iter [29050/40000]	lr: 3.642e-08, eta: 13:17:23, time: 8.587, data_time: 4.475, memory: 51902, decode.loss_cls: 0.3644, decode.loss_mask: 0.5335, decode.loss_dice: 0.7990, decode.d0.loss_cls: 5.2903, decode.d0.loss_mask: 0.5311, decode.d0.loss_dice: 0.8693, decode.d1.loss_cls: 0.4780, decode.d1.loss_mask: 0.5640, decode.d1.loss_dice: 0.8562, decode.d2.loss_cls: 0.4192, decode.d2.loss_mask: 0.5502, decode.d2.loss_dice: 0.8271, decode.d3.loss_cls: 0.3907, decode.d3.loss_mask: 0.5428, decode.d3.loss_dice: 0.8105, decode.d4.loss_cls: 0.3853, decode.d4.loss_mask: 0.5376, decode.d4.loss_dice: 0.8034, decode.d5.loss_cls: 0.3699, decode.d5.loss_mask: 0.5370, decode.d5.loss_dice: 0.8043, decode.d6.loss_cls: 0.3694, decode.d6.loss_mask: 0.5367, decode.d6.loss_dice: 0.8032, decode.d7.loss_cls: 0.3655, decode.d7.loss_mask: 0.5343, decode.d7.loss_dice: 0.7984, decode.d8.loss_cls: 0.3625, decode.d8.loss_mask: 0.5338, decode.d8.loss_dice: 0.7989, loss: 22.3666
2022-12-01 07:49:42,871 - mmseg - INFO - Iter [29100/40000]	lr: 3.625e-08, eta: 13:13:41, time: 4.158, data_time: 0.067, memory: 51902, decode.loss_cls: 0.3437, decode.loss_mask: 0.5408, decode.loss_dice: 0.8038, decode.d0.loss_cls: 5.2651, decode.d0.loss_mask: 0.5314, decode.d0.loss_dice: 0.8595, decode.d1.loss_cls: 0.4562, decode.d1.loss_mask: 0.5649, decode.d1.loss_dice: 0.8637, decode.d2.loss_cls: 0.4027, decode.d2.loss_mask: 0.5543, decode.d2.loss_dice: 0.8268, decode.d3.loss_cls: 0.3697, decode.d3.loss_mask: 0.5467, decode.d3.loss_dice: 0.8145, decode.d4.loss_cls: 0.3607, decode.d4.loss_mask: 0.5452, decode.d4.loss_dice: 0.8114, decode.d5.loss_cls: 0.3486, decode.d5.loss_mask: 0.5426, decode.d5.loss_dice: 0.8070, decode.d6.loss_cls: 0.3455, decode.d6.loss_mask: 0.5431, decode.d6.loss_dice: 0.8046, decode.d7.loss_cls: 0.3409, decode.d7.loss_mask: 0.5429, decode.d7.loss_dice: 0.8057, decode.d8.loss_cls: 0.3406, decode.d8.loss_mask: 0.5426, decode.d8.loss_dice: 0.8058, loss: 22.2307
2022-12-01 07:53:08,864 - mmseg - INFO - Iter [29150/40000]	lr: 3.609e-08, eta: 13:09:57, time: 4.120, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3460, decode.loss_mask: 0.5428, decode.loss_dice: 0.7878, decode.d0.loss_cls: 5.2533, decode.d0.loss_mask: 0.5407, decode.d0.loss_dice: 0.8646, decode.d1.loss_cls: 0.4539, decode.d1.loss_mask: 0.5711, decode.d1.loss_dice: 0.8514, decode.d2.loss_cls: 0.3996, decode.d2.loss_mask: 0.5587, decode.d2.loss_dice: 0.8175, decode.d3.loss_cls: 0.3642, decode.d3.loss_mask: 0.5506, decode.d3.loss_dice: 0.8029, decode.d4.loss_cls: 0.3587, decode.d4.loss_mask: 0.5493, decode.d4.loss_dice: 0.7973, decode.d5.loss_cls: 0.3495, decode.d5.loss_mask: 0.5443, decode.d5.loss_dice: 0.7942, decode.d6.loss_cls: 0.3474, decode.d6.loss_mask: 0.5449, decode.d6.loss_dice: 0.7891, decode.d7.loss_cls: 0.3460, decode.d7.loss_mask: 0.5436, decode.d7.loss_dice: 0.7904, decode.d8.loss_cls: 0.3452, decode.d8.loss_mask: 0.5438, decode.d8.loss_dice: 0.7916, loss: 22.1402
2022-12-01 07:56:34,847 - mmseg - INFO - Iter [29200/40000]	lr: 3.592e-08, eta: 13:06:14, time: 4.120, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3619, decode.loss_mask: 0.5322, decode.loss_dice: 0.8040, decode.d0.loss_cls: 5.2875, decode.d0.loss_mask: 0.5223, decode.d0.loss_dice: 0.8718, decode.d1.loss_cls: 0.4852, decode.d1.loss_mask: 0.5561, decode.d1.loss_dice: 0.8567, decode.d2.loss_cls: 0.4170, decode.d2.loss_mask: 0.5463, decode.d2.loss_dice: 0.8296, decode.d3.loss_cls: 0.3860, decode.d3.loss_mask: 0.5396, decode.d3.loss_dice: 0.8141, decode.d4.loss_cls: 0.3780, decode.d4.loss_mask: 0.5370, decode.d4.loss_dice: 0.8112, decode.d5.loss_cls: 0.3676, decode.d5.loss_mask: 0.5359, decode.d5.loss_dice: 0.8058, decode.d6.loss_cls: 0.3677, decode.d6.loss_mask: 0.5330, decode.d6.loss_dice: 0.8013, decode.d7.loss_cls: 0.3632, decode.d7.loss_mask: 0.5326, decode.d7.loss_dice: 0.8016, decode.d8.loss_cls: 0.3599, decode.d8.loss_mask: 0.5343, decode.d8.loss_dice: 0.8061, loss: 22.3456
2022-12-01 08:00:00,470 - mmseg - INFO - Iter [29250/40000]	lr: 3.575e-08, eta: 13:02:31, time: 4.112, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3399, decode.loss_mask: 0.5359, decode.loss_dice: 0.7855, decode.d0.loss_cls: 5.2578, decode.d0.loss_mask: 0.5280, decode.d0.loss_dice: 0.8535, decode.d1.loss_cls: 0.4548, decode.d1.loss_mask: 0.5639, decode.d1.loss_dice: 0.8467, decode.d2.loss_cls: 0.3983, decode.d2.loss_mask: 0.5483, decode.d2.loss_dice: 0.8113, decode.d3.loss_cls: 0.3683, decode.d3.loss_mask: 0.5443, decode.d3.loss_dice: 0.7985, decode.d4.loss_cls: 0.3577, decode.d4.loss_mask: 0.5417, decode.d4.loss_dice: 0.7937, decode.d5.loss_cls: 0.3455, decode.d5.loss_mask: 0.5394, decode.d5.loss_dice: 0.7922, decode.d6.loss_cls: 0.3420, decode.d6.loss_mask: 0.5367, decode.d6.loss_dice: 0.7878, decode.d7.loss_cls: 0.3390, decode.d7.loss_mask: 0.5367, decode.d7.loss_dice: 0.7868, decode.d8.loss_cls: 0.3391, decode.d8.loss_mask: 0.5367, decode.d8.loss_dice: 0.7854, loss: 21.9957
2022-12-01 08:03:26,240 - mmseg - INFO - Iter [29300/40000]	lr: 3.559e-08, eta: 12:58:48, time: 4.115, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3327, decode.loss_mask: 0.5199, decode.loss_dice: 0.7873, decode.d0.loss_cls: 5.2655, decode.d0.loss_mask: 0.5134, decode.d0.loss_dice: 0.8491, decode.d1.loss_cls: 0.4494, decode.d1.loss_mask: 0.5476, decode.d1.loss_dice: 0.8419, decode.d2.loss_cls: 0.3905, decode.d2.loss_mask: 0.5350, decode.d2.loss_dice: 0.8163, decode.d3.loss_cls: 0.3645, decode.d3.loss_mask: 0.5270, decode.d3.loss_dice: 0.7985, decode.d4.loss_cls: 0.3556, decode.d4.loss_mask: 0.5240, decode.d4.loss_dice: 0.7977, decode.d5.loss_cls: 0.3420, decode.d5.loss_mask: 0.5218, decode.d5.loss_dice: 0.7938, decode.d6.loss_cls: 0.3389, decode.d6.loss_mask: 0.5202, decode.d6.loss_dice: 0.7890, decode.d7.loss_cls: 0.3332, decode.d7.loss_mask: 0.5191, decode.d7.loss_dice: 0.7902, decode.d8.loss_cls: 0.3318, decode.d8.loss_mask: 0.5212, decode.d8.loss_dice: 0.7884, loss: 21.8054
2022-12-01 08:06:52,010 - mmseg - INFO - Iter [29350/40000]	lr: 3.542e-08, eta: 12:55:05, time: 4.115, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3322, decode.loss_mask: 0.5465, decode.loss_dice: 0.7864, decode.d0.loss_cls: 5.2433, decode.d0.loss_mask: 0.5383, decode.d0.loss_dice: 0.8497, decode.d1.loss_cls: 0.4475, decode.d1.loss_mask: 0.5732, decode.d1.loss_dice: 0.8481, decode.d2.loss_cls: 0.3911, decode.d2.loss_mask: 0.5578, decode.d2.loss_dice: 0.8124, decode.d3.loss_cls: 0.3591, decode.d3.loss_mask: 0.5516, decode.d3.loss_dice: 0.7973, decode.d4.loss_cls: 0.3531, decode.d4.loss_mask: 0.5513, decode.d4.loss_dice: 0.7956, decode.d5.loss_cls: 0.3402, decode.d5.loss_mask: 0.5477, decode.d5.loss_dice: 0.7916, decode.d6.loss_cls: 0.3350, decode.d6.loss_mask: 0.5459, decode.d6.loss_dice: 0.7885, decode.d7.loss_cls: 0.3363, decode.d7.loss_mask: 0.5456, decode.d7.loss_dice: 0.7870, decode.d8.loss_cls: 0.3349, decode.d8.loss_mask: 0.5451, decode.d8.loss_dice: 0.7873, loss: 22.0194
2022-12-01 08:10:17,741 - mmseg - INFO - Iter [29400/40000]	lr: 3.526e-08, eta: 12:51:23, time: 4.115, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3432, decode.loss_mask: 0.5359, decode.loss_dice: 0.7838, decode.d0.loss_cls: 5.2486, decode.d0.loss_mask: 0.5239, decode.d0.loss_dice: 0.8497, decode.d1.loss_cls: 0.4523, decode.d1.loss_mask: 0.5631, decode.d1.loss_dice: 0.8450, decode.d2.loss_cls: 0.3984, decode.d2.loss_mask: 0.5511, decode.d2.loss_dice: 0.8123, decode.d3.loss_cls: 0.3683, decode.d3.loss_mask: 0.5442, decode.d3.loss_dice: 0.7956, decode.d4.loss_cls: 0.3593, decode.d4.loss_mask: 0.5412, decode.d4.loss_dice: 0.7948, decode.d5.loss_cls: 0.3500, decode.d5.loss_mask: 0.5384, decode.d5.loss_dice: 0.7914, decode.d6.loss_cls: 0.3452, decode.d6.loss_mask: 0.5373, decode.d6.loss_dice: 0.7864, decode.d7.loss_cls: 0.3437, decode.d7.loss_mask: 0.5383, decode.d7.loss_dice: 0.7892, decode.d8.loss_cls: 0.3425, decode.d8.loss_mask: 0.5381, decode.d8.loss_dice: 0.7864, loss: 21.9974
2022-12-01 08:13:43,812 - mmseg - INFO - Iter [29450/40000]	lr: 3.509e-08, eta: 12:47:40, time: 4.121, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3364, decode.loss_mask: 0.5400, decode.loss_dice: 0.7950, decode.d0.loss_cls: 5.2443, decode.d0.loss_mask: 0.5286, decode.d0.loss_dice: 0.8517, decode.d1.loss_cls: 0.4493, decode.d1.loss_mask: 0.5652, decode.d1.loss_dice: 0.8460, decode.d2.loss_cls: 0.3981, decode.d2.loss_mask: 0.5516, decode.d2.loss_dice: 0.8148, decode.d3.loss_cls: 0.3640, decode.d3.loss_mask: 0.5479, decode.d3.loss_dice: 0.8005, decode.d4.loss_cls: 0.3539, decode.d4.loss_mask: 0.5463, decode.d4.loss_dice: 0.7989, decode.d5.loss_cls: 0.3447, decode.d5.loss_mask: 0.5428, decode.d5.loss_dice: 0.7978, decode.d6.loss_cls: 0.3394, decode.d6.loss_mask: 0.5419, decode.d6.loss_dice: 0.7982, decode.d7.loss_cls: 0.3380, decode.d7.loss_mask: 0.5399, decode.d7.loss_dice: 0.7953, decode.d8.loss_cls: 0.3361, decode.d8.loss_mask: 0.5401, decode.d8.loss_dice: 0.7964, loss: 22.0426
2022-12-01 08:17:09,370 - mmseg - INFO - Iter [29500/40000]	lr: 3.492e-08, eta: 12:43:57, time: 4.111, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3459, decode.loss_mask: 0.5431, decode.loss_dice: 0.7976, decode.d0.loss_cls: 5.2474, decode.d0.loss_mask: 0.5251, decode.d0.loss_dice: 0.8571, decode.d1.loss_cls: 0.4588, decode.d1.loss_mask: 0.5641, decode.d1.loss_dice: 0.8603, decode.d2.loss_cls: 0.3986, decode.d2.loss_mask: 0.5556, decode.d2.loss_dice: 0.8265, decode.d3.loss_cls: 0.3695, decode.d3.loss_mask: 0.5487, decode.d3.loss_dice: 0.8115, decode.d4.loss_cls: 0.3622, decode.d4.loss_mask: 0.5463, decode.d4.loss_dice: 0.8082, decode.d5.loss_cls: 0.3486, decode.d5.loss_mask: 0.5461, decode.d5.loss_dice: 0.8036, decode.d6.loss_cls: 0.3486, decode.d6.loss_mask: 0.5417, decode.d6.loss_dice: 0.7980, decode.d7.loss_cls: 0.3467, decode.d7.loss_mask: 0.5422, decode.d7.loss_dice: 0.7997, decode.d8.loss_cls: 0.3442, decode.d8.loss_mask: 0.5436, decode.d8.loss_dice: 0.7969, loss: 22.1864
2022-12-01 08:20:35,255 - mmseg - INFO - Iter [29550/40000]	lr: 3.476e-08, eta: 12:40:14, time: 4.118, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3466, decode.loss_mask: 0.5411, decode.loss_dice: 0.8006, decode.d0.loss_cls: 5.2368, decode.d0.loss_mask: 0.5313, decode.d0.loss_dice: 0.8664, decode.d1.loss_cls: 0.4486, decode.d1.loss_mask: 0.5677, decode.d1.loss_dice: 0.8566, decode.d2.loss_cls: 0.4010, decode.d2.loss_mask: 0.5521, decode.d2.loss_dice: 0.8198, decode.d3.loss_cls: 0.3723, decode.d3.loss_mask: 0.5466, decode.d3.loss_dice: 0.8102, decode.d4.loss_cls: 0.3644, decode.d4.loss_mask: 0.5438, decode.d4.loss_dice: 0.8089, decode.d5.loss_cls: 0.3536, decode.d5.loss_mask: 0.5443, decode.d5.loss_dice: 0.8046, decode.d6.loss_cls: 0.3497, decode.d6.loss_mask: 0.5423, decode.d6.loss_dice: 0.7996, decode.d7.loss_cls: 0.3466, decode.d7.loss_mask: 0.5424, decode.d7.loss_dice: 0.8011, decode.d8.loss_cls: 0.3451, decode.d8.loss_mask: 0.5395, decode.d8.loss_dice: 0.8012, loss: 22.1847
2022-12-01 08:24:00,891 - mmseg - INFO - Iter [29600/40000]	lr: 3.459e-08, eta: 12:36:32, time: 4.113, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3552, decode.loss_mask: 0.5399, decode.loss_dice: 0.8063, decode.d0.loss_cls: 5.2351, decode.d0.loss_mask: 0.5298, decode.d0.loss_dice: 0.8703, decode.d1.loss_cls: 0.4632, decode.d1.loss_mask: 0.5677, decode.d1.loss_dice: 0.8618, decode.d2.loss_cls: 0.4099, decode.d2.loss_mask: 0.5549, decode.d2.loss_dice: 0.8290, decode.d3.loss_cls: 0.3797, decode.d3.loss_mask: 0.5492, decode.d3.loss_dice: 0.8166, decode.d4.loss_cls: 0.3704, decode.d4.loss_mask: 0.5471, decode.d4.loss_dice: 0.8139, decode.d5.loss_cls: 0.3600, decode.d5.loss_mask: 0.5458, decode.d5.loss_dice: 0.8107, decode.d6.loss_cls: 0.3574, decode.d6.loss_mask: 0.5435, decode.d6.loss_dice: 0.8040, decode.d7.loss_cls: 0.3545, decode.d7.loss_mask: 0.5415, decode.d7.loss_dice: 0.8038, decode.d8.loss_cls: 0.3542, decode.d8.loss_mask: 0.5414, decode.d8.loss_dice: 0.8065, loss: 22.3230
2022-12-01 08:27:26,582 - mmseg - INFO - Iter [29650/40000]	lr: 3.442e-08, eta: 12:32:49, time: 4.114, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3544, decode.loss_mask: 0.5324, decode.loss_dice: 0.7970, decode.d0.loss_cls: 5.2598, decode.d0.loss_mask: 0.5226, decode.d0.loss_dice: 0.8589, decode.d1.loss_cls: 0.4703, decode.d1.loss_mask: 0.5571, decode.d1.loss_dice: 0.8520, decode.d2.loss_cls: 0.4136, decode.d2.loss_mask: 0.5458, decode.d2.loss_dice: 0.8201, decode.d3.loss_cls: 0.3744, decode.d3.loss_mask: 0.5418, decode.d3.loss_dice: 0.8105, decode.d4.loss_cls: 0.3703, decode.d4.loss_mask: 0.5378, decode.d4.loss_dice: 0.8050, decode.d5.loss_cls: 0.3601, decode.d5.loss_mask: 0.5356, decode.d5.loss_dice: 0.8011, decode.d6.loss_cls: 0.3571, decode.d6.loss_mask: 0.5334, decode.d6.loss_dice: 0.7944, decode.d7.loss_cls: 0.3554, decode.d7.loss_mask: 0.5323, decode.d7.loss_dice: 0.7975, decode.d8.loss_cls: 0.3560, decode.d8.loss_mask: 0.5312, decode.d8.loss_dice: 0.7933, loss: 22.1713
2022-12-01 08:30:52,555 - mmseg - INFO - Iter [29700/40000]	lr: 3.426e-08, eta: 12:29:07, time: 4.119, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3484, decode.loss_mask: 0.5348, decode.loss_dice: 0.7892, decode.d0.loss_cls: 5.2395, decode.d0.loss_mask: 0.5242, decode.d0.loss_dice: 0.8643, decode.d1.loss_cls: 0.4672, decode.d1.loss_mask: 0.5573, decode.d1.loss_dice: 0.8468, decode.d2.loss_cls: 0.4080, decode.d2.loss_mask: 0.5439, decode.d2.loss_dice: 0.8082, decode.d3.loss_cls: 0.3776, decode.d3.loss_mask: 0.5395, decode.d3.loss_dice: 0.7984, decode.d4.loss_cls: 0.3685, decode.d4.loss_mask: 0.5354, decode.d4.loss_dice: 0.7917, decode.d5.loss_cls: 0.3589, decode.d5.loss_mask: 0.5326, decode.d5.loss_dice: 0.7897, decode.d6.loss_cls: 0.3544, decode.d6.loss_mask: 0.5348, decode.d6.loss_dice: 0.7885, decode.d7.loss_cls: 0.3485, decode.d7.loss_mask: 0.5326, decode.d7.loss_dice: 0.7928, decode.d8.loss_cls: 0.3496, decode.d8.loss_mask: 0.5341, decode.d8.loss_dice: 0.7881, loss: 22.0477
2022-12-01 08:34:20,420 - mmseg - INFO - Iter [29750/40000]	lr: 3.409e-08, eta: 12:25:25, time: 4.157, data_time: 0.066, memory: 51902, decode.loss_cls: 0.3281, decode.loss_mask: 0.5209, decode.loss_dice: 0.7811, decode.d0.loss_cls: 5.2583, decode.d0.loss_mask: 0.5089, decode.d0.loss_dice: 0.8470, decode.d1.loss_cls: 0.4500, decode.d1.loss_mask: 0.5453, decode.d1.loss_dice: 0.8424, decode.d2.loss_cls: 0.3902, decode.d2.loss_mask: 0.5330, decode.d2.loss_dice: 0.8049, decode.d3.loss_cls: 0.3577, decode.d3.loss_mask: 0.5258, decode.d3.loss_dice: 0.7911, decode.d4.loss_cls: 0.3490, decode.d4.loss_mask: 0.5245, decode.d4.loss_dice: 0.7885, decode.d5.loss_cls: 0.3416, decode.d5.loss_mask: 0.5204, decode.d5.loss_dice: 0.7835, decode.d6.loss_cls: 0.3321, decode.d6.loss_mask: 0.5204, decode.d6.loss_dice: 0.7815, decode.d7.loss_cls: 0.3279, decode.d7.loss_mask: 0.5199, decode.d7.loss_dice: 0.7817, decode.d8.loss_cls: 0.3319, decode.d8.loss_mask: 0.5182, decode.d8.loss_dice: 0.7821, loss: 21.6879
2022-12-01 08:37:46,418 - mmseg - INFO - Iter [29800/40000]	lr: 3.393e-08, eta: 12:21:42, time: 4.120, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3234, decode.loss_mask: 0.5272, decode.loss_dice: 0.7812, decode.d0.loss_cls: 5.2101, decode.d0.loss_mask: 0.5201, decode.d0.loss_dice: 0.8474, decode.d1.loss_cls: 0.4384, decode.d1.loss_mask: 0.5536, decode.d1.loss_dice: 0.8442, decode.d2.loss_cls: 0.3859, decode.d2.loss_mask: 0.5400, decode.d2.loss_dice: 0.8099, decode.d3.loss_cls: 0.3530, decode.d3.loss_mask: 0.5351, decode.d3.loss_dice: 0.7959, decode.d4.loss_cls: 0.3407, decode.d4.loss_mask: 0.5348, decode.d4.loss_dice: 0.7921, decode.d5.loss_cls: 0.3312, decode.d5.loss_mask: 0.5320, decode.d5.loss_dice: 0.7869, decode.d6.loss_cls: 0.3285, decode.d6.loss_mask: 0.5282, decode.d6.loss_dice: 0.7848, decode.d7.loss_cls: 0.3223, decode.d7.loss_mask: 0.5290, decode.d7.loss_dice: 0.7852, decode.d8.loss_cls: 0.3240, decode.d8.loss_mask: 0.5277, decode.d8.loss_dice: 0.7832, loss: 21.6959
2022-12-01 08:41:12,168 - mmseg - INFO - Iter [29850/40000]	lr: 3.376e-08, eta: 12:18:00, time: 4.115, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3450, decode.loss_mask: 0.5421, decode.loss_dice: 0.8013, decode.d0.loss_cls: 5.2168, decode.d0.loss_mask: 0.5334, decode.d0.loss_dice: 0.8691, decode.d1.loss_cls: 0.4615, decode.d1.loss_mask: 0.5686, decode.d1.loss_dice: 0.8614, decode.d2.loss_cls: 0.4067, decode.d2.loss_mask: 0.5577, decode.d2.loss_dice: 0.8247, decode.d3.loss_cls: 0.3703, decode.d3.loss_mask: 0.5487, decode.d3.loss_dice: 0.8137, decode.d4.loss_cls: 0.3641, decode.d4.loss_mask: 0.5447, decode.d4.loss_dice: 0.8089, decode.d5.loss_cls: 0.3513, decode.d5.loss_mask: 0.5443, decode.d5.loss_dice: 0.8068, decode.d6.loss_cls: 0.3484, decode.d6.loss_mask: 0.5438, decode.d6.loss_dice: 0.8052, decode.d7.loss_cls: 0.3421, decode.d7.loss_mask: 0.5414, decode.d7.loss_dice: 0.8010, decode.d8.loss_cls: 0.3443, decode.d8.loss_mask: 0.5414, decode.d8.loss_dice: 0.8024, loss: 22.2108
2022-12-01 08:44:37,603 - mmseg - INFO - Iter [29900/40000]	lr: 3.359e-08, eta: 12:14:18, time: 4.109, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3322, decode.loss_mask: 0.5265, decode.loss_dice: 0.7843, decode.d0.loss_cls: 5.2170, decode.d0.loss_mask: 0.5193, decode.d0.loss_dice: 0.8476, decode.d1.loss_cls: 0.4540, decode.d1.loss_mask: 0.5519, decode.d1.loss_dice: 0.8463, decode.d2.loss_cls: 0.3923, decode.d2.loss_mask: 0.5389, decode.d2.loss_dice: 0.8126, decode.d3.loss_cls: 0.3607, decode.d3.loss_mask: 0.5321, decode.d3.loss_dice: 0.7966, decode.d4.loss_cls: 0.3522, decode.d4.loss_mask: 0.5310, decode.d4.loss_dice: 0.7919, decode.d5.loss_cls: 0.3391, decode.d5.loss_mask: 0.5292, decode.d5.loss_dice: 0.7909, decode.d6.loss_cls: 0.3395, decode.d6.loss_mask: 0.5263, decode.d6.loss_dice: 0.7841, decode.d7.loss_cls: 0.3375, decode.d7.loss_mask: 0.5275, decode.d7.loss_dice: 0.7825, decode.d8.loss_cls: 0.3373, decode.d8.loss_mask: 0.5259, decode.d8.loss_dice: 0.7861, loss: 21.7933
2022-12-01 08:48:03,432 - mmseg - INFO - Iter [29950/40000]	lr: 3.343e-08, eta: 12:10:35, time: 4.117, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3375, decode.loss_mask: 0.5322, decode.loss_dice: 0.7820, decode.d0.loss_cls: 5.2209, decode.d0.loss_mask: 0.5248, decode.d0.loss_dice: 0.8587, decode.d1.loss_cls: 0.4505, decode.d1.loss_mask: 0.5612, decode.d1.loss_dice: 0.8416, decode.d2.loss_cls: 0.3941, decode.d2.loss_mask: 0.5481, decode.d2.loss_dice: 0.8077, decode.d3.loss_cls: 0.3635, decode.d3.loss_mask: 0.5406, decode.d3.loss_dice: 0.7932, decode.d4.loss_cls: 0.3571, decode.d4.loss_mask: 0.5371, decode.d4.loss_dice: 0.7918, decode.d5.loss_cls: 0.3478, decode.d5.loss_mask: 0.5351, decode.d5.loss_dice: 0.7878, decode.d6.loss_cls: 0.3386, decode.d6.loss_mask: 0.5338, decode.d6.loss_dice: 0.7839, decode.d7.loss_cls: 0.3367, decode.d7.loss_mask: 0.5329, decode.d7.loss_dice: 0.7859, decode.d8.loss_cls: 0.3342, decode.d8.loss_mask: 0.5327, decode.d8.loss_dice: 0.7848, loss: 21.8767
2022-12-01 08:51:29,391 - mmseg - INFO - Saving checkpoint at 30000 iterations
2022-12-01 08:52:16,508 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 08:52:16,508 - mmseg - INFO - Iter [30000/40000]	lr: 3.326e-08, eta: 12:07:09, time: 5.062, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3414, decode.loss_mask: 0.5306, decode.loss_dice: 0.7887, decode.d0.loss_cls: 5.2239, decode.d0.loss_mask: 0.5154, decode.d0.loss_dice: 0.8535, decode.d1.loss_cls: 0.4560, decode.d1.loss_mask: 0.5529, decode.d1.loss_dice: 0.8454, decode.d2.loss_cls: 0.4031, decode.d2.loss_mask: 0.5424, decode.d2.loss_dice: 0.8115, decode.d3.loss_cls: 0.3669, decode.d3.loss_mask: 0.5361, decode.d3.loss_dice: 0.7993, decode.d4.loss_cls: 0.3583, decode.d4.loss_mask: 0.5345, decode.d4.loss_dice: 0.7951, decode.d5.loss_cls: 0.3484, decode.d5.loss_mask: 0.5319, decode.d5.loss_dice: 0.7916, decode.d6.loss_cls: 0.3448, decode.d6.loss_mask: 0.5312, decode.d6.loss_dice: 0.7914, decode.d7.loss_cls: 0.3426, decode.d7.loss_mask: 0.5304, decode.d7.loss_dice: 0.7917, decode.d8.loss_cls: 0.3382, decode.d8.loss_mask: 0.5313, decode.d8.loss_dice: 0.7913, loss: 21.9198
2022-12-01 08:55:14,577 - mmseg - INFO - per class results:
2022-12-01 08:55:14,582 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 83.11 | 89.44 |
|       building      |  85.2 | 91.76 |
|         sky         |  95.2 | 97.27 |
|        floor        | 85.78 | 90.49 |
|         tree        | 78.71 | 89.46 |
|       ceiling       | 87.09 | 93.41 |
|         road        | 88.23 |  91.7 |
|         bed         | 93.72 | 97.01 |
|      windowpane     | 68.67 | 82.87 |
|        grass        | 68.21 | 80.65 |
|       cabinet       | 63.47 | 73.53 |
|       sidewalk      | 72.01 | 85.25 |
|        person       | 88.42 | 94.33 |
|        earth        | 43.01 | 58.27 |
|         door        | 63.48 | 80.17 |
|        table        |  72.5 | 81.78 |
|       mountain      | 60.95 | 69.26 |
|        plant        | 56.73 | 72.28 |
|       curtain       | 81.91 | 90.23 |
|        chair        |  69.2 | 79.46 |
|         car         | 89.63 | 95.35 |
|        water        | 70.53 | 84.93 |
|       painting      | 80.37 | 91.68 |
|         sofa        |  85.5 | 91.13 |
|        shelf        | 46.83 | 56.71 |
|        house        | 51.73 | 69.95 |
|         sea         | 80.29 | 89.82 |
|        mirror       | 81.26 |  91.3 |
|         rug         | 71.91 | 84.88 |
|        field        | 37.58 |  70.9 |
|       armchair      | 63.38 | 80.11 |
|         seat        | 66.22 | 90.06 |
|        fence        | 57.03 | 75.02 |
|         desk        | 59.72 | 83.97 |
|         rock        | 60.72 | 75.96 |
|       wardrobe      | 59.03 | 86.06 |
|         lamp        |  80.9 | 90.76 |
|       bathtub       | 91.96 | 93.57 |
|       railing       | 47.32 | 69.85 |
|       cushion       | 76.34 |  91.1 |
|         base        | 47.25 | 76.54 |
|         box         | 43.23 | 60.94 |
|        column       | 59.72 | 75.17 |
|      signboard      | 44.46 | 69.24 |
|   chest of drawers  | 44.16 | 70.97 |
|       counter       | 54.43 | 65.22 |
|         sand        | 63.18 | 88.32 |
|         sink        | 82.51 | 87.02 |
|      skyscraper     |  43.1 |  53.8 |
|      fireplace      | 80.48 | 96.45 |
|     refrigerator    | 83.68 | 94.55 |
|      grandstand     | 50.84 | 82.45 |
|         path        | 31.68 | 43.75 |
|        stairs       | 36.45 |  49.0 |
|        runway       |  74.4 | 93.72 |
|         case        | 68.55 | 87.98 |
|      pool table     | 95.84 | 98.51 |
|        pillow       | 73.24 | 83.15 |
|     screen door     | 84.42 | 92.44 |
|       stairway      | 57.45 |  75.0 |
|        river        | 25.72 | 30.21 |
|        bridge       | 71.46 | 86.78 |
|       bookcase      | 39.17 | 65.36 |
|        blind        | 42.48 | 53.15 |
|     coffee table    | 73.97 |  90.5 |
|        toilet       | 93.32 | 96.72 |
|        flower       | 45.69 | 70.98 |
|         book        | 60.85 | 82.81 |
|         hill        | 12.84 |  28.0 |
|        bench        | 74.14 | 84.64 |
|      countertop     | 73.11 | 87.85 |
|        stove        |  87.2 |  91.5 |
|         palm        | 56.51 | 83.09 |
|    kitchen island   |  45.9 | 96.26 |
|       computer      |  81.0 | 88.37 |
|     swivel chair    | 56.65 | 85.21 |
|         boat        | 61.49 | 89.46 |
|         bar         | 70.65 | 77.14 |
|    arcade machine   | 91.41 |  98.6 |
|        hovel        | 31.99 | 43.06 |
|         bus         | 94.13 |  96.3 |
|        towel        | 85.97 | 94.33 |
|        light        | 66.32 | 81.45 |
|        truck        | 52.16 | 74.21 |
|        tower        | 32.93 | 63.31 |
|      chandelier     | 77.06 | 87.05 |
|        awning       | 36.04 | 61.65 |
|     streetlight     | 45.63 | 71.08 |
|        booth        | 60.83 | 76.73 |
| television receiver | 77.54 | 92.29 |
|       airplane      | 89.16 | 96.65 |
|      dirt track     |  7.34 | 14.13 |
|       apparel       | 53.28 | 86.41 |
|         pole        | 34.21 | 49.58 |
|         land        |  6.91 |  9.64 |
|      bannister      | 24.59 |  32.4 |
|      escalator      | 64.09 | 86.12 |
|       ottoman       | 59.41 | 78.88 |
|        bottle       |  53.0 |  83.3 |
|        buffet       | 42.28 | 58.29 |
|        poster       | 38.32 | 58.85 |
|        stage        | 34.85 | 79.19 |
|         van         | 53.34 | 74.46 |
|         ship        | 51.03 | 53.88 |
|       fountain      | 49.42 | 57.02 |
|    conveyer belt    | 77.23 | 97.03 |
|        canopy       | 68.34 | 92.15 |
|        washer       | 91.02 | 93.53 |
|      plaything      | 38.48 | 58.33 |
|    swimming pool    | 46.85 | 75.49 |
|        stool        | 56.29 | 85.92 |
|        barrel       | 66.75 | 97.67 |
|        basket       | 45.65 | 68.51 |
|      waterfall      | 45.85 | 57.46 |
|         tent        | 95.31 | 98.15 |
|         bag         | 34.89 |  49.5 |
|       minibike      | 80.83 | 94.36 |
|        cradle       | 91.33 | 97.31 |
|         oven        | 66.45 |  84.0 |
|         ball        | 38.98 |  42.2 |
|         food        | 68.05 | 80.14 |
|         step        | 24.45 | 37.28 |
|         tank        | 62.79 | 67.35 |
|      trade name     | 30.04 | 39.19 |
|      microwave      | 89.77 | 94.44 |
|         pot         | 61.68 | 75.08 |
|        animal       | 80.07 |  82.3 |
|       bicycle       | 62.65 | 84.18 |
|         lake        | 49.24 | 68.68 |
|      dishwasher     | 70.65 | 90.72 |
|        screen       | 61.01 | 94.21 |
|       blanket       | 44.49 | 61.46 |
|      sculpture      | 71.25 | 90.98 |
|         hood        | 86.48 | 91.75 |
|        sconce       | 67.01 | 83.19 |
|         vase        | 58.66 | 82.64 |
|    traffic light    | 53.52 | 75.16 |
|         tray        | 32.39 |  54.9 |
|        ashcan       | 53.92 | 79.86 |
|         fan         | 73.53 | 87.06 |
|         pier        |  39.0 |  41.5 |
|      crt screen     |  3.81 | 10.68 |
|        plate        | 69.53 | 86.75 |
|       monitor       |  3.23 |  4.44 |
|    bulletin board   | 62.91 | 83.08 |
|        shower       | 20.12 | 28.09 |
|       radiator      | 75.07 | 91.86 |
|        glass        |  29.2 | 32.58 |
|        clock        | 62.66 | 78.29 |
|         flag        | 68.11 | 85.04 |
+---------------------+-------+-------+
2022-12-01 08:55:14,582 - mmseg - INFO - Summary:
2022-12-01 08:55:14,583 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 86.96 | 60.99 | 75.98 |
+-------+-------+-------+
2022-12-01 08:55:14,588 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 08:55:14,589 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8696, mIoU: 0.6099, mAcc: 0.7598, IoU.wall: 0.8311, IoU.building: 0.8520, IoU.sky: 0.9520, IoU.floor: 0.8578, IoU.tree: 0.7871, IoU.ceiling: 0.8709, IoU.road: 0.8823, IoU.bed : 0.9372, IoU.windowpane: 0.6867, IoU.grass: 0.6821, IoU.cabinet: 0.6347, IoU.sidewalk: 0.7201, IoU.person: 0.8842, IoU.earth: 0.4301, IoU.door: 0.6348, IoU.table: 0.7250, IoU.mountain: 0.6095, IoU.plant: 0.5673, IoU.curtain: 0.8191, IoU.chair: 0.6920, IoU.car: 0.8963, IoU.water: 0.7053, IoU.painting: 0.8037, IoU.sofa: 0.8550, IoU.shelf: 0.4683, IoU.house: 0.5173, IoU.sea: 0.8029, IoU.mirror: 0.8126, IoU.rug: 0.7191, IoU.field: 0.3758, IoU.armchair: 0.6338, IoU.seat: 0.6622, IoU.fence: 0.5703, IoU.desk: 0.5972, IoU.rock: 0.6072, IoU.wardrobe: 0.5903, IoU.lamp: 0.8090, IoU.bathtub: 0.9196, IoU.railing: 0.4732, IoU.cushion: 0.7634, IoU.base: 0.4725, IoU.box: 0.4323, IoU.column: 0.5972, IoU.signboard: 0.4446, IoU.chest of drawers: 0.4416, IoU.counter: 0.5443, IoU.sand: 0.6318, IoU.sink: 0.8251, IoU.skyscraper: 0.4310, IoU.fireplace: 0.8048, IoU.refrigerator: 0.8368, IoU.grandstand: 0.5084, IoU.path: 0.3168, IoU.stairs: 0.3645, IoU.runway: 0.7440, IoU.case: 0.6855, IoU.pool table: 0.9584, IoU.pillow: 0.7324, IoU.screen door: 0.8442, IoU.stairway: 0.5745, IoU.river: 0.2572, IoU.bridge: 0.7146, IoU.bookcase: 0.3917, IoU.blind: 0.4248, IoU.coffee table: 0.7397, IoU.toilet: 0.9332, IoU.flower: 0.4569, IoU.book: 0.6085, IoU.hill: 0.1284, IoU.bench: 0.7414, IoU.countertop: 0.7311, IoU.stove: 0.8720, IoU.palm: 0.5651, IoU.kitchen island: 0.4590, IoU.computer: 0.8100, IoU.swivel chair: 0.5665, IoU.boat: 0.6149, IoU.bar: 0.7065, IoU.arcade machine: 0.9141, IoU.hovel: 0.3199, IoU.bus: 0.9413, IoU.towel: 0.8597, IoU.light: 0.6632, IoU.truck: 0.5216, IoU.tower: 0.3293, IoU.chandelier: 0.7706, IoU.awning: 0.3604, IoU.streetlight: 0.4563, IoU.booth: 0.6083, IoU.television receiver: 0.7754, IoU.airplane: 0.8916, IoU.dirt track: 0.0734, IoU.apparel: 0.5328, IoU.pole: 0.3421, IoU.land: 0.0691, IoU.bannister: 0.2459, IoU.escalator: 0.6409, IoU.ottoman: 0.5941, IoU.bottle: 0.5300, IoU.buffet: 0.4228, IoU.poster: 0.3832, IoU.stage: 0.3485, IoU.van: 0.5334, IoU.ship: 0.5103, IoU.fountain: 0.4942, IoU.conveyer belt: 0.7723, IoU.canopy: 0.6834, IoU.washer: 0.9102, IoU.plaything: 0.3848, IoU.swimming pool: 0.4685, IoU.stool: 0.5629, IoU.barrel: 0.6675, IoU.basket: 0.4565, IoU.waterfall: 0.4585, IoU.tent: 0.9531, IoU.bag: 0.3489, IoU.minibike: 0.8083, IoU.cradle: 0.9133, IoU.oven: 0.6645, IoU.ball: 0.3898, IoU.food: 0.6805, IoU.step: 0.2445, IoU.tank: 0.6279, IoU.trade name: 0.3004, IoU.microwave: 0.8977, IoU.pot: 0.6168, IoU.animal: 0.8007, IoU.bicycle: 0.6265, IoU.lake: 0.4924, IoU.dishwasher: 0.7065, IoU.screen: 0.6101, IoU.blanket: 0.4449, IoU.sculpture: 0.7125, IoU.hood: 0.8648, IoU.sconce: 0.6701, IoU.vase: 0.5866, IoU.traffic light: 0.5352, IoU.tray: 0.3239, IoU.ashcan: 0.5392, IoU.fan: 0.7353, IoU.pier: 0.3900, IoU.crt screen: 0.0381, IoU.plate: 0.6953, IoU.monitor: 0.0323, IoU.bulletin board: 0.6291, IoU.shower: 0.2012, IoU.radiator: 0.7507, IoU.glass: 0.2920, IoU.clock: 0.6266, IoU.flag: 0.6811, Acc.wall: 0.8944, Acc.building: 0.9176, Acc.sky: 0.9727, Acc.floor: 0.9049, Acc.tree: 0.8946, Acc.ceiling: 0.9341, Acc.road: 0.9170, Acc.bed : 0.9701, Acc.windowpane: 0.8287, Acc.grass: 0.8065, Acc.cabinet: 0.7353, Acc.sidewalk: 0.8525, Acc.person: 0.9433, Acc.earth: 0.5827, Acc.door: 0.8017, Acc.table: 0.8178, Acc.mountain: 0.6926, Acc.plant: 0.7228, Acc.curtain: 0.9023, Acc.chair: 0.7946, Acc.car: 0.9535, Acc.water: 0.8493, Acc.painting: 0.9168, Acc.sofa: 0.9113, Acc.shelf: 0.5671, Acc.house: 0.6995, Acc.sea: 0.8982, Acc.mirror: 0.9130, Acc.rug: 0.8488, Acc.field: 0.7090, Acc.armchair: 0.8011, Acc.seat: 0.9006, Acc.fence: 0.7502, Acc.desk: 0.8397, Acc.rock: 0.7596, Acc.wardrobe: 0.8606, Acc.lamp: 0.9076, Acc.bathtub: 0.9357, Acc.railing: 0.6985, Acc.cushion: 0.9110, Acc.base: 0.7654, Acc.box: 0.6094, Acc.column: 0.7517, Acc.signboard: 0.6924, Acc.chest of drawers: 0.7097, Acc.counter: 0.6522, Acc.sand: 0.8832, Acc.sink: 0.8702, Acc.skyscraper: 0.5380, Acc.fireplace: 0.9645, Acc.refrigerator: 0.9455, Acc.grandstand: 0.8245, Acc.path: 0.4375, Acc.stairs: 0.4900, Acc.runway: 0.9372, Acc.case: 0.8798, Acc.pool table: 0.9851, Acc.pillow: 0.8315, Acc.screen door: 0.9244, Acc.stairway: 0.7500, Acc.river: 0.3021, Acc.bridge: 0.8678, Acc.bookcase: 0.6536, Acc.blind: 0.5315, Acc.coffee table: 0.9050, Acc.toilet: 0.9672, Acc.flower: 0.7098, Acc.book: 0.8281, Acc.hill: 0.2800, Acc.bench: 0.8464, Acc.countertop: 0.8785, Acc.stove: 0.9150, Acc.palm: 0.8309, Acc.kitchen island: 0.9626, Acc.computer: 0.8837, Acc.swivel chair: 0.8521, Acc.boat: 0.8946, Acc.bar: 0.7714, Acc.arcade machine: 0.9860, Acc.hovel: 0.4306, Acc.bus: 0.9630, Acc.towel: 0.9433, Acc.light: 0.8145, Acc.truck: 0.7421, Acc.tower: 0.6331, Acc.chandelier: 0.8705, Acc.awning: 0.6165, Acc.streetlight: 0.7108, Acc.booth: 0.7673, Acc.television receiver: 0.9229, Acc.airplane: 0.9665, Acc.dirt track: 0.1413, Acc.apparel: 0.8641, Acc.pole: 0.4958, Acc.land: 0.0964, Acc.bannister: 0.3240, Acc.escalator: 0.8612, Acc.ottoman: 0.7888, Acc.bottle: 0.8330, Acc.buffet: 0.5829, Acc.poster: 0.5885, Acc.stage: 0.7919, Acc.van: 0.7446, Acc.ship: 0.5388, Acc.fountain: 0.5702, Acc.conveyer belt: 0.9703, Acc.canopy: 0.9215, Acc.washer: 0.9353, Acc.plaything: 0.5833, Acc.swimming pool: 0.7549, Acc.stool: 0.8592, Acc.barrel: 0.9767, Acc.basket: 0.6851, Acc.waterfall: 0.5746, Acc.tent: 0.9815, Acc.bag: 0.4950, Acc.minibike: 0.9436, Acc.cradle: 0.9731, Acc.oven: 0.8400, Acc.ball: 0.4220, Acc.food: 0.8014, Acc.step: 0.3728, Acc.tank: 0.6735, Acc.trade name: 0.3919, Acc.microwave: 0.9444, Acc.pot: 0.7508, Acc.animal: 0.8230, Acc.bicycle: 0.8418, Acc.lake: 0.6868, Acc.dishwasher: 0.9072, Acc.screen: 0.9421, Acc.blanket: 0.6146, Acc.sculpture: 0.9098, Acc.hood: 0.9175, Acc.sconce: 0.8319, Acc.vase: 0.8264, Acc.traffic light: 0.7516, Acc.tray: 0.5490, Acc.ashcan: 0.7986, Acc.fan: 0.8706, Acc.pier: 0.4150, Acc.crt screen: 0.1068, Acc.plate: 0.8675, Acc.monitor: 0.0444, Acc.bulletin board: 0.8308, Acc.shower: 0.2809, Acc.radiator: 0.9186, Acc.glass: 0.3258, Acc.clock: 0.7829, Acc.flag: 0.8504
2022-12-01 08:58:40,652 - mmseg - INFO - Iter [30050/40000]	lr: 3.309e-08, eta: 12:04:26, time: 7.683, data_time: 3.583, memory: 51902, decode.loss_cls: 0.3525, decode.loss_mask: 0.5395, decode.loss_dice: 0.8103, decode.d0.loss_cls: 5.2268, decode.d0.loss_mask: 0.5364, decode.d0.loss_dice: 0.8831, decode.d1.loss_cls: 0.4718, decode.d1.loss_mask: 0.5665, decode.d1.loss_dice: 0.8739, decode.d2.loss_cls: 0.4163, decode.d2.loss_mask: 0.5501, decode.d2.loss_dice: 0.8398, decode.d3.loss_cls: 0.3816, decode.d3.loss_mask: 0.5442, decode.d3.loss_dice: 0.8252, decode.d4.loss_cls: 0.3720, decode.d4.loss_mask: 0.5436, decode.d4.loss_dice: 0.8196, decode.d5.loss_cls: 0.3668, decode.d5.loss_mask: 0.5396, decode.d5.loss_dice: 0.8142, decode.d6.loss_cls: 0.3608, decode.d6.loss_mask: 0.5371, decode.d6.loss_dice: 0.8098, decode.d7.loss_cls: 0.3533, decode.d7.loss_mask: 0.5404, decode.d7.loss_dice: 0.8132, decode.d8.loss_cls: 0.3534, decode.d8.loss_mask: 0.5381, decode.d8.loss_dice: 0.8116, loss: 22.3915
2022-12-01 09:02:06,668 - mmseg - INFO - Iter [30100/40000]	lr: 3.293e-08, eta: 12:00:43, time: 4.120, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3446, decode.loss_mask: 0.5326, decode.loss_dice: 0.7821, decode.d0.loss_cls: 5.2078, decode.d0.loss_mask: 0.5216, decode.d0.loss_dice: 0.8441, decode.d1.loss_cls: 0.4621, decode.d1.loss_mask: 0.5560, decode.d1.loss_dice: 0.8375, decode.d2.loss_cls: 0.4013, decode.d2.loss_mask: 0.5439, decode.d2.loss_dice: 0.8076, decode.d3.loss_cls: 0.3685, decode.d3.loss_mask: 0.5403, decode.d3.loss_dice: 0.7924, decode.d4.loss_cls: 0.3640, decode.d4.loss_mask: 0.5361, decode.d4.loss_dice: 0.7879, decode.d5.loss_cls: 0.3511, decode.d5.loss_mask: 0.5356, decode.d5.loss_dice: 0.7835, decode.d6.loss_cls: 0.3456, decode.d6.loss_mask: 0.5350, decode.d6.loss_dice: 0.7847, decode.d7.loss_cls: 0.3448, decode.d7.loss_mask: 0.5333, decode.d7.loss_dice: 0.7841, decode.d8.loss_cls: 0.3433, decode.d8.loss_mask: 0.5327, decode.d8.loss_dice: 0.7848, loss: 21.8890
2022-12-01 09:05:32,425 - mmseg - INFO - Iter [30150/40000]	lr: 3.276e-08, eta: 11:57:01, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3324, decode.loss_mask: 0.5494, decode.loss_dice: 0.8044, decode.d0.loss_cls: 5.1862, decode.d0.loss_mask: 0.5384, decode.d0.loss_dice: 0.8642, decode.d1.loss_cls: 0.4556, decode.d1.loss_mask: 0.5743, decode.d1.loss_dice: 0.8677, decode.d2.loss_cls: 0.3977, decode.d2.loss_mask: 0.5635, decode.d2.loss_dice: 0.8310, decode.d3.loss_cls: 0.3638, decode.d3.loss_mask: 0.5570, decode.d3.loss_dice: 0.8140, decode.d4.loss_cls: 0.3510, decode.d4.loss_mask: 0.5537, decode.d4.loss_dice: 0.8088, decode.d5.loss_cls: 0.3439, decode.d5.loss_mask: 0.5500, decode.d5.loss_dice: 0.8094, decode.d6.loss_cls: 0.3452, decode.d6.loss_mask: 0.5471, decode.d6.loss_dice: 0.8074, decode.d7.loss_cls: 0.3376, decode.d7.loss_mask: 0.5495, decode.d7.loss_dice: 0.8054, decode.d8.loss_cls: 0.3369, decode.d8.loss_mask: 0.5494, decode.d8.loss_dice: 0.8074, loss: 22.2023
2022-12-01 09:08:57,989 - mmseg - INFO - Iter [30200/40000]	lr: 3.260e-08, eta: 11:53:18, time: 4.111, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3358, decode.loss_mask: 0.5306, decode.loss_dice: 0.7751, decode.d0.loss_cls: 5.1956, decode.d0.loss_mask: 0.5252, decode.d0.loss_dice: 0.8421, decode.d1.loss_cls: 0.4500, decode.d1.loss_mask: 0.5593, decode.d1.loss_dice: 0.8344, decode.d2.loss_cls: 0.3973, decode.d2.loss_mask: 0.5450, decode.d2.loss_dice: 0.8003, decode.d3.loss_cls: 0.3645, decode.d3.loss_mask: 0.5401, decode.d3.loss_dice: 0.7891, decode.d4.loss_cls: 0.3589, decode.d4.loss_mask: 0.5368, decode.d4.loss_dice: 0.7816, decode.d5.loss_cls: 0.3465, decode.d5.loss_mask: 0.5349, decode.d5.loss_dice: 0.7830, decode.d6.loss_cls: 0.3418, decode.d6.loss_mask: 0.5324, decode.d6.loss_dice: 0.7800, decode.d7.loss_cls: 0.3389, decode.d7.loss_mask: 0.5314, decode.d7.loss_dice: 0.7788, decode.d8.loss_cls: 0.3401, decode.d8.loss_mask: 0.5294, decode.d8.loss_dice: 0.7740, loss: 21.7729
2022-12-01 09:12:23,905 - mmseg - INFO - Iter [30250/40000]	lr: 3.243e-08, eta: 11:49:36, time: 4.118, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3478, decode.loss_mask: 0.5354, decode.loss_dice: 0.7899, decode.d0.loss_cls: 5.2090, decode.d0.loss_mask: 0.5299, decode.d0.loss_dice: 0.8557, decode.d1.loss_cls: 0.4595, decode.d1.loss_mask: 0.5651, decode.d1.loss_dice: 0.8483, decode.d2.loss_cls: 0.4053, decode.d2.loss_mask: 0.5521, decode.d2.loss_dice: 0.8164, decode.d3.loss_cls: 0.3737, decode.d3.loss_mask: 0.5461, decode.d3.loss_dice: 0.8013, decode.d4.loss_cls: 0.3679, decode.d4.loss_mask: 0.5426, decode.d4.loss_dice: 0.7998, decode.d5.loss_cls: 0.3560, decode.d5.loss_mask: 0.5389, decode.d5.loss_dice: 0.7969, decode.d6.loss_cls: 0.3549, decode.d6.loss_mask: 0.5376, decode.d6.loss_dice: 0.7907, decode.d7.loss_cls: 0.3499, decode.d7.loss_mask: 0.5381, decode.d7.loss_dice: 0.7926, decode.d8.loss_cls: 0.3496, decode.d8.loss_mask: 0.5373, decode.d8.loss_dice: 0.7915, loss: 22.0794
2022-12-01 09:15:49,513 - mmseg - INFO - Iter [30300/40000]	lr: 3.226e-08, eta: 11:45:53, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3508, decode.loss_mask: 0.5285, decode.loss_dice: 0.7809, decode.d0.loss_cls: 5.2091, decode.d0.loss_mask: 0.5229, decode.d0.loss_dice: 0.8506, decode.d1.loss_cls: 0.4673, decode.d1.loss_mask: 0.5554, decode.d1.loss_dice: 0.8365, decode.d2.loss_cls: 0.4089, decode.d2.loss_mask: 0.5429, decode.d2.loss_dice: 0.8020, decode.d3.loss_cls: 0.3793, decode.d3.loss_mask: 0.5321, decode.d3.loss_dice: 0.7852, decode.d4.loss_cls: 0.3702, decode.d4.loss_mask: 0.5313, decode.d4.loss_dice: 0.7821, decode.d5.loss_cls: 0.3588, decode.d5.loss_mask: 0.5297, decode.d5.loss_dice: 0.7811, decode.d6.loss_cls: 0.3523, decode.d6.loss_mask: 0.5283, decode.d6.loss_dice: 0.7796, decode.d7.loss_cls: 0.3527, decode.d7.loss_mask: 0.5274, decode.d7.loss_dice: 0.7805, decode.d8.loss_cls: 0.3492, decode.d8.loss_mask: 0.5278, decode.d8.loss_dice: 0.7805, loss: 21.8838
2022-12-01 09:19:17,251 - mmseg - INFO - Iter [30350/40000]	lr: 3.210e-08, eta: 11:42:12, time: 4.155, data_time: 0.066, memory: 51902, decode.loss_cls: 0.3371, decode.loss_mask: 0.5280, decode.loss_dice: 0.7829, decode.d0.loss_cls: 5.1915, decode.d0.loss_mask: 0.5201, decode.d0.loss_dice: 0.8481, decode.d1.loss_cls: 0.4530, decode.d1.loss_mask: 0.5546, decode.d1.loss_dice: 0.8418, decode.d2.loss_cls: 0.3948, decode.d2.loss_mask: 0.5430, decode.d2.loss_dice: 0.8045, decode.d3.loss_cls: 0.3583, decode.d3.loss_mask: 0.5366, decode.d3.loss_dice: 0.7945, decode.d4.loss_cls: 0.3495, decode.d4.loss_mask: 0.5343, decode.d4.loss_dice: 0.7923, decode.d5.loss_cls: 0.3408, decode.d5.loss_mask: 0.5285, decode.d5.loss_dice: 0.7885, decode.d6.loss_cls: 0.3391, decode.d6.loss_mask: 0.5283, decode.d6.loss_dice: 0.7831, decode.d7.loss_cls: 0.3355, decode.d7.loss_mask: 0.5274, decode.d7.loss_dice: 0.7829, decode.d8.loss_cls: 0.3344, decode.d8.loss_mask: 0.5265, decode.d8.loss_dice: 0.7841, loss: 21.7638
2022-12-01 09:22:42,951 - mmseg - INFO - Iter [30400/40000]	lr: 3.193e-08, eta: 11:38:30, time: 4.114, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3324, decode.loss_mask: 0.5175, decode.loss_dice: 0.7719, decode.d0.loss_cls: 5.1768, decode.d0.loss_mask: 0.5139, decode.d0.loss_dice: 0.8416, decode.d1.loss_cls: 0.4511, decode.d1.loss_mask: 0.5479, decode.d1.loss_dice: 0.8323, decode.d2.loss_cls: 0.3892, decode.d2.loss_mask: 0.5330, decode.d2.loss_dice: 0.7991, decode.d3.loss_cls: 0.3608, decode.d3.loss_mask: 0.5246, decode.d3.loss_dice: 0.7828, decode.d4.loss_cls: 0.3508, decode.d4.loss_mask: 0.5231, decode.d4.loss_dice: 0.7824, decode.d5.loss_cls: 0.3392, decode.d5.loss_mask: 0.5194, decode.d5.loss_dice: 0.7754, decode.d6.loss_cls: 0.3346, decode.d6.loss_mask: 0.5174, decode.d6.loss_dice: 0.7727, decode.d7.loss_cls: 0.3334, decode.d7.loss_mask: 0.5178, decode.d7.loss_dice: 0.7717, decode.d8.loss_cls: 0.3322, decode.d8.loss_mask: 0.5170, decode.d8.loss_dice: 0.7728, loss: 21.5350
2022-12-01 09:26:08,761 - mmseg - INFO - Iter [30450/40000]	lr: 3.176e-08, eta: 11:34:47, time: 4.116, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3377, decode.loss_mask: 0.5455, decode.loss_dice: 0.7878, decode.d0.loss_cls: 5.1788, decode.d0.loss_mask: 0.5337, decode.d0.loss_dice: 0.8520, decode.d1.loss_cls: 0.4575, decode.d1.loss_mask: 0.5717, decode.d1.loss_dice: 0.8473, decode.d2.loss_cls: 0.4036, decode.d2.loss_mask: 0.5598, decode.d2.loss_dice: 0.8142, decode.d3.loss_cls: 0.3692, decode.d3.loss_mask: 0.5533, decode.d3.loss_dice: 0.7966, decode.d4.loss_cls: 0.3581, decode.d4.loss_mask: 0.5526, decode.d4.loss_dice: 0.7987, decode.d5.loss_cls: 0.3491, decode.d5.loss_mask: 0.5480, decode.d5.loss_dice: 0.7947, decode.d6.loss_cls: 0.3438, decode.d6.loss_mask: 0.5465, decode.d6.loss_dice: 0.7907, decode.d7.loss_cls: 0.3419, decode.d7.loss_mask: 0.5444, decode.d7.loss_dice: 0.7895, decode.d8.loss_cls: 0.3388, decode.d8.loss_mask: 0.5444, decode.d8.loss_dice: 0.7875, loss: 22.0373
2022-12-01 09:29:34,005 - mmseg - INFO - Iter [30500/40000]	lr: 3.160e-08, eta: 11:31:05, time: 4.105, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3560, decode.loss_mask: 0.5442, decode.loss_dice: 0.8014, decode.d0.loss_cls: 5.1773, decode.d0.loss_mask: 0.5324, decode.d0.loss_dice: 0.8576, decode.d1.loss_cls: 0.4629, decode.d1.loss_mask: 0.5716, decode.d1.loss_dice: 0.8591, decode.d2.loss_cls: 0.4114, decode.d2.loss_mask: 0.5569, decode.d2.loss_dice: 0.8231, decode.d3.loss_cls: 0.3816, decode.d3.loss_mask: 0.5537, decode.d3.loss_dice: 0.8082, decode.d4.loss_cls: 0.3724, decode.d4.loss_mask: 0.5514, decode.d4.loss_dice: 0.8085, decode.d5.loss_cls: 0.3641, decode.d5.loss_mask: 0.5485, decode.d5.loss_dice: 0.8057, decode.d6.loss_cls: 0.3583, decode.d6.loss_mask: 0.5465, decode.d6.loss_dice: 0.7982, decode.d7.loss_cls: 0.3561, decode.d7.loss_mask: 0.5455, decode.d7.loss_dice: 0.8003, decode.d8.loss_cls: 0.3540, decode.d8.loss_mask: 0.5438, decode.d8.loss_dice: 0.7988, loss: 22.2496
2022-12-01 09:32:59,884 - mmseg - INFO - Iter [30550/40000]	lr: 3.143e-08, eta: 11:27:23, time: 4.118, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3373, decode.loss_mask: 0.5268, decode.loss_dice: 0.7969, decode.d0.loss_cls: 5.1945, decode.d0.loss_mask: 0.5187, decode.d0.loss_dice: 0.8607, decode.d1.loss_cls: 0.4582, decode.d1.loss_mask: 0.5496, decode.d1.loss_dice: 0.8528, decode.d2.loss_cls: 0.4014, decode.d2.loss_mask: 0.5409, decode.d2.loss_dice: 0.8196, decode.d3.loss_cls: 0.3694, decode.d3.loss_mask: 0.5345, decode.d3.loss_dice: 0.8041, decode.d4.loss_cls: 0.3576, decode.d4.loss_mask: 0.5324, decode.d4.loss_dice: 0.8045, decode.d5.loss_cls: 0.3495, decode.d5.loss_mask: 0.5289, decode.d5.loss_dice: 0.7989, decode.d6.loss_cls: 0.3476, decode.d6.loss_mask: 0.5292, decode.d6.loss_dice: 0.7937, decode.d7.loss_cls: 0.3413, decode.d7.loss_mask: 0.5287, decode.d7.loss_dice: 0.7935, decode.d8.loss_cls: 0.3378, decode.d8.loss_mask: 0.5278, decode.d8.loss_dice: 0.7928, loss: 21.9294
2022-12-01 09:36:25,863 - mmseg - INFO - Iter [30600/40000]	lr: 3.126e-08, eta: 11:23:41, time: 4.120, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3312, decode.loss_mask: 0.5314, decode.loss_dice: 0.7815, decode.d0.loss_cls: 5.1686, decode.d0.loss_mask: 0.5226, decode.d0.loss_dice: 0.8377, decode.d1.loss_cls: 0.4475, decode.d1.loss_mask: 0.5582, decode.d1.loss_dice: 0.8404, decode.d2.loss_cls: 0.3916, decode.d2.loss_mask: 0.5471, decode.d2.loss_dice: 0.8035, decode.d3.loss_cls: 0.3585, decode.d3.loss_mask: 0.5419, decode.d3.loss_dice: 0.7916, decode.d4.loss_cls: 0.3480, decode.d4.loss_mask: 0.5394, decode.d4.loss_dice: 0.7897, decode.d5.loss_cls: 0.3366, decode.d5.loss_mask: 0.5366, decode.d5.loss_dice: 0.7884, decode.d6.loss_cls: 0.3323, decode.d6.loss_mask: 0.5333, decode.d6.loss_dice: 0.7821, decode.d7.loss_cls: 0.3328, decode.d7.loss_mask: 0.5322, decode.d7.loss_dice: 0.7853, decode.d8.loss_cls: 0.3321, decode.d8.loss_mask: 0.5322, decode.d8.loss_dice: 0.7850, loss: 21.7392
2022-12-01 09:39:51,285 - mmseg - INFO - Iter [30650/40000]	lr: 3.110e-08, eta: 11:19:59, time: 4.108, data_time: 0.022, memory: 51902, decode.loss_cls: 0.3495, decode.loss_mask: 0.5251, decode.loss_dice: 0.7911, decode.d0.loss_cls: 5.2011, decode.d0.loss_mask: 0.5156, decode.d0.loss_dice: 0.8530, decode.d1.loss_cls: 0.4715, decode.d1.loss_mask: 0.5458, decode.d1.loss_dice: 0.8465, decode.d2.loss_cls: 0.4107, decode.d2.loss_mask: 0.5393, decode.d2.loss_dice: 0.8179, decode.d3.loss_cls: 0.3786, decode.d3.loss_mask: 0.5308, decode.d3.loss_dice: 0.8026, decode.d4.loss_cls: 0.3693, decode.d4.loss_mask: 0.5288, decode.d4.loss_dice: 0.7986, decode.d5.loss_cls: 0.3528, decode.d5.loss_mask: 0.5279, decode.d5.loss_dice: 0.7984, decode.d6.loss_cls: 0.3491, decode.d6.loss_mask: 0.5286, decode.d6.loss_dice: 0.7951, decode.d7.loss_cls: 0.3478, decode.d7.loss_mask: 0.5262, decode.d7.loss_dice: 0.7942, decode.d8.loss_cls: 0.3455, decode.d8.loss_mask: 0.5255, decode.d8.loss_dice: 0.7946, loss: 21.9614
2022-12-01 09:43:17,056 - mmseg - INFO - Iter [30700/40000]	lr: 3.093e-08, eta: 11:16:17, time: 4.115, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3519, decode.loss_mask: 0.5312, decode.loss_dice: 0.7935, decode.d0.loss_cls: 5.1761, decode.d0.loss_mask: 0.5270, decode.d0.loss_dice: 0.8565, decode.d1.loss_cls: 0.4591, decode.d1.loss_mask: 0.5557, decode.d1.loss_dice: 0.8473, decode.d2.loss_cls: 0.4030, decode.d2.loss_mask: 0.5443, decode.d2.loss_dice: 0.8137, decode.d3.loss_cls: 0.3728, decode.d3.loss_mask: 0.5381, decode.d3.loss_dice: 0.8010, decode.d4.loss_cls: 0.3630, decode.d4.loss_mask: 0.5388, decode.d4.loss_dice: 0.7996, decode.d5.loss_cls: 0.3574, decode.d5.loss_mask: 0.5350, decode.d5.loss_dice: 0.7977, decode.d6.loss_cls: 0.3544, decode.d6.loss_mask: 0.5327, decode.d6.loss_dice: 0.7940, decode.d7.loss_cls: 0.3532, decode.d7.loss_mask: 0.5324, decode.d7.loss_dice: 0.7907, decode.d8.loss_cls: 0.3490, decode.d8.loss_mask: 0.5320, decode.d8.loss_dice: 0.7920, loss: 21.9931
2022-12-01 09:46:42,917 - mmseg - INFO - Iter [30750/40000]	lr: 3.077e-08, eta: 11:12:35, time: 4.117, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3401, decode.loss_mask: 0.5468, decode.loss_dice: 0.7991, decode.d0.loss_cls: 5.1798, decode.d0.loss_mask: 0.5403, decode.d0.loss_dice: 0.8650, decode.d1.loss_cls: 0.4631, decode.d1.loss_mask: 0.5736, decode.d1.loss_dice: 0.8566, decode.d2.loss_cls: 0.4029, decode.d2.loss_mask: 0.5609, decode.d2.loss_dice: 0.8241, decode.d3.loss_cls: 0.3685, decode.d3.loss_mask: 0.5544, decode.d3.loss_dice: 0.8118, decode.d4.loss_cls: 0.3578, decode.d4.loss_mask: 0.5514, decode.d4.loss_dice: 0.8098, decode.d5.loss_cls: 0.3497, decode.d5.loss_mask: 0.5476, decode.d5.loss_dice: 0.8055, decode.d6.loss_cls: 0.3445, decode.d6.loss_mask: 0.5475, decode.d6.loss_dice: 0.7994, decode.d7.loss_cls: 0.3423, decode.d7.loss_mask: 0.5460, decode.d7.loss_dice: 0.7989, decode.d8.loss_cls: 0.3414, decode.d8.loss_mask: 0.5462, decode.d8.loss_dice: 0.7972, loss: 22.1722
2022-12-01 09:50:08,475 - mmseg - INFO - Iter [30800/40000]	lr: 3.060e-08, eta: 11:08:53, time: 4.111, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3458, decode.loss_mask: 0.5328, decode.loss_dice: 0.7831, decode.d0.loss_cls: 5.1682, decode.d0.loss_mask: 0.5281, decode.d0.loss_dice: 0.8565, decode.d1.loss_cls: 0.4607, decode.d1.loss_mask: 0.5586, decode.d1.loss_dice: 0.8405, decode.d2.loss_cls: 0.4073, decode.d2.loss_mask: 0.5449, decode.d2.loss_dice: 0.8055, decode.d3.loss_cls: 0.3723, decode.d3.loss_mask: 0.5388, decode.d3.loss_dice: 0.7949, decode.d4.loss_cls: 0.3630, decode.d4.loss_mask: 0.5382, decode.d4.loss_dice: 0.7929, decode.d5.loss_cls: 0.3547, decode.d5.loss_mask: 0.5353, decode.d5.loss_dice: 0.7860, decode.d6.loss_cls: 0.3498, decode.d6.loss_mask: 0.5355, decode.d6.loss_dice: 0.7853, decode.d7.loss_cls: 0.3445, decode.d7.loss_mask: 0.5353, decode.d7.loss_dice: 0.7844, decode.d8.loss_cls: 0.3430, decode.d8.loss_mask: 0.5342, decode.d8.loss_dice: 0.7822, loss: 21.9023
2022-12-01 09:53:34,246 - mmseg - INFO - Iter [30850/40000]	lr: 3.043e-08, eta: 11:05:11, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3307, decode.loss_mask: 0.5466, decode.loss_dice: 0.8039, decode.d0.loss_cls: 5.1523, decode.d0.loss_mask: 0.5393, decode.d0.loss_dice: 0.8616, decode.d1.loss_cls: 0.4425, decode.d1.loss_mask: 0.5738, decode.d1.loss_dice: 0.8610, decode.d2.loss_cls: 0.3833, decode.d2.loss_mask: 0.5639, decode.d2.loss_dice: 0.8301, decode.d3.loss_cls: 0.3508, decode.d3.loss_mask: 0.5571, decode.d3.loss_dice: 0.8149, decode.d4.loss_cls: 0.3453, decode.d4.loss_mask: 0.5549, decode.d4.loss_dice: 0.8170, decode.d5.loss_cls: 0.3396, decode.d5.loss_mask: 0.5523, decode.d5.loss_dice: 0.8095, decode.d6.loss_cls: 0.3370, decode.d6.loss_mask: 0.5489, decode.d6.loss_dice: 0.8051, decode.d7.loss_cls: 0.3317, decode.d7.loss_mask: 0.5487, decode.d7.loss_dice: 0.8063, decode.d8.loss_cls: 0.3290, decode.d8.loss_mask: 0.5479, decode.d8.loss_dice: 0.8079, loss: 22.0929
2022-12-01 09:57:00,032 - mmseg - INFO - Iter [30900/40000]	lr: 3.027e-08, eta: 11:01:30, time: 4.117, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3475, decode.loss_mask: 0.5229, decode.loss_dice: 0.7866, decode.d0.loss_cls: 5.1589, decode.d0.loss_mask: 0.5190, decode.d0.loss_dice: 0.8532, decode.d1.loss_cls: 0.4593, decode.d1.loss_mask: 0.5474, decode.d1.loss_dice: 0.8460, decode.d2.loss_cls: 0.3988, decode.d2.loss_mask: 0.5354, decode.d2.loss_dice: 0.8126, decode.d3.loss_cls: 0.3690, decode.d3.loss_mask: 0.5290, decode.d3.loss_dice: 0.8001, decode.d4.loss_cls: 0.3597, decode.d4.loss_mask: 0.5279, decode.d4.loss_dice: 0.7948, decode.d5.loss_cls: 0.3554, decode.d5.loss_mask: 0.5260, decode.d5.loss_dice: 0.7955, decode.d6.loss_cls: 0.3506, decode.d6.loss_mask: 0.5225, decode.d6.loss_dice: 0.7892, decode.d7.loss_cls: 0.3441, decode.d7.loss_mask: 0.5228, decode.d7.loss_dice: 0.7908, decode.d8.loss_cls: 0.3418, decode.d8.loss_mask: 0.5227, decode.d8.loss_dice: 0.7902, loss: 21.8196
2022-12-01 10:00:25,970 - mmseg - INFO - Iter [30950/40000]	lr: 3.010e-08, eta: 10:57:48, time: 4.119, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3468, decode.loss_mask: 0.5276, decode.loss_dice: 0.7824, decode.d0.loss_cls: 5.1518, decode.d0.loss_mask: 0.5164, decode.d0.loss_dice: 0.8517, decode.d1.loss_cls: 0.4598, decode.d1.loss_mask: 0.5542, decode.d1.loss_dice: 0.8487, decode.d2.loss_cls: 0.4025, decode.d2.loss_mask: 0.5433, decode.d2.loss_dice: 0.8128, decode.d3.loss_cls: 0.3721, decode.d3.loss_mask: 0.5379, decode.d3.loss_dice: 0.8006, decode.d4.loss_cls: 0.3633, decode.d4.loss_mask: 0.5344, decode.d4.loss_dice: 0.7957, decode.d5.loss_cls: 0.3543, decode.d5.loss_mask: 0.5315, decode.d5.loss_dice: 0.7932, decode.d6.loss_cls: 0.3523, decode.d6.loss_mask: 0.5279, decode.d6.loss_dice: 0.7875, decode.d7.loss_cls: 0.3485, decode.d7.loss_mask: 0.5274, decode.d7.loss_dice: 0.7879, decode.d8.loss_cls: 0.3451, decode.d8.loss_mask: 0.5275, decode.d8.loss_dice: 0.7840, loss: 21.8692
2022-12-01 10:03:53,827 - mmseg - INFO - Saving checkpoint at 31000 iterations
2022-12-01 10:04:42,022 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 10:04:42,022 - mmseg - INFO - Iter [31000/40000]	lr: 2.993e-08, eta: 10:54:21, time: 5.121, data_time: 0.066, memory: 51902, decode.loss_cls: 0.3403, decode.loss_mask: 0.5348, decode.loss_dice: 0.7952, decode.d0.loss_cls: 5.1777, decode.d0.loss_mask: 0.5287, decode.d0.loss_dice: 0.8568, decode.d1.loss_cls: 0.4513, decode.d1.loss_mask: 0.5613, decode.d1.loss_dice: 0.8561, decode.d2.loss_cls: 0.3949, decode.d2.loss_mask: 0.5508, decode.d2.loss_dice: 0.8227, decode.d3.loss_cls: 0.3635, decode.d3.loss_mask: 0.5426, decode.d3.loss_dice: 0.8096, decode.d4.loss_cls: 0.3580, decode.d4.loss_mask: 0.5419, decode.d4.loss_dice: 0.8040, decode.d5.loss_cls: 0.3447, decode.d5.loss_mask: 0.5401, decode.d5.loss_dice: 0.8001, decode.d6.loss_cls: 0.3410, decode.d6.loss_mask: 0.5364, decode.d6.loss_dice: 0.7974, decode.d7.loss_cls: 0.3428, decode.d7.loss_mask: 0.5362, decode.d7.loss_dice: 0.7961, decode.d8.loss_cls: 0.3414, decode.d8.loss_mask: 0.5347, decode.d8.loss_dice: 0.7953, loss: 21.9962
2022-12-01 10:07:40,097 - mmseg - INFO - per class results:
2022-12-01 10:07:40,102 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        |  83.2 | 89.16 |
|       building      | 85.48 | 91.82 |
|         sky         | 95.22 | 97.24 |
|        floor        | 85.68 | 91.21 |
|         tree        |  78.5 | 90.27 |
|       ceiling       | 87.28 | 93.84 |
|         road        | 88.38 | 91.75 |
|         bed         | 93.75 | 97.24 |
|      windowpane     | 68.55 | 83.87 |
|        grass        |  70.5 | 83.29 |
|       cabinet       | 62.33 | 72.68 |
|       sidewalk      | 73.22 | 86.55 |
|        person       | 88.49 | 94.43 |
|        earth        | 44.18 |  59.2 |
|         door        | 64.72 | 82.46 |
|        table        | 72.34 | 81.85 |
|       mountain      | 60.59 |  70.8 |
|        plant        | 57.75 | 68.75 |
|       curtain       | 82.31 | 90.77 |
|        chair        | 69.58 | 80.63 |
|         car         |  89.5 | 95.44 |
|        water        |  64.7 | 80.16 |
|       painting      | 80.16 |  92.2 |
|         sofa        | 85.52 | 90.98 |
|        shelf        | 47.61 | 58.77 |
|        house        | 55.61 | 71.38 |
|         sea         | 76.22 | 85.33 |
|        mirror       | 80.95 | 91.54 |
|         rug         | 71.71 | 84.14 |
|        field        | 39.15 | 71.94 |
|       armchair      |  63.8 | 81.41 |
|         seat        | 65.47 | 89.63 |
|        fence        | 56.28 | 74.15 |
|         desk        | 59.46 | 84.36 |
|         rock        | 59.23 | 76.37 |
|       wardrobe      | 57.81 | 86.24 |
|         lamp        | 80.99 | 90.24 |
|       bathtub       | 92.22 | 93.83 |
|       railing       |  46.0 | 69.43 |
|       cushion       | 77.28 | 89.45 |
|         base        | 45.93 | 74.13 |
|         box         | 43.72 | 60.27 |
|        column       | 57.83 | 78.62 |
|      signboard      | 44.69 | 67.72 |
|   chest of drawers  | 47.57 | 75.15 |
|       counter       | 59.25 | 68.95 |
|         sand        | 58.64 | 87.29 |
|         sink        | 83.32 | 86.94 |
|      skyscraper     | 44.03 | 58.14 |
|      fireplace      | 80.51 | 95.09 |
|     refrigerator    |  83.9 | 94.56 |
|      grandstand     |  49.6 | 81.44 |
|         path        | 32.58 | 41.93 |
|        stairs       | 35.74 | 45.23 |
|        runway       | 74.14 | 93.48 |
|         case        | 69.35 | 86.36 |
|      pool table     | 95.89 | 98.77 |
|        pillow       | 72.41 | 83.68 |
|     screen door     | 83.76 |  91.9 |
|       stairway      | 58.26 | 74.54 |
|        river        | 22.36 | 39.46 |
|        bridge       | 77.57 | 84.66 |
|       bookcase      |  43.2 | 66.43 |
|        blind        | 42.67 | 51.69 |
|     coffee table    | 73.63 | 90.76 |
|        toilet       |  92.2 | 95.29 |
|        flower       | 46.51 | 72.62 |
|         book        | 60.94 | 81.02 |
|         hill        | 11.59 | 19.12 |
|        bench        | 75.77 | 85.12 |
|      countertop     | 73.06 | 90.02 |
|        stove        |  86.3 |  90.2 |
|         palm        | 56.08 | 82.68 |
|    kitchen island   | 47.86 | 95.66 |
|       computer      | 81.78 | 90.69 |
|     swivel chair    | 57.53 | 84.38 |
|         boat        | 63.82 | 89.49 |
|         bar         | 70.05 | 77.08 |
|    arcade machine   | 91.49 | 98.55 |
|        hovel        | 55.33 | 69.22 |
|         bus         | 95.08 | 96.89 |
|        towel        | 85.82 | 94.53 |
|        light        |  66.6 | 80.32 |
|        truck        | 52.34 | 73.06 |
|        tower        | 34.27 | 62.99 |
|      chandelier     |  77.2 | 86.45 |
|        awning       | 32.07 | 52.26 |
|     streetlight     | 45.42 |  68.2 |
|        booth        | 63.19 | 79.17 |
| television receiver | 75.73 | 92.24 |
|       airplane      | 89.01 | 96.64 |
|      dirt track     | 22.04 | 43.98 |
|       apparel       | 54.35 | 86.17 |
|         pole        | 36.93 | 52.91 |
|         land        |  6.31 |  9.45 |
|      bannister      | 23.44 | 32.97 |
|      escalator      | 65.75 | 86.34 |
|       ottoman       | 60.19 | 78.48 |
|        bottle       | 52.37 | 82.75 |
|        buffet       | 42.24 | 54.94 |
|        poster       | 39.47 | 61.36 |
|        stage        | 34.11 | 67.38 |
|         van         | 53.71 | 75.44 |
|         ship        | 17.39 | 18.38 |
|       fountain      |  48.4 | 55.83 |
|    conveyer belt    | 77.49 | 97.15 |
|        canopy       | 45.04 |  60.4 |
|        washer       | 90.81 | 93.48 |
|      plaything      | 37.04 | 58.06 |
|    swimming pool    | 46.88 | 76.64 |
|        stool        | 60.58 | 86.08 |
|        barrel       | 66.58 | 97.47 |
|        basket       | 48.75 | 77.46 |
|      waterfall      | 47.04 | 58.15 |
|         tent        | 95.07 | 98.19 |
|         bag         | 34.07 | 46.61 |
|       minibike      | 81.26 | 94.08 |
|        cradle       | 91.36 | 97.48 |
|         oven        | 64.61 |  83.3 |
|         ball        | 37.65 | 40.14 |
|         food        | 69.39 | 83.74 |
|         step        | 30.68 | 45.27 |
|         tank        | 60.25 | 67.56 |
|      trade name     | 34.43 | 47.23 |
|      microwave      | 89.77 | 94.64 |
|         pot         | 62.71 | 75.66 |
|        animal       |  82.5 | 85.04 |
|       bicycle       | 62.62 | 83.84 |
|         lake        | 51.76 | 53.95 |
|      dishwasher     | 81.87 | 90.39 |
|        screen       | 62.08 | 96.02 |
|       blanket       | 45.73 | 60.36 |
|      sculpture      | 72.57 | 90.51 |
|         hood        | 77.66 | 82.19 |
|        sconce       |  66.2 | 82.95 |
|         vase        |  60.3 | 81.19 |
|    traffic light    | 52.39 | 73.31 |
|         tray        | 35.61 | 54.87 |
|        ashcan       | 56.32 | 80.05 |
|         fan         | 73.68 | 86.79 |
|         pier        | 39.09 | 41.31 |
|      crt screen     |  1.51 |  3.87 |
|        plate        | 70.21 | 83.98 |
|       monitor       |  4.45 |  5.8  |
|    bulletin board   | 61.18 | 83.94 |
|        shower       | 20.87 | 28.41 |
|       radiator      | 74.75 | 92.87 |
|        glass        | 29.21 | 32.24 |
|        clock        | 62.43 |  77.9 |
|         flag        |  68.2 | 86.23 |
+---------------------+-------+-------+
2022-12-01 10:07:40,102 - mmseg - INFO - Summary:
2022-12-01 10:07:40,103 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 87.08 | 61.14 | 75.73 |
+-------+-------+-------+
2022-12-01 10:07:40,106 - mmseg - INFO - The previous best checkpoint /mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune/lr1.0_lrd0.9/best_mIoU_iter_29000.pth was removed
2022-12-01 10:08:28,420 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_31000.pth.
2022-12-01 10:08:28,420 - mmseg - INFO - Best mIoU is 0.6114 at 31000 iter.
2022-12-01 10:08:28,428 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 10:08:28,428 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8708, mIoU: 0.6114, mAcc: 0.7573, IoU.wall: 0.8320, IoU.building: 0.8548, IoU.sky: 0.9522, IoU.floor: 0.8568, IoU.tree: 0.7850, IoU.ceiling: 0.8728, IoU.road: 0.8838, IoU.bed : 0.9375, IoU.windowpane: 0.6855, IoU.grass: 0.7050, IoU.cabinet: 0.6233, IoU.sidewalk: 0.7322, IoU.person: 0.8849, IoU.earth: 0.4418, IoU.door: 0.6472, IoU.table: 0.7234, IoU.mountain: 0.6059, IoU.plant: 0.5775, IoU.curtain: 0.8231, IoU.chair: 0.6958, IoU.car: 0.8950, IoU.water: 0.6470, IoU.painting: 0.8016, IoU.sofa: 0.8552, IoU.shelf: 0.4761, IoU.house: 0.5561, IoU.sea: 0.7622, IoU.mirror: 0.8095, IoU.rug: 0.7171, IoU.field: 0.3915, IoU.armchair: 0.6380, IoU.seat: 0.6547, IoU.fence: 0.5628, IoU.desk: 0.5946, IoU.rock: 0.5923, IoU.wardrobe: 0.5781, IoU.lamp: 0.8099, IoU.bathtub: 0.9222, IoU.railing: 0.4600, IoU.cushion: 0.7728, IoU.base: 0.4593, IoU.box: 0.4372, IoU.column: 0.5783, IoU.signboard: 0.4469, IoU.chest of drawers: 0.4757, IoU.counter: 0.5925, IoU.sand: 0.5864, IoU.sink: 0.8332, IoU.skyscraper: 0.4403, IoU.fireplace: 0.8051, IoU.refrigerator: 0.8390, IoU.grandstand: 0.4960, IoU.path: 0.3258, IoU.stairs: 0.3574, IoU.runway: 0.7414, IoU.case: 0.6935, IoU.pool table: 0.9589, IoU.pillow: 0.7241, IoU.screen door: 0.8376, IoU.stairway: 0.5826, IoU.river: 0.2236, IoU.bridge: 0.7757, IoU.bookcase: 0.4320, IoU.blind: 0.4267, IoU.coffee table: 0.7363, IoU.toilet: 0.9220, IoU.flower: 0.4651, IoU.book: 0.6094, IoU.hill: 0.1159, IoU.bench: 0.7577, IoU.countertop: 0.7306, IoU.stove: 0.8630, IoU.palm: 0.5608, IoU.kitchen island: 0.4786, IoU.computer: 0.8178, IoU.swivel chair: 0.5753, IoU.boat: 0.6382, IoU.bar: 0.7005, IoU.arcade machine: 0.9149, IoU.hovel: 0.5533, IoU.bus: 0.9508, IoU.towel: 0.8582, IoU.light: 0.6660, IoU.truck: 0.5234, IoU.tower: 0.3427, IoU.chandelier: 0.7720, IoU.awning: 0.3207, IoU.streetlight: 0.4542, IoU.booth: 0.6319, IoU.television receiver: 0.7573, IoU.airplane: 0.8901, IoU.dirt track: 0.2204, IoU.apparel: 0.5435, IoU.pole: 0.3693, IoU.land: 0.0631, IoU.bannister: 0.2344, IoU.escalator: 0.6575, IoU.ottoman: 0.6019, IoU.bottle: 0.5237, IoU.buffet: 0.4224, IoU.poster: 0.3947, IoU.stage: 0.3411, IoU.van: 0.5371, IoU.ship: 0.1739, IoU.fountain: 0.4840, IoU.conveyer belt: 0.7749, IoU.canopy: 0.4504, IoU.washer: 0.9081, IoU.plaything: 0.3704, IoU.swimming pool: 0.4688, IoU.stool: 0.6058, IoU.barrel: 0.6658, IoU.basket: 0.4875, IoU.waterfall: 0.4704, IoU.tent: 0.9507, IoU.bag: 0.3407, IoU.minibike: 0.8126, IoU.cradle: 0.9136, IoU.oven: 0.6461, IoU.ball: 0.3765, IoU.food: 0.6939, IoU.step: 0.3068, IoU.tank: 0.6025, IoU.trade name: 0.3443, IoU.microwave: 0.8977, IoU.pot: 0.6271, IoU.animal: 0.8250, IoU.bicycle: 0.6262, IoU.lake: 0.5176, IoU.dishwasher: 0.8187, IoU.screen: 0.6208, IoU.blanket: 0.4573, IoU.sculpture: 0.7257, IoU.hood: 0.7766, IoU.sconce: 0.6620, IoU.vase: 0.6030, IoU.traffic light: 0.5239, IoU.tray: 0.3561, IoU.ashcan: 0.5632, IoU.fan: 0.7368, IoU.pier: 0.3909, IoU.crt screen: 0.0151, IoU.plate: 0.7021, IoU.monitor: 0.0445, IoU.bulletin board: 0.6118, IoU.shower: 0.2087, IoU.radiator: 0.7475, IoU.glass: 0.2921, IoU.clock: 0.6243, IoU.flag: 0.6820, Acc.wall: 0.8916, Acc.building: 0.9182, Acc.sky: 0.9724, Acc.floor: 0.9121, Acc.tree: 0.9027, Acc.ceiling: 0.9384, Acc.road: 0.9175, Acc.bed : 0.9724, Acc.windowpane: 0.8387, Acc.grass: 0.8329, Acc.cabinet: 0.7268, Acc.sidewalk: 0.8655, Acc.person: 0.9443, Acc.earth: 0.5920, Acc.door: 0.8246, Acc.table: 0.8185, Acc.mountain: 0.7080, Acc.plant: 0.6875, Acc.curtain: 0.9077, Acc.chair: 0.8063, Acc.car: 0.9544, Acc.water: 0.8016, Acc.painting: 0.9220, Acc.sofa: 0.9098, Acc.shelf: 0.5877, Acc.house: 0.7138, Acc.sea: 0.8533, Acc.mirror: 0.9154, Acc.rug: 0.8414, Acc.field: 0.7194, Acc.armchair: 0.8141, Acc.seat: 0.8963, Acc.fence: 0.7415, Acc.desk: 0.8436, Acc.rock: 0.7637, Acc.wardrobe: 0.8624, Acc.lamp: 0.9024, Acc.bathtub: 0.9383, Acc.railing: 0.6943, Acc.cushion: 0.8945, Acc.base: 0.7413, Acc.box: 0.6027, Acc.column: 0.7862, Acc.signboard: 0.6772, Acc.chest of drawers: 0.7515, Acc.counter: 0.6895, Acc.sand: 0.8729, Acc.sink: 0.8694, Acc.skyscraper: 0.5814, Acc.fireplace: 0.9509, Acc.refrigerator: 0.9456, Acc.grandstand: 0.8144, Acc.path: 0.4193, Acc.stairs: 0.4523, Acc.runway: 0.9348, Acc.case: 0.8636, Acc.pool table: 0.9877, Acc.pillow: 0.8368, Acc.screen door: 0.9190, Acc.stairway: 0.7454, Acc.river: 0.3946, Acc.bridge: 0.8466, Acc.bookcase: 0.6643, Acc.blind: 0.5169, Acc.coffee table: 0.9076, Acc.toilet: 0.9529, Acc.flower: 0.7262, Acc.book: 0.8102, Acc.hill: 0.1912, Acc.bench: 0.8512, Acc.countertop: 0.9002, Acc.stove: 0.9020, Acc.palm: 0.8268, Acc.kitchen island: 0.9566, Acc.computer: 0.9069, Acc.swivel chair: 0.8438, Acc.boat: 0.8949, Acc.bar: 0.7708, Acc.arcade machine: 0.9855, Acc.hovel: 0.6922, Acc.bus: 0.9689, Acc.towel: 0.9453, Acc.light: 0.8032, Acc.truck: 0.7306, Acc.tower: 0.6299, Acc.chandelier: 0.8645, Acc.awning: 0.5226, Acc.streetlight: 0.6820, Acc.booth: 0.7917, Acc.television receiver: 0.9224, Acc.airplane: 0.9664, Acc.dirt track: 0.4398, Acc.apparel: 0.8617, Acc.pole: 0.5291, Acc.land: 0.0945, Acc.bannister: 0.3297, Acc.escalator: 0.8634, Acc.ottoman: 0.7848, Acc.bottle: 0.8275, Acc.buffet: 0.5494, Acc.poster: 0.6136, Acc.stage: 0.6738, Acc.van: 0.7544, Acc.ship: 0.1838, Acc.fountain: 0.5583, Acc.conveyer belt: 0.9715, Acc.canopy: 0.6040, Acc.washer: 0.9348, Acc.plaything: 0.5806, Acc.swimming pool: 0.7664, Acc.stool: 0.8608, Acc.barrel: 0.9747, Acc.basket: 0.7746, Acc.waterfall: 0.5815, Acc.tent: 0.9819, Acc.bag: 0.4661, Acc.minibike: 0.9408, Acc.cradle: 0.9748, Acc.oven: 0.8330, Acc.ball: 0.4014, Acc.food: 0.8374, Acc.step: 0.4527, Acc.tank: 0.6756, Acc.trade name: 0.4723, Acc.microwave: 0.9464, Acc.pot: 0.7566, Acc.animal: 0.8504, Acc.bicycle: 0.8384, Acc.lake: 0.5395, Acc.dishwasher: 0.9039, Acc.screen: 0.9602, Acc.blanket: 0.6036, Acc.sculpture: 0.9051, Acc.hood: 0.8219, Acc.sconce: 0.8295, Acc.vase: 0.8119, Acc.traffic light: 0.7331, Acc.tray: 0.5487, Acc.ashcan: 0.8005, Acc.fan: 0.8679, Acc.pier: 0.4131, Acc.crt screen: 0.0387, Acc.plate: 0.8398, Acc.monitor: 0.0580, Acc.bulletin board: 0.8394, Acc.shower: 0.2841, Acc.radiator: 0.9287, Acc.glass: 0.3224, Acc.clock: 0.7790, Acc.flag: 0.8623
2022-12-01 10:11:53,983 - mmseg - INFO - Iter [31050/40000]	lr: 2.977e-08, eta: 10:51:45, time: 8.639, data_time: 4.548, memory: 51902, decode.loss_cls: 0.3284, decode.loss_mask: 0.5219, decode.loss_dice: 0.7831, decode.d0.loss_cls: 5.1406, decode.d0.loss_mask: 0.5173, decode.d0.loss_dice: 0.8474, decode.d1.loss_cls: 0.4426, decode.d1.loss_mask: 0.5485, decode.d1.loss_dice: 0.8409, decode.d2.loss_cls: 0.3872, decode.d2.loss_mask: 0.5381, decode.d2.loss_dice: 0.8104, decode.d3.loss_cls: 0.3566, decode.d3.loss_mask: 0.5293, decode.d3.loss_dice: 0.7946, decode.d4.loss_cls: 0.3430, decode.d4.loss_mask: 0.5297, decode.d4.loss_dice: 0.7928, decode.d5.loss_cls: 0.3363, decode.d5.loss_mask: 0.5269, decode.d5.loss_dice: 0.7894, decode.d6.loss_cls: 0.3338, decode.d6.loss_mask: 0.5257, decode.d6.loss_dice: 0.7833, decode.d7.loss_cls: 0.3319, decode.d7.loss_mask: 0.5231, decode.d7.loss_dice: 0.7832, decode.d8.loss_cls: 0.3312, decode.d8.loss_mask: 0.5231, decode.d8.loss_dice: 0.7823, loss: 21.6226
2022-12-01 10:15:19,681 - mmseg - INFO - Iter [31100/40000]	lr: 2.960e-08, eta: 10:48:02, time: 4.114, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3382, decode.loss_mask: 0.5290, decode.loss_dice: 0.7837, decode.d0.loss_cls: 5.1428, decode.d0.loss_mask: 0.5220, decode.d0.loss_dice: 0.8522, decode.d1.loss_cls: 0.4448, decode.d1.loss_mask: 0.5546, decode.d1.loss_dice: 0.8449, decode.d2.loss_cls: 0.3964, decode.d2.loss_mask: 0.5445, decode.d2.loss_dice: 0.8089, decode.d3.loss_cls: 0.3662, decode.d3.loss_mask: 0.5366, decode.d3.loss_dice: 0.7931, decode.d4.loss_cls: 0.3577, decode.d4.loss_mask: 0.5336, decode.d4.loss_dice: 0.7903, decode.d5.loss_cls: 0.3455, decode.d5.loss_mask: 0.5302, decode.d5.loss_dice: 0.7895, decode.d6.loss_cls: 0.3431, decode.d6.loss_mask: 0.5278, decode.d6.loss_dice: 0.7833, decode.d7.loss_cls: 0.3389, decode.d7.loss_mask: 0.5277, decode.d7.loss_dice: 0.7845, decode.d8.loss_cls: 0.3388, decode.d8.loss_mask: 0.5291, decode.d8.loss_dice: 0.7851, loss: 21.7631
2022-12-01 10:18:45,435 - mmseg - INFO - Iter [31150/40000]	lr: 2.944e-08, eta: 10:44:20, time: 4.115, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3566, decode.loss_mask: 0.5410, decode.loss_dice: 0.7995, decode.d0.loss_cls: 5.1554, decode.d0.loss_mask: 0.5329, decode.d0.loss_dice: 0.8680, decode.d1.loss_cls: 0.4727, decode.d1.loss_mask: 0.5643, decode.d1.loss_dice: 0.8587, decode.d2.loss_cls: 0.4157, decode.d2.loss_mask: 0.5538, decode.d2.loss_dice: 0.8276, decode.d3.loss_cls: 0.3847, decode.d3.loss_mask: 0.5488, decode.d3.loss_dice: 0.8117, decode.d4.loss_cls: 0.3759, decode.d4.loss_mask: 0.5471, decode.d4.loss_dice: 0.8126, decode.d5.loss_cls: 0.3648, decode.d5.loss_mask: 0.5442, decode.d5.loss_dice: 0.8065, decode.d6.loss_cls: 0.3643, decode.d6.loss_mask: 0.5412, decode.d6.loss_dice: 0.7999, decode.d7.loss_cls: 0.3578, decode.d7.loss_mask: 0.5414, decode.d7.loss_dice: 0.8007, decode.d8.loss_cls: 0.3573, decode.d8.loss_mask: 0.5411, decode.d8.loss_dice: 0.7996, loss: 22.2457
2022-12-01 10:22:11,142 - mmseg - INFO - Iter [31200/40000]	lr: 2.927e-08, eta: 10:40:38, time: 4.114, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3448, decode.loss_mask: 0.5383, decode.loss_dice: 0.8038, decode.d0.loss_cls: 5.1476, decode.d0.loss_mask: 0.5378, decode.d0.loss_dice: 0.8703, decode.d1.loss_cls: 0.4613, decode.d1.loss_mask: 0.5682, decode.d1.loss_dice: 0.8656, decode.d2.loss_cls: 0.4071, decode.d2.loss_mask: 0.5535, decode.d2.loss_dice: 0.8317, decode.d3.loss_cls: 0.3725, decode.d3.loss_mask: 0.5441, decode.d3.loss_dice: 0.8154, decode.d4.loss_cls: 0.3630, decode.d4.loss_mask: 0.5411, decode.d4.loss_dice: 0.8117, decode.d5.loss_cls: 0.3568, decode.d5.loss_mask: 0.5406, decode.d5.loss_dice: 0.8113, decode.d6.loss_cls: 0.3512, decode.d6.loss_mask: 0.5380, decode.d6.loss_dice: 0.8049, decode.d7.loss_cls: 0.3464, decode.d7.loss_mask: 0.5374, decode.d7.loss_dice: 0.8041, decode.d8.loss_cls: 0.3442, decode.d8.loss_mask: 0.5366, decode.d8.loss_dice: 0.8048, loss: 22.1540
2022-12-01 10:25:36,621 - mmseg - INFO - Iter [31250/40000]	lr: 2.910e-08, eta: 10:36:56, time: 4.110, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3424, decode.loss_mask: 0.5160, decode.loss_dice: 0.7840, decode.d0.loss_cls: 5.1474, decode.d0.loss_mask: 0.5103, decode.d0.loss_dice: 0.8455, decode.d1.loss_cls: 0.4658, decode.d1.loss_mask: 0.5410, decode.d1.loss_dice: 0.8389, decode.d2.loss_cls: 0.4008, decode.d2.loss_mask: 0.5297, decode.d2.loss_dice: 0.8063, decode.d3.loss_cls: 0.3697, decode.d3.loss_mask: 0.5223, decode.d3.loss_dice: 0.7899, decode.d4.loss_cls: 0.3601, decode.d4.loss_mask: 0.5213, decode.d4.loss_dice: 0.7870, decode.d5.loss_cls: 0.3510, decode.d5.loss_mask: 0.5191, decode.d5.loss_dice: 0.7852, decode.d6.loss_cls: 0.3463, decode.d6.loss_mask: 0.5164, decode.d6.loss_dice: 0.7825, decode.d7.loss_cls: 0.3437, decode.d7.loss_mask: 0.5157, decode.d7.loss_dice: 0.7811, decode.d8.loss_cls: 0.3418, decode.d8.loss_mask: 0.5171, decode.d8.loss_dice: 0.7836, loss: 21.6619
2022-12-01 10:29:02,139 - mmseg - INFO - Iter [31300/40000]	lr: 2.894e-08, eta: 10:33:14, time: 4.110, data_time: 0.022, memory: 51902, decode.loss_cls: 0.3376, decode.loss_mask: 0.5160, decode.loss_dice: 0.7804, decode.d0.loss_cls: 5.1159, decode.d0.loss_mask: 0.5139, decode.d0.loss_dice: 0.8492, decode.d1.loss_cls: 0.4524, decode.d1.loss_mask: 0.5423, decode.d1.loss_dice: 0.8432, decode.d2.loss_cls: 0.3948, decode.d2.loss_mask: 0.5321, decode.d2.loss_dice: 0.8085, decode.d3.loss_cls: 0.3658, decode.d3.loss_mask: 0.5231, decode.d3.loss_dice: 0.7923, decode.d4.loss_cls: 0.3531, decode.d4.loss_mask: 0.5205, decode.d4.loss_dice: 0.7885, decode.d5.loss_cls: 0.3414, decode.d5.loss_mask: 0.5189, decode.d5.loss_dice: 0.7854, decode.d6.loss_cls: 0.3371, decode.d6.loss_mask: 0.5174, decode.d6.loss_dice: 0.7787, decode.d7.loss_cls: 0.3356, decode.d7.loss_mask: 0.5176, decode.d7.loss_dice: 0.7836, decode.d8.loss_cls: 0.3387, decode.d8.loss_mask: 0.5155, decode.d8.loss_dice: 0.7783, loss: 21.5779
2022-12-01 10:32:28,011 - mmseg - INFO - Iter [31350/40000]	lr: 2.877e-08, eta: 10:29:33, time: 4.117, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3527, decode.loss_mask: 0.5123, decode.loss_dice: 0.7782, decode.d0.loss_cls: 5.1643, decode.d0.loss_mask: 0.5038, decode.d0.loss_dice: 0.8456, decode.d1.loss_cls: 0.4691, decode.d1.loss_mask: 0.5365, decode.d1.loss_dice: 0.8350, decode.d2.loss_cls: 0.4123, decode.d2.loss_mask: 0.5250, decode.d2.loss_dice: 0.7987, decode.d3.loss_cls: 0.3879, decode.d3.loss_mask: 0.5186, decode.d3.loss_dice: 0.7877, decode.d4.loss_cls: 0.3716, decode.d4.loss_mask: 0.5172, decode.d4.loss_dice: 0.7847, decode.d5.loss_cls: 0.3640, decode.d5.loss_mask: 0.5141, decode.d5.loss_dice: 0.7798, decode.d6.loss_cls: 0.3591, decode.d6.loss_mask: 0.5131, decode.d6.loss_dice: 0.7758, decode.d7.loss_cls: 0.3585, decode.d7.loss_mask: 0.5118, decode.d7.loss_dice: 0.7773, decode.d8.loss_cls: 0.3506, decode.d8.loss_mask: 0.5126, decode.d8.loss_dice: 0.7767, loss: 21.6945
2022-12-01 10:35:53,754 - mmseg - INFO - Iter [31400/40000]	lr: 2.860e-08, eta: 10:25:51, time: 4.115, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3404, decode.loss_mask: 0.5250, decode.loss_dice: 0.7839, decode.d0.loss_cls: 5.1369, decode.d0.loss_mask: 0.5190, decode.d0.loss_dice: 0.8497, decode.d1.loss_cls: 0.4531, decode.d1.loss_mask: 0.5570, decode.d1.loss_dice: 0.8480, decode.d2.loss_cls: 0.3965, decode.d2.loss_mask: 0.5440, decode.d2.loss_dice: 0.8100, decode.d3.loss_cls: 0.3675, decode.d3.loss_mask: 0.5363, decode.d3.loss_dice: 0.7967, decode.d4.loss_cls: 0.3578, decode.d4.loss_mask: 0.5349, decode.d4.loss_dice: 0.7930, decode.d5.loss_cls: 0.3441, decode.d5.loss_mask: 0.5292, decode.d5.loss_dice: 0.7908, decode.d6.loss_cls: 0.3383, decode.d6.loss_mask: 0.5282, decode.d6.loss_dice: 0.7841, decode.d7.loss_cls: 0.3390, decode.d7.loss_mask: 0.5266, decode.d7.loss_dice: 0.7833, decode.d8.loss_cls: 0.3355, decode.d8.loss_mask: 0.5257, decode.d8.loss_dice: 0.7867, loss: 21.7614
2022-12-01 10:39:19,421 - mmseg - INFO - Iter [31450/40000]	lr: 2.844e-08, eta: 10:22:09, time: 4.113, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3534, decode.loss_mask: 0.5477, decode.loss_dice: 0.8018, decode.d0.loss_cls: 5.1473, decode.d0.loss_mask: 0.5369, decode.d0.loss_dice: 0.8703, decode.d1.loss_cls: 0.4684, decode.d1.loss_mask: 0.5718, decode.d1.loss_dice: 0.8692, decode.d2.loss_cls: 0.4157, decode.d2.loss_mask: 0.5578, decode.d2.loss_dice: 0.8320, decode.d3.loss_cls: 0.3825, decode.d3.loss_mask: 0.5541, decode.d3.loss_dice: 0.8225, decode.d4.loss_cls: 0.3702, decode.d4.loss_mask: 0.5524, decode.d4.loss_dice: 0.8147, decode.d5.loss_cls: 0.3620, decode.d5.loss_mask: 0.5496, decode.d5.loss_dice: 0.8137, decode.d6.loss_cls: 0.3587, decode.d6.loss_mask: 0.5485, decode.d6.loss_dice: 0.8066, decode.d7.loss_cls: 0.3587, decode.d7.loss_mask: 0.5483, decode.d7.loss_dice: 0.8047, decode.d8.loss_cls: 0.3532, decode.d8.loss_mask: 0.5471, decode.d8.loss_dice: 0.8066, loss: 22.3264
2022-12-01 10:42:45,020 - mmseg - INFO - Iter [31500/40000]	lr: 2.827e-08, eta: 10:18:27, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3381, decode.loss_mask: 0.5419, decode.loss_dice: 0.7860, decode.d0.loss_cls: 5.1106, decode.d0.loss_mask: 0.5324, decode.d0.loss_dice: 0.8517, decode.d1.loss_cls: 0.4506, decode.d1.loss_mask: 0.5709, decode.d1.loss_dice: 0.8486, decode.d2.loss_cls: 0.3987, decode.d2.loss_mask: 0.5558, decode.d2.loss_dice: 0.8119, decode.d3.loss_cls: 0.3672, decode.d3.loss_mask: 0.5494, decode.d3.loss_dice: 0.7975, decode.d4.loss_cls: 0.3568, decode.d4.loss_mask: 0.5464, decode.d4.loss_dice: 0.7953, decode.d5.loss_cls: 0.3488, decode.d5.loss_mask: 0.5454, decode.d5.loss_dice: 0.7924, decode.d6.loss_cls: 0.3417, decode.d6.loss_mask: 0.5441, decode.d6.loss_dice: 0.7887, decode.d7.loss_cls: 0.3426, decode.d7.loss_mask: 0.5428, decode.d7.loss_dice: 0.7874, decode.d8.loss_cls: 0.3405, decode.d8.loss_mask: 0.5419, decode.d8.loss_dice: 0.7896, loss: 21.9159
2022-12-01 10:46:10,952 - mmseg - INFO - Iter [31550/40000]	lr: 2.811e-08, eta: 10:14:46, time: 4.119, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3157, decode.loss_mask: 0.5360, decode.loss_dice: 0.7796, decode.d0.loss_cls: 5.1241, decode.d0.loss_mask: 0.5276, decode.d0.loss_dice: 0.8396, decode.d1.loss_cls: 0.4343, decode.d1.loss_mask: 0.5584, decode.d1.loss_dice: 0.8353, decode.d2.loss_cls: 0.3797, decode.d2.loss_mask: 0.5476, decode.d2.loss_dice: 0.8021, decode.d3.loss_cls: 0.3463, decode.d3.loss_mask: 0.5395, decode.d3.loss_dice: 0.7904, decode.d4.loss_cls: 0.3333, decode.d4.loss_mask: 0.5381, decode.d4.loss_dice: 0.7886, decode.d5.loss_cls: 0.3282, decode.d5.loss_mask: 0.5365, decode.d5.loss_dice: 0.7841, decode.d6.loss_cls: 0.3266, decode.d6.loss_mask: 0.5357, decode.d6.loss_dice: 0.7803, decode.d7.loss_cls: 0.3183, decode.d7.loss_mask: 0.5343, decode.d7.loss_dice: 0.7799, decode.d8.loss_cls: 0.3171, decode.d8.loss_mask: 0.5360, decode.d8.loss_dice: 0.7787, loss: 21.5717
2022-12-01 10:49:36,161 - mmseg - INFO - Iter [31600/40000]	lr: 2.794e-08, eta: 10:11:04, time: 4.104, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3325, decode.loss_mask: 0.5384, decode.loss_dice: 0.7877, decode.d0.loss_cls: 5.0884, decode.d0.loss_mask: 0.5314, decode.d0.loss_dice: 0.8503, decode.d1.loss_cls: 0.4470, decode.d1.loss_mask: 0.5630, decode.d1.loss_dice: 0.8501, decode.d2.loss_cls: 0.3926, decode.d2.loss_mask: 0.5507, decode.d2.loss_dice: 0.8123, decode.d3.loss_cls: 0.3586, decode.d3.loss_mask: 0.5439, decode.d3.loss_dice: 0.7968, decode.d4.loss_cls: 0.3520, decode.d4.loss_mask: 0.5416, decode.d4.loss_dice: 0.7952, decode.d5.loss_cls: 0.3418, decode.d5.loss_mask: 0.5386, decode.d5.loss_dice: 0.7934, decode.d6.loss_cls: 0.3417, decode.d6.loss_mask: 0.5372, decode.d6.loss_dice: 0.7878, decode.d7.loss_cls: 0.3329, decode.d7.loss_mask: 0.5375, decode.d7.loss_dice: 0.7921, decode.d8.loss_cls: 0.3358, decode.d8.loss_mask: 0.5367, decode.d8.loss_dice: 0.7896, loss: 21.7978
2022-12-01 10:53:04,301 - mmseg - INFO - Iter [31650/40000]	lr: 2.777e-08, eta: 10:07:23, time: 4.163, data_time: 0.065, memory: 51902, decode.loss_cls: 0.3250, decode.loss_mask: 0.5221, decode.loss_dice: 0.7870, decode.d0.loss_cls: 5.1144, decode.d0.loss_mask: 0.5135, decode.d0.loss_dice: 0.8545, decode.d1.loss_cls: 0.4405, decode.d1.loss_mask: 0.5441, decode.d1.loss_dice: 0.8428, decode.d2.loss_cls: 0.3843, decode.d2.loss_mask: 0.5309, decode.d2.loss_dice: 0.8125, decode.d3.loss_cls: 0.3483, decode.d3.loss_mask: 0.5284, decode.d3.loss_dice: 0.8017, decode.d4.loss_cls: 0.3373, decode.d4.loss_mask: 0.5259, decode.d4.loss_dice: 0.7960, decode.d5.loss_cls: 0.3315, decode.d5.loss_mask: 0.5231, decode.d5.loss_dice: 0.7946, decode.d6.loss_cls: 0.3274, decode.d6.loss_mask: 0.5225, decode.d6.loss_dice: 0.7900, decode.d7.loss_cls: 0.3256, decode.d7.loss_mask: 0.5215, decode.d7.loss_dice: 0.7896, decode.d8.loss_cls: 0.3237, decode.d8.loss_mask: 0.5225, decode.d8.loss_dice: 0.7873, loss: 21.5686
2022-12-01 10:56:30,060 - mmseg - INFO - Iter [31700/40000]	lr: 2.761e-08, eta: 10:03:42, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3468, decode.loss_mask: 0.5188, decode.loss_dice: 0.7837, decode.d0.loss_cls: 5.1281, decode.d0.loss_mask: 0.5106, decode.d0.loss_dice: 0.8507, decode.d1.loss_cls: 0.4595, decode.d1.loss_mask: 0.5442, decode.d1.loss_dice: 0.8419, decode.d2.loss_cls: 0.4053, decode.d2.loss_mask: 0.5291, decode.d2.loss_dice: 0.8066, decode.d3.loss_cls: 0.3720, decode.d3.loss_mask: 0.5213, decode.d3.loss_dice: 0.7948, decode.d4.loss_cls: 0.3626, decode.d4.loss_mask: 0.5232, decode.d4.loss_dice: 0.7959, decode.d5.loss_cls: 0.3550, decode.d5.loss_mask: 0.5209, decode.d5.loss_dice: 0.7917, decode.d6.loss_cls: 0.3516, decode.d6.loss_mask: 0.5198, decode.d6.loss_dice: 0.7868, decode.d7.loss_cls: 0.3504, decode.d7.loss_mask: 0.5172, decode.d7.loss_dice: 0.7874, decode.d8.loss_cls: 0.3484, decode.d8.loss_mask: 0.5178, decode.d8.loss_dice: 0.7839, loss: 21.7258
2022-12-01 10:59:55,608 - mmseg - INFO - Iter [31750/40000]	lr: 2.744e-08, eta: 10:00:00, time: 4.111, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3439, decode.loss_mask: 0.5323, decode.loss_dice: 0.7908, decode.d0.loss_cls: 5.1148, decode.d0.loss_mask: 0.5288, decode.d0.loss_dice: 0.8475, decode.d1.loss_cls: 0.4506, decode.d1.loss_mask: 0.5619, decode.d1.loss_dice: 0.8496, decode.d2.loss_cls: 0.4002, decode.d2.loss_mask: 0.5499, decode.d2.loss_dice: 0.8171, decode.d3.loss_cls: 0.3653, decode.d3.loss_mask: 0.5445, decode.d3.loss_dice: 0.8005, decode.d4.loss_cls: 0.3612, decode.d4.loss_mask: 0.5400, decode.d4.loss_dice: 0.7969, decode.d5.loss_cls: 0.3511, decode.d5.loss_mask: 0.5369, decode.d5.loss_dice: 0.7924, decode.d6.loss_cls: 0.3460, decode.d6.loss_mask: 0.5349, decode.d6.loss_dice: 0.7887, decode.d7.loss_cls: 0.3427, decode.d7.loss_mask: 0.5345, decode.d7.loss_dice: 0.7907, decode.d8.loss_cls: 0.3443, decode.d8.loss_mask: 0.5321, decode.d8.loss_dice: 0.7939, loss: 21.8841
2022-12-01 11:03:21,163 - mmseg - INFO - Iter [31800/40000]	lr: 2.727e-08, eta: 9:56:19, time: 4.111, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3165, decode.loss_mask: 0.5376, decode.loss_dice: 0.7796, decode.d0.loss_cls: 5.0773, decode.d0.loss_mask: 0.5319, decode.d0.loss_dice: 0.8469, decode.d1.loss_cls: 0.4283, decode.d1.loss_mask: 0.5661, decode.d1.loss_dice: 0.8428, decode.d2.loss_cls: 0.3739, decode.d2.loss_mask: 0.5539, decode.d2.loss_dice: 0.8054, decode.d3.loss_cls: 0.3438, decode.d3.loss_mask: 0.5481, decode.d3.loss_dice: 0.7945, decode.d4.loss_cls: 0.3356, decode.d4.loss_mask: 0.5439, decode.d4.loss_dice: 0.7898, decode.d5.loss_cls: 0.3223, decode.d5.loss_mask: 0.5426, decode.d5.loss_dice: 0.7842, decode.d6.loss_cls: 0.3186, decode.d6.loss_mask: 0.5400, decode.d6.loss_dice: 0.7829, decode.d7.loss_cls: 0.3145, decode.d7.loss_mask: 0.5395, decode.d7.loss_dice: 0.7872, decode.d8.loss_cls: 0.3172, decode.d8.loss_mask: 0.5365, decode.d8.loss_dice: 0.7817, loss: 21.5829
2022-12-01 11:06:46,761 - mmseg - INFO - Iter [31850/40000]	lr: 2.711e-08, eta: 9:52:37, time: 4.112, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3395, decode.loss_mask: 0.5429, decode.loss_dice: 0.7959, decode.d0.loss_cls: 5.0962, decode.d0.loss_mask: 0.5364, decode.d0.loss_dice: 0.8563, decode.d1.loss_cls: 0.4588, decode.d1.loss_mask: 0.5690, decode.d1.loss_dice: 0.8536, decode.d2.loss_cls: 0.4031, decode.d2.loss_mask: 0.5585, decode.d2.loss_dice: 0.8203, decode.d3.loss_cls: 0.3699, decode.d3.loss_mask: 0.5489, decode.d3.loss_dice: 0.8055, decode.d4.loss_cls: 0.3593, decode.d4.loss_mask: 0.5477, decode.d4.loss_dice: 0.8079, decode.d5.loss_cls: 0.3486, decode.d5.loss_mask: 0.5463, decode.d5.loss_dice: 0.8013, decode.d6.loss_cls: 0.3475, decode.d6.loss_mask: 0.5414, decode.d6.loss_dice: 0.7955, decode.d7.loss_cls: 0.3446, decode.d7.loss_mask: 0.5411, decode.d7.loss_dice: 0.7958, decode.d8.loss_cls: 0.3451, decode.d8.loss_mask: 0.5409, decode.d8.loss_dice: 0.7964, loss: 22.0141
2022-12-01 11:10:12,534 - mmseg - INFO - Iter [31900/40000]	lr: 2.694e-08, eta: 9:48:56, time: 4.115, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3262, decode.loss_mask: 0.5281, decode.loss_dice: 0.7966, decode.d0.loss_cls: 5.1183, decode.d0.loss_mask: 0.5224, decode.d0.loss_dice: 0.8536, decode.d1.loss_cls: 0.4527, decode.d1.loss_mask: 0.5551, decode.d1.loss_dice: 0.8549, decode.d2.loss_cls: 0.3927, decode.d2.loss_mask: 0.5423, decode.d2.loss_dice: 0.8182, decode.d3.loss_cls: 0.3574, decode.d3.loss_mask: 0.5355, decode.d3.loss_dice: 0.8054, decode.d4.loss_cls: 0.3475, decode.d4.loss_mask: 0.5335, decode.d4.loss_dice: 0.8046, decode.d5.loss_cls: 0.3371, decode.d5.loss_mask: 0.5308, decode.d5.loss_dice: 0.8008, decode.d6.loss_cls: 0.3287, decode.d6.loss_mask: 0.5305, decode.d6.loss_dice: 0.8000, decode.d7.loss_cls: 0.3315, decode.d7.loss_mask: 0.5301, decode.d7.loss_dice: 0.7984, decode.d8.loss_cls: 0.3278, decode.d8.loss_mask: 0.5294, decode.d8.loss_dice: 0.7949, loss: 21.7848
2022-12-01 11:13:38,172 - mmseg - INFO - Iter [31950/40000]	lr: 2.678e-08, eta: 9:45:15, time: 4.113, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3227, decode.loss_mask: 0.5250, decode.loss_dice: 0.7740, decode.d0.loss_cls: 5.1083, decode.d0.loss_mask: 0.5220, decode.d0.loss_dice: 0.8374, decode.d1.loss_cls: 0.4357, decode.d1.loss_mask: 0.5512, decode.d1.loss_dice: 0.8351, decode.d2.loss_cls: 0.3799, decode.d2.loss_mask: 0.5406, decode.d2.loss_dice: 0.8024, decode.d3.loss_cls: 0.3473, decode.d3.loss_mask: 0.5332, decode.d3.loss_dice: 0.7911, decode.d4.loss_cls: 0.3356, decode.d4.loss_mask: 0.5327, decode.d4.loss_dice: 0.7858, decode.d5.loss_cls: 0.3287, decode.d5.loss_mask: 0.5298, decode.d5.loss_dice: 0.7844, decode.d6.loss_cls: 0.3240, decode.d6.loss_mask: 0.5273, decode.d6.loss_dice: 0.7754, decode.d7.loss_cls: 0.3225, decode.d7.loss_mask: 0.5267, decode.d7.loss_dice: 0.7755, decode.d8.loss_cls: 0.3228, decode.d8.loss_mask: 0.5264, decode.d8.loss_dice: 0.7781, loss: 21.4816
2022-12-01 11:17:03,978 - mmseg - INFO - Saving checkpoint at 32000 iterations
2022-12-01 11:17:56,468 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 11:17:56,469 - mmseg - INFO - Iter [32000/40000]	lr: 2.661e-08, eta: 9:41:47, time: 5.166, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3373, decode.loss_mask: 0.5290, decode.loss_dice: 0.7810, decode.d0.loss_cls: 5.1027, decode.d0.loss_mask: 0.5270, decode.d0.loss_dice: 0.8510, decode.d1.loss_cls: 0.4537, decode.d1.loss_mask: 0.5571, decode.d1.loss_dice: 0.8401, decode.d2.loss_cls: 0.3959, decode.d2.loss_mask: 0.5444, decode.d2.loss_dice: 0.8053, decode.d3.loss_cls: 0.3657, decode.d3.loss_mask: 0.5359, decode.d3.loss_dice: 0.7858, decode.d4.loss_cls: 0.3545, decode.d4.loss_mask: 0.5325, decode.d4.loss_dice: 0.7851, decode.d5.loss_cls: 0.3433, decode.d5.loss_mask: 0.5311, decode.d5.loss_dice: 0.7815, decode.d6.loss_cls: 0.3406, decode.d6.loss_mask: 0.5303, decode.d6.loss_dice: 0.7775, decode.d7.loss_cls: 0.3382, decode.d7.loss_mask: 0.5278, decode.d7.loss_dice: 0.7788, decode.d8.loss_cls: 0.3366, decode.d8.loss_mask: 0.5296, decode.d8.loss_dice: 0.7820, loss: 21.6813
2022-12-01 11:20:54,452 - mmseg - INFO - per class results:
2022-12-01 11:20:54,457 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 83.27 | 89.43 |
|       building      | 85.35 | 91.78 |
|         sky         |  95.2 | 97.33 |
|        floor        |  85.7 | 90.95 |
|         tree        | 78.08 | 89.77 |
|       ceiling       | 87.05 |  93.1 |
|         road        |  88.3 | 92.01 |
|         bed         | 93.82 |  97.2 |
|      windowpane     | 68.17 | 81.54 |
|        grass        | 70.65 | 82.78 |
|       cabinet       | 63.66 | 72.91 |
|       sidewalk      |  71.6 | 83.45 |
|        person       | 88.46 | 94.24 |
|        earth        | 43.88 |  60.6 |
|         door        |  65.0 | 83.81 |
|        table        |  72.9 | 82.52 |
|       mountain      | 61.87 | 70.42 |
|        plant        | 57.37 | 71.18 |
|       curtain       | 81.76 |  91.2 |
|        chair        | 69.28 |  79.4 |
|         car         | 89.43 | 95.01 |
|        water        | 70.02 | 85.95 |
|       painting      | 80.65 | 92.48 |
|         sofa        | 85.44 |  91.6 |
|        shelf        | 49.95 |  62.4 |
|        house        | 54.54 | 70.43 |
|         sea         | 80.46 | 89.66 |
|        mirror       | 81.44 | 92.56 |
|         rug         | 73.16 | 87.24 |
|        field        | 38.27 | 64.86 |
|       armchair      | 63.18 |  81.7 |
|         seat        | 65.43 |  88.5 |
|        fence        | 55.43 | 74.07 |
|         desk        | 61.04 | 84.51 |
|         rock        | 62.03 | 79.35 |
|       wardrobe      | 58.64 | 86.86 |
|         lamp        | 80.97 | 91.14 |
|       bathtub       | 91.72 | 93.39 |
|       railing       | 45.26 | 67.41 |
|       cushion       | 77.88 | 90.22 |
|         base        | 45.58 | 72.17 |
|         box         | 43.83 | 63.04 |
|        column       | 56.14 | 73.69 |
|      signboard      | 45.04 | 68.44 |
|   chest of drawers  | 49.28 | 70.15 |
|       counter       | 56.65 | 64.33 |
|         sand        | 62.25 | 87.27 |
|         sink        | 83.44 | 87.16 |
|      skyscraper     |  43.1 | 54.78 |
|      fireplace      | 79.91 | 94.85 |
|     refrigerator    | 84.47 | 94.48 |
|      grandstand     | 50.73 | 81.74 |
|         path        | 28.82 | 42.22 |
|        stairs       | 37.14 | 50.52 |
|        runway       | 74.29 | 93.21 |
|         case        | 66.67 | 87.56 |
|      pool table     | 95.91 | 98.78 |
|        pillow       | 72.58 | 83.12 |
|     screen door     | 83.87 |  91.8 |
|       stairway      | 57.98 | 72.37 |
|        river        | 29.94 | 34.78 |
|        bridge       | 71.35 | 85.61 |
|       bookcase      | 45.66 | 67.19 |
|        blind        | 50.64 | 64.24 |
|     coffee table    | 74.39 | 90.63 |
|        toilet       | 92.11 | 95.28 |
|        flower       | 46.63 | 71.63 |
|         book        | 61.99 | 83.24 |
|         hill        | 14.81 | 27.44 |
|        bench        | 75.56 | 84.23 |
|      countertop     | 73.13 | 90.58 |
|        stove        | 86.66 | 90.47 |
|         palm        | 56.56 | 82.79 |
|    kitchen island   | 48.49 | 94.93 |
|       computer      | 81.95 | 89.56 |
|     swivel chair    | 56.36 | 85.25 |
|         boat        | 60.29 | 89.26 |
|         bar         | 67.78 | 75.68 |
|    arcade machine   | 90.71 | 98.66 |
|        hovel        | 50.84 | 69.61 |
|         bus         | 93.42 | 95.63 |
|        towel        | 85.24 | 94.47 |
|        light        |  66.8 | 80.79 |
|        truck        | 53.15 | 73.69 |
|        tower        | 33.28 | 63.25 |
|      chandelier     | 77.42 | 87.51 |
|        awning       | 33.22 | 53.48 |
|     streetlight     | 44.11 | 73.29 |
|        booth        | 65.94 | 77.98 |
| television receiver | 77.91 | 92.18 |
|       airplane      | 89.19 | 96.31 |
|      dirt track     | 24.73 |  49.2 |
|       apparel       |  53.6 | 86.55 |
|         pole        | 31.03 | 43.65 |
|         land        |  6.69 |  9.62 |
|      bannister      | 23.67 | 35.87 |
|      escalator      | 65.33 | 81.93 |
|       ottoman       | 60.44 | 78.72 |
|        bottle       | 52.07 | 80.55 |
|        buffet       |  45.4 | 62.21 |
|        poster       | 40.72 | 60.15 |
|        stage        |  32.2 | 61.05 |
|         van         | 50.61 | 75.78 |
|         ship        | 22.29 | 23.51 |
|       fountain      |  45.1 | 51.97 |
|    conveyer belt    | 77.02 | 97.14 |
|        canopy       |  39.2 | 63.28 |
|        washer       | 90.54 | 93.39 |
|      plaything      | 36.81 | 58.93 |
|    swimming pool    | 51.22 | 76.72 |
|        stool        | 59.18 | 85.83 |
|        barrel       | 66.17 | 96.93 |
|        basket       | 44.01 | 71.03 |
|      waterfall      | 45.83 | 56.11 |
|         tent        | 95.21 | 98.34 |
|         bag         |  34.5 | 48.73 |
|       minibike      | 81.18 | 94.08 |
|        cradle       | 91.45 | 97.47 |
|         oven        | 70.67 | 83.98 |
|         ball        | 43.79 |  47.4 |
|         food        |  66.5 | 77.91 |
|         step        | 26.53 | 40.77 |
|         tank        | 62.97 | 67.56 |
|      trade name     | 33.72 | 44.16 |
|      microwave      | 91.47 | 96.57 |
|         pot         | 59.43 | 71.74 |
|        animal       | 81.75 | 84.06 |
|       bicycle       | 64.31 | 84.54 |
|         lake        | 65.67 | 68.61 |
|      dishwasher     | 72.38 | 90.69 |
|        screen       | 59.36 | 91.29 |
|       blanket       | 46.32 | 61.32 |
|      sculpture      | 74.61 | 90.19 |
|         hood        | 83.75 | 88.64 |
|        sconce       | 66.23 | 84.03 |
|         vase        | 59.36 | 81.96 |
|    traffic light    | 52.54 | 73.22 |
|         tray        | 33.95 | 50.36 |
|        ashcan       | 54.42 |  77.1 |
|         fan         | 73.81 | 86.81 |
|         pier        | 38.88 | 41.68 |
|      crt screen     |  1.53 |  4.24 |
|        plate        | 71.14 | 84.82 |
|       monitor       |  4.03 |  5.41 |
|    bulletin board   | 64.59 | 83.09 |
|        shower       |  16.6 | 28.62 |
|       radiator      | 73.43 | 93.52 |
|        glass        | 28.84 | 31.59 |
|        clock        |  62.3 | 78.56 |
|         flag        | 66.87 | 87.47 |
+---------------------+-------+-------+
2022-12-01 11:20:54,457 - mmseg - INFO - Summary:
2022-12-01 11:20:54,457 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 87.12 | 61.25 | 75.85 |
+-------+-------+-------+
2022-12-01 11:20:54,461 - mmseg - INFO - The previous best checkpoint /mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune/lr1.0_lrd0.9/best_mIoU_iter_31000.pth was removed
2022-12-01 11:21:46,656 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_32000.pth.
2022-12-01 11:21:46,657 - mmseg - INFO - Best mIoU is 0.6125 at 32000 iter.
2022-12-01 11:21:46,668 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 11:21:46,668 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8712, mIoU: 0.6125, mAcc: 0.7585, IoU.wall: 0.8327, IoU.building: 0.8535, IoU.sky: 0.9520, IoU.floor: 0.8570, IoU.tree: 0.7808, IoU.ceiling: 0.8705, IoU.road: 0.8830, IoU.bed : 0.9382, IoU.windowpane: 0.6817, IoU.grass: 0.7065, IoU.cabinet: 0.6366, IoU.sidewalk: 0.7160, IoU.person: 0.8846, IoU.earth: 0.4388, IoU.door: 0.6500, IoU.table: 0.7290, IoU.mountain: 0.6187, IoU.plant: 0.5737, IoU.curtain: 0.8176, IoU.chair: 0.6928, IoU.car: 0.8943, IoU.water: 0.7002, IoU.painting: 0.8065, IoU.sofa: 0.8544, IoU.shelf: 0.4995, IoU.house: 0.5454, IoU.sea: 0.8046, IoU.mirror: 0.8144, IoU.rug: 0.7316, IoU.field: 0.3827, IoU.armchair: 0.6318, IoU.seat: 0.6543, IoU.fence: 0.5543, IoU.desk: 0.6104, IoU.rock: 0.6203, IoU.wardrobe: 0.5864, IoU.lamp: 0.8097, IoU.bathtub: 0.9172, IoU.railing: 0.4526, IoU.cushion: 0.7788, IoU.base: 0.4558, IoU.box: 0.4383, IoU.column: 0.5614, IoU.signboard: 0.4504, IoU.chest of drawers: 0.4928, IoU.counter: 0.5665, IoU.sand: 0.6225, IoU.sink: 0.8344, IoU.skyscraper: 0.4310, IoU.fireplace: 0.7991, IoU.refrigerator: 0.8447, IoU.grandstand: 0.5073, IoU.path: 0.2882, IoU.stairs: 0.3714, IoU.runway: 0.7429, IoU.case: 0.6667, IoU.pool table: 0.9591, IoU.pillow: 0.7258, IoU.screen door: 0.8387, IoU.stairway: 0.5798, IoU.river: 0.2994, IoU.bridge: 0.7135, IoU.bookcase: 0.4566, IoU.blind: 0.5064, IoU.coffee table: 0.7439, IoU.toilet: 0.9211, IoU.flower: 0.4663, IoU.book: 0.6199, IoU.hill: 0.1481, IoU.bench: 0.7556, IoU.countertop: 0.7313, IoU.stove: 0.8666, IoU.palm: 0.5656, IoU.kitchen island: 0.4849, IoU.computer: 0.8195, IoU.swivel chair: 0.5636, IoU.boat: 0.6029, IoU.bar: 0.6778, IoU.arcade machine: 0.9071, IoU.hovel: 0.5084, IoU.bus: 0.9342, IoU.towel: 0.8524, IoU.light: 0.6680, IoU.truck: 0.5315, IoU.tower: 0.3328, IoU.chandelier: 0.7742, IoU.awning: 0.3322, IoU.streetlight: 0.4411, IoU.booth: 0.6594, IoU.television receiver: 0.7791, IoU.airplane: 0.8919, IoU.dirt track: 0.2473, IoU.apparel: 0.5360, IoU.pole: 0.3103, IoU.land: 0.0669, IoU.bannister: 0.2367, IoU.escalator: 0.6533, IoU.ottoman: 0.6044, IoU.bottle: 0.5207, IoU.buffet: 0.4540, IoU.poster: 0.4072, IoU.stage: 0.3220, IoU.van: 0.5061, IoU.ship: 0.2229, IoU.fountain: 0.4510, IoU.conveyer belt: 0.7702, IoU.canopy: 0.3920, IoU.washer: 0.9054, IoU.plaything: 0.3681, IoU.swimming pool: 0.5122, IoU.stool: 0.5918, IoU.barrel: 0.6617, IoU.basket: 0.4401, IoU.waterfall: 0.4583, IoU.tent: 0.9521, IoU.bag: 0.3450, IoU.minibike: 0.8118, IoU.cradle: 0.9145, IoU.oven: 0.7067, IoU.ball: 0.4379, IoU.food: 0.6650, IoU.step: 0.2653, IoU.tank: 0.6297, IoU.trade name: 0.3372, IoU.microwave: 0.9147, IoU.pot: 0.5943, IoU.animal: 0.8175, IoU.bicycle: 0.6431, IoU.lake: 0.6567, IoU.dishwasher: 0.7238, IoU.screen: 0.5936, IoU.blanket: 0.4632, IoU.sculpture: 0.7461, IoU.hood: 0.8375, IoU.sconce: 0.6623, IoU.vase: 0.5936, IoU.traffic light: 0.5254, IoU.tray: 0.3395, IoU.ashcan: 0.5442, IoU.fan: 0.7381, IoU.pier: 0.3888, IoU.crt screen: 0.0153, IoU.plate: 0.7114, IoU.monitor: 0.0403, IoU.bulletin board: 0.6459, IoU.shower: 0.1660, IoU.radiator: 0.7343, IoU.glass: 0.2884, IoU.clock: 0.6230, IoU.flag: 0.6687, Acc.wall: 0.8943, Acc.building: 0.9178, Acc.sky: 0.9733, Acc.floor: 0.9095, Acc.tree: 0.8977, Acc.ceiling: 0.9310, Acc.road: 0.9201, Acc.bed : 0.9720, Acc.windowpane: 0.8154, Acc.grass: 0.8278, Acc.cabinet: 0.7291, Acc.sidewalk: 0.8345, Acc.person: 0.9424, Acc.earth: 0.6060, Acc.door: 0.8381, Acc.table: 0.8252, Acc.mountain: 0.7042, Acc.plant: 0.7118, Acc.curtain: 0.9120, Acc.chair: 0.7940, Acc.car: 0.9501, Acc.water: 0.8595, Acc.painting: 0.9248, Acc.sofa: 0.9160, Acc.shelf: 0.6240, Acc.house: 0.7043, Acc.sea: 0.8966, Acc.mirror: 0.9256, Acc.rug: 0.8724, Acc.field: 0.6486, Acc.armchair: 0.8170, Acc.seat: 0.8850, Acc.fence: 0.7407, Acc.desk: 0.8451, Acc.rock: 0.7935, Acc.wardrobe: 0.8686, Acc.lamp: 0.9114, Acc.bathtub: 0.9339, Acc.railing: 0.6741, Acc.cushion: 0.9022, Acc.base: 0.7217, Acc.box: 0.6304, Acc.column: 0.7369, Acc.signboard: 0.6844, Acc.chest of drawers: 0.7015, Acc.counter: 0.6433, Acc.sand: 0.8727, Acc.sink: 0.8716, Acc.skyscraper: 0.5478, Acc.fireplace: 0.9485, Acc.refrigerator: 0.9448, Acc.grandstand: 0.8174, Acc.path: 0.4222, Acc.stairs: 0.5052, Acc.runway: 0.9321, Acc.case: 0.8756, Acc.pool table: 0.9878, Acc.pillow: 0.8312, Acc.screen door: 0.9180, Acc.stairway: 0.7237, Acc.river: 0.3478, Acc.bridge: 0.8561, Acc.bookcase: 0.6719, Acc.blind: 0.6424, Acc.coffee table: 0.9063, Acc.toilet: 0.9528, Acc.flower: 0.7163, Acc.book: 0.8324, Acc.hill: 0.2744, Acc.bench: 0.8423, Acc.countertop: 0.9058, Acc.stove: 0.9047, Acc.palm: 0.8279, Acc.kitchen island: 0.9493, Acc.computer: 0.8956, Acc.swivel chair: 0.8525, Acc.boat: 0.8926, Acc.bar: 0.7568, Acc.arcade machine: 0.9866, Acc.hovel: 0.6961, Acc.bus: 0.9563, Acc.towel: 0.9447, Acc.light: 0.8079, Acc.truck: 0.7369, Acc.tower: 0.6325, Acc.chandelier: 0.8751, Acc.awning: 0.5348, Acc.streetlight: 0.7329, Acc.booth: 0.7798, Acc.television receiver: 0.9218, Acc.airplane: 0.9631, Acc.dirt track: 0.4920, Acc.apparel: 0.8655, Acc.pole: 0.4365, Acc.land: 0.0962, Acc.bannister: 0.3587, Acc.escalator: 0.8193, Acc.ottoman: 0.7872, Acc.bottle: 0.8055, Acc.buffet: 0.6221, Acc.poster: 0.6015, Acc.stage: 0.6105, Acc.van: 0.7578, Acc.ship: 0.2351, Acc.fountain: 0.5197, Acc.conveyer belt: 0.9714, Acc.canopy: 0.6328, Acc.washer: 0.9339, Acc.plaything: 0.5893, Acc.swimming pool: 0.7672, Acc.stool: 0.8583, Acc.barrel: 0.9693, Acc.basket: 0.7103, Acc.waterfall: 0.5611, Acc.tent: 0.9834, Acc.bag: 0.4873, Acc.minibike: 0.9408, Acc.cradle: 0.9747, Acc.oven: 0.8398, Acc.ball: 0.4740, Acc.food: 0.7791, Acc.step: 0.4077, Acc.tank: 0.6756, Acc.trade name: 0.4416, Acc.microwave: 0.9657, Acc.pot: 0.7174, Acc.animal: 0.8406, Acc.bicycle: 0.8454, Acc.lake: 0.6861, Acc.dishwasher: 0.9069, Acc.screen: 0.9129, Acc.blanket: 0.6132, Acc.sculpture: 0.9019, Acc.hood: 0.8864, Acc.sconce: 0.8403, Acc.vase: 0.8196, Acc.traffic light: 0.7322, Acc.tray: 0.5036, Acc.ashcan: 0.7710, Acc.fan: 0.8681, Acc.pier: 0.4168, Acc.crt screen: 0.0424, Acc.plate: 0.8482, Acc.monitor: 0.0541, Acc.bulletin board: 0.8309, Acc.shower: 0.2862, Acc.radiator: 0.9352, Acc.glass: 0.3159, Acc.clock: 0.7856, Acc.flag: 0.8747
2022-12-01 11:25:12,548 - mmseg - INFO - Iter [32050/40000]	lr: 2.644e-08, eta: 9:39:03, time: 8.722, data_time: 4.624, memory: 51902, decode.loss_cls: 0.3422, decode.loss_mask: 0.5408, decode.loss_dice: 0.7891, decode.d0.loss_cls: 5.0792, decode.d0.loss_mask: 0.5340, decode.d0.loss_dice: 0.8579, decode.d1.loss_cls: 0.4551, decode.d1.loss_mask: 0.5692, decode.d1.loss_dice: 0.8513, decode.d2.loss_cls: 0.4003, decode.d2.loss_mask: 0.5554, decode.d2.loss_dice: 0.8166, decode.d3.loss_cls: 0.3681, decode.d3.loss_mask: 0.5506, decode.d3.loss_dice: 0.8030, decode.d4.loss_cls: 0.3571, decode.d4.loss_mask: 0.5458, decode.d4.loss_dice: 0.7958, decode.d5.loss_cls: 0.3497, decode.d5.loss_mask: 0.5430, decode.d5.loss_dice: 0.7926, decode.d6.loss_cls: 0.3467, decode.d6.loss_mask: 0.5426, decode.d6.loss_dice: 0.7907, decode.d7.loss_cls: 0.3467, decode.d7.loss_mask: 0.5415, decode.d7.loss_dice: 0.7883, decode.d8.loss_cls: 0.3426, decode.d8.loss_mask: 0.5402, decode.d8.loss_dice: 0.7861, loss: 21.9222
2022-12-01 11:28:38,069 - mmseg - INFO - Iter [32100/40000]	lr: 2.628e-08, eta: 9:35:21, time: 4.110, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3350, decode.loss_mask: 0.5347, decode.loss_dice: 0.7968, decode.d0.loss_cls: 5.0961, decode.d0.loss_mask: 0.5281, decode.d0.loss_dice: 0.8622, decode.d1.loss_cls: 0.4513, decode.d1.loss_mask: 0.5639, decode.d1.loss_dice: 0.8538, decode.d2.loss_cls: 0.3893, decode.d2.loss_mask: 0.5513, decode.d2.loss_dice: 0.8269, decode.d3.loss_cls: 0.3598, decode.d3.loss_mask: 0.5446, decode.d3.loss_dice: 0.8089, decode.d4.loss_cls: 0.3482, decode.d4.loss_mask: 0.5420, decode.d4.loss_dice: 0.8063, decode.d5.loss_cls: 0.3401, decode.d5.loss_mask: 0.5393, decode.d5.loss_dice: 0.8032, decode.d6.loss_cls: 0.3375, decode.d6.loss_mask: 0.5377, decode.d6.loss_dice: 0.8006, decode.d7.loss_cls: 0.3361, decode.d7.loss_mask: 0.5368, decode.d7.loss_dice: 0.7988, decode.d8.loss_cls: 0.3322, decode.d8.loss_mask: 0.5374, decode.d8.loss_dice: 0.7986, loss: 21.8977
2022-12-01 11:32:03,783 - mmseg - INFO - Iter [32150/40000]	lr: 2.611e-08, eta: 9:31:39, time: 4.114, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3467, decode.loss_mask: 0.5309, decode.loss_dice: 0.7952, decode.d0.loss_cls: 5.1064, decode.d0.loss_mask: 0.5241, decode.d0.loss_dice: 0.8678, decode.d1.loss_cls: 0.4587, decode.d1.loss_mask: 0.5620, decode.d1.loss_dice: 0.8584, decode.d2.loss_cls: 0.4047, decode.d2.loss_mask: 0.5461, decode.d2.loss_dice: 0.8226, decode.d3.loss_cls: 0.3732, decode.d3.loss_mask: 0.5385, decode.d3.loss_dice: 0.8073, decode.d4.loss_cls: 0.3658, decode.d4.loss_mask: 0.5364, decode.d4.loss_dice: 0.8049, decode.d5.loss_cls: 0.3553, decode.d5.loss_mask: 0.5366, decode.d5.loss_dice: 0.7992, decode.d6.loss_cls: 0.3509, decode.d6.loss_mask: 0.5346, decode.d6.loss_dice: 0.7990, decode.d7.loss_cls: 0.3481, decode.d7.loss_mask: 0.5322, decode.d7.loss_dice: 0.7935, decode.d8.loss_cls: 0.3492, decode.d8.loss_mask: 0.5307, decode.d8.loss_dice: 0.7957, loss: 21.9750
2022-12-01 11:35:29,481 - mmseg - INFO - Iter [32200/40000]	lr: 2.594e-08, eta: 9:27:58, time: 4.114, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3467, decode.loss_mask: 0.5456, decode.loss_dice: 0.8017, decode.d0.loss_cls: 5.1000, decode.d0.loss_mask: 0.5361, decode.d0.loss_dice: 0.8626, decode.d1.loss_cls: 0.4600, decode.d1.loss_mask: 0.5740, decode.d1.loss_dice: 0.8614, decode.d2.loss_cls: 0.4095, decode.d2.loss_mask: 0.5609, decode.d2.loss_dice: 0.8284, decode.d3.loss_cls: 0.3782, decode.d3.loss_mask: 0.5534, decode.d3.loss_dice: 0.8140, decode.d4.loss_cls: 0.3690, decode.d4.loss_mask: 0.5495, decode.d4.loss_dice: 0.8089, decode.d5.loss_cls: 0.3560, decode.d5.loss_mask: 0.5469, decode.d5.loss_dice: 0.8052, decode.d6.loss_cls: 0.3516, decode.d6.loss_mask: 0.5455, decode.d6.loss_dice: 0.8022, decode.d7.loss_cls: 0.3484, decode.d7.loss_mask: 0.5449, decode.d7.loss_dice: 0.8031, decode.d8.loss_cls: 0.3454, decode.d8.loss_mask: 0.5458, decode.d8.loss_dice: 0.8017, loss: 22.1564
2022-12-01 11:38:57,379 - mmseg - INFO - Iter [32250/40000]	lr: 2.578e-08, eta: 9:24:17, time: 4.158, data_time: 0.065, memory: 51902, decode.loss_cls: 0.3443, decode.loss_mask: 0.5274, decode.loss_dice: 0.7773, decode.d0.loss_cls: 5.1067, decode.d0.loss_mask: 0.5259, decode.d0.loss_dice: 0.8521, decode.d1.loss_cls: 0.4642, decode.d1.loss_mask: 0.5563, decode.d1.loss_dice: 0.8364, decode.d2.loss_cls: 0.4061, decode.d2.loss_mask: 0.5425, decode.d2.loss_dice: 0.8020, decode.d3.loss_cls: 0.3730, decode.d3.loss_mask: 0.5371, decode.d3.loss_dice: 0.7914, decode.d4.loss_cls: 0.3654, decode.d4.loss_mask: 0.5323, decode.d4.loss_dice: 0.7861, decode.d5.loss_cls: 0.3527, decode.d5.loss_mask: 0.5302, decode.d5.loss_dice: 0.7854, decode.d6.loss_cls: 0.3478, decode.d6.loss_mask: 0.5279, decode.d6.loss_dice: 0.7796, decode.d7.loss_cls: 0.3426, decode.d7.loss_mask: 0.5276, decode.d7.loss_dice: 0.7821, decode.d8.loss_cls: 0.3450, decode.d8.loss_mask: 0.5266, decode.d8.loss_dice: 0.7793, loss: 21.7530
2022-12-01 11:42:22,868 - mmseg - INFO - Iter [32300/40000]	lr: 2.561e-08, eta: 9:20:35, time: 4.110, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3533, decode.loss_mask: 0.5359, decode.loss_dice: 0.7981, decode.d0.loss_cls: 5.1130, decode.d0.loss_mask: 0.5312, decode.d0.loss_dice: 0.8707, decode.d1.loss_cls: 0.4783, decode.d1.loss_mask: 0.5623, decode.d1.loss_dice: 0.8638, decode.d2.loss_cls: 0.4130, decode.d2.loss_mask: 0.5523, decode.d2.loss_dice: 0.8285, decode.d3.loss_cls: 0.3848, decode.d3.loss_mask: 0.5426, decode.d3.loss_dice: 0.8106, decode.d4.loss_cls: 0.3751, decode.d4.loss_mask: 0.5394, decode.d4.loss_dice: 0.8053, decode.d5.loss_cls: 0.3606, decode.d5.loss_mask: 0.5394, decode.d5.loss_dice: 0.8050, decode.d6.loss_cls: 0.3557, decode.d6.loss_mask: 0.5379, decode.d6.loss_dice: 0.8037, decode.d7.loss_cls: 0.3527, decode.d7.loss_mask: 0.5352, decode.d7.loss_dice: 0.8021, decode.d8.loss_cls: 0.3527, decode.d8.loss_mask: 0.5362, decode.d8.loss_dice: 0.8000, loss: 22.1396
2022-12-01 11:45:48,587 - mmseg - INFO - Iter [32350/40000]	lr: 2.544e-08, eta: 9:16:54, time: 4.114, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3289, decode.loss_mask: 0.5383, decode.loss_dice: 0.7915, decode.d0.loss_cls: 5.0860, decode.d0.loss_mask: 0.5305, decode.d0.loss_dice: 0.8581, decode.d1.loss_cls: 0.4461, decode.d1.loss_mask: 0.5638, decode.d1.loss_dice: 0.8511, decode.d2.loss_cls: 0.3883, decode.d2.loss_mask: 0.5537, decode.d2.loss_dice: 0.8166, decode.d3.loss_cls: 0.3537, decode.d3.loss_mask: 0.5470, decode.d3.loss_dice: 0.8044, decode.d4.loss_cls: 0.3469, decode.d4.loss_mask: 0.5434, decode.d4.loss_dice: 0.7974, decode.d5.loss_cls: 0.3392, decode.d5.loss_mask: 0.5409, decode.d5.loss_dice: 0.7961, decode.d6.loss_cls: 0.3317, decode.d6.loss_mask: 0.5405, decode.d6.loss_dice: 0.7932, decode.d7.loss_cls: 0.3283, decode.d7.loss_mask: 0.5393, decode.d7.loss_dice: 0.7934, decode.d8.loss_cls: 0.3310, decode.d8.loss_mask: 0.5398, decode.d8.loss_dice: 0.7901, loss: 21.8092
2022-12-01 11:49:14,097 - mmseg - INFO - Iter [32400/40000]	lr: 2.528e-08, eta: 9:13:12, time: 4.110, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3444, decode.loss_mask: 0.5422, decode.loss_dice: 0.7900, decode.d0.loss_cls: 5.0764, decode.d0.loss_mask: 0.5344, decode.d0.loss_dice: 0.8506, decode.d1.loss_cls: 0.4643, decode.d1.loss_mask: 0.5693, decode.d1.loss_dice: 0.8495, decode.d2.loss_cls: 0.4068, decode.d2.loss_mask: 0.5566, decode.d2.loss_dice: 0.8110, decode.d3.loss_cls: 0.3757, decode.d3.loss_mask: 0.5493, decode.d3.loss_dice: 0.8001, decode.d4.loss_cls: 0.3643, decode.d4.loss_mask: 0.5473, decode.d4.loss_dice: 0.7990, decode.d5.loss_cls: 0.3547, decode.d5.loss_mask: 0.5456, decode.d5.loss_dice: 0.7926, decode.d6.loss_cls: 0.3491, decode.d6.loss_mask: 0.5454, decode.d6.loss_dice: 0.7908, decode.d7.loss_cls: 0.3449, decode.d7.loss_mask: 0.5448, decode.d7.loss_dice: 0.7920, decode.d8.loss_cls: 0.3439, decode.d8.loss_mask: 0.5443, decode.d8.loss_dice: 0.7909, loss: 21.9704
2022-12-01 11:52:39,874 - mmseg - INFO - Iter [32450/40000]	lr: 2.511e-08, eta: 9:09:31, time: 4.116, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3257, decode.loss_mask: 0.5313, decode.loss_dice: 0.7900, decode.d0.loss_cls: 5.0793, decode.d0.loss_mask: 0.5269, decode.d0.loss_dice: 0.8588, decode.d1.loss_cls: 0.4445, decode.d1.loss_mask: 0.5609, decode.d1.loss_dice: 0.8487, decode.d2.loss_cls: 0.3878, decode.d2.loss_mask: 0.5467, decode.d2.loss_dice: 0.8134, decode.d3.loss_cls: 0.3555, decode.d3.loss_mask: 0.5397, decode.d3.loss_dice: 0.8022, decode.d4.loss_cls: 0.3436, decode.d4.loss_mask: 0.5377, decode.d4.loss_dice: 0.7994, decode.d5.loss_cls: 0.3354, decode.d5.loss_mask: 0.5355, decode.d5.loss_dice: 0.7946, decode.d6.loss_cls: 0.3319, decode.d6.loss_mask: 0.5352, decode.d6.loss_dice: 0.7935, decode.d7.loss_cls: 0.3273, decode.d7.loss_mask: 0.5334, decode.d7.loss_dice: 0.7915, decode.d8.loss_cls: 0.3282, decode.d8.loss_mask: 0.5319, decode.d8.loss_dice: 0.7912, loss: 21.7216
2022-12-01 11:56:05,475 - mmseg - INFO - Iter [32500/40000]	lr: 2.495e-08, eta: 9:05:50, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3404, decode.loss_mask: 0.5267, decode.loss_dice: 0.7788, decode.d0.loss_cls: 5.0787, decode.d0.loss_mask: 0.5210, decode.d0.loss_dice: 0.8462, decode.d1.loss_cls: 0.4635, decode.d1.loss_mask: 0.5570, decode.d1.loss_dice: 0.8427, decode.d2.loss_cls: 0.4035, decode.d2.loss_mask: 0.5422, decode.d2.loss_dice: 0.8070, decode.d3.loss_cls: 0.3706, decode.d3.loss_mask: 0.5333, decode.d3.loss_dice: 0.7904, decode.d4.loss_cls: 0.3600, decode.d4.loss_mask: 0.5309, decode.d4.loss_dice: 0.7883, decode.d5.loss_cls: 0.3496, decode.d5.loss_mask: 0.5299, decode.d5.loss_dice: 0.7867, decode.d6.loss_cls: 0.3451, decode.d6.loss_mask: 0.5294, decode.d6.loss_dice: 0.7822, decode.d7.loss_cls: 0.3451, decode.d7.loss_mask: 0.5271, decode.d7.loss_dice: 0.7762, decode.d8.loss_cls: 0.3450, decode.d8.loss_mask: 0.5270, decode.d8.loss_dice: 0.7796, loss: 21.7043
2022-12-01 11:59:30,894 - mmseg - INFO - Iter [32550/40000]	lr: 2.478e-08, eta: 9:02:08, time: 4.108, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3283, decode.loss_mask: 0.5284, decode.loss_dice: 0.7935, decode.d0.loss_cls: 5.0701, decode.d0.loss_mask: 0.5166, decode.d0.loss_dice: 0.8535, decode.d1.loss_cls: 0.4447, decode.d1.loss_mask: 0.5530, decode.d1.loss_dice: 0.8526, decode.d2.loss_cls: 0.3886, decode.d2.loss_mask: 0.5419, decode.d2.loss_dice: 0.8187, decode.d3.loss_cls: 0.3591, decode.d3.loss_mask: 0.5358, decode.d3.loss_dice: 0.8074, decode.d4.loss_cls: 0.3472, decode.d4.loss_mask: 0.5324, decode.d4.loss_dice: 0.8038, decode.d5.loss_cls: 0.3363, decode.d5.loss_mask: 0.5302, decode.d5.loss_dice: 0.8021, decode.d6.loss_cls: 0.3293, decode.d6.loss_mask: 0.5295, decode.d6.loss_dice: 0.7969, decode.d7.loss_cls: 0.3283, decode.d7.loss_mask: 0.5281, decode.d7.loss_dice: 0.7962, decode.d8.loss_cls: 0.3288, decode.d8.loss_mask: 0.5290, decode.d8.loss_dice: 0.7959, loss: 21.7063
2022-12-01 12:02:56,583 - mmseg - INFO - Iter [32600/40000]	lr: 2.461e-08, eta: 8:58:27, time: 4.114, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3406, decode.loss_mask: 0.5191, decode.loss_dice: 0.7789, decode.d0.loss_cls: 5.0737, decode.d0.loss_mask: 0.5179, decode.d0.loss_dice: 0.8467, decode.d1.loss_cls: 0.4671, decode.d1.loss_mask: 0.5447, decode.d1.loss_dice: 0.8396, decode.d2.loss_cls: 0.4022, decode.d2.loss_mask: 0.5323, decode.d2.loss_dice: 0.8015, decode.d3.loss_cls: 0.3661, decode.d3.loss_mask: 0.5252, decode.d3.loss_dice: 0.7909, decode.d4.loss_cls: 0.3576, decode.d4.loss_mask: 0.5238, decode.d4.loss_dice: 0.7888, decode.d5.loss_cls: 0.3456, decode.d5.loss_mask: 0.5226, decode.d5.loss_dice: 0.7859, decode.d6.loss_cls: 0.3448, decode.d6.loss_mask: 0.5196, decode.d6.loss_dice: 0.7794, decode.d7.loss_cls: 0.3459, decode.d7.loss_mask: 0.5190, decode.d7.loss_dice: 0.7793, decode.d8.loss_cls: 0.3407, decode.d8.loss_mask: 0.5180, decode.d8.loss_dice: 0.7793, loss: 21.5966
2022-12-01 12:06:22,311 - mmseg - INFO - Iter [32650/40000]	lr: 2.445e-08, eta: 8:54:46, time: 4.115, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3377, decode.loss_mask: 0.5361, decode.loss_dice: 0.7792, decode.d0.loss_cls: 5.0631, decode.d0.loss_mask: 0.5308, decode.d0.loss_dice: 0.8409, decode.d1.loss_cls: 0.4533, decode.d1.loss_mask: 0.5667, decode.d1.loss_dice: 0.8399, decode.d2.loss_cls: 0.3992, decode.d2.loss_mask: 0.5527, decode.d2.loss_dice: 0.8061, decode.d3.loss_cls: 0.3724, decode.d3.loss_mask: 0.5444, decode.d3.loss_dice: 0.7944, decode.d4.loss_cls: 0.3623, decode.d4.loss_mask: 0.5398, decode.d4.loss_dice: 0.7886, decode.d5.loss_cls: 0.3501, decode.d5.loss_mask: 0.5398, decode.d5.loss_dice: 0.7825, decode.d6.loss_cls: 0.3468, decode.d6.loss_mask: 0.5377, decode.d6.loss_dice: 0.7793, decode.d7.loss_cls: 0.3450, decode.d7.loss_mask: 0.5371, decode.d7.loss_dice: 0.7810, decode.d8.loss_cls: 0.3400, decode.d8.loss_mask: 0.5375, decode.d8.loss_dice: 0.7828, loss: 21.7673
2022-12-01 12:09:47,995 - mmseg - INFO - Iter [32700/40000]	lr: 2.428e-08, eta: 8:51:05, time: 4.114, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3308, decode.loss_mask: 0.5285, decode.loss_dice: 0.7763, decode.d0.loss_cls: 5.0886, decode.d0.loss_mask: 0.5232, decode.d0.loss_dice: 0.8450, decode.d1.loss_cls: 0.4475, decode.d1.loss_mask: 0.5563, decode.d1.loss_dice: 0.8397, decode.d2.loss_cls: 0.3908, decode.d2.loss_mask: 0.5414, decode.d2.loss_dice: 0.8034, decode.d3.loss_cls: 0.3609, decode.d3.loss_mask: 0.5359, decode.d3.loss_dice: 0.7913, decode.d4.loss_cls: 0.3498, decode.d4.loss_mask: 0.5334, decode.d4.loss_dice: 0.7896, decode.d5.loss_cls: 0.3381, decode.d5.loss_mask: 0.5322, decode.d5.loss_dice: 0.7824, decode.d6.loss_cls: 0.3337, decode.d6.loss_mask: 0.5306, decode.d6.loss_dice: 0.7815, decode.d7.loss_cls: 0.3303, decode.d7.loss_mask: 0.5297, decode.d7.loss_dice: 0.7797, decode.d8.loss_cls: 0.3325, decode.d8.loss_mask: 0.5280, decode.d8.loss_dice: 0.7800, loss: 21.6113
2022-12-01 12:13:13,741 - mmseg - INFO - Iter [32750/40000]	lr: 2.411e-08, eta: 8:47:24, time: 4.115, data_time: 0.022, memory: 51902, decode.loss_cls: 0.3434, decode.loss_mask: 0.5304, decode.loss_dice: 0.7885, decode.d0.loss_cls: 5.0546, decode.d0.loss_mask: 0.5307, decode.d0.loss_dice: 0.8575, decode.d1.loss_cls: 0.4620, decode.d1.loss_mask: 0.5551, decode.d1.loss_dice: 0.8495, decode.d2.loss_cls: 0.4027, decode.d2.loss_mask: 0.5446, decode.d2.loss_dice: 0.8142, decode.d3.loss_cls: 0.3744, decode.d3.loss_mask: 0.5383, decode.d3.loss_dice: 0.7989, decode.d4.loss_cls: 0.3665, decode.d4.loss_mask: 0.5340, decode.d4.loss_dice: 0.7962, decode.d5.loss_cls: 0.3547, decode.d5.loss_mask: 0.5326, decode.d5.loss_dice: 0.7907, decode.d6.loss_cls: 0.3491, decode.d6.loss_mask: 0.5303, decode.d6.loss_dice: 0.7896, decode.d7.loss_cls: 0.3472, decode.d7.loss_mask: 0.5313, decode.d7.loss_dice: 0.7900, decode.d8.loss_cls: 0.3465, decode.d8.loss_mask: 0.5288, decode.d8.loss_dice: 0.7888, loss: 21.8212
2022-12-01 12:16:39,635 - mmseg - INFO - Iter [32800/40000]	lr: 2.395e-08, eta: 8:43:43, time: 4.118, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3343, decode.loss_mask: 0.5296, decode.loss_dice: 0.7853, decode.d0.loss_cls: 5.0691, decode.d0.loss_mask: 0.5248, decode.d0.loss_dice: 0.8524, decode.d1.loss_cls: 0.4493, decode.d1.loss_mask: 0.5622, decode.d1.loss_dice: 0.8489, decode.d2.loss_cls: 0.3941, decode.d2.loss_mask: 0.5489, decode.d2.loss_dice: 0.8169, decode.d3.loss_cls: 0.3653, decode.d3.loss_mask: 0.5392, decode.d3.loss_dice: 0.7967, decode.d4.loss_cls: 0.3534, decode.d4.loss_mask: 0.5386, decode.d4.loss_dice: 0.7957, decode.d5.loss_cls: 0.3439, decode.d5.loss_mask: 0.5363, decode.d5.loss_dice: 0.7919, decode.d6.loss_cls: 0.3378, decode.d6.loss_mask: 0.5326, decode.d6.loss_dice: 0.7867, decode.d7.loss_cls: 0.3365, decode.d7.loss_mask: 0.5326, decode.d7.loss_dice: 0.7844, decode.d8.loss_cls: 0.3333, decode.d8.loss_mask: 0.5317, decode.d8.loss_dice: 0.7852, loss: 21.7377
2022-12-01 12:20:05,145 - mmseg - INFO - Iter [32850/40000]	lr: 2.378e-08, eta: 8:40:02, time: 4.110, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3218, decode.loss_mask: 0.5184, decode.loss_dice: 0.7847, decode.d0.loss_cls: 5.0748, decode.d0.loss_mask: 0.5099, decode.d0.loss_dice: 0.8407, decode.d1.loss_cls: 0.4400, decode.d1.loss_mask: 0.5430, decode.d1.loss_dice: 0.8372, decode.d2.loss_cls: 0.3859, decode.d2.loss_mask: 0.5287, decode.d2.loss_dice: 0.8051, decode.d3.loss_cls: 0.3538, decode.d3.loss_mask: 0.5252, decode.d3.loss_dice: 0.7931, decode.d4.loss_cls: 0.3419, decode.d4.loss_mask: 0.5222, decode.d4.loss_dice: 0.7908, decode.d5.loss_cls: 0.3350, decode.d5.loss_mask: 0.5198, decode.d5.loss_dice: 0.7864, decode.d6.loss_cls: 0.3291, decode.d6.loss_mask: 0.5194, decode.d6.loss_dice: 0.7863, decode.d7.loss_cls: 0.3228, decode.d7.loss_mask: 0.5194, decode.d7.loss_dice: 0.7858, decode.d8.loss_cls: 0.3240, decode.d8.loss_mask: 0.5168, decode.d8.loss_dice: 0.7826, loss: 21.4444
2022-12-01 12:23:33,099 - mmseg - INFO - Iter [32900/40000]	lr: 2.362e-08, eta: 8:36:22, time: 4.159, data_time: 0.066, memory: 51902, decode.loss_cls: 0.3276, decode.loss_mask: 0.5345, decode.loss_dice: 0.7857, decode.d0.loss_cls: 5.0393, decode.d0.loss_mask: 0.5293, decode.d0.loss_dice: 0.8524, decode.d1.loss_cls: 0.4431, decode.d1.loss_mask: 0.5614, decode.d1.loss_dice: 0.8439, decode.d2.loss_cls: 0.3910, decode.d2.loss_mask: 0.5518, decode.d2.loss_dice: 0.8102, decode.d3.loss_cls: 0.3568, decode.d3.loss_mask: 0.5420, decode.d3.loss_dice: 0.7961, decode.d4.loss_cls: 0.3474, decode.d4.loss_mask: 0.5396, decode.d4.loss_dice: 0.7953, decode.d5.loss_cls: 0.3417, decode.d5.loss_mask: 0.5362, decode.d5.loss_dice: 0.7863, decode.d6.loss_cls: 0.3365, decode.d6.loss_mask: 0.5340, decode.d6.loss_dice: 0.7853, decode.d7.loss_cls: 0.3329, decode.d7.loss_mask: 0.5337, decode.d7.loss_dice: 0.7830, decode.d8.loss_cls: 0.3290, decode.d8.loss_mask: 0.5346, decode.d8.loss_dice: 0.7839, loss: 21.6644
2022-12-01 12:26:58,840 - mmseg - INFO - Iter [32950/40000]	lr: 2.345e-08, eta: 8:32:41, time: 4.115, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3259, decode.loss_mask: 0.5221, decode.loss_dice: 0.7798, decode.d0.loss_cls: 5.0566, decode.d0.loss_mask: 0.5178, decode.d0.loss_dice: 0.8396, decode.d1.loss_cls: 0.4431, decode.d1.loss_mask: 0.5509, decode.d1.loss_dice: 0.8369, decode.d2.loss_cls: 0.3921, decode.d2.loss_mask: 0.5365, decode.d2.loss_dice: 0.8038, decode.d3.loss_cls: 0.3544, decode.d3.loss_mask: 0.5308, decode.d3.loss_dice: 0.7888, decode.d4.loss_cls: 0.3427, decode.d4.loss_mask: 0.5266, decode.d4.loss_dice: 0.7878, decode.d5.loss_cls: 0.3348, decode.d5.loss_mask: 0.5267, decode.d5.loss_dice: 0.7850, decode.d6.loss_cls: 0.3279, decode.d6.loss_mask: 0.5253, decode.d6.loss_dice: 0.7810, decode.d7.loss_cls: 0.3242, decode.d7.loss_mask: 0.5251, decode.d7.loss_dice: 0.7818, decode.d8.loss_cls: 0.3266, decode.d8.loss_mask: 0.5229, decode.d8.loss_dice: 0.7780, loss: 21.4756
2022-12-01 12:30:24,351 - mmseg - INFO - Saving checkpoint at 33000 iterations
2022-12-01 12:31:12,850 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 12:31:12,850 - mmseg - INFO - Iter [33000/40000]	lr: 2.328e-08, eta: 8:29:10, time: 5.080, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3326, decode.loss_mask: 0.5339, decode.loss_dice: 0.7825, decode.d0.loss_cls: 5.0374, decode.d0.loss_mask: 0.5256, decode.d0.loss_dice: 0.8411, decode.d1.loss_cls: 0.4425, decode.d1.loss_mask: 0.5569, decode.d1.loss_dice: 0.8400, decode.d2.loss_cls: 0.3899, decode.d2.loss_mask: 0.5440, decode.d2.loss_dice: 0.8075, decode.d3.loss_cls: 0.3568, decode.d3.loss_mask: 0.5394, decode.d3.loss_dice: 0.7959, decode.d4.loss_cls: 0.3476, decode.d4.loss_mask: 0.5396, decode.d4.loss_dice: 0.7961, decode.d5.loss_cls: 0.3394, decode.d5.loss_mask: 0.5383, decode.d5.loss_dice: 0.7890, decode.d6.loss_cls: 0.3378, decode.d6.loss_mask: 0.5354, decode.d6.loss_dice: 0.7846, decode.d7.loss_cls: 0.3350, decode.d7.loss_mask: 0.5346, decode.d7.loss_dice: 0.7851, decode.d8.loss_cls: 0.3326, decode.d8.loss_mask: 0.5339, decode.d8.loss_dice: 0.7847, loss: 21.6398
2022-12-01 12:34:10,781 - mmseg - INFO - per class results:
2022-12-01 12:34:10,786 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 83.05 | 88.94 |
|       building      | 85.14 | 91.63 |
|         sky         | 95.24 |  97.6 |
|        floor        | 85.27 | 90.46 |
|         tree        | 78.52 | 88.95 |
|       ceiling       | 86.52 | 92.87 |
|         road        | 88.78 |  92.6 |
|         bed         | 93.79 | 97.32 |
|      windowpane     | 67.97 | 82.17 |
|        grass        | 69.26 | 83.23 |
|       cabinet       |  62.5 | 72.41 |
|       sidewalk      | 71.37 | 83.04 |
|        person       | 88.35 | 94.36 |
|        earth        | 43.02 |  57.3 |
|         door        | 65.86 | 84.26 |
|        table        | 73.01 |  82.7 |
|       mountain      | 62.71 | 72.34 |
|        plant        | 57.55 | 70.28 |
|       curtain       | 82.02 | 91.62 |
|        chair        | 69.42 | 80.85 |
|         car         | 89.41 | 95.18 |
|        water        | 66.75 | 87.06 |
|       painting      | 80.25 | 91.86 |
|         sofa        | 85.88 | 91.97 |
|        shelf        | 48.03 | 61.35 |
|        house        | 58.06 | 78.77 |
|         sea         | 79.26 |  88.5 |
|        mirror       | 80.77 |  91.0 |
|         rug         | 72.62 | 86.89 |
|        field        | 36.74 | 67.55 |
|       armchair      | 63.14 |  79.7 |
|         seat        | 65.23 | 90.18 |
|        fence        | 56.28 | 75.71 |
|         desk        | 58.04 | 84.35 |
|         rock        | 58.39 | 76.19 |
|       wardrobe      |  58.0 | 87.21 |
|         lamp        | 81.07 | 90.63 |
|       bathtub       | 92.07 | 93.71 |
|       railing       | 47.57 | 69.11 |
|       cushion       | 78.53 | 90.67 |
|         base        | 45.12 | 66.38 |
|         box         | 45.57 | 64.53 |
|        column       | 59.06 | 77.95 |
|      signboard      | 44.58 | 68.55 |
|   chest of drawers  | 47.17 | 73.28 |
|       counter       | 57.78 | 68.77 |
|         sand        | 62.69 | 87.87 |
|         sink        | 84.84 | 88.62 |
|      skyscraper     | 43.72 | 55.62 |
|      fireplace      | 82.92 | 95.32 |
|     refrigerator    | 84.41 | 94.98 |
|      grandstand     | 50.19 | 81.23 |
|         path        | 28.88 |  43.7 |
|        stairs       |  36.7 |  48.1 |
|        runway       | 74.35 | 93.72 |
|         case        |  67.8 | 87.49 |
|      pool table     | 95.94 | 98.82 |
|        pillow       | 73.51 | 82.96 |
|     screen door     | 82.92 | 91.21 |
|       stairway      | 56.06 | 71.92 |
|        river        | 26.74 | 31.14 |
|        bridge       | 63.52 |  86.3 |
|       bookcase      | 38.79 | 59.26 |
|        blind        | 46.53 | 57.83 |
|     coffee table    | 74.46 | 90.12 |
|        toilet       | 92.09 | 95.26 |
|        flower       | 45.13 | 72.14 |
|         book        | 61.71 |  82.9 |
|         hill        |  16.6 | 28.42 |
|        bench        | 75.76 | 84.35 |
|      countertop     | 74.12 | 90.94 |
|        stove        |  86.9 | 90.96 |
|         palm        | 56.16 |  82.5 |
|    kitchen island   | 47.69 | 90.52 |
|       computer      | 78.27 | 86.39 |
|     swivel chair    | 57.27 | 85.11 |
|         boat        | 59.08 | 89.98 |
|         bar         | 65.48 | 72.46 |
|    arcade machine   | 91.68 |  98.6 |
|        hovel        | 58.37 | 73.22 |
|         bus         | 95.36 | 97.29 |
|        towel        | 83.66 | 94.12 |
|        light        | 66.66 |  80.1 |
|        truck        | 53.93 | 70.73 |
|        tower        | 33.13 |  63.1 |
|      chandelier     | 77.39 |  87.3 |
|        awning       | 31.51 | 54.02 |
|     streetlight     | 43.69 | 71.35 |
|        booth        | 66.36 | 79.51 |
| television receiver |  79.0 | 92.37 |
|       airplane      |  89.0 | 96.46 |
|      dirt track     | 21.09 | 38.48 |
|       apparel       | 53.41 | 81.53 |
|         pole        | 31.79 | 44.37 |
|         land        |  6.2  |  9.48 |
|      bannister      | 25.49 | 36.38 |
|      escalator      | 65.72 | 83.65 |
|       ottoman       | 56.72 | 71.92 |
|        bottle       | 51.95 | 81.56 |
|        buffet       | 46.43 |  66.1 |
|        poster       | 40.38 | 60.48 |
|        stage        | 34.54 | 72.73 |
|         van         |  49.0 | 71.57 |
|         ship        |  30.0 | 31.63 |
|       fountain      |  57.4 | 64.42 |
|    conveyer belt    | 78.09 | 97.04 |
|        canopy       | 41.24 | 64.65 |
|        washer       | 90.88 | 93.51 |
|      plaything      | 37.48 | 57.76 |
|    swimming pool    | 52.68 | 76.07 |
|        stool        | 59.77 | 86.08 |
|        barrel       | 66.61 | 97.26 |
|        basket       | 46.74 | 72.58 |
|      waterfall      | 45.24 | 55.38 |
|         tent        |  95.0 | 98.27 |
|         bag         | 34.95 | 49.16 |
|       minibike      | 81.24 | 93.69 |
|        cradle       | 91.44 | 97.49 |
|         oven        | 66.71 | 83.83 |
|         ball        | 39.05 | 41.96 |
|         food        | 64.22 |  75.0 |
|         step        | 25.35 | 38.49 |
|         tank        | 64.96 | 67.55 |
|      trade name     | 28.52 |  36.9 |
|      microwave      | 89.45 | 94.22 |
|         pot         | 62.93 | 74.53 |
|        animal       | 80.95 | 83.44 |
|       bicycle       | 63.75 | 83.07 |
|         lake        |  0.15 |  0.15 |
|      dishwasher     | 72.89 | 90.35 |
|        screen       | 59.23 | 91.49 |
|       blanket       | 45.92 | 60.48 |
|      sculpture      | 75.06 | 90.57 |
|         hood        | 67.28 | 76.28 |
|        sconce       | 67.08 | 83.29 |
|         vase        | 58.44 | 81.18 |
|    traffic light    | 53.08 | 73.98 |
|         tray        |  34.2 | 52.41 |
|        ashcan       | 56.57 | 81.18 |
|         fan         | 73.44 | 87.09 |
|         pier        | 38.61 | 41.36 |
|      crt screen     |  1.5  |  4.04 |
|        plate        | 69.78 | 85.06 |
|       monitor       |  6.1  |  8.84 |
|    bulletin board   | 65.14 | 83.08 |
|        shower       |  15.7 | 28.77 |
|       radiator      | 74.78 |  93.4 |
|        glass        | 28.63 | 31.39 |
|        clock        | 62.13 | 77.87 |
|         flag        | 68.82 | 85.86 |
+---------------------+-------+-------+
2022-12-01 12:34:10,786 - mmseg - INFO - Summary:
2022-12-01 12:34:10,786 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 86.96 | 60.65 | 75.26 |
+-------+-------+-------+
2022-12-01 12:34:10,791 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 12:34:10,792 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8696, mIoU: 0.6065, mAcc: 0.7526, IoU.wall: 0.8305, IoU.building: 0.8514, IoU.sky: 0.9524, IoU.floor: 0.8527, IoU.tree: 0.7852, IoU.ceiling: 0.8652, IoU.road: 0.8878, IoU.bed : 0.9379, IoU.windowpane: 0.6797, IoU.grass: 0.6926, IoU.cabinet: 0.6250, IoU.sidewalk: 0.7137, IoU.person: 0.8835, IoU.earth: 0.4302, IoU.door: 0.6586, IoU.table: 0.7301, IoU.mountain: 0.6271, IoU.plant: 0.5755, IoU.curtain: 0.8202, IoU.chair: 0.6942, IoU.car: 0.8941, IoU.water: 0.6675, IoU.painting: 0.8025, IoU.sofa: 0.8588, IoU.shelf: 0.4803, IoU.house: 0.5806, IoU.sea: 0.7926, IoU.mirror: 0.8077, IoU.rug: 0.7262, IoU.field: 0.3674, IoU.armchair: 0.6314, IoU.seat: 0.6523, IoU.fence: 0.5628, IoU.desk: 0.5804, IoU.rock: 0.5839, IoU.wardrobe: 0.5800, IoU.lamp: 0.8107, IoU.bathtub: 0.9207, IoU.railing: 0.4757, IoU.cushion: 0.7853, IoU.base: 0.4512, IoU.box: 0.4557, IoU.column: 0.5906, IoU.signboard: 0.4458, IoU.chest of drawers: 0.4717, IoU.counter: 0.5778, IoU.sand: 0.6269, IoU.sink: 0.8484, IoU.skyscraper: 0.4372, IoU.fireplace: 0.8292, IoU.refrigerator: 0.8441, IoU.grandstand: 0.5019, IoU.path: 0.2888, IoU.stairs: 0.3670, IoU.runway: 0.7435, IoU.case: 0.6780, IoU.pool table: 0.9594, IoU.pillow: 0.7351, IoU.screen door: 0.8292, IoU.stairway: 0.5606, IoU.river: 0.2674, IoU.bridge: 0.6352, IoU.bookcase: 0.3879, IoU.blind: 0.4653, IoU.coffee table: 0.7446, IoU.toilet: 0.9209, IoU.flower: 0.4513, IoU.book: 0.6171, IoU.hill: 0.1660, IoU.bench: 0.7576, IoU.countertop: 0.7412, IoU.stove: 0.8690, IoU.palm: 0.5616, IoU.kitchen island: 0.4769, IoU.computer: 0.7827, IoU.swivel chair: 0.5727, IoU.boat: 0.5908, IoU.bar: 0.6548, IoU.arcade machine: 0.9168, IoU.hovel: 0.5837, IoU.bus: 0.9536, IoU.towel: 0.8366, IoU.light: 0.6666, IoU.truck: 0.5393, IoU.tower: 0.3313, IoU.chandelier: 0.7739, IoU.awning: 0.3151, IoU.streetlight: 0.4369, IoU.booth: 0.6636, IoU.television receiver: 0.7900, IoU.airplane: 0.8900, IoU.dirt track: 0.2109, IoU.apparel: 0.5341, IoU.pole: 0.3179, IoU.land: 0.0620, IoU.bannister: 0.2549, IoU.escalator: 0.6572, IoU.ottoman: 0.5672, IoU.bottle: 0.5195, IoU.buffet: 0.4643, IoU.poster: 0.4038, IoU.stage: 0.3454, IoU.van: 0.4900, IoU.ship: 0.3000, IoU.fountain: 0.5740, IoU.conveyer belt: 0.7809, IoU.canopy: 0.4124, IoU.washer: 0.9088, IoU.plaything: 0.3748, IoU.swimming pool: 0.5268, IoU.stool: 0.5977, IoU.barrel: 0.6661, IoU.basket: 0.4674, IoU.waterfall: 0.4524, IoU.tent: 0.9500, IoU.bag: 0.3495, IoU.minibike: 0.8124, IoU.cradle: 0.9144, IoU.oven: 0.6671, IoU.ball: 0.3905, IoU.food: 0.6422, IoU.step: 0.2535, IoU.tank: 0.6496, IoU.trade name: 0.2852, IoU.microwave: 0.8945, IoU.pot: 0.6293, IoU.animal: 0.8095, IoU.bicycle: 0.6375, IoU.lake: 0.0015, IoU.dishwasher: 0.7289, IoU.screen: 0.5923, IoU.blanket: 0.4592, IoU.sculpture: 0.7506, IoU.hood: 0.6728, IoU.sconce: 0.6708, IoU.vase: 0.5844, IoU.traffic light: 0.5308, IoU.tray: 0.3420, IoU.ashcan: 0.5657, IoU.fan: 0.7344, IoU.pier: 0.3861, IoU.crt screen: 0.0150, IoU.plate: 0.6978, IoU.monitor: 0.0610, IoU.bulletin board: 0.6514, IoU.shower: 0.1570, IoU.radiator: 0.7478, IoU.glass: 0.2863, IoU.clock: 0.6213, IoU.flag: 0.6882, Acc.wall: 0.8894, Acc.building: 0.9163, Acc.sky: 0.9760, Acc.floor: 0.9046, Acc.tree: 0.8895, Acc.ceiling: 0.9287, Acc.road: 0.9260, Acc.bed : 0.9732, Acc.windowpane: 0.8217, Acc.grass: 0.8323, Acc.cabinet: 0.7241, Acc.sidewalk: 0.8304, Acc.person: 0.9436, Acc.earth: 0.5730, Acc.door: 0.8426, Acc.table: 0.8270, Acc.mountain: 0.7234, Acc.plant: 0.7028, Acc.curtain: 0.9162, Acc.chair: 0.8085, Acc.car: 0.9518, Acc.water: 0.8706, Acc.painting: 0.9186, Acc.sofa: 0.9197, Acc.shelf: 0.6135, Acc.house: 0.7877, Acc.sea: 0.8850, Acc.mirror: 0.9100, Acc.rug: 0.8689, Acc.field: 0.6755, Acc.armchair: 0.7970, Acc.seat: 0.9018, Acc.fence: 0.7571, Acc.desk: 0.8435, Acc.rock: 0.7619, Acc.wardrobe: 0.8721, Acc.lamp: 0.9063, Acc.bathtub: 0.9371, Acc.railing: 0.6911, Acc.cushion: 0.9067, Acc.base: 0.6638, Acc.box: 0.6453, Acc.column: 0.7795, Acc.signboard: 0.6855, Acc.chest of drawers: 0.7328, Acc.counter: 0.6877, Acc.sand: 0.8787, Acc.sink: 0.8862, Acc.skyscraper: 0.5562, Acc.fireplace: 0.9532, Acc.refrigerator: 0.9498, Acc.grandstand: 0.8123, Acc.path: 0.4370, Acc.stairs: 0.4810, Acc.runway: 0.9372, Acc.case: 0.8749, Acc.pool table: 0.9882, Acc.pillow: 0.8296, Acc.screen door: 0.9121, Acc.stairway: 0.7192, Acc.river: 0.3114, Acc.bridge: 0.8630, Acc.bookcase: 0.5926, Acc.blind: 0.5783, Acc.coffee table: 0.9012, Acc.toilet: 0.9526, Acc.flower: 0.7214, Acc.book: 0.8290, Acc.hill: 0.2842, Acc.bench: 0.8435, Acc.countertop: 0.9094, Acc.stove: 0.9096, Acc.palm: 0.8250, Acc.kitchen island: 0.9052, Acc.computer: 0.8639, Acc.swivel chair: 0.8511, Acc.boat: 0.8998, Acc.bar: 0.7246, Acc.arcade machine: 0.9860, Acc.hovel: 0.7322, Acc.bus: 0.9729, Acc.towel: 0.9412, Acc.light: 0.8010, Acc.truck: 0.7073, Acc.tower: 0.6310, Acc.chandelier: 0.8730, Acc.awning: 0.5402, Acc.streetlight: 0.7135, Acc.booth: 0.7951, Acc.television receiver: 0.9237, Acc.airplane: 0.9646, Acc.dirt track: 0.3848, Acc.apparel: 0.8153, Acc.pole: 0.4437, Acc.land: 0.0948, Acc.bannister: 0.3638, Acc.escalator: 0.8365, Acc.ottoman: 0.7192, Acc.bottle: 0.8156, Acc.buffet: 0.6610, Acc.poster: 0.6048, Acc.stage: 0.7273, Acc.van: 0.7157, Acc.ship: 0.3163, Acc.fountain: 0.6442, Acc.conveyer belt: 0.9704, Acc.canopy: 0.6465, Acc.washer: 0.9351, Acc.plaything: 0.5776, Acc.swimming pool: 0.7607, Acc.stool: 0.8608, Acc.barrel: 0.9726, Acc.basket: 0.7258, Acc.waterfall: 0.5538, Acc.tent: 0.9827, Acc.bag: 0.4916, Acc.minibike: 0.9369, Acc.cradle: 0.9749, Acc.oven: 0.8383, Acc.ball: 0.4196, Acc.food: 0.7500, Acc.step: 0.3849, Acc.tank: 0.6755, Acc.trade name: 0.3690, Acc.microwave: 0.9422, Acc.pot: 0.7453, Acc.animal: 0.8344, Acc.bicycle: 0.8307, Acc.lake: 0.0015, Acc.dishwasher: 0.9035, Acc.screen: 0.9149, Acc.blanket: 0.6048, Acc.sculpture: 0.9057, Acc.hood: 0.7628, Acc.sconce: 0.8329, Acc.vase: 0.8118, Acc.traffic light: 0.7398, Acc.tray: 0.5241, Acc.ashcan: 0.8118, Acc.fan: 0.8709, Acc.pier: 0.4136, Acc.crt screen: 0.0404, Acc.plate: 0.8506, Acc.monitor: 0.0884, Acc.bulletin board: 0.8308, Acc.shower: 0.2877, Acc.radiator: 0.9340, Acc.glass: 0.3139, Acc.clock: 0.7787, Acc.flag: 0.8586
2022-12-01 12:37:37,041 - mmseg - INFO - Iter [33050/40000]	lr: 2.312e-08, eta: 8:26:07, time: 7.684, data_time: 3.578, memory: 51902, decode.loss_cls: 0.3408, decode.loss_mask: 0.5268, decode.loss_dice: 0.7920, decode.d0.loss_cls: 5.0762, decode.d0.loss_mask: 0.5220, decode.d0.loss_dice: 0.8582, decode.d1.loss_cls: 0.4554, decode.d1.loss_mask: 0.5563, decode.d1.loss_dice: 0.8530, decode.d2.loss_cls: 0.3984, decode.d2.loss_mask: 0.5453, decode.d2.loss_dice: 0.8208, decode.d3.loss_cls: 0.3723, decode.d3.loss_mask: 0.5343, decode.d3.loss_dice: 0.8071, decode.d4.loss_cls: 0.3617, decode.d4.loss_mask: 0.5318, decode.d4.loss_dice: 0.8025, decode.d5.loss_cls: 0.3504, decode.d5.loss_mask: 0.5305, decode.d5.loss_dice: 0.7973, decode.d6.loss_cls: 0.3485, decode.d6.loss_mask: 0.5284, decode.d6.loss_dice: 0.7921, decode.d7.loss_cls: 0.3433, decode.d7.loss_mask: 0.5261, decode.d7.loss_dice: 0.7932, decode.d8.loss_cls: 0.3427, decode.d8.loss_mask: 0.5270, decode.d8.loss_dice: 0.7941, loss: 21.8286
2022-12-01 12:41:02,542 - mmseg - INFO - Iter [33100/40000]	lr: 2.295e-08, eta: 8:22:26, time: 4.110, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3302, decode.loss_mask: 0.5213, decode.loss_dice: 0.7792, decode.d0.loss_cls: 5.0601, decode.d0.loss_mask: 0.5123, decode.d0.loss_dice: 0.8443, decode.d1.loss_cls: 0.4478, decode.d1.loss_mask: 0.5457, decode.d1.loss_dice: 0.8391, decode.d2.loss_cls: 0.3878, decode.d2.loss_mask: 0.5342, decode.d2.loss_dice: 0.8061, decode.d3.loss_cls: 0.3535, decode.d3.loss_mask: 0.5290, decode.d3.loss_dice: 0.7912, decode.d4.loss_cls: 0.3489, decode.d4.loss_mask: 0.5231, decode.d4.loss_dice: 0.7841, decode.d5.loss_cls: 0.3372, decode.d5.loss_mask: 0.5225, decode.d5.loss_dice: 0.7828, decode.d6.loss_cls: 0.3336, decode.d6.loss_mask: 0.5195, decode.d6.loss_dice: 0.7800, decode.d7.loss_cls: 0.3293, decode.d7.loss_mask: 0.5204, decode.d7.loss_dice: 0.7808, decode.d8.loss_cls: 0.3280, decode.d8.loss_mask: 0.5202, decode.d8.loss_dice: 0.7789, loss: 21.4712
2022-12-01 12:44:28,043 - mmseg - INFO - Iter [33150/40000]	lr: 2.278e-08, eta: 8:18:45, time: 4.110, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3324, decode.loss_mask: 0.5161, decode.loss_dice: 0.7710, decode.d0.loss_cls: 5.0618, decode.d0.loss_mask: 0.5086, decode.d0.loss_dice: 0.8347, decode.d1.loss_cls: 0.4437, decode.d1.loss_mask: 0.5431, decode.d1.loss_dice: 0.8316, decode.d2.loss_cls: 0.3879, decode.d2.loss_mask: 0.5284, decode.d2.loss_dice: 0.7963, decode.d3.loss_cls: 0.3536, decode.d3.loss_mask: 0.5219, decode.d3.loss_dice: 0.7818, decode.d4.loss_cls: 0.3459, decode.d4.loss_mask: 0.5196, decode.d4.loss_dice: 0.7785, decode.d5.loss_cls: 0.3355, decode.d5.loss_mask: 0.5150, decode.d5.loss_dice: 0.7767, decode.d6.loss_cls: 0.3353, decode.d6.loss_mask: 0.5168, decode.d6.loss_dice: 0.7754, decode.d7.loss_cls: 0.3307, decode.d7.loss_mask: 0.5139, decode.d7.loss_dice: 0.7765, decode.d8.loss_cls: 0.3311, decode.d8.loss_mask: 0.5149, decode.d8.loss_dice: 0.7750, loss: 21.3537
2022-12-01 12:47:53,615 - mmseg - INFO - Iter [33200/40000]	lr: 2.262e-08, eta: 8:15:04, time: 4.111, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3398, decode.loss_mask: 0.5336, decode.loss_dice: 0.7864, decode.d0.loss_cls: 5.0379, decode.d0.loss_mask: 0.5286, decode.d0.loss_dice: 0.8565, decode.d1.loss_cls: 0.4582, decode.d1.loss_mask: 0.5622, decode.d1.loss_dice: 0.8491, decode.d2.loss_cls: 0.4019, decode.d2.loss_mask: 0.5486, decode.d2.loss_dice: 0.8137, decode.d3.loss_cls: 0.3658, decode.d3.loss_mask: 0.5425, decode.d3.loss_dice: 0.8024, decode.d4.loss_cls: 0.3628, decode.d4.loss_mask: 0.5373, decode.d4.loss_dice: 0.7943, decode.d5.loss_cls: 0.3524, decode.d5.loss_mask: 0.5372, decode.d5.loss_dice: 0.7898, decode.d6.loss_cls: 0.3454, decode.d6.loss_mask: 0.5355, decode.d6.loss_dice: 0.7927, decode.d7.loss_cls: 0.3443, decode.d7.loss_mask: 0.5345, decode.d7.loss_dice: 0.7905, decode.d8.loss_cls: 0.3418, decode.d8.loss_mask: 0.5343, decode.d8.loss_dice: 0.7912, loss: 21.8113
2022-12-01 12:51:19,543 - mmseg - INFO - Iter [33250/40000]	lr: 2.245e-08, eta: 8:11:23, time: 4.119, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3290, decode.loss_mask: 0.5342, decode.loss_dice: 0.7893, decode.d0.loss_cls: 5.0392, decode.d0.loss_mask: 0.5247, decode.d0.loss_dice: 0.8468, decode.d1.loss_cls: 0.4484, decode.d1.loss_mask: 0.5597, decode.d1.loss_dice: 0.8477, decode.d2.loss_cls: 0.3912, decode.d2.loss_mask: 0.5465, decode.d2.loss_dice: 0.8154, decode.d3.loss_cls: 0.3635, decode.d3.loss_mask: 0.5376, decode.d3.loss_dice: 0.7991, decode.d4.loss_cls: 0.3493, decode.d4.loss_mask: 0.5373, decode.d4.loss_dice: 0.7957, decode.d5.loss_cls: 0.3418, decode.d5.loss_mask: 0.5337, decode.d5.loss_dice: 0.7909, decode.d6.loss_cls: 0.3359, decode.d6.loss_mask: 0.5322, decode.d6.loss_dice: 0.7890, decode.d7.loss_cls: 0.3340, decode.d7.loss_mask: 0.5308, decode.d7.loss_dice: 0.7898, decode.d8.loss_cls: 0.3313, decode.d8.loss_mask: 0.5324, decode.d8.loss_dice: 0.7914, loss: 21.6878
2022-12-01 12:54:44,880 - mmseg - INFO - Iter [33300/40000]	lr: 2.229e-08, eta: 8:07:42, time: 4.107, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3375, decode.loss_mask: 0.5228, decode.loss_dice: 0.7803, decode.d0.loss_cls: 5.0533, decode.d0.loss_mask: 0.5189, decode.d0.loss_dice: 0.8470, decode.d1.loss_cls: 0.4526, decode.d1.loss_mask: 0.5463, decode.d1.loss_dice: 0.8357, decode.d2.loss_cls: 0.3971, decode.d2.loss_mask: 0.5350, decode.d2.loss_dice: 0.8042, decode.d3.loss_cls: 0.3657, decode.d3.loss_mask: 0.5287, decode.d3.loss_dice: 0.7923, decode.d4.loss_cls: 0.3561, decode.d4.loss_mask: 0.5276, decode.d4.loss_dice: 0.7895, decode.d5.loss_cls: 0.3480, decode.d5.loss_mask: 0.5256, decode.d5.loss_dice: 0.7838, decode.d6.loss_cls: 0.3425, decode.d6.loss_mask: 0.5229, decode.d6.loss_dice: 0.7796, decode.d7.loss_cls: 0.3398, decode.d7.loss_mask: 0.5221, decode.d7.loss_dice: 0.7827, decode.d8.loss_cls: 0.3369, decode.d8.loss_mask: 0.5224, decode.d8.loss_dice: 0.7789, loss: 21.5759
2022-12-01 12:58:10,733 - mmseg - INFO - Iter [33350/40000]	lr: 2.212e-08, eta: 8:04:01, time: 4.117, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3203, decode.loss_mask: 0.5052, decode.loss_dice: 0.7645, decode.d0.loss_cls: 5.0637, decode.d0.loss_mask: 0.4990, decode.d0.loss_dice: 0.8248, decode.d1.loss_cls: 0.4266, decode.d1.loss_mask: 0.5334, decode.d1.loss_dice: 0.8285, decode.d2.loss_cls: 0.3773, decode.d2.loss_mask: 0.5201, decode.d2.loss_dice: 0.7917, decode.d3.loss_cls: 0.3463, decode.d3.loss_mask: 0.5140, decode.d3.loss_dice: 0.7796, decode.d4.loss_cls: 0.3365, decode.d4.loss_mask: 0.5107, decode.d4.loss_dice: 0.7767, decode.d5.loss_cls: 0.3299, decode.d5.loss_mask: 0.5087, decode.d5.loss_dice: 0.7717, decode.d6.loss_cls: 0.3239, decode.d6.loss_mask: 0.5089, decode.d6.loss_dice: 0.7708, decode.d7.loss_cls: 0.3213, decode.d7.loss_mask: 0.5072, decode.d7.loss_dice: 0.7692, decode.d8.loss_cls: 0.3234, decode.d8.loss_mask: 0.5062, decode.d8.loss_dice: 0.7709, loss: 21.1310
2022-12-01 13:01:36,397 - mmseg - INFO - Iter [33400/40000]	lr: 2.195e-08, eta: 8:00:20, time: 4.113, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3342, decode.loss_mask: 0.5380, decode.loss_dice: 0.7942, decode.d0.loss_cls: 5.0358, decode.d0.loss_mask: 0.5321, decode.d0.loss_dice: 0.8575, decode.d1.loss_cls: 0.4451, decode.d1.loss_mask: 0.5615, decode.d1.loss_dice: 0.8512, decode.d2.loss_cls: 0.3939, decode.d2.loss_mask: 0.5494, decode.d2.loss_dice: 0.8152, decode.d3.loss_cls: 0.3597, decode.d3.loss_mask: 0.5418, decode.d3.loss_dice: 0.8055, decode.d4.loss_cls: 0.3534, decode.d4.loss_mask: 0.5387, decode.d4.loss_dice: 0.8017, decode.d5.loss_cls: 0.3447, decode.d5.loss_mask: 0.5365, decode.d5.loss_dice: 0.7972, decode.d6.loss_cls: 0.3375, decode.d6.loss_mask: 0.5375, decode.d6.loss_dice: 0.7957, decode.d7.loss_cls: 0.3392, decode.d7.loss_mask: 0.5362, decode.d7.loss_dice: 0.7949, decode.d8.loss_cls: 0.3357, decode.d8.loss_mask: 0.5376, decode.d8.loss_dice: 0.7917, loss: 21.7932
2022-12-01 13:05:01,796 - mmseg - INFO - Iter [33450/40000]	lr: 2.179e-08, eta: 7:56:39, time: 4.108, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3209, decode.loss_mask: 0.5284, decode.loss_dice: 0.7841, decode.d0.loss_cls: 5.0109, decode.d0.loss_mask: 0.5266, decode.d0.loss_dice: 0.8392, decode.d1.loss_cls: 0.4297, decode.d1.loss_mask: 0.5577, decode.d1.loss_dice: 0.8370, decode.d2.loss_cls: 0.3777, decode.d2.loss_mask: 0.5443, decode.d2.loss_dice: 0.8070, decode.d3.loss_cls: 0.3459, decode.d3.loss_mask: 0.5373, decode.d3.loss_dice: 0.7904, decode.d4.loss_cls: 0.3353, decode.d4.loss_mask: 0.5338, decode.d4.loss_dice: 0.7903, decode.d5.loss_cls: 0.3257, decode.d5.loss_mask: 0.5334, decode.d5.loss_dice: 0.7837, decode.d6.loss_cls: 0.3220, decode.d6.loss_mask: 0.5308, decode.d6.loss_dice: 0.7801, decode.d7.loss_cls: 0.3199, decode.d7.loss_mask: 0.5301, decode.d7.loss_dice: 0.7811, decode.d8.loss_cls: 0.3188, decode.d8.loss_mask: 0.5294, decode.d8.loss_dice: 0.7823, loss: 21.4338
2022-12-01 13:08:29,711 - mmseg - INFO - Iter [33500/40000]	lr: 2.162e-08, eta: 7:52:59, time: 4.158, data_time: 0.067, memory: 51902, decode.loss_cls: 0.3378, decode.loss_mask: 0.5198, decode.loss_dice: 0.7739, decode.d0.loss_cls: 5.0333, decode.d0.loss_mask: 0.5209, decode.d0.loss_dice: 0.8475, decode.d1.loss_cls: 0.4551, decode.d1.loss_mask: 0.5476, decode.d1.loss_dice: 0.8321, decode.d2.loss_cls: 0.3984, decode.d2.loss_mask: 0.5356, decode.d2.loss_dice: 0.8012, decode.d3.loss_cls: 0.3641, decode.d3.loss_mask: 0.5284, decode.d3.loss_dice: 0.7837, decode.d4.loss_cls: 0.3563, decode.d4.loss_mask: 0.5247, decode.d4.loss_dice: 0.7835, decode.d5.loss_cls: 0.3464, decode.d5.loss_mask: 0.5237, decode.d5.loss_dice: 0.7786, decode.d6.loss_cls: 0.3424, decode.d6.loss_mask: 0.5215, decode.d6.loss_dice: 0.7748, decode.d7.loss_cls: 0.3393, decode.d7.loss_mask: 0.5201, decode.d7.loss_dice: 0.7759, decode.d8.loss_cls: 0.3383, decode.d8.loss_mask: 0.5206, decode.d8.loss_dice: 0.7751, loss: 21.5007
2022-12-01 13:11:55,358 - mmseg - INFO - Iter [33550/40000]	lr: 2.145e-08, eta: 7:49:18, time: 4.113, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3298, decode.loss_mask: 0.5242, decode.loss_dice: 0.7770, decode.d0.loss_cls: 5.0293, decode.d0.loss_mask: 0.5158, decode.d0.loss_dice: 0.8420, decode.d1.loss_cls: 0.4416, decode.d1.loss_mask: 0.5530, decode.d1.loss_dice: 0.8352, decode.d2.loss_cls: 0.3897, decode.d2.loss_mask: 0.5380, decode.d2.loss_dice: 0.8079, decode.d3.loss_cls: 0.3548, decode.d3.loss_mask: 0.5327, decode.d3.loss_dice: 0.7898, decode.d4.loss_cls: 0.3434, decode.d4.loss_mask: 0.5299, decode.d4.loss_dice: 0.7901, decode.d5.loss_cls: 0.3373, decode.d5.loss_mask: 0.5256, decode.d5.loss_dice: 0.7852, decode.d6.loss_cls: 0.3315, decode.d6.loss_mask: 0.5237, decode.d6.loss_dice: 0.7797, decode.d7.loss_cls: 0.3284, decode.d7.loss_mask: 0.5246, decode.d7.loss_dice: 0.7808, decode.d8.loss_cls: 0.3298, decode.d8.loss_mask: 0.5234, decode.d8.loss_dice: 0.7789, loss: 21.4733
2022-12-01 13:15:21,233 - mmseg - INFO - Iter [33600/40000]	lr: 2.129e-08, eta: 7:45:37, time: 4.117, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3268, decode.loss_mask: 0.5225, decode.loss_dice: 0.7716, decode.d0.loss_cls: 5.0466, decode.d0.loss_mask: 0.5195, decode.d0.loss_dice: 0.8397, decode.d1.loss_cls: 0.4392, decode.d1.loss_mask: 0.5544, decode.d1.loss_dice: 0.8330, decode.d2.loss_cls: 0.3882, decode.d2.loss_mask: 0.5396, decode.d2.loss_dice: 0.8009, decode.d3.loss_cls: 0.3532, decode.d3.loss_mask: 0.5325, decode.d3.loss_dice: 0.7867, decode.d4.loss_cls: 0.3440, decode.d4.loss_mask: 0.5310, decode.d4.loss_dice: 0.7852, decode.d5.loss_cls: 0.3328, decode.d5.loss_mask: 0.5269, decode.d5.loss_dice: 0.7827, decode.d6.loss_cls: 0.3258, decode.d6.loss_mask: 0.5280, decode.d6.loss_dice: 0.7802, decode.d7.loss_cls: 0.3246, decode.d7.loss_mask: 0.5247, decode.d7.loss_dice: 0.7782, decode.d8.loss_cls: 0.3236, decode.d8.loss_mask: 0.5252, decode.d8.loss_dice: 0.7808, loss: 21.4478
2022-12-01 13:18:46,779 - mmseg - INFO - Iter [33650/40000]	lr: 2.112e-08, eta: 7:41:57, time: 4.111, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3419, decode.loss_mask: 0.5302, decode.loss_dice: 0.7882, decode.d0.loss_cls: 5.0201, decode.d0.loss_mask: 0.5282, decode.d0.loss_dice: 0.8565, decode.d1.loss_cls: 0.4508, decode.d1.loss_mask: 0.5576, decode.d1.loss_dice: 0.8474, decode.d2.loss_cls: 0.4000, decode.d2.loss_mask: 0.5442, decode.d2.loss_dice: 0.8128, decode.d3.loss_cls: 0.3676, decode.d3.loss_mask: 0.5375, decode.d3.loss_dice: 0.8011, decode.d4.loss_cls: 0.3595, decode.d4.loss_mask: 0.5365, decode.d4.loss_dice: 0.7961, decode.d5.loss_cls: 0.3488, decode.d5.loss_mask: 0.5354, decode.d5.loss_dice: 0.7950, decode.d6.loss_cls: 0.3439, decode.d6.loss_mask: 0.5326, decode.d6.loss_dice: 0.7895, decode.d7.loss_cls: 0.3458, decode.d7.loss_mask: 0.5327, decode.d7.loss_dice: 0.7899, decode.d8.loss_cls: 0.3406, decode.d8.loss_mask: 0.5321, decode.d8.loss_dice: 0.7909, loss: 21.7535
2022-12-01 13:22:12,564 - mmseg - INFO - Iter [33700/40000]	lr: 2.096e-08, eta: 7:38:16, time: 4.116, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3253, decode.loss_mask: 0.5284, decode.loss_dice: 0.7888, decode.d0.loss_cls: 5.0089, decode.d0.loss_mask: 0.5260, decode.d0.loss_dice: 0.8511, decode.d1.loss_cls: 0.4431, decode.d1.loss_mask: 0.5564, decode.d1.loss_dice: 0.8463, decode.d2.loss_cls: 0.3838, decode.d2.loss_mask: 0.5415, decode.d2.loss_dice: 0.8119, decode.d3.loss_cls: 0.3495, decode.d3.loss_mask: 0.5363, decode.d3.loss_dice: 0.7965, decode.d4.loss_cls: 0.3418, decode.d4.loss_mask: 0.5317, decode.d4.loss_dice: 0.7952, decode.d5.loss_cls: 0.3333, decode.d5.loss_mask: 0.5284, decode.d5.loss_dice: 0.7890, decode.d6.loss_cls: 0.3263, decode.d6.loss_mask: 0.5290, decode.d6.loss_dice: 0.7879, decode.d7.loss_cls: 0.3255, decode.d7.loss_mask: 0.5291, decode.d7.loss_dice: 0.7877, decode.d8.loss_cls: 0.3251, decode.d8.loss_mask: 0.5287, decode.d8.loss_dice: 0.7887, loss: 21.5411
2022-12-01 13:25:38,408 - mmseg - INFO - Iter [33750/40000]	lr: 2.079e-08, eta: 7:34:36, time: 4.117, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3165, decode.loss_mask: 0.5234, decode.loss_dice: 0.7640, decode.d0.loss_cls: 5.0115, decode.d0.loss_mask: 0.5148, decode.d0.loss_dice: 0.8221, decode.d1.loss_cls: 0.4326, decode.d1.loss_mask: 0.5470, decode.d1.loss_dice: 0.8189, decode.d2.loss_cls: 0.3765, decode.d2.loss_mask: 0.5360, decode.d2.loss_dice: 0.7919, decode.d3.loss_cls: 0.3407, decode.d3.loss_mask: 0.5293, decode.d3.loss_dice: 0.7756, decode.d4.loss_cls: 0.3344, decode.d4.loss_mask: 0.5259, decode.d4.loss_dice: 0.7706, decode.d5.loss_cls: 0.3250, decode.d5.loss_mask: 0.5263, decode.d5.loss_dice: 0.7680, decode.d6.loss_cls: 0.3181, decode.d6.loss_mask: 0.5245, decode.d6.loss_dice: 0.7636, decode.d7.loss_cls: 0.3160, decode.d7.loss_mask: 0.5229, decode.d7.loss_dice: 0.7684, decode.d8.loss_cls: 0.3147, decode.d8.loss_mask: 0.5232, decode.d8.loss_dice: 0.7699, loss: 21.1727
2022-12-01 13:29:03,771 - mmseg - INFO - Iter [33800/40000]	lr: 2.062e-08, eta: 7:30:55, time: 4.107, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3260, decode.loss_mask: 0.5375, decode.loss_dice: 0.7909, decode.d0.loss_cls: 5.0109, decode.d0.loss_mask: 0.5287, decode.d0.loss_dice: 0.8539, decode.d1.loss_cls: 0.4444, decode.d1.loss_mask: 0.5625, decode.d1.loss_dice: 0.8492, decode.d2.loss_cls: 0.3920, decode.d2.loss_mask: 0.5488, decode.d2.loss_dice: 0.8139, decode.d3.loss_cls: 0.3576, decode.d3.loss_mask: 0.5436, decode.d3.loss_dice: 0.7991, decode.d4.loss_cls: 0.3457, decode.d4.loss_mask: 0.5403, decode.d4.loss_dice: 0.7984, decode.d5.loss_cls: 0.3347, decode.d5.loss_mask: 0.5401, decode.d5.loss_dice: 0.7932, decode.d6.loss_cls: 0.3355, decode.d6.loss_mask: 0.5366, decode.d6.loss_dice: 0.7906, decode.d7.loss_cls: 0.3279, decode.d7.loss_mask: 0.5368, decode.d7.loss_dice: 0.7936, decode.d8.loss_cls: 0.3266, decode.d8.loss_mask: 0.5382, decode.d8.loss_dice: 0.7898, loss: 21.6870
2022-12-01 13:32:29,835 - mmseg - INFO - Iter [33850/40000]	lr: 2.046e-08, eta: 7:27:15, time: 4.121, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3362, decode.loss_mask: 0.5007, decode.loss_dice: 0.7723, decode.d0.loss_cls: 5.0379, decode.d0.loss_mask: 0.4966, decode.d0.loss_dice: 0.8406, decode.d1.loss_cls: 0.4506, decode.d1.loss_mask: 0.5308, decode.d1.loss_dice: 0.8338, decode.d2.loss_cls: 0.3991, decode.d2.loss_mask: 0.5156, decode.d2.loss_dice: 0.7982, decode.d3.loss_cls: 0.3606, decode.d3.loss_mask: 0.5098, decode.d3.loss_dice: 0.7853, decode.d4.loss_cls: 0.3539, decode.d4.loss_mask: 0.5060, decode.d4.loss_dice: 0.7820, decode.d5.loss_cls: 0.3421, decode.d5.loss_mask: 0.5055, decode.d5.loss_dice: 0.7780, decode.d6.loss_cls: 0.3406, decode.d6.loss_mask: 0.5029, decode.d6.loss_dice: 0.7755, decode.d7.loss_cls: 0.3355, decode.d7.loss_mask: 0.5022, decode.d7.loss_dice: 0.7754, decode.d8.loss_cls: 0.3348, decode.d8.loss_mask: 0.5019, decode.d8.loss_dice: 0.7740, loss: 21.2785
2022-12-01 13:35:55,710 - mmseg - INFO - Iter [33900/40000]	lr: 2.029e-08, eta: 7:23:34, time: 4.117, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3411, decode.loss_mask: 0.5282, decode.loss_dice: 0.7927, decode.d0.loss_cls: 5.0297, decode.d0.loss_mask: 0.5267, decode.d0.loss_dice: 0.8605, decode.d1.loss_cls: 0.4511, decode.d1.loss_mask: 0.5546, decode.d1.loss_dice: 0.8511, decode.d2.loss_cls: 0.4036, decode.d2.loss_mask: 0.5425, decode.d2.loss_dice: 0.8184, decode.d3.loss_cls: 0.3693, decode.d3.loss_mask: 0.5353, decode.d3.loss_dice: 0.8085, decode.d4.loss_cls: 0.3612, decode.d4.loss_mask: 0.5319, decode.d4.loss_dice: 0.8038, decode.d5.loss_cls: 0.3484, decode.d5.loss_mask: 0.5328, decode.d5.loss_dice: 0.7990, decode.d6.loss_cls: 0.3464, decode.d6.loss_mask: 0.5306, decode.d6.loss_dice: 0.7985, decode.d7.loss_cls: 0.3385, decode.d7.loss_mask: 0.5296, decode.d7.loss_dice: 0.7982, decode.d8.loss_cls: 0.3434, decode.d8.loss_mask: 0.5262, decode.d8.loss_dice: 0.7900, loss: 21.7922
2022-12-01 13:39:21,150 - mmseg - INFO - Iter [33950/40000]	lr: 2.012e-08, eta: 7:19:54, time: 4.109, data_time: 0.021, memory: 51902, decode.loss_cls: 0.3315, decode.loss_mask: 0.5282, decode.loss_dice: 0.7907, decode.d0.loss_cls: 5.0006, decode.d0.loss_mask: 0.5213, decode.d0.loss_dice: 0.8540, decode.d1.loss_cls: 0.4493, decode.d1.loss_mask: 0.5525, decode.d1.loss_dice: 0.8465, decode.d2.loss_cls: 0.3931, decode.d2.loss_mask: 0.5387, decode.d2.loss_dice: 0.8181, decode.d3.loss_cls: 0.3575, decode.d3.loss_mask: 0.5328, decode.d3.loss_dice: 0.8019, decode.d4.loss_cls: 0.3491, decode.d4.loss_mask: 0.5322, decode.d4.loss_dice: 0.7987, decode.d5.loss_cls: 0.3374, decode.d5.loss_mask: 0.5309, decode.d5.loss_dice: 0.7948, decode.d6.loss_cls: 0.3315, decode.d6.loss_mask: 0.5310, decode.d6.loss_dice: 0.7929, decode.d7.loss_cls: 0.3309, decode.d7.loss_mask: 0.5292, decode.d7.loss_dice: 0.7936, decode.d8.loss_cls: 0.3298, decode.d8.loss_mask: 0.5285, decode.d8.loss_dice: 0.7915, loss: 21.6187
2022-12-01 13:42:46,870 - mmseg - INFO - Saving checkpoint at 34000 iterations
2022-12-01 13:43:34,735 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 13:43:34,735 - mmseg - INFO - Iter [34000/40000]	lr: 1.996e-08, eta: 7:16:22, time: 5.072, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3357, decode.loss_mask: 0.5181, decode.loss_dice: 0.7725, decode.d0.loss_cls: 5.0080, decode.d0.loss_mask: 0.5142, decode.d0.loss_dice: 0.8405, decode.d1.loss_cls: 0.4518, decode.d1.loss_mask: 0.5451, decode.d1.loss_dice: 0.8267, decode.d2.loss_cls: 0.3957, decode.d2.loss_mask: 0.5340, decode.d2.loss_dice: 0.7970, decode.d3.loss_cls: 0.3644, decode.d3.loss_mask: 0.5272, decode.d3.loss_dice: 0.7844, decode.d4.loss_cls: 0.3527, decode.d4.loss_mask: 0.5245, decode.d4.loss_dice: 0.7810, decode.d5.loss_cls: 0.3443, decode.d5.loss_mask: 0.5202, decode.d5.loss_dice: 0.7772, decode.d6.loss_cls: 0.3404, decode.d6.loss_mask: 0.5168, decode.d6.loss_dice: 0.7701, decode.d7.loss_cls: 0.3385, decode.d7.loss_mask: 0.5173, decode.d7.loss_dice: 0.7714, decode.d8.loss_cls: 0.3357, decode.d8.loss_mask: 0.5186, decode.d8.loss_dice: 0.7712, loss: 21.3953
2022-12-01 13:46:32,717 - mmseg - INFO - per class results:
2022-12-01 13:46:32,722 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        |  83.2 | 89.62 |
|       building      | 85.23 | 91.88 |
|         sky         | 95.23 | 97.48 |
|        floor        | 85.33 | 90.57 |
|         tree        | 78.81 | 89.09 |
|       ceiling       | 86.97 | 92.76 |
|         road        | 88.45 | 92.27 |
|         bed         | 93.75 | 97.31 |
|      windowpane     | 68.59 | 82.08 |
|        grass        | 68.49 | 81.78 |
|       cabinet       | 62.96 | 71.96 |
|       sidewalk      | 72.82 | 85.08 |
|        person       | 88.34 | 94.16 |
|        earth        | 42.43 | 57.69 |
|         door        | 65.18 | 81.87 |
|        table        | 71.92 | 80.67 |
|       mountain      | 61.52 | 69.81 |
|        plant        | 57.71 | 70.48 |
|       curtain       | 81.74 | 91.13 |
|        chair        | 68.86 | 79.88 |
|         car         | 89.68 | 95.24 |
|        water        | 70.18 | 86.02 |
|       painting      | 79.87 | 91.23 |
|         sofa        | 85.33 | 91.45 |
|        shelf        | 49.78 | 64.87 |
|        house        | 53.82 | 71.69 |
|         sea         | 80.74 | 90.52 |
|        mirror       | 80.97 | 91.15 |
|         rug         | 72.67 | 86.83 |
|        field        | 37.99 | 71.85 |
|       armchair      | 61.78 | 78.63 |
|         seat        | 65.53 | 89.43 |
|        fence        | 55.43 | 73.44 |
|         desk        |  60.5 | 82.95 |
|         rock        | 62.21 |  77.3 |
|       wardrobe      | 58.58 | 88.89 |
|         lamp        | 81.19 | 90.19 |
|       bathtub       | 92.37 | 94.02 |
|       railing       |  44.6 | 65.52 |
|       cushion       | 77.09 | 90.32 |
|         base        | 42.65 | 65.87 |
|         box         | 45.56 | 63.64 |
|        column       | 60.32 | 73.16 |
|      signboard      | 45.14 | 67.25 |
|   chest of drawers  | 45.07 | 72.29 |
|       counter       | 60.11 | 68.18 |
|         sand        | 62.83 | 87.71 |
|         sink        | 83.48 | 86.94 |
|      skyscraper     | 43.19 | 55.98 |
|      fireplace      | 79.71 | 95.62 |
|     refrigerator    | 83.15 | 93.89 |
|      grandstand     | 49.05 | 79.67 |
|         path        | 31.79 | 41.69 |
|        stairs       | 34.06 | 45.68 |
|        runway       | 74.53 | 93.88 |
|         case        | 66.05 | 89.03 |
|      pool table     | 95.99 | 98.73 |
|        pillow       | 72.54 | 82.61 |
|     screen door     | 83.19 | 91.41 |
|       stairway      |  56.6 | 71.93 |
|        river        | 30.22 | 35.59 |
|        bridge       | 70.35 | 86.73 |
|       bookcase      | 45.67 | 67.96 |
|        blind        | 49.18 |  61.6 |
|     coffee table    | 68.41 | 90.52 |
|        toilet       | 92.17 | 95.34 |
|        flower       | 47.23 | 69.53 |
|         book        | 61.44 | 81.93 |
|         hill        | 12.67 | 27.86 |
|        bench        |  75.7 | 85.21 |
|      countertop     | 73.51 | 89.69 |
|        stove        | 86.71 | 90.68 |
|         palm        |  56.9 | 82.23 |
|    kitchen island   | 49.99 | 95.29 |
|       computer      | 82.05 | 90.71 |
|     swivel chair    | 57.27 | 84.83 |
|         boat        | 55.15 |  91.3 |
|         bar         | 65.96 | 72.16 |
|    arcade machine   | 91.97 | 98.69 |
|        hovel        | 49.12 | 73.18 |
|         bus         | 95.78 | 97.78 |
|        towel        | 83.52 | 94.11 |
|        light        | 67.69 | 79.22 |
|        truck        | 53.15 | 73.52 |
|        tower        | 32.94 | 63.21 |
|      chandelier     | 77.46 | 88.02 |
|        awning       | 34.45 |  57.2 |
|     streetlight     |  46.4 | 71.01 |
|        booth        | 56.62 | 81.14 |
| television receiver | 80.85 | 92.16 |
|       airplane      | 88.79 | 96.53 |
|      dirt track     | 24.84 | 48.89 |
|       apparel       | 53.67 | 85.55 |
|         pole        | 38.87 |  53.0 |
|         land        |  6.63 |  9.57 |
|      bannister      | 21.98 | 33.72 |
|      escalator      | 66.25 | 83.37 |
|       ottoman       | 55.66 | 72.31 |
|        bottle       | 51.57 | 80.12 |
|        buffet       | 47.45 | 65.43 |
|        poster       | 38.66 | 61.48 |
|        stage        | 32.78 | 63.39 |
|         van         | 51.98 | 73.91 |
|         ship        | 25.55 | 27.01 |
|       fountain      | 55.33 | 63.82 |
|    conveyer belt    | 77.96 | 96.94 |
|        canopy       | 53.26 | 86.21 |
|        washer       | 90.84 | 93.39 |
|      plaything      | 36.96 | 58.68 |
|    swimming pool    | 50.64 | 76.39 |
|        stool        | 57.56 | 86.08 |
|        barrel       | 57.81 | 83.84 |
|        basket       | 46.76 | 72.43 |
|      waterfall      | 45.26 | 55.37 |
|         tent        | 94.83 | 98.21 |
|         bag         | 34.52 | 47.51 |
|       minibike      | 81.09 |  94.2 |
|        cradle       | 91.38 | 97.36 |
|         oven        | 65.18 | 83.93 |
|         ball        | 38.62 | 41.35 |
|         food        | 63.36 | 73.51 |
|         step        | 26.52 | 32.85 |
|         tank        | 60.35 |  67.6 |
|      trade name     | 34.78 | 46.97 |
|      microwave      | 89.75 | 94.51 |
|         pot         | 61.96 | 74.61 |
|        animal       | 81.19 | 83.66 |
|       bicycle       | 64.59 | 83.58 |
|         lake        | 66.17 | 69.19 |
|      dishwasher     | 80.23 | 90.57 |
|        screen       |  61.1 | 94.38 |
|       blanket       | 47.04 | 61.08 |
|      sculpture      | 73.32 | 90.43 |
|         hood        | 86.78 | 91.75 |
|        sconce       | 68.28 | 82.87 |
|         vase        | 59.66 | 81.64 |
|    traffic light    | 53.46 | 73.58 |
|         tray        | 34.76 | 52.54 |
|        ashcan       | 55.88 | 81.31 |
|         fan         | 73.64 | 87.05 |
|         pier        | 38.52 | 41.13 |
|      crt screen     |  1.42 |  3.82 |
|        plate        | 71.18 | 84.95 |
|       monitor       |  9.67 | 12.82 |
|    bulletin board   |  63.0 | 83.52 |
|        shower       | 18.48 | 28.48 |
|       radiator      | 73.87 | 93.38 |
|        glass        | 29.09 |  32.1 |
|        clock        | 64.24 | 77.95 |
|         flag        | 69.31 | 86.74 |
+---------------------+-------+-------+
2022-12-01 13:46:32,722 - mmseg - INFO - Summary:
2022-12-01 13:46:32,722 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 87.05 | 61.32 | 76.01 |
+-------+-------+-------+
2022-12-01 13:46:32,725 - mmseg - INFO - The previous best checkpoint /mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune/lr1.0_lrd0.9/best_mIoU_iter_32000.pth was removed
2022-12-01 13:47:21,467 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_34000.pth.
2022-12-01 13:47:21,467 - mmseg - INFO - Best mIoU is 0.6132 at 34000 iter.
2022-12-01 13:47:21,475 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 13:47:21,475 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8705, mIoU: 0.6132, mAcc: 0.7601, IoU.wall: 0.8320, IoU.building: 0.8523, IoU.sky: 0.9523, IoU.floor: 0.8533, IoU.tree: 0.7881, IoU.ceiling: 0.8697, IoU.road: 0.8845, IoU.bed : 0.9375, IoU.windowpane: 0.6859, IoU.grass: 0.6849, IoU.cabinet: 0.6296, IoU.sidewalk: 0.7282, IoU.person: 0.8834, IoU.earth: 0.4243, IoU.door: 0.6518, IoU.table: 0.7192, IoU.mountain: 0.6152, IoU.plant: 0.5771, IoU.curtain: 0.8174, IoU.chair: 0.6886, IoU.car: 0.8968, IoU.water: 0.7018, IoU.painting: 0.7987, IoU.sofa: 0.8533, IoU.shelf: 0.4978, IoU.house: 0.5382, IoU.sea: 0.8074, IoU.mirror: 0.8097, IoU.rug: 0.7267, IoU.field: 0.3799, IoU.armchair: 0.6178, IoU.seat: 0.6553, IoU.fence: 0.5543, IoU.desk: 0.6050, IoU.rock: 0.6221, IoU.wardrobe: 0.5858, IoU.lamp: 0.8119, IoU.bathtub: 0.9237, IoU.railing: 0.4460, IoU.cushion: 0.7709, IoU.base: 0.4265, IoU.box: 0.4556, IoU.column: 0.6032, IoU.signboard: 0.4514, IoU.chest of drawers: 0.4507, IoU.counter: 0.6011, IoU.sand: 0.6283, IoU.sink: 0.8348, IoU.skyscraper: 0.4319, IoU.fireplace: 0.7971, IoU.refrigerator: 0.8315, IoU.grandstand: 0.4905, IoU.path: 0.3179, IoU.stairs: 0.3406, IoU.runway: 0.7453, IoU.case: 0.6605, IoU.pool table: 0.9599, IoU.pillow: 0.7254, IoU.screen door: 0.8319, IoU.stairway: 0.5660, IoU.river: 0.3022, IoU.bridge: 0.7035, IoU.bookcase: 0.4567, IoU.blind: 0.4918, IoU.coffee table: 0.6841, IoU.toilet: 0.9217, IoU.flower: 0.4723, IoU.book: 0.6144, IoU.hill: 0.1267, IoU.bench: 0.7570, IoU.countertop: 0.7351, IoU.stove: 0.8671, IoU.palm: 0.5690, IoU.kitchen island: 0.4999, IoU.computer: 0.8205, IoU.swivel chair: 0.5727, IoU.boat: 0.5515, IoU.bar: 0.6596, IoU.arcade machine: 0.9197, IoU.hovel: 0.4912, IoU.bus: 0.9578, IoU.towel: 0.8352, IoU.light: 0.6769, IoU.truck: 0.5315, IoU.tower: 0.3294, IoU.chandelier: 0.7746, IoU.awning: 0.3445, IoU.streetlight: 0.4640, IoU.booth: 0.5662, IoU.television receiver: 0.8085, IoU.airplane: 0.8879, IoU.dirt track: 0.2484, IoU.apparel: 0.5367, IoU.pole: 0.3887, IoU.land: 0.0663, IoU.bannister: 0.2198, IoU.escalator: 0.6625, IoU.ottoman: 0.5566, IoU.bottle: 0.5157, IoU.buffet: 0.4745, IoU.poster: 0.3866, IoU.stage: 0.3278, IoU.van: 0.5198, IoU.ship: 0.2555, IoU.fountain: 0.5533, IoU.conveyer belt: 0.7796, IoU.canopy: 0.5326, IoU.washer: 0.9084, IoU.plaything: 0.3696, IoU.swimming pool: 0.5064, IoU.stool: 0.5756, IoU.barrel: 0.5781, IoU.basket: 0.4676, IoU.waterfall: 0.4526, IoU.tent: 0.9483, IoU.bag: 0.3452, IoU.minibike: 0.8109, IoU.cradle: 0.9138, IoU.oven: 0.6518, IoU.ball: 0.3862, IoU.food: 0.6336, IoU.step: 0.2652, IoU.tank: 0.6035, IoU.trade name: 0.3478, IoU.microwave: 0.8975, IoU.pot: 0.6196, IoU.animal: 0.8119, IoU.bicycle: 0.6459, IoU.lake: 0.6617, IoU.dishwasher: 0.8023, IoU.screen: 0.6110, IoU.blanket: 0.4704, IoU.sculpture: 0.7332, IoU.hood: 0.8678, IoU.sconce: 0.6828, IoU.vase: 0.5966, IoU.traffic light: 0.5346, IoU.tray: 0.3476, IoU.ashcan: 0.5588, IoU.fan: 0.7364, IoU.pier: 0.3852, IoU.crt screen: 0.0142, IoU.plate: 0.7118, IoU.monitor: 0.0967, IoU.bulletin board: 0.6300, IoU.shower: 0.1848, IoU.radiator: 0.7387, IoU.glass: 0.2909, IoU.clock: 0.6424, IoU.flag: 0.6931, Acc.wall: 0.8962, Acc.building: 0.9188, Acc.sky: 0.9748, Acc.floor: 0.9057, Acc.tree: 0.8909, Acc.ceiling: 0.9276, Acc.road: 0.9227, Acc.bed : 0.9731, Acc.windowpane: 0.8208, Acc.grass: 0.8178, Acc.cabinet: 0.7196, Acc.sidewalk: 0.8508, Acc.person: 0.9416, Acc.earth: 0.5769, Acc.door: 0.8187, Acc.table: 0.8067, Acc.mountain: 0.6981, Acc.plant: 0.7048, Acc.curtain: 0.9113, Acc.chair: 0.7988, Acc.car: 0.9524, Acc.water: 0.8602, Acc.painting: 0.9123, Acc.sofa: 0.9145, Acc.shelf: 0.6487, Acc.house: 0.7169, Acc.sea: 0.9052, Acc.mirror: 0.9115, Acc.rug: 0.8683, Acc.field: 0.7185, Acc.armchair: 0.7863, Acc.seat: 0.8943, Acc.fence: 0.7344, Acc.desk: 0.8295, Acc.rock: 0.7730, Acc.wardrobe: 0.8889, Acc.lamp: 0.9019, Acc.bathtub: 0.9402, Acc.railing: 0.6552, Acc.cushion: 0.9032, Acc.base: 0.6587, Acc.box: 0.6364, Acc.column: 0.7316, Acc.signboard: 0.6725, Acc.chest of drawers: 0.7229, Acc.counter: 0.6818, Acc.sand: 0.8771, Acc.sink: 0.8694, Acc.skyscraper: 0.5598, Acc.fireplace: 0.9562, Acc.refrigerator: 0.9389, Acc.grandstand: 0.7967, Acc.path: 0.4169, Acc.stairs: 0.4568, Acc.runway: 0.9388, Acc.case: 0.8903, Acc.pool table: 0.9873, Acc.pillow: 0.8261, Acc.screen door: 0.9141, Acc.stairway: 0.7193, Acc.river: 0.3559, Acc.bridge: 0.8673, Acc.bookcase: 0.6796, Acc.blind: 0.6160, Acc.coffee table: 0.9052, Acc.toilet: 0.9534, Acc.flower: 0.6953, Acc.book: 0.8193, Acc.hill: 0.2786, Acc.bench: 0.8521, Acc.countertop: 0.8969, Acc.stove: 0.9068, Acc.palm: 0.8223, Acc.kitchen island: 0.9529, Acc.computer: 0.9071, Acc.swivel chair: 0.8483, Acc.boat: 0.9130, Acc.bar: 0.7216, Acc.arcade machine: 0.9869, Acc.hovel: 0.7318, Acc.bus: 0.9778, Acc.towel: 0.9411, Acc.light: 0.7922, Acc.truck: 0.7352, Acc.tower: 0.6321, Acc.chandelier: 0.8802, Acc.awning: 0.5720, Acc.streetlight: 0.7101, Acc.booth: 0.8114, Acc.television receiver: 0.9216, Acc.airplane: 0.9653, Acc.dirt track: 0.4889, Acc.apparel: 0.8555, Acc.pole: 0.5300, Acc.land: 0.0957, Acc.bannister: 0.3372, Acc.escalator: 0.8337, Acc.ottoman: 0.7231, Acc.bottle: 0.8012, Acc.buffet: 0.6543, Acc.poster: 0.6148, Acc.stage: 0.6339, Acc.van: 0.7391, Acc.ship: 0.2701, Acc.fountain: 0.6382, Acc.conveyer belt: 0.9694, Acc.canopy: 0.8621, Acc.washer: 0.9339, Acc.plaything: 0.5868, Acc.swimming pool: 0.7639, Acc.stool: 0.8608, Acc.barrel: 0.8384, Acc.basket: 0.7243, Acc.waterfall: 0.5537, Acc.tent: 0.9821, Acc.bag: 0.4751, Acc.minibike: 0.9420, Acc.cradle: 0.9736, Acc.oven: 0.8393, Acc.ball: 0.4135, Acc.food: 0.7351, Acc.step: 0.3285, Acc.tank: 0.6760, Acc.trade name: 0.4697, Acc.microwave: 0.9451, Acc.pot: 0.7461, Acc.animal: 0.8366, Acc.bicycle: 0.8358, Acc.lake: 0.6919, Acc.dishwasher: 0.9057, Acc.screen: 0.9438, Acc.blanket: 0.6108, Acc.sculpture: 0.9043, Acc.hood: 0.9175, Acc.sconce: 0.8287, Acc.vase: 0.8164, Acc.traffic light: 0.7358, Acc.tray: 0.5254, Acc.ashcan: 0.8131, Acc.fan: 0.8705, Acc.pier: 0.4113, Acc.crt screen: 0.0382, Acc.plate: 0.8495, Acc.monitor: 0.1282, Acc.bulletin board: 0.8352, Acc.shower: 0.2848, Acc.radiator: 0.9338, Acc.glass: 0.3210, Acc.clock: 0.7795, Acc.flag: 0.8674
2022-12-01 13:50:47,323 - mmseg - INFO - Iter [34050/40000]	lr: 1.979e-08, eta: 7:13:21, time: 8.652, data_time: 4.556, memory: 51902, decode.loss_cls: 0.3168, decode.loss_mask: 0.5313, decode.loss_dice: 0.7681, decode.d0.loss_cls: 5.0023, decode.d0.loss_mask: 0.5188, decode.d0.loss_dice: 0.8251, decode.d1.loss_cls: 0.4275, decode.d1.loss_mask: 0.5530, decode.d1.loss_dice: 0.8206, decode.d2.loss_cls: 0.3750, decode.d2.loss_mask: 0.5436, decode.d2.loss_dice: 0.7928, decode.d3.loss_cls: 0.3472, decode.d3.loss_mask: 0.5374, decode.d3.loss_dice: 0.7813, decode.d4.loss_cls: 0.3326, decode.d4.loss_mask: 0.5356, decode.d4.loss_dice: 0.7744, decode.d5.loss_cls: 0.3247, decode.d5.loss_mask: 0.5328, decode.d5.loss_dice: 0.7731, decode.d6.loss_cls: 0.3206, decode.d6.loss_mask: 0.5329, decode.d6.loss_dice: 0.7704, decode.d7.loss_cls: 0.3169, decode.d7.loss_mask: 0.5333, decode.d7.loss_dice: 0.7703, decode.d8.loss_cls: 0.3175, decode.d8.loss_mask: 0.5322, decode.d8.loss_dice: 0.7712, loss: 21.2793
2022-12-01 13:54:12,830 - mmseg - INFO - Iter [34100/40000]	lr: 1.962e-08, eta: 7:09:40, time: 4.110, data_time: 0.022, memory: 51902, decode.loss_cls: 0.3435, decode.loss_mask: 0.5385, decode.loss_dice: 0.7959, decode.d0.loss_cls: 5.0393, decode.d0.loss_mask: 0.5354, decode.d0.loss_dice: 0.8607, decode.d1.loss_cls: 0.4602, decode.d1.loss_mask: 0.5642, decode.d1.loss_dice: 0.8505, decode.d2.loss_cls: 0.4052, decode.d2.loss_mask: 0.5520, decode.d2.loss_dice: 0.8160, decode.d3.loss_cls: 0.3744, decode.d3.loss_mask: 0.5466, decode.d3.loss_dice: 0.8058, decode.d4.loss_cls: 0.3614, decode.d4.loss_mask: 0.5432, decode.d4.loss_dice: 0.8029, decode.d5.loss_cls: 0.3550, decode.d5.loss_mask: 0.5430, decode.d5.loss_dice: 0.7981, decode.d6.loss_cls: 0.3518, decode.d6.loss_mask: 0.5379, decode.d6.loss_dice: 0.7926, decode.d7.loss_cls: 0.3438, decode.d7.loss_mask: 0.5402, decode.d7.loss_dice: 0.7931, decode.d8.loss_cls: 0.3439, decode.d8.loss_mask: 0.5395, decode.d8.loss_dice: 0.7929, loss: 21.9274
2022-12-01 13:57:40,890 - mmseg - INFO - Iter [34150/40000]	lr: 1.946e-08, eta: 7:06:00, time: 4.161, data_time: 0.064, memory: 51902, decode.loss_cls: 0.3386, decode.loss_mask: 0.5198, decode.loss_dice: 0.7800, decode.d0.loss_cls: 5.0253, decode.d0.loss_mask: 0.5197, decode.d0.loss_dice: 0.8531, decode.d1.loss_cls: 0.4557, decode.d1.loss_mask: 0.5452, decode.d1.loss_dice: 0.8425, decode.d2.loss_cls: 0.3987, decode.d2.loss_mask: 0.5330, decode.d2.loss_dice: 0.8056, decode.d3.loss_cls: 0.3680, decode.d3.loss_mask: 0.5281, decode.d3.loss_dice: 0.7961, decode.d4.loss_cls: 0.3594, decode.d4.loss_mask: 0.5253, decode.d4.loss_dice: 0.7874, decode.d5.loss_cls: 0.3458, decode.d5.loss_mask: 0.5236, decode.d5.loss_dice: 0.7874, decode.d6.loss_cls: 0.3480, decode.d6.loss_mask: 0.5214, decode.d6.loss_dice: 0.7789, decode.d7.loss_cls: 0.3420, decode.d7.loss_mask: 0.5198, decode.d7.loss_dice: 0.7825, decode.d8.loss_cls: 0.3419, decode.d8.loss_mask: 0.5199, decode.d8.loss_dice: 0.7803, loss: 21.5730
2022-12-01 14:01:06,551 - mmseg - INFO - Iter [34200/40000]	lr: 1.929e-08, eta: 7:02:20, time: 4.113, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3417, decode.loss_mask: 0.5231, decode.loss_dice: 0.7826, decode.d0.loss_cls: 5.0005, decode.d0.loss_mask: 0.5176, decode.d0.loss_dice: 0.8558, decode.d1.loss_cls: 0.4591, decode.d1.loss_mask: 0.5522, decode.d1.loss_dice: 0.8443, decode.d2.loss_cls: 0.4011, decode.d2.loss_mask: 0.5359, decode.d2.loss_dice: 0.8060, decode.d3.loss_cls: 0.3718, decode.d3.loss_mask: 0.5297, decode.d3.loss_dice: 0.7944, decode.d4.loss_cls: 0.3610, decode.d4.loss_mask: 0.5269, decode.d4.loss_dice: 0.7939, decode.d5.loss_cls: 0.3512, decode.d5.loss_mask: 0.5251, decode.d5.loss_dice: 0.7851, decode.d6.loss_cls: 0.3436, decode.d6.loss_mask: 0.5244, decode.d6.loss_dice: 0.7821, decode.d7.loss_cls: 0.3446, decode.d7.loss_mask: 0.5218, decode.d7.loss_dice: 0.7826, decode.d8.loss_cls: 0.3427, decode.d8.loss_mask: 0.5227, decode.d8.loss_dice: 0.7848, loss: 21.6081
2022-12-01 14:04:32,016 - mmseg - INFO - Iter [34250/40000]	lr: 1.913e-08, eta: 6:58:39, time: 4.109, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3395, decode.loss_mask: 0.5336, decode.loss_dice: 0.7871, decode.d0.loss_cls: 5.0217, decode.d0.loss_mask: 0.5301, decode.d0.loss_dice: 0.8567, decode.d1.loss_cls: 0.4628, decode.d1.loss_mask: 0.5631, decode.d1.loss_dice: 0.8490, decode.d2.loss_cls: 0.3998, decode.d2.loss_mask: 0.5476, decode.d2.loss_dice: 0.8140, decode.d3.loss_cls: 0.3684, decode.d3.loss_mask: 0.5396, decode.d3.loss_dice: 0.7978, decode.d4.loss_cls: 0.3631, decode.d4.loss_mask: 0.5365, decode.d4.loss_dice: 0.7970, decode.d5.loss_cls: 0.3501, decode.d5.loss_mask: 0.5349, decode.d5.loss_dice: 0.7953, decode.d6.loss_cls: 0.3471, decode.d6.loss_mask: 0.5309, decode.d6.loss_dice: 0.7860, decode.d7.loss_cls: 0.3417, decode.d7.loss_mask: 0.5303, decode.d7.loss_dice: 0.7881, decode.d8.loss_cls: 0.3438, decode.d8.loss_mask: 0.5298, decode.d8.loss_dice: 0.7843, loss: 21.7699
2022-12-01 14:07:57,620 - mmseg - INFO - Iter [34300/40000]	lr: 1.896e-08, eta: 6:54:58, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3349, decode.loss_mask: 0.5299, decode.loss_dice: 0.7859, decode.d0.loss_cls: 4.9807, decode.d0.loss_mask: 0.5278, decode.d0.loss_dice: 0.8458, decode.d1.loss_cls: 0.4434, decode.d1.loss_mask: 0.5550, decode.d1.loss_dice: 0.8466, decode.d2.loss_cls: 0.3886, decode.d2.loss_mask: 0.5449, decode.d2.loss_dice: 0.8148, decode.d3.loss_cls: 0.3634, decode.d3.loss_mask: 0.5369, decode.d3.loss_dice: 0.7990, decode.d4.loss_cls: 0.3578, decode.d4.loss_mask: 0.5338, decode.d4.loss_dice: 0.7926, decode.d5.loss_cls: 0.3444, decode.d5.loss_mask: 0.5320, decode.d5.loss_dice: 0.7881, decode.d6.loss_cls: 0.3418, decode.d6.loss_mask: 0.5286, decode.d6.loss_dice: 0.7828, decode.d7.loss_cls: 0.3354, decode.d7.loss_mask: 0.5288, decode.d7.loss_dice: 0.7855, decode.d8.loss_cls: 0.3355, decode.d8.loss_mask: 0.5294, decode.d8.loss_dice: 0.7859, loss: 21.5999
2022-12-01 14:11:23,201 - mmseg - INFO - Iter [34350/40000]	lr: 1.879e-08, eta: 6:51:18, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3276, decode.loss_mask: 0.5213, decode.loss_dice: 0.7747, decode.d0.loss_cls: 5.0148, decode.d0.loss_mask: 0.5111, decode.d0.loss_dice: 0.8419, decode.d1.loss_cls: 0.4433, decode.d1.loss_mask: 0.5459, decode.d1.loss_dice: 0.8388, decode.d2.loss_cls: 0.3867, decode.d2.loss_mask: 0.5329, decode.d2.loss_dice: 0.8072, decode.d3.loss_cls: 0.3561, decode.d3.loss_mask: 0.5274, decode.d3.loss_dice: 0.7938, decode.d4.loss_cls: 0.3463, decode.d4.loss_mask: 0.5263, decode.d4.loss_dice: 0.7868, decode.d5.loss_cls: 0.3351, decode.d5.loss_mask: 0.5255, decode.d5.loss_dice: 0.7847, decode.d6.loss_cls: 0.3311, decode.d6.loss_mask: 0.5218, decode.d6.loss_dice: 0.7812, decode.d7.loss_cls: 0.3271, decode.d7.loss_mask: 0.5200, decode.d7.loss_dice: 0.7777, decode.d8.loss_cls: 0.3292, decode.d8.loss_mask: 0.5211, decode.d8.loss_dice: 0.7786, loss: 21.4159
2022-12-01 14:14:48,727 - mmseg - INFO - Iter [34400/40000]	lr: 1.863e-08, eta: 6:47:37, time: 4.111, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3407, decode.loss_mask: 0.5342, decode.loss_dice: 0.7849, decode.d0.loss_cls: 4.9890, decode.d0.loss_mask: 0.5337, decode.d0.loss_dice: 0.8485, decode.d1.loss_cls: 0.4678, decode.d1.loss_mask: 0.5637, decode.d1.loss_dice: 0.8435, decode.d2.loss_cls: 0.4074, decode.d2.loss_mask: 0.5507, decode.d2.loss_dice: 0.8137, decode.d3.loss_cls: 0.3737, decode.d3.loss_mask: 0.5441, decode.d3.loss_dice: 0.7963, decode.d4.loss_cls: 0.3601, decode.d4.loss_mask: 0.5382, decode.d4.loss_dice: 0.7932, decode.d5.loss_cls: 0.3505, decode.d5.loss_mask: 0.5357, decode.d5.loss_dice: 0.7875, decode.d6.loss_cls: 0.3442, decode.d6.loss_mask: 0.5374, decode.d6.loss_dice: 0.7909, decode.d7.loss_cls: 0.3448, decode.d7.loss_mask: 0.5364, decode.d7.loss_dice: 0.7870, decode.d8.loss_cls: 0.3424, decode.d8.loss_mask: 0.5351, decode.d8.loss_dice: 0.7864, loss: 21.7617
2022-12-01 14:18:14,197 - mmseg - INFO - Iter [34450/40000]	lr: 1.846e-08, eta: 6:43:57, time: 4.109, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3433, decode.loss_mask: 0.5220, decode.loss_dice: 0.7798, decode.d0.loss_cls: 5.0159, decode.d0.loss_mask: 0.5210, decode.d0.loss_dice: 0.8519, decode.d1.loss_cls: 0.4622, decode.d1.loss_mask: 0.5472, decode.d1.loss_dice: 0.8425, decode.d2.loss_cls: 0.4033, decode.d2.loss_mask: 0.5363, decode.d2.loss_dice: 0.8098, decode.d3.loss_cls: 0.3668, decode.d3.loss_mask: 0.5294, decode.d3.loss_dice: 0.7934, decode.d4.loss_cls: 0.3574, decode.d4.loss_mask: 0.5282, decode.d4.loss_dice: 0.7927, decode.d5.loss_cls: 0.3476, decode.d5.loss_mask: 0.5245, decode.d5.loss_dice: 0.7898, decode.d6.loss_cls: 0.3427, decode.d6.loss_mask: 0.5232, decode.d6.loss_dice: 0.7852, decode.d7.loss_cls: 0.3392, decode.d7.loss_mask: 0.5234, decode.d7.loss_dice: 0.7841, decode.d8.loss_cls: 0.3396, decode.d8.loss_mask: 0.5227, decode.d8.loss_dice: 0.7831, loss: 21.6080
2022-12-01 14:21:40,153 - mmseg - INFO - Iter [34500/40000]	lr: 1.829e-08, eta: 6:40:17, time: 4.119, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3428, decode.loss_mask: 0.5179, decode.loss_dice: 0.7756, decode.d0.loss_cls: 5.0297, decode.d0.loss_mask: 0.5138, decode.d0.loss_dice: 0.8496, decode.d1.loss_cls: 0.4577, decode.d1.loss_mask: 0.5437, decode.d1.loss_dice: 0.8351, decode.d2.loss_cls: 0.3995, decode.d2.loss_mask: 0.5303, decode.d2.loss_dice: 0.8074, decode.d3.loss_cls: 0.3710, decode.d3.loss_mask: 0.5259, decode.d3.loss_dice: 0.7917, decode.d4.loss_cls: 0.3586, decode.d4.loss_mask: 0.5223, decode.d4.loss_dice: 0.7868, decode.d5.loss_cls: 0.3472, decode.d5.loss_mask: 0.5204, decode.d5.loss_dice: 0.7831, decode.d6.loss_cls: 0.3483, decode.d6.loss_mask: 0.5196, decode.d6.loss_dice: 0.7784, decode.d7.loss_cls: 0.3455, decode.d7.loss_mask: 0.5193, decode.d7.loss_dice: 0.7781, decode.d8.loss_cls: 0.3431, decode.d8.loss_mask: 0.5173, decode.d8.loss_dice: 0.7758, loss: 21.5352
2022-12-01 14:25:05,425 - mmseg - INFO - Iter [34550/40000]	lr: 1.813e-08, eta: 6:36:36, time: 4.105, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3318, decode.loss_mask: 0.5350, decode.loss_dice: 0.7888, decode.d0.loss_cls: 4.9930, decode.d0.loss_mask: 0.5368, decode.d0.loss_dice: 0.8538, decode.d1.loss_cls: 0.4404, decode.d1.loss_mask: 0.5703, decode.d1.loss_dice: 0.8488, decode.d2.loss_cls: 0.3885, decode.d2.loss_mask: 0.5520, decode.d2.loss_dice: 0.8184, decode.d3.loss_cls: 0.3521, decode.d3.loss_mask: 0.5468, decode.d3.loss_dice: 0.8039, decode.d4.loss_cls: 0.3434, decode.d4.loss_mask: 0.5436, decode.d4.loss_dice: 0.7996, decode.d5.loss_cls: 0.3389, decode.d5.loss_mask: 0.5372, decode.d5.loss_dice: 0.7938, decode.d6.loss_cls: 0.3330, decode.d6.loss_mask: 0.5372, decode.d6.loss_dice: 0.7895, decode.d7.loss_cls: 0.3290, decode.d7.loss_mask: 0.5343, decode.d7.loss_dice: 0.7893, decode.d8.loss_cls: 0.3281, decode.d8.loss_mask: 0.5345, decode.d8.loss_dice: 0.7923, loss: 21.6843
2022-12-01 14:28:31,210 - mmseg - INFO - Iter [34600/40000]	lr: 1.796e-08, eta: 6:32:56, time: 4.116, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3265, decode.loss_mask: 0.5232, decode.loss_dice: 0.7748, decode.d0.loss_cls: 4.9830, decode.d0.loss_mask: 0.5149, decode.d0.loss_dice: 0.8400, decode.d1.loss_cls: 0.4403, decode.d1.loss_mask: 0.5492, decode.d1.loss_dice: 0.8341, decode.d2.loss_cls: 0.3863, decode.d2.loss_mask: 0.5362, decode.d2.loss_dice: 0.8041, decode.d3.loss_cls: 0.3559, decode.d3.loss_mask: 0.5297, decode.d3.loss_dice: 0.7874, decode.d4.loss_cls: 0.3425, decode.d4.loss_mask: 0.5287, decode.d4.loss_dice: 0.7856, decode.d5.loss_cls: 0.3347, decode.d5.loss_mask: 0.5269, decode.d5.loss_dice: 0.7801, decode.d6.loss_cls: 0.3323, decode.d6.loss_mask: 0.5264, decode.d6.loss_dice: 0.7807, decode.d7.loss_cls: 0.3273, decode.d7.loss_mask: 0.5260, decode.d7.loss_dice: 0.7807, decode.d8.loss_cls: 0.3268, decode.d8.loss_mask: 0.5227, decode.d8.loss_dice: 0.7794, loss: 21.3864
2022-12-01 14:31:56,657 - mmseg - INFO - Iter [34650/40000]	lr: 1.780e-08, eta: 6:29:16, time: 4.109, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3141, decode.loss_mask: 0.5265, decode.loss_dice: 0.7772, decode.d0.loss_cls: 4.9676, decode.d0.loss_mask: 0.5206, decode.d0.loss_dice: 0.8326, decode.d1.loss_cls: 0.4218, decode.d1.loss_mask: 0.5516, decode.d1.loss_dice: 0.8331, decode.d2.loss_cls: 0.3761, decode.d2.loss_mask: 0.5388, decode.d2.loss_dice: 0.7983, decode.d3.loss_cls: 0.3429, decode.d3.loss_mask: 0.5329, decode.d3.loss_dice: 0.7890, decode.d4.loss_cls: 0.3278, decode.d4.loss_mask: 0.5312, decode.d4.loss_dice: 0.7866, decode.d5.loss_cls: 0.3220, decode.d5.loss_mask: 0.5292, decode.d5.loss_dice: 0.7781, decode.d6.loss_cls: 0.3178, decode.d6.loss_mask: 0.5245, decode.d6.loss_dice: 0.7774, decode.d7.loss_cls: 0.3139, decode.d7.loss_mask: 0.5258, decode.d7.loss_dice: 0.7792, decode.d8.loss_cls: 0.3142, decode.d8.loss_mask: 0.5247, decode.d8.loss_dice: 0.7782, loss: 21.2535
2022-12-01 14:35:22,195 - mmseg - INFO - Iter [34700/40000]	lr: 1.763e-08, eta: 6:25:35, time: 4.111, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3069, decode.loss_mask: 0.5339, decode.loss_dice: 0.7654, decode.d0.loss_cls: 4.9666, decode.d0.loss_mask: 0.5242, decode.d0.loss_dice: 0.8297, decode.d1.loss_cls: 0.4283, decode.d1.loss_mask: 0.5616, decode.d1.loss_dice: 0.8232, decode.d2.loss_cls: 0.3684, decode.d2.loss_mask: 0.5469, decode.d2.loss_dice: 0.7909, decode.d3.loss_cls: 0.3330, decode.d3.loss_mask: 0.5399, decode.d3.loss_dice: 0.7787, decode.d4.loss_cls: 0.3271, decode.d4.loss_mask: 0.5382, decode.d4.loss_dice: 0.7737, decode.d5.loss_cls: 0.3129, decode.d5.loss_mask: 0.5359, decode.d5.loss_dice: 0.7719, decode.d6.loss_cls: 0.3112, decode.d6.loss_mask: 0.5363, decode.d6.loss_dice: 0.7686, decode.d7.loss_cls: 0.3046, decode.d7.loss_mask: 0.5359, decode.d7.loss_dice: 0.7707, decode.d8.loss_cls: 0.3049, decode.d8.loss_mask: 0.5346, decode.d8.loss_dice: 0.7695, loss: 21.1935
2022-12-01 14:38:47,774 - mmseg - INFO - Iter [34750/40000]	lr: 1.746e-08, eta: 6:21:55, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3247, decode.loss_mask: 0.5227, decode.loss_dice: 0.7730, decode.d0.loss_cls: 4.9639, decode.d0.loss_mask: 0.5218, decode.d0.loss_dice: 0.8449, decode.d1.loss_cls: 0.4359, decode.d1.loss_mask: 0.5487, decode.d1.loss_dice: 0.8364, decode.d2.loss_cls: 0.3785, decode.d2.loss_mask: 0.5388, decode.d2.loss_dice: 0.8008, decode.d3.loss_cls: 0.3474, decode.d3.loss_mask: 0.5274, decode.d3.loss_dice: 0.7849, decode.d4.loss_cls: 0.3411, decode.d4.loss_mask: 0.5281, decode.d4.loss_dice: 0.7828, decode.d5.loss_cls: 0.3310, decode.d5.loss_mask: 0.5256, decode.d5.loss_dice: 0.7791, decode.d6.loss_cls: 0.3244, decode.d6.loss_mask: 0.5251, decode.d6.loss_dice: 0.7757, decode.d7.loss_cls: 0.3262, decode.d7.loss_mask: 0.5234, decode.d7.loss_dice: 0.7745, decode.d8.loss_cls: 0.3232, decode.d8.loss_mask: 0.5229, decode.d8.loss_dice: 0.7729, loss: 21.3059
2022-12-01 14:42:16,006 - mmseg - INFO - Iter [34800/40000]	lr: 1.730e-08, eta: 6:18:15, time: 4.165, data_time: 0.063, memory: 51902, decode.loss_cls: 0.3292, decode.loss_mask: 0.5344, decode.loss_dice: 0.7847, decode.d0.loss_cls: 4.9820, decode.d0.loss_mask: 0.5231, decode.d0.loss_dice: 0.8480, decode.d1.loss_cls: 0.4436, decode.d1.loss_mask: 0.5606, decode.d1.loss_dice: 0.8384, decode.d2.loss_cls: 0.3895, decode.d2.loss_mask: 0.5462, decode.d2.loss_dice: 0.8103, decode.d3.loss_cls: 0.3540, decode.d3.loss_mask: 0.5401, decode.d3.loss_dice: 0.7993, decode.d4.loss_cls: 0.3456, decode.d4.loss_mask: 0.5374, decode.d4.loss_dice: 0.7952, decode.d5.loss_cls: 0.3355, decode.d5.loss_mask: 0.5382, decode.d5.loss_dice: 0.7879, decode.d6.loss_cls: 0.3311, decode.d6.loss_mask: 0.5365, decode.d6.loss_dice: 0.7876, decode.d7.loss_cls: 0.3306, decode.d7.loss_mask: 0.5358, decode.d7.loss_dice: 0.7866, decode.d8.loss_cls: 0.3301, decode.d8.loss_mask: 0.5339, decode.d8.loss_dice: 0.7864, loss: 21.5817
2022-12-01 14:45:41,914 - mmseg - INFO - Iter [34850/40000]	lr: 1.713e-08, eta: 6:14:35, time: 4.118, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3215, decode.loss_mask: 0.5207, decode.loss_dice: 0.7735, decode.d0.loss_cls: 4.9551, decode.d0.loss_mask: 0.5167, decode.d0.loss_dice: 0.8397, decode.d1.loss_cls: 0.4351, decode.d1.loss_mask: 0.5494, decode.d1.loss_dice: 0.8346, decode.d2.loss_cls: 0.3797, decode.d2.loss_mask: 0.5362, decode.d2.loss_dice: 0.8028, decode.d3.loss_cls: 0.3486, decode.d3.loss_mask: 0.5297, decode.d3.loss_dice: 0.7856, decode.d4.loss_cls: 0.3397, decode.d4.loss_mask: 0.5274, decode.d4.loss_dice: 0.7843, decode.d5.loss_cls: 0.3292, decode.d5.loss_mask: 0.5246, decode.d5.loss_dice: 0.7791, decode.d6.loss_cls: 0.3270, decode.d6.loss_mask: 0.5215, decode.d6.loss_dice: 0.7747, decode.d7.loss_cls: 0.3261, decode.d7.loss_mask: 0.5223, decode.d7.loss_dice: 0.7745, decode.d8.loss_cls: 0.3238, decode.d8.loss_mask: 0.5187, decode.d8.loss_dice: 0.7737, loss: 21.2756
2022-12-01 14:49:07,244 - mmseg - INFO - Iter [34900/40000]	lr: 1.696e-08, eta: 6:10:55, time: 4.107, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3311, decode.loss_mask: 0.5365, decode.loss_dice: 0.7882, decode.d0.loss_cls: 4.9967, decode.d0.loss_mask: 0.5311, decode.d0.loss_dice: 0.8551, decode.d1.loss_cls: 0.4436, decode.d1.loss_mask: 0.5633, decode.d1.loss_dice: 0.8525, decode.d2.loss_cls: 0.3912, decode.d2.loss_mask: 0.5501, decode.d2.loss_dice: 0.8156, decode.d3.loss_cls: 0.3550, decode.d3.loss_mask: 0.5436, decode.d3.loss_dice: 0.8050, decode.d4.loss_cls: 0.3494, decode.d4.loss_mask: 0.5430, decode.d4.loss_dice: 0.7982, decode.d5.loss_cls: 0.3373, decode.d5.loss_mask: 0.5394, decode.d5.loss_dice: 0.7917, decode.d6.loss_cls: 0.3353, decode.d6.loss_mask: 0.5383, decode.d6.loss_dice: 0.7892, decode.d7.loss_cls: 0.3346, decode.d7.loss_mask: 0.5388, decode.d7.loss_dice: 0.7902, decode.d8.loss_cls: 0.3291, decode.d8.loss_mask: 0.5386, decode.d8.loss_dice: 0.7902, loss: 21.7019
2022-12-01 14:52:33,135 - mmseg - INFO - Iter [34950/40000]	lr: 1.680e-08, eta: 6:07:15, time: 4.118, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3289, decode.loss_mask: 0.5351, decode.loss_dice: 0.7970, decode.d0.loss_cls: 4.9599, decode.d0.loss_mask: 0.5338, decode.d0.loss_dice: 0.8551, decode.d1.loss_cls: 0.4420, decode.d1.loss_mask: 0.5622, decode.d1.loss_dice: 0.8537, decode.d2.loss_cls: 0.3886, decode.d2.loss_mask: 0.5498, decode.d2.loss_dice: 0.8240, decode.d3.loss_cls: 0.3563, decode.d3.loss_mask: 0.5440, decode.d3.loss_dice: 0.8051, decode.d4.loss_cls: 0.3451, decode.d4.loss_mask: 0.5406, decode.d4.loss_dice: 0.8038, decode.d5.loss_cls: 0.3328, decode.d5.loss_mask: 0.5410, decode.d5.loss_dice: 0.8035, decode.d6.loss_cls: 0.3299, decode.d6.loss_mask: 0.5378, decode.d6.loss_dice: 0.7998, decode.d7.loss_cls: 0.3279, decode.d7.loss_mask: 0.5356, decode.d7.loss_dice: 0.7976, decode.d8.loss_cls: 0.3265, decode.d8.loss_mask: 0.5367, decode.d8.loss_dice: 0.7968, loss: 21.6907
2022-12-01 14:55:58,622 - mmseg - INFO - Saving checkpoint at 35000 iterations
2022-12-01 14:56:46,611 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 14:56:46,611 - mmseg - INFO - Iter [35000/40000]	lr: 1.663e-08, eta: 6:03:42, time: 5.069, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3192, decode.loss_mask: 0.5374, decode.loss_dice: 0.7833, decode.d0.loss_cls: 4.9624, decode.d0.loss_mask: 0.5371, decode.d0.loss_dice: 0.8518, decode.d1.loss_cls: 0.4371, decode.d1.loss_mask: 0.5652, decode.d1.loss_dice: 0.8514, decode.d2.loss_cls: 0.3792, decode.d2.loss_mask: 0.5502, decode.d2.loss_dice: 0.8137, decode.d3.loss_cls: 0.3483, decode.d3.loss_mask: 0.5447, decode.d3.loss_dice: 0.7956, decode.d4.loss_cls: 0.3410, decode.d4.loss_mask: 0.5421, decode.d4.loss_dice: 0.7938, decode.d5.loss_cls: 0.3276, decode.d5.loss_mask: 0.5391, decode.d5.loss_dice: 0.7920, decode.d6.loss_cls: 0.3281, decode.d6.loss_mask: 0.5360, decode.d6.loss_dice: 0.7875, decode.d7.loss_cls: 0.3188, decode.d7.loss_mask: 0.5364, decode.d7.loss_dice: 0.7894, decode.d8.loss_cls: 0.3215, decode.d8.loss_mask: 0.5369, decode.d8.loss_dice: 0.7834, loss: 21.5503
2022-12-01 14:59:44,606 - mmseg - INFO - per class results:
2022-12-01 14:59:44,611 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 83.26 | 89.65 |
|       building      | 85.08 | 91.98 |
|         sky         | 95.25 | 97.37 |
|        floor        | 85.82 | 90.96 |
|         tree        | 78.53 |  89.7 |
|       ceiling       | 87.36 | 93.42 |
|         road        | 88.24 | 91.97 |
|         bed         | 93.89 | 97.46 |
|      windowpane     | 69.18 | 83.12 |
|        grass        | 68.96 | 81.15 |
|       cabinet       | 63.05 |  72.7 |
|       sidewalk      | 72.93 | 86.27 |
|        person       | 88.37 | 94.16 |
|        earth        | 43.35 | 58.58 |
|         door        | 64.61 | 81.79 |
|        table        | 71.42 | 80.55 |
|       mountain      | 62.67 | 73.13 |
|        plant        | 57.47 | 69.81 |
|       curtain       | 83.36 |  91.4 |
|        chair        | 69.41 | 80.21 |
|         car         | 89.77 |  95.3 |
|        water        | 71.06 | 85.45 |
|       painting      | 80.12 | 91.41 |
|         sofa        | 85.34 |  92.0 |
|        shelf        | 48.37 | 61.25 |
|        house        | 56.35 |  72.9 |
|         sea         | 81.37 | 90.82 |
|        mirror       | 81.05 | 90.57 |
|         rug         |  72.5 | 86.76 |
|        field        | 34.99 | 65.17 |
|       armchair      | 63.84 | 79.92 |
|         seat        | 65.56 | 90.02 |
|        fence        | 55.26 | 74.43 |
|         desk        |  58.5 | 84.11 |
|         rock        | 61.89 | 75.13 |
|       wardrobe      | 59.06 | 87.61 |
|         lamp        | 81.05 |  90.8 |
|       bathtub       | 91.54 | 93.84 |
|       railing       |  48.0 | 68.33 |
|       cushion       | 77.97 | 91.02 |
|         base        | 42.95 | 65.92 |
|         box         | 44.92 | 63.45 |
|        column       | 54.78 | 72.02 |
|      signboard      | 44.67 | 68.29 |
|   chest of drawers  | 45.02 |  68.9 |
|       counter       | 54.95 | 63.71 |
|         sand        | 60.58 | 87.47 |
|         sink        | 86.09 | 89.76 |
|      skyscraper     | 42.47 | 52.58 |
|      fireplace      | 79.92 | 94.76 |
|     refrigerator    | 82.63 | 92.81 |
|      grandstand     | 49.07 | 78.92 |
|         path        | 32.07 |  41.5 |
|        stairs       | 37.69 | 48.99 |
|        runway       | 74.31 | 93.72 |
|         case        | 67.61 | 87.55 |
|      pool table     | 95.98 | 98.75 |
|        pillow       | 73.32 | 82.59 |
|     screen door     | 83.36 | 91.27 |
|       stairway      | 60.48 | 77.84 |
|        river        | 27.99 | 35.46 |
|        bridge       | 71.44 |  88.4 |
|       bookcase      | 39.73 | 58.12 |
|        blind        | 47.62 | 57.45 |
|     coffee table    | 69.21 | 93.08 |
|        toilet       | 92.19 | 95.41 |
|        flower       | 48.13 | 72.35 |
|         book        |  61.9 | 83.23 |
|         hill        | 16.18 | 27.18 |
|        bench        | 75.52 | 83.66 |
|      countertop     |  73.6 | 90.34 |
|        stove        | 86.85 |  90.8 |
|         palm        | 56.77 | 82.02 |
|    kitchen island   | 47.13 | 92.32 |
|       computer      | 79.49 | 87.69 |
|     swivel chair    | 57.24 |  84.5 |
|         boat        | 59.59 | 90.25 |
|         bar         | 67.25 |  77.4 |
|    arcade machine   | 92.25 | 98.69 |
|        hovel        | 63.05 | 73.04 |
|         bus         | 95.31 | 97.65 |
|        towel        | 83.37 | 92.16 |
|        light        | 67.62 | 79.11 |
|        truck        | 52.75 | 72.87 |
|        tower        | 32.86 | 63.02 |
|      chandelier     | 77.39 |  87.4 |
|        awning       |  31.1 | 52.96 |
|     streetlight     | 44.86 | 72.57 |
|        booth        | 60.38 | 73.02 |
| television receiver | 77.45 | 92.14 |
|       airplane      | 88.68 | 96.73 |
|      dirt track     | 26.16 | 38.16 |
|       apparel       | 53.73 | 85.64 |
|         pole        |  29.0 | 38.97 |
|         land        |  6.26 |  9.67 |
|      bannister      | 22.89 | 32.12 |
|      escalator      | 66.65 | 83.53 |
|       ottoman       | 61.26 | 77.97 |
|        bottle       | 51.54 | 82.68 |
|        buffet       | 46.18 | 65.24 |
|        poster       | 38.82 | 61.27 |
|        stage        | 30.16 | 66.25 |
|         van         | 51.83 |  75.3 |
|         ship        | 26.92 | 28.49 |
|       fountain      |  58.1 | 63.64 |
|    conveyer belt    | 78.07 | 97.07 |
|        canopy       | 45.59 |  59.1 |
|        washer       | 91.12 | 93.61 |
|      plaything      | 37.81 | 58.87 |
|    swimming pool    | 52.44 | 76.12 |
|        stool        |  56.9 | 85.89 |
|        barrel       | 74.02 | 83.06 |
|        basket       | 47.25 | 70.45 |
|      waterfall      |  45.9 | 56.51 |
|         tent        | 95.16 | 98.18 |
|         bag         | 32.94 |  47.0 |
|       minibike      | 81.09 | 94.23 |
|        cradle       | 91.45 | 97.55 |
|         oven        | 66.78 | 83.93 |
|         ball        | 47.79 | 51.74 |
|         food        |  66.9 | 78.81 |
|         step        | 28.86 |  39.9 |
|         tank        | 60.37 | 67.51 |
|      trade name     | 32.48 |  44.0 |
|      microwave      |  89.7 | 94.48 |
|         pot         |  61.9 | 74.01 |
|        animal       | 81.78 | 84.31 |
|       bicycle       | 64.24 | 84.32 |
|         lake        | 52.19 | 69.74 |
|      dishwasher     | 80.61 | 90.37 |
|        screen       | 62.09 | 95.92 |
|       blanket       | 48.36 | 60.79 |
|      sculpture      | 74.38 | 90.62 |
|         hood        |  71.7 | 75.32 |
|        sconce       | 68.36 | 83.05 |
|         vase        | 58.47 | 81.46 |
|    traffic light    | 53.49 | 75.62 |
|         tray        | 32.87 | 48.11 |
|        ashcan       | 55.99 | 80.26 |
|         fan         |  74.1 | 86.37 |
|         pier        | 38.56 | 41.66 |
|      crt screen     |  1.31 |  3.43 |
|        plate        |  71.7 | 85.17 |
|       monitor       |  3.83 |  5.38 |
|    bulletin board   | 63.22 | 83.47 |
|        shower       | 17.82 | 28.44 |
|       radiator      | 74.81 | 93.54 |
|        glass        | 29.18 | 32.19 |
|        clock        | 64.96 | 77.59 |
|         flag        | 69.03 | 87.49 |
+---------------------+-------+-------+
2022-12-01 14:59:44,611 - mmseg - INFO - Summary:
2022-12-01 14:59:44,611 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 87.13 | 61.34 | 75.53 |
+-------+-------+-------+
2022-12-01 14:59:44,615 - mmseg - INFO - The previous best checkpoint /mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune/lr1.0_lrd0.9/best_mIoU_iter_34000.pth was removed
2022-12-01 15:00:35,786 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_35000.pth.
2022-12-01 15:00:35,786 - mmseg - INFO - Best mIoU is 0.6134 at 35000 iter.
2022-12-01 15:00:35,795 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 15:00:35,795 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8713, mIoU: 0.6134, mAcc: 0.7553, IoU.wall: 0.8326, IoU.building: 0.8508, IoU.sky: 0.9525, IoU.floor: 0.8582, IoU.tree: 0.7853, IoU.ceiling: 0.8736, IoU.road: 0.8824, IoU.bed : 0.9389, IoU.windowpane: 0.6918, IoU.grass: 0.6896, IoU.cabinet: 0.6305, IoU.sidewalk: 0.7293, IoU.person: 0.8837, IoU.earth: 0.4335, IoU.door: 0.6461, IoU.table: 0.7142, IoU.mountain: 0.6267, IoU.plant: 0.5747, IoU.curtain: 0.8336, IoU.chair: 0.6941, IoU.car: 0.8977, IoU.water: 0.7106, IoU.painting: 0.8012, IoU.sofa: 0.8534, IoU.shelf: 0.4837, IoU.house: 0.5635, IoU.sea: 0.8137, IoU.mirror: 0.8105, IoU.rug: 0.7250, IoU.field: 0.3499, IoU.armchair: 0.6384, IoU.seat: 0.6556, IoU.fence: 0.5526, IoU.desk: 0.5850, IoU.rock: 0.6189, IoU.wardrobe: 0.5906, IoU.lamp: 0.8105, IoU.bathtub: 0.9154, IoU.railing: 0.4800, IoU.cushion: 0.7797, IoU.base: 0.4295, IoU.box: 0.4492, IoU.column: 0.5478, IoU.signboard: 0.4467, IoU.chest of drawers: 0.4502, IoU.counter: 0.5495, IoU.sand: 0.6058, IoU.sink: 0.8609, IoU.skyscraper: 0.4247, IoU.fireplace: 0.7992, IoU.refrigerator: 0.8263, IoU.grandstand: 0.4907, IoU.path: 0.3207, IoU.stairs: 0.3769, IoU.runway: 0.7431, IoU.case: 0.6761, IoU.pool table: 0.9598, IoU.pillow: 0.7332, IoU.screen door: 0.8336, IoU.stairway: 0.6048, IoU.river: 0.2799, IoU.bridge: 0.7144, IoU.bookcase: 0.3973, IoU.blind: 0.4762, IoU.coffee table: 0.6921, IoU.toilet: 0.9219, IoU.flower: 0.4813, IoU.book: 0.6190, IoU.hill: 0.1618, IoU.bench: 0.7552, IoU.countertop: 0.7360, IoU.stove: 0.8685, IoU.palm: 0.5677, IoU.kitchen island: 0.4713, IoU.computer: 0.7949, IoU.swivel chair: 0.5724, IoU.boat: 0.5959, IoU.bar: 0.6725, IoU.arcade machine: 0.9225, IoU.hovel: 0.6305, IoU.bus: 0.9531, IoU.towel: 0.8337, IoU.light: 0.6762, IoU.truck: 0.5275, IoU.tower: 0.3286, IoU.chandelier: 0.7739, IoU.awning: 0.3110, IoU.streetlight: 0.4486, IoU.booth: 0.6038, IoU.television receiver: 0.7745, IoU.airplane: 0.8868, IoU.dirt track: 0.2616, IoU.apparel: 0.5373, IoU.pole: 0.2900, IoU.land: 0.0626, IoU.bannister: 0.2289, IoU.escalator: 0.6665, IoU.ottoman: 0.6126, IoU.bottle: 0.5154, IoU.buffet: 0.4618, IoU.poster: 0.3882, IoU.stage: 0.3016, IoU.van: 0.5183, IoU.ship: 0.2692, IoU.fountain: 0.5810, IoU.conveyer belt: 0.7807, IoU.canopy: 0.4559, IoU.washer: 0.9112, IoU.plaything: 0.3781, IoU.swimming pool: 0.5244, IoU.stool: 0.5690, IoU.barrel: 0.7402, IoU.basket: 0.4725, IoU.waterfall: 0.4590, IoU.tent: 0.9516, IoU.bag: 0.3294, IoU.minibike: 0.8109, IoU.cradle: 0.9145, IoU.oven: 0.6678, IoU.ball: 0.4779, IoU.food: 0.6690, IoU.step: 0.2886, IoU.tank: 0.6037, IoU.trade name: 0.3248, IoU.microwave: 0.8970, IoU.pot: 0.6190, IoU.animal: 0.8178, IoU.bicycle: 0.6424, IoU.lake: 0.5219, IoU.dishwasher: 0.8061, IoU.screen: 0.6209, IoU.blanket: 0.4836, IoU.sculpture: 0.7438, IoU.hood: 0.7170, IoU.sconce: 0.6836, IoU.vase: 0.5847, IoU.traffic light: 0.5349, IoU.tray: 0.3287, IoU.ashcan: 0.5599, IoU.fan: 0.7410, IoU.pier: 0.3856, IoU.crt screen: 0.0131, IoU.plate: 0.7170, IoU.monitor: 0.0383, IoU.bulletin board: 0.6322, IoU.shower: 0.1782, IoU.radiator: 0.7481, IoU.glass: 0.2918, IoU.clock: 0.6496, IoU.flag: 0.6903, Acc.wall: 0.8965, Acc.building: 0.9198, Acc.sky: 0.9737, Acc.floor: 0.9096, Acc.tree: 0.8970, Acc.ceiling: 0.9342, Acc.road: 0.9197, Acc.bed : 0.9746, Acc.windowpane: 0.8312, Acc.grass: 0.8115, Acc.cabinet: 0.7270, Acc.sidewalk: 0.8627, Acc.person: 0.9416, Acc.earth: 0.5858, Acc.door: 0.8179, Acc.table: 0.8055, Acc.mountain: 0.7313, Acc.plant: 0.6981, Acc.curtain: 0.9140, Acc.chair: 0.8021, Acc.car: 0.9530, Acc.water: 0.8545, Acc.painting: 0.9141, Acc.sofa: 0.9200, Acc.shelf: 0.6125, Acc.house: 0.7290, Acc.sea: 0.9082, Acc.mirror: 0.9057, Acc.rug: 0.8676, Acc.field: 0.6517, Acc.armchair: 0.7992, Acc.seat: 0.9002, Acc.fence: 0.7443, Acc.desk: 0.8411, Acc.rock: 0.7513, Acc.wardrobe: 0.8761, Acc.lamp: 0.9080, Acc.bathtub: 0.9384, Acc.railing: 0.6833, Acc.cushion: 0.9102, Acc.base: 0.6592, Acc.box: 0.6345, Acc.column: 0.7202, Acc.signboard: 0.6829, Acc.chest of drawers: 0.6890, Acc.counter: 0.6371, Acc.sand: 0.8747, Acc.sink: 0.8976, Acc.skyscraper: 0.5258, Acc.fireplace: 0.9476, Acc.refrigerator: 0.9281, Acc.grandstand: 0.7892, Acc.path: 0.4150, Acc.stairs: 0.4899, Acc.runway: 0.9372, Acc.case: 0.8755, Acc.pool table: 0.9875, Acc.pillow: 0.8259, Acc.screen door: 0.9127, Acc.stairway: 0.7784, Acc.river: 0.3546, Acc.bridge: 0.8840, Acc.bookcase: 0.5812, Acc.blind: 0.5745, Acc.coffee table: 0.9308, Acc.toilet: 0.9541, Acc.flower: 0.7235, Acc.book: 0.8323, Acc.hill: 0.2718, Acc.bench: 0.8366, Acc.countertop: 0.9034, Acc.stove: 0.9080, Acc.palm: 0.8202, Acc.kitchen island: 0.9232, Acc.computer: 0.8769, Acc.swivel chair: 0.8450, Acc.boat: 0.9025, Acc.bar: 0.7740, Acc.arcade machine: 0.9869, Acc.hovel: 0.7304, Acc.bus: 0.9765, Acc.towel: 0.9216, Acc.light: 0.7911, Acc.truck: 0.7287, Acc.tower: 0.6302, Acc.chandelier: 0.8740, Acc.awning: 0.5296, Acc.streetlight: 0.7257, Acc.booth: 0.7302, Acc.television receiver: 0.9214, Acc.airplane: 0.9673, Acc.dirt track: 0.3816, Acc.apparel: 0.8564, Acc.pole: 0.3897, Acc.land: 0.0967, Acc.bannister: 0.3212, Acc.escalator: 0.8353, Acc.ottoman: 0.7797, Acc.bottle: 0.8268, Acc.buffet: 0.6524, Acc.poster: 0.6127, Acc.stage: 0.6625, Acc.van: 0.7530, Acc.ship: 0.2849, Acc.fountain: 0.6364, Acc.conveyer belt: 0.9707, Acc.canopy: 0.5910, Acc.washer: 0.9361, Acc.plaything: 0.5887, Acc.swimming pool: 0.7612, Acc.stool: 0.8589, Acc.barrel: 0.8306, Acc.basket: 0.7045, Acc.waterfall: 0.5651, Acc.tent: 0.9818, Acc.bag: 0.4700, Acc.minibike: 0.9423, Acc.cradle: 0.9755, Acc.oven: 0.8393, Acc.ball: 0.5174, Acc.food: 0.7881, Acc.step: 0.3990, Acc.tank: 0.6751, Acc.trade name: 0.4400, Acc.microwave: 0.9448, Acc.pot: 0.7401, Acc.animal: 0.8431, Acc.bicycle: 0.8432, Acc.lake: 0.6974, Acc.dishwasher: 0.9037, Acc.screen: 0.9592, Acc.blanket: 0.6079, Acc.sculpture: 0.9062, Acc.hood: 0.7532, Acc.sconce: 0.8305, Acc.vase: 0.8146, Acc.traffic light: 0.7562, Acc.tray: 0.4811, Acc.ashcan: 0.8026, Acc.fan: 0.8637, Acc.pier: 0.4166, Acc.crt screen: 0.0343, Acc.plate: 0.8517, Acc.monitor: 0.0538, Acc.bulletin board: 0.8347, Acc.shower: 0.2844, Acc.radiator: 0.9354, Acc.glass: 0.3219, Acc.clock: 0.7759, Acc.flag: 0.8749
2022-12-01 15:04:01,602 - mmseg - INFO - Iter [35050/40000]	lr: 1.647e-08, eta: 6:00:35, time: 8.700, data_time: 4.603, memory: 51902, decode.loss_cls: 0.3293, decode.loss_mask: 0.4987, decode.loss_dice: 0.7741, decode.d0.loss_cls: 5.0111, decode.d0.loss_mask: 0.4967, decode.d0.loss_dice: 0.8446, decode.d1.loss_cls: 0.4466, decode.d1.loss_mask: 0.5258, decode.d1.loss_dice: 0.8378, decode.d2.loss_cls: 0.3903, decode.d2.loss_mask: 0.5139, decode.d2.loss_dice: 0.8013, decode.d3.loss_cls: 0.3605, decode.d3.loss_mask: 0.5067, decode.d3.loss_dice: 0.7849, decode.d4.loss_cls: 0.3466, decode.d4.loss_mask: 0.5068, decode.d4.loss_dice: 0.7845, decode.d5.loss_cls: 0.3359, decode.d5.loss_mask: 0.5037, decode.d5.loss_dice: 0.7824, decode.d6.loss_cls: 0.3329, decode.d6.loss_mask: 0.5025, decode.d6.loss_dice: 0.7792, decode.d7.loss_cls: 0.3290, decode.d7.loss_mask: 0.5018, decode.d7.loss_dice: 0.7784, decode.d8.loss_cls: 0.3275, decode.d8.loss_mask: 0.5001, decode.d8.loss_dice: 0.7756, loss: 21.2092
2022-12-01 15:07:27,274 - mmseg - INFO - Iter [35100/40000]	lr: 1.630e-08, eta: 5:56:54, time: 4.113, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3178, decode.loss_mask: 0.5177, decode.loss_dice: 0.7704, decode.d0.loss_cls: 4.9748, decode.d0.loss_mask: 0.5166, decode.d0.loss_dice: 0.8314, decode.d1.loss_cls: 0.4263, decode.d1.loss_mask: 0.5466, decode.d1.loss_dice: 0.8304, decode.d2.loss_cls: 0.3726, decode.d2.loss_mask: 0.5325, decode.d2.loss_dice: 0.7925, decode.d3.loss_cls: 0.3445, decode.d3.loss_mask: 0.5276, decode.d3.loss_dice: 0.7818, decode.d4.loss_cls: 0.3343, decode.d4.loss_mask: 0.5255, decode.d4.loss_dice: 0.7786, decode.d5.loss_cls: 0.3246, decode.d5.loss_mask: 0.5214, decode.d5.loss_dice: 0.7744, decode.d6.loss_cls: 0.3231, decode.d6.loss_mask: 0.5189, decode.d6.loss_dice: 0.7685, decode.d7.loss_cls: 0.3174, decode.d7.loss_mask: 0.5173, decode.d7.loss_dice: 0.7704, decode.d8.loss_cls: 0.3185, decode.d8.loss_mask: 0.5168, decode.d8.loss_dice: 0.7688, loss: 21.1619
2022-12-01 15:10:53,106 - mmseg - INFO - Iter [35150/40000]	lr: 1.613e-08, eta: 5:53:14, time: 4.117, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3323, decode.loss_mask: 0.5211, decode.loss_dice: 0.7791, decode.d0.loss_cls: 4.9963, decode.d0.loss_mask: 0.5175, decode.d0.loss_dice: 0.8528, decode.d1.loss_cls: 0.4599, decode.d1.loss_mask: 0.5442, decode.d1.loss_dice: 0.8411, decode.d2.loss_cls: 0.3957, decode.d2.loss_mask: 0.5368, decode.d2.loss_dice: 0.8110, decode.d3.loss_cls: 0.3639, decode.d3.loss_mask: 0.5303, decode.d3.loss_dice: 0.7928, decode.d4.loss_cls: 0.3572, decode.d4.loss_mask: 0.5250, decode.d4.loss_dice: 0.7875, decode.d5.loss_cls: 0.3439, decode.d5.loss_mask: 0.5235, decode.d5.loss_dice: 0.7869, decode.d6.loss_cls: 0.3365, decode.d6.loss_mask: 0.5210, decode.d6.loss_dice: 0.7789, decode.d7.loss_cls: 0.3362, decode.d7.loss_mask: 0.5220, decode.d7.loss_dice: 0.7787, decode.d8.loss_cls: 0.3332, decode.d8.loss_mask: 0.5215, decode.d8.loss_dice: 0.7793, loss: 21.5059
2022-12-01 15:14:18,648 - mmseg - INFO - Iter [35200/40000]	lr: 1.597e-08, eta: 5:49:34, time: 4.111, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3309, decode.loss_mask: 0.5404, decode.loss_dice: 0.7797, decode.d0.loss_cls: 4.9795, decode.d0.loss_mask: 0.5360, decode.d0.loss_dice: 0.8502, decode.d1.loss_cls: 0.4459, decode.d1.loss_mask: 0.5634, decode.d1.loss_dice: 0.8401, decode.d2.loss_cls: 0.3888, decode.d2.loss_mask: 0.5517, decode.d2.loss_dice: 0.8098, decode.d3.loss_cls: 0.3611, decode.d3.loss_mask: 0.5467, decode.d3.loss_dice: 0.7938, decode.d4.loss_cls: 0.3539, decode.d4.loss_mask: 0.5415, decode.d4.loss_dice: 0.7891, decode.d5.loss_cls: 0.3393, decode.d5.loss_mask: 0.5402, decode.d5.loss_dice: 0.7879, decode.d6.loss_cls: 0.3369, decode.d6.loss_mask: 0.5386, decode.d6.loss_dice: 0.7812, decode.d7.loss_cls: 0.3336, decode.d7.loss_mask: 0.5373, decode.d7.loss_dice: 0.7840, decode.d8.loss_cls: 0.3337, decode.d8.loss_mask: 0.5386, decode.d8.loss_dice: 0.7828, loss: 21.6366
2022-12-01 15:17:44,217 - mmseg - INFO - Iter [35250/40000]	lr: 1.580e-08, eta: 5:45:53, time: 4.111, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3272, decode.loss_mask: 0.5170, decode.loss_dice: 0.7719, decode.d0.loss_cls: 4.9596, decode.d0.loss_mask: 0.5170, decode.d0.loss_dice: 0.8411, decode.d1.loss_cls: 0.4367, decode.d1.loss_mask: 0.5466, decode.d1.loss_dice: 0.8338, decode.d2.loss_cls: 0.3878, decode.d2.loss_mask: 0.5318, decode.d2.loss_dice: 0.7915, decode.d3.loss_cls: 0.3545, decode.d3.loss_mask: 0.5269, decode.d3.loss_dice: 0.7803, decode.d4.loss_cls: 0.3460, decode.d4.loss_mask: 0.5241, decode.d4.loss_dice: 0.7758, decode.d5.loss_cls: 0.3351, decode.d5.loss_mask: 0.5215, decode.d5.loss_dice: 0.7729, decode.d6.loss_cls: 0.3332, decode.d6.loss_mask: 0.5192, decode.d6.loss_dice: 0.7670, decode.d7.loss_cls: 0.3297, decode.d7.loss_mask: 0.5181, decode.d7.loss_dice: 0.7699, decode.d8.loss_cls: 0.3314, decode.d8.loss_mask: 0.5174, decode.d8.loss_dice: 0.7686, loss: 21.2536
2022-12-01 15:21:10,056 - mmseg - INFO - Iter [35300/40000]	lr: 1.563e-08, eta: 5:42:13, time: 4.117, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3292, decode.loss_mask: 0.5219, decode.loss_dice: 0.7623, decode.d0.loss_cls: 4.9827, decode.d0.loss_mask: 0.5225, decode.d0.loss_dice: 0.8359, decode.d1.loss_cls: 0.4409, decode.d1.loss_mask: 0.5517, decode.d1.loss_dice: 0.8234, decode.d2.loss_cls: 0.3883, decode.d2.loss_mask: 0.5373, decode.d2.loss_dice: 0.7898, decode.d3.loss_cls: 0.3550, decode.d3.loss_mask: 0.5307, decode.d3.loss_dice: 0.7771, decode.d4.loss_cls: 0.3470, decode.d4.loss_mask: 0.5291, decode.d4.loss_dice: 0.7690, decode.d5.loss_cls: 0.3367, decode.d5.loss_mask: 0.5251, decode.d5.loss_dice: 0.7661, decode.d6.loss_cls: 0.3379, decode.d6.loss_mask: 0.5237, decode.d6.loss_dice: 0.7604, decode.d7.loss_cls: 0.3313, decode.d7.loss_mask: 0.5242, decode.d7.loss_dice: 0.7640, decode.d8.loss_cls: 0.3301, decode.d8.loss_mask: 0.5225, decode.d8.loss_dice: 0.7640, loss: 21.2799
2022-12-01 15:24:35,207 - mmseg - INFO - Iter [35350/40000]	lr: 1.547e-08, eta: 5:38:33, time: 4.103, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3428, decode.loss_mask: 0.5271, decode.loss_dice: 0.7974, decode.d0.loss_cls: 4.9577, decode.d0.loss_mask: 0.5221, decode.d0.loss_dice: 0.8583, decode.d1.loss_cls: 0.4589, decode.d1.loss_mask: 0.5569, decode.d1.loss_dice: 0.8502, decode.d2.loss_cls: 0.4042, decode.d2.loss_mask: 0.5442, decode.d2.loss_dice: 0.8186, decode.d3.loss_cls: 0.3709, decode.d3.loss_mask: 0.5375, decode.d3.loss_dice: 0.8040, decode.d4.loss_cls: 0.3622, decode.d4.loss_mask: 0.5348, decode.d4.loss_dice: 0.8012, decode.d5.loss_cls: 0.3502, decode.d5.loss_mask: 0.5321, decode.d5.loss_dice: 0.8001, decode.d6.loss_cls: 0.3503, decode.d6.loss_mask: 0.5307, decode.d6.loss_dice: 0.7938, decode.d7.loss_cls: 0.3427, decode.d7.loss_mask: 0.5292, decode.d7.loss_dice: 0.7969, decode.d8.loss_cls: 0.3448, decode.d8.loss_mask: 0.5283, decode.d8.loss_dice: 0.7967, loss: 21.7447
2022-12-01 15:28:03,582 - mmseg - INFO - Iter [35400/40000]	lr: 1.530e-08, eta: 5:34:53, time: 4.168, data_time: 0.064, memory: 51902, decode.loss_cls: 0.3333, decode.loss_mask: 0.5285, decode.loss_dice: 0.7827, decode.d0.loss_cls: 4.9655, decode.d0.loss_mask: 0.5219, decode.d0.loss_dice: 0.8527, decode.d1.loss_cls: 0.4474, decode.d1.loss_mask: 0.5579, decode.d1.loss_dice: 0.8473, decode.d2.loss_cls: 0.3910, decode.d2.loss_mask: 0.5457, decode.d2.loss_dice: 0.8135, decode.d3.loss_cls: 0.3587, decode.d3.loss_mask: 0.5381, decode.d3.loss_dice: 0.7955, decode.d4.loss_cls: 0.3495, decode.d4.loss_mask: 0.5351, decode.d4.loss_dice: 0.7933, decode.d5.loss_cls: 0.3398, decode.d5.loss_mask: 0.5311, decode.d5.loss_dice: 0.7919, decode.d6.loss_cls: 0.3349, decode.d6.loss_mask: 0.5329, decode.d6.loss_dice: 0.7852, decode.d7.loss_cls: 0.3331, decode.d7.loss_mask: 0.5309, decode.d7.loss_dice: 0.7853, decode.d8.loss_cls: 0.3306, decode.d8.loss_mask: 0.5288, decode.d8.loss_dice: 0.7867, loss: 21.5688
2022-12-01 15:31:29,129 - mmseg - INFO - Iter [35450/40000]	lr: 1.514e-08, eta: 5:31:13, time: 4.111, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3499, decode.loss_mask: 0.5334, decode.loss_dice: 0.7824, decode.d0.loss_cls: 4.9751, decode.d0.loss_mask: 0.5332, decode.d0.loss_dice: 0.8617, decode.d1.loss_cls: 0.4587, decode.d1.loss_mask: 0.5613, decode.d1.loss_dice: 0.8505, decode.d2.loss_cls: 0.4065, decode.d2.loss_mask: 0.5498, decode.d2.loss_dice: 0.8136, decode.d3.loss_cls: 0.3750, decode.d3.loss_mask: 0.5392, decode.d3.loss_dice: 0.7970, decode.d4.loss_cls: 0.3678, decode.d4.loss_mask: 0.5366, decode.d4.loss_dice: 0.7930, decode.d5.loss_cls: 0.3553, decode.d5.loss_mask: 0.5350, decode.d5.loss_dice: 0.7912, decode.d6.loss_cls: 0.3515, decode.d6.loss_mask: 0.5328, decode.d6.loss_dice: 0.7885, decode.d7.loss_cls: 0.3474, decode.d7.loss_mask: 0.5332, decode.d7.loss_dice: 0.7880, decode.d8.loss_cls: 0.3482, decode.d8.loss_mask: 0.5320, decode.d8.loss_dice: 0.7845, loss: 21.7722
2022-12-01 15:34:54,526 - mmseg - INFO - Iter [35500/40000]	lr: 1.497e-08, eta: 5:27:33, time: 4.108, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3344, decode.loss_mask: 0.5352, decode.loss_dice: 0.7755, decode.d0.loss_cls: 4.9774, decode.d0.loss_mask: 0.5327, decode.d0.loss_dice: 0.8435, decode.d1.loss_cls: 0.4403, decode.d1.loss_mask: 0.5579, decode.d1.loss_dice: 0.8364, decode.d2.loss_cls: 0.3895, decode.d2.loss_mask: 0.5486, decode.d2.loss_dice: 0.8058, decode.d3.loss_cls: 0.3569, decode.d3.loss_mask: 0.5447, decode.d3.loss_dice: 0.7915, decode.d4.loss_cls: 0.3478, decode.d4.loss_mask: 0.5406, decode.d4.loss_dice: 0.7877, decode.d5.loss_cls: 0.3373, decode.d5.loss_mask: 0.5374, decode.d5.loss_dice: 0.7832, decode.d6.loss_cls: 0.3330, decode.d6.loss_mask: 0.5366, decode.d6.loss_dice: 0.7809, decode.d7.loss_cls: 0.3310, decode.d7.loss_mask: 0.5334, decode.d7.loss_dice: 0.7804, decode.d8.loss_cls: 0.3311, decode.d8.loss_mask: 0.5346, decode.d8.loss_dice: 0.7807, loss: 21.5459
2022-12-01 15:38:20,165 - mmseg - INFO - Iter [35550/40000]	lr: 1.480e-08, eta: 5:23:53, time: 4.113, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3184, decode.loss_mask: 0.5315, decode.loss_dice: 0.7709, decode.d0.loss_cls: 4.9333, decode.d0.loss_mask: 0.5267, decode.d0.loss_dice: 0.8406, decode.d1.loss_cls: 0.4335, decode.d1.loss_mask: 0.5616, decode.d1.loss_dice: 0.8299, decode.d2.loss_cls: 0.3761, decode.d2.loss_mask: 0.5490, decode.d2.loss_dice: 0.7970, decode.d3.loss_cls: 0.3482, decode.d3.loss_mask: 0.5418, decode.d3.loss_dice: 0.7836, decode.d4.loss_cls: 0.3383, decode.d4.loss_mask: 0.5363, decode.d4.loss_dice: 0.7770, decode.d5.loss_cls: 0.3296, decode.d5.loss_mask: 0.5338, decode.d5.loss_dice: 0.7757, decode.d6.loss_cls: 0.3214, decode.d6.loss_mask: 0.5332, decode.d6.loss_dice: 0.7724, decode.d7.loss_cls: 0.3204, decode.d7.loss_mask: 0.5318, decode.d7.loss_dice: 0.7752, decode.d8.loss_cls: 0.3193, decode.d8.loss_mask: 0.5300, decode.d8.loss_dice: 0.7725, loss: 21.3091
2022-12-01 15:41:45,897 - mmseg - INFO - Iter [35600/40000]	lr: 1.464e-08, eta: 5:20:13, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3279, decode.loss_mask: 0.5179, decode.loss_dice: 0.7596, decode.d0.loss_cls: 4.9585, decode.d0.loss_mask: 0.5159, decode.d0.loss_dice: 0.8274, decode.d1.loss_cls: 0.4429, decode.d1.loss_mask: 0.5438, decode.d1.loss_dice: 0.8189, decode.d2.loss_cls: 0.3858, decode.d2.loss_mask: 0.5299, decode.d2.loss_dice: 0.7881, decode.d3.loss_cls: 0.3496, decode.d3.loss_mask: 0.5264, decode.d3.loss_dice: 0.7768, decode.d4.loss_cls: 0.3438, decode.d4.loss_mask: 0.5241, decode.d4.loss_dice: 0.7729, decode.d5.loss_cls: 0.3281, decode.d5.loss_mask: 0.5219, decode.d5.loss_dice: 0.7703, decode.d6.loss_cls: 0.3250, decode.d6.loss_mask: 0.5204, decode.d6.loss_dice: 0.7675, decode.d7.loss_cls: 0.3217, decode.d7.loss_mask: 0.5191, decode.d7.loss_dice: 0.7653, decode.d8.loss_cls: 0.3240, decode.d8.loss_mask: 0.5188, decode.d8.loss_dice: 0.7620, loss: 21.1542
2022-12-01 15:45:11,264 - mmseg - INFO - Iter [35650/40000]	lr: 1.447e-08, eta: 5:16:33, time: 4.107, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3468, decode.loss_mask: 0.5386, decode.loss_dice: 0.8055, decode.d0.loss_cls: 4.9557, decode.d0.loss_mask: 0.5360, decode.d0.loss_dice: 0.8766, decode.d1.loss_cls: 0.4749, decode.d1.loss_mask: 0.5710, decode.d1.loss_dice: 0.8650, decode.d2.loss_cls: 0.4148, decode.d2.loss_mask: 0.5562, decode.d2.loss_dice: 0.8307, decode.d3.loss_cls: 0.3754, decode.d3.loss_mask: 0.5476, decode.d3.loss_dice: 0.8201, decode.d4.loss_cls: 0.3638, decode.d4.loss_mask: 0.5464, decode.d4.loss_dice: 0.8156, decode.d5.loss_cls: 0.3548, decode.d5.loss_mask: 0.5437, decode.d5.loss_dice: 0.8122, decode.d6.loss_cls: 0.3527, decode.d6.loss_mask: 0.5418, decode.d6.loss_dice: 0.8065, decode.d7.loss_cls: 0.3470, decode.d7.loss_mask: 0.5403, decode.d7.loss_dice: 0.8085, decode.d8.loss_cls: 0.3443, decode.d8.loss_mask: 0.5380, decode.d8.loss_dice: 0.8063, loss: 22.0371
2022-12-01 15:48:36,731 - mmseg - INFO - Iter [35700/40000]	lr: 1.430e-08, eta: 5:12:54, time: 4.109, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3213, decode.loss_mask: 0.5261, decode.loss_dice: 0.7761, decode.d0.loss_cls: 4.9293, decode.d0.loss_mask: 0.5220, decode.d0.loss_dice: 0.8343, decode.d1.loss_cls: 0.4315, decode.d1.loss_mask: 0.5517, decode.d1.loss_dice: 0.8301, decode.d2.loss_cls: 0.3804, decode.d2.loss_mask: 0.5372, decode.d2.loss_dice: 0.7953, decode.d3.loss_cls: 0.3486, decode.d3.loss_mask: 0.5344, decode.d3.loss_dice: 0.7848, decode.d4.loss_cls: 0.3385, decode.d4.loss_mask: 0.5320, decode.d4.loss_dice: 0.7825, decode.d5.loss_cls: 0.3272, decode.d5.loss_mask: 0.5283, decode.d5.loss_dice: 0.7769, decode.d6.loss_cls: 0.3255, decode.d6.loss_mask: 0.5274, decode.d6.loss_dice: 0.7779, decode.d7.loss_cls: 0.3207, decode.d7.loss_mask: 0.5252, decode.d7.loss_dice: 0.7755, decode.d8.loss_cls: 0.3198, decode.d8.loss_mask: 0.5272, decode.d8.loss_dice: 0.7740, loss: 21.2617
2022-12-01 15:52:02,626 - mmseg - INFO - Iter [35750/40000]	lr: 1.414e-08, eta: 5:09:14, time: 4.118, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3354, decode.loss_mask: 0.5274, decode.loss_dice: 0.7810, decode.d0.loss_cls: 4.9495, decode.d0.loss_mask: 0.5236, decode.d0.loss_dice: 0.8444, decode.d1.loss_cls: 0.4458, decode.d1.loss_mask: 0.5532, decode.d1.loss_dice: 0.8403, decode.d2.loss_cls: 0.3938, decode.d2.loss_mask: 0.5425, decode.d2.loss_dice: 0.8066, decode.d3.loss_cls: 0.3595, decode.d3.loss_mask: 0.5361, decode.d3.loss_dice: 0.7922, decode.d4.loss_cls: 0.3459, decode.d4.loss_mask: 0.5335, decode.d4.loss_dice: 0.7928, decode.d5.loss_cls: 0.3393, decode.d5.loss_mask: 0.5318, decode.d5.loss_dice: 0.7880, decode.d6.loss_cls: 0.3337, decode.d6.loss_mask: 0.5317, decode.d6.loss_dice: 0.7841, decode.d7.loss_cls: 0.3334, decode.d7.loss_mask: 0.5306, decode.d7.loss_dice: 0.7836, decode.d8.loss_cls: 0.3316, decode.d8.loss_mask: 0.5301, decode.d8.loss_dice: 0.7830, loss: 21.5042
2022-12-01 15:55:28,324 - mmseg - INFO - Iter [35800/40000]	lr: 1.397e-08, eta: 5:05:34, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3243, decode.loss_mask: 0.5383, decode.loss_dice: 0.7964, decode.d0.loss_cls: 4.9585, decode.d0.loss_mask: 0.5356, decode.d0.loss_dice: 0.8599, decode.d1.loss_cls: 0.4363, decode.d1.loss_mask: 0.5682, decode.d1.loss_dice: 0.8592, decode.d2.loss_cls: 0.3805, decode.d2.loss_mask: 0.5555, decode.d2.loss_dice: 0.8209, decode.d3.loss_cls: 0.3534, decode.d3.loss_mask: 0.5465, decode.d3.loss_dice: 0.8102, decode.d4.loss_cls: 0.3443, decode.d4.loss_mask: 0.5430, decode.d4.loss_dice: 0.8031, decode.d5.loss_cls: 0.3326, decode.d5.loss_mask: 0.5403, decode.d5.loss_dice: 0.8020, decode.d6.loss_cls: 0.3307, decode.d6.loss_mask: 0.5416, decode.d6.loss_dice: 0.7967, decode.d7.loss_cls: 0.3278, decode.d7.loss_mask: 0.5375, decode.d7.loss_dice: 0.7972, decode.d8.loss_cls: 0.3266, decode.d8.loss_mask: 0.5383, decode.d8.loss_dice: 0.7954, loss: 21.7008
2022-12-01 15:58:53,795 - mmseg - INFO - Iter [35850/40000]	lr: 1.380e-08, eta: 5:01:54, time: 4.109, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3210, decode.loss_mask: 0.5196, decode.loss_dice: 0.7620, decode.d0.loss_cls: 4.9420, decode.d0.loss_mask: 0.5101, decode.d0.loss_dice: 0.8304, decode.d1.loss_cls: 0.4290, decode.d1.loss_mask: 0.5436, decode.d1.loss_dice: 0.8232, decode.d2.loss_cls: 0.3780, decode.d2.loss_mask: 0.5326, decode.d2.loss_dice: 0.7899, decode.d3.loss_cls: 0.3487, decode.d3.loss_mask: 0.5260, decode.d3.loss_dice: 0.7731, decode.d4.loss_cls: 0.3374, decode.d4.loss_mask: 0.5234, decode.d4.loss_dice: 0.7688, decode.d5.loss_cls: 0.3252, decode.d5.loss_mask: 0.5225, decode.d5.loss_dice: 0.7704, decode.d6.loss_cls: 0.3217, decode.d6.loss_mask: 0.5202, decode.d6.loss_dice: 0.7636, decode.d7.loss_cls: 0.3240, decode.d7.loss_mask: 0.5199, decode.d7.loss_dice: 0.7627, decode.d8.loss_cls: 0.3181, decode.d8.loss_mask: 0.5195, decode.d8.loss_dice: 0.7646, loss: 21.0912
2022-12-01 16:02:19,406 - mmseg - INFO - Iter [35900/40000]	lr: 1.364e-08, eta: 4:58:15, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3256, decode.loss_mask: 0.5095, decode.loss_dice: 0.7749, decode.d0.loss_cls: 4.9847, decode.d0.loss_mask: 0.5070, decode.d0.loss_dice: 0.8431, decode.d1.loss_cls: 0.4406, decode.d1.loss_mask: 0.5366, decode.d1.loss_dice: 0.8387, decode.d2.loss_cls: 0.3907, decode.d2.loss_mask: 0.5206, decode.d2.loss_dice: 0.7996, decode.d3.loss_cls: 0.3540, decode.d3.loss_mask: 0.5175, decode.d3.loss_dice: 0.7895, decode.d4.loss_cls: 0.3482, decode.d4.loss_mask: 0.5137, decode.d4.loss_dice: 0.7868, decode.d5.loss_cls: 0.3360, decode.d5.loss_mask: 0.5124, decode.d5.loss_dice: 0.7844, decode.d6.loss_cls: 0.3291, decode.d6.loss_mask: 0.5114, decode.d6.loss_dice: 0.7784, decode.d7.loss_cls: 0.3273, decode.d7.loss_mask: 0.5089, decode.d7.loss_dice: 0.7757, decode.d8.loss_cls: 0.3270, decode.d8.loss_mask: 0.5097, decode.d8.loss_dice: 0.7769, loss: 21.2586
2022-12-01 16:05:45,376 - mmseg - INFO - Iter [35950/40000]	lr: 1.347e-08, eta: 4:54:35, time: 4.119, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3305, decode.loss_mask: 0.5336, decode.loss_dice: 0.7934, decode.d0.loss_cls: 4.9566, decode.d0.loss_mask: 0.5300, decode.d0.loss_dice: 0.8511, decode.d1.loss_cls: 0.4418, decode.d1.loss_mask: 0.5584, decode.d1.loss_dice: 0.8481, decode.d2.loss_cls: 0.3887, decode.d2.loss_mask: 0.5444, decode.d2.loss_dice: 0.8158, decode.d3.loss_cls: 0.3582, decode.d3.loss_mask: 0.5401, decode.d3.loss_dice: 0.8026, decode.d4.loss_cls: 0.3456, decode.d4.loss_mask: 0.5390, decode.d4.loss_dice: 0.7999, decode.d5.loss_cls: 0.3376, decode.d5.loss_mask: 0.5371, decode.d5.loss_dice: 0.7988, decode.d6.loss_cls: 0.3341, decode.d6.loss_mask: 0.5347, decode.d6.loss_dice: 0.7931, decode.d7.loss_cls: 0.3305, decode.d7.loss_mask: 0.5338, decode.d7.loss_dice: 0.7932, decode.d8.loss_cls: 0.3288, decode.d8.loss_mask: 0.5364, decode.d8.loss_dice: 0.7956, loss: 21.6313
2022-12-01 16:09:10,637 - mmseg - INFO - Saving checkpoint at 36000 iterations
2022-12-01 16:09:59,623 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 16:09:59,624 - mmseg - INFO - Iter [36000/40000]	lr: 1.331e-08, eta: 4:51:01, time: 5.085, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3251, decode.loss_mask: 0.5061, decode.loss_dice: 0.7639, decode.d0.loss_cls: 4.9606, decode.d0.loss_mask: 0.5066, decode.d0.loss_dice: 0.8382, decode.d1.loss_cls: 0.4292, decode.d1.loss_mask: 0.5335, decode.d1.loss_dice: 0.8264, decode.d2.loss_cls: 0.3831, decode.d2.loss_mask: 0.5220, decode.d2.loss_dice: 0.7921, decode.d3.loss_cls: 0.3470, decode.d3.loss_mask: 0.5166, decode.d3.loss_dice: 0.7793, decode.d4.loss_cls: 0.3394, decode.d4.loss_mask: 0.5116, decode.d4.loss_dice: 0.7740, decode.d5.loss_cls: 0.3340, decode.d5.loss_mask: 0.5095, decode.d5.loss_dice: 0.7713, decode.d6.loss_cls: 0.3280, decode.d6.loss_mask: 0.5089, decode.d6.loss_dice: 0.7665, decode.d7.loss_cls: 0.3249, decode.d7.loss_mask: 0.5076, decode.d7.loss_dice: 0.7660, decode.d8.loss_cls: 0.3246, decode.d8.loss_mask: 0.5056, decode.d8.loss_dice: 0.7659, loss: 21.0674
2022-12-01 16:12:57,717 - mmseg - INFO - per class results:
2022-12-01 16:12:57,722 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        |  83.4 |  89.8 |
|       building      | 85.44 | 92.02 |
|         sky         | 95.19 | 97.32 |
|        floor        | 86.22 | 90.77 |
|         tree        | 78.47 | 89.44 |
|       ceiling       | 87.26 | 93.44 |
|         road        | 88.43 | 92.27 |
|         bed         | 93.83 |  97.3 |
|      windowpane     | 68.85 |  82.0 |
|        grass        | 69.05 | 82.36 |
|       cabinet       | 63.49 | 73.11 |
|       sidewalk      | 73.41 | 85.35 |
|        person       | 88.47 | 94.26 |
|        earth        | 42.85 | 57.63 |
|         door        |  65.5 | 83.04 |
|        table        |  71.1 | 81.07 |
|       mountain      | 61.57 | 71.27 |
|        plant        | 57.29 | 70.66 |
|       curtain       |  82.5 | 91.57 |
|        chair        | 69.36 |  79.9 |
|         car         |  89.8 | 95.31 |
|        water        | 70.07 | 86.54 |
|       painting      | 80.14 | 91.46 |
|         sofa        |  85.1 | 91.56 |
|        shelf        | 48.97 | 62.35 |
|        house        | 57.56 | 74.92 |
|         sea         | 81.24 | 90.59 |
|        mirror       |  81.2 | 91.84 |
|         rug         |  73.2 | 86.64 |
|        field        | 34.97 |  62.2 |
|       armchair      | 64.44 | 80.83 |
|         seat        | 66.15 | 88.79 |
|        fence        | 54.95 | 75.53 |
|         desk        |  60.1 | 82.66 |
|         rock        | 62.31 | 75.89 |
|       wardrobe      | 57.86 | 85.27 |
|         lamp        | 81.26 | 90.69 |
|       bathtub       | 92.06 | 94.16 |
|       railing       | 46.83 | 67.58 |
|       cushion       | 78.19 | 90.77 |
|         base        | 44.99 | 65.41 |
|         box         | 45.45 |  64.4 |
|        column       | 58.71 | 72.12 |
|      signboard      | 44.93 | 66.88 |
|   chest of drawers  | 46.09 | 67.59 |
|       counter       | 56.08 | 68.94 |
|         sand        | 60.55 | 87.12 |
|         sink        | 83.44 | 87.17 |
|      skyscraper     | 41.41 | 52.64 |
|      fireplace      | 79.92 | 95.14 |
|     refrigerator    | 82.63 | 92.64 |
|      grandstand     | 49.27 | 79.82 |
|         path        | 29.55 | 41.95 |
|        stairs       |  38.0 | 50.64 |
|        runway       |  73.9 | 93.31 |
|         case        | 67.79 | 86.29 |
|      pool table     | 95.94 |  98.7 |
|        pillow       | 73.31 | 83.09 |
|     screen door     | 84.23 | 92.64 |
|       stairway      | 58.72 | 74.96 |
|        river        | 25.46 | 29.59 |
|        bridge       | 72.02 | 88.88 |
|       bookcase      | 38.21 | 52.92 |
|        blind        | 49.44 |  61.1 |
|     coffee table    | 68.15 | 90.66 |
|        toilet       | 93.26 | 96.79 |
|        flower       | 46.52 | 70.71 |
|         book        | 61.48 | 84.55 |
|         hill        | 13.69 | 27.63 |
|        bench        | 74.78 | 84.32 |
|      countertop     | 71.92 |  91.6 |
|        stove        | 86.57 | 90.44 |
|         palm        | 56.77 | 82.19 |
|    kitchen island   | 48.11 | 92.62 |
|       computer      | 82.56 | 91.21 |
|     swivel chair    | 55.17 | 83.96 |
|         boat        | 59.74 | 90.31 |
|         bar         | 66.86 | 73.96 |
|    arcade machine   | 92.06 | 98.68 |
|        hovel        | 58.32 | 73.28 |
|         bus         | 94.87 | 96.99 |
|        towel        | 83.15 | 93.31 |
|        light        | 67.35 | 79.73 |
|        truck        | 52.56 | 71.47 |
|        tower        | 33.04 | 63.09 |
|      chandelier     | 77.49 | 87.41 |
|        awning       | 31.56 | 52.91 |
|     streetlight     | 46.17 | 71.45 |
|        booth        | 58.06 | 68.66 |
| television receiver | 77.67 | 92.32 |
|       airplane      | 88.61 | 96.45 |
|      dirt track     | 20.16 | 38.38 |
|       apparel       | 53.66 | 84.61 |
|         pole        | 36.46 | 50.24 |
|         land        |  6.3  |  9.31 |
|      bannister      | 22.06 | 34.01 |
|      escalator      | 65.72 | 84.43 |
|       ottoman       | 58.42 | 79.58 |
|        bottle       | 52.09 | 82.68 |
|        buffet       | 45.74 | 62.81 |
|        poster       | 37.71 |  62.7 |
|        stage        | 32.46 | 64.55 |
|         van         | 51.76 | 75.32 |
|         ship        | 69.93 | 77.03 |
|       fountain      | 46.72 | 53.94 |
|    conveyer belt    | 77.98 | 97.05 |
|        canopy       | 65.08 |  86.5 |
|        washer       | 90.82 | 93.56 |
|      plaything      | 37.66 | 59.52 |
|    swimming pool    | 52.54 | 75.96 |
|        stool        | 59.07 | 86.35 |
|        barrel       | 63.75 | 93.78 |
|        basket       | 46.55 | 73.09 |
|      waterfall      | 45.48 | 56.18 |
|         tent        | 95.04 | 98.17 |
|         bag         | 35.44 | 49.96 |
|       minibike      | 81.38 | 93.85 |
|        cradle       | 91.46 | 97.64 |
|         oven        | 65.89 | 83.99 |
|         ball        | 47.41 | 51.34 |
|         food        | 67.08 | 80.37 |
|         step        | 32.61 | 44.58 |
|         tank        |  62.7 | 67.48 |
|      trade name     | 32.93 | 42.42 |
|      microwave      | 89.71 |  94.6 |
|         pot         | 62.35 | 75.14 |
|        animal       | 82.12 | 84.47 |
|       bicycle       |  63.4 | 83.74 |
|         lake        | 65.67 | 68.64 |
|      dishwasher     | 72.86 | 90.57 |
|        screen       | 60.99 |  94.5 |
|       blanket       | 45.19 |  59.1 |
|      sculpture      | 72.92 | 90.38 |
|         hood        | 72.11 |  76.1 |
|        sconce       | 68.11 | 82.97 |
|         vase        |  57.8 | 81.97 |
|    traffic light    | 53.56 | 74.27 |
|         tray        | 33.67 | 52.72 |
|        ashcan       | 54.91 | 81.18 |
|         fan         | 74.03 | 87.29 |
|         pier        | 38.57 | 41.67 |
|      crt screen     |  1.29 |  3.5  |
|        plate        |  69.7 |  85.4 |
|       monitor       |  4.06 |  5.37 |
|    bulletin board   | 63.93 | 84.07 |
|        shower       | 16.78 |  28.5 |
|       radiator      | 72.88 | 93.91 |
|        glass        | 28.97 | 31.85 |
|        clock        | 63.34 |  77.5 |
|         flag        | 67.07 |  87.0 |
+---------------------+-------+-------+
2022-12-01 16:12:57,722 - mmseg - INFO - Summary:
2022-12-01 16:12:57,722 - mmseg - INFO - 
+------+-------+-------+
| aAcc |  mIoU |  mAcc |
+------+-------+-------+
| 87.2 | 61.54 | 76.12 |
+------+-------+-------+
2022-12-01 16:12:57,726 - mmseg - INFO - The previous best checkpoint /mnt/sfs_turbo/output/hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune/lr1.0_lrd0.9/best_mIoU_iter_35000.pth was removed
2022-12-01 16:13:46,071 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_iter_36000.pth.
2022-12-01 16:13:46,071 - mmseg - INFO - Best mIoU is 0.6154 at 36000 iter.
2022-12-01 16:13:46,079 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 16:13:46,080 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8720, mIoU: 0.6154, mAcc: 0.7612, IoU.wall: 0.8340, IoU.building: 0.8544, IoU.sky: 0.9519, IoU.floor: 0.8622, IoU.tree: 0.7847, IoU.ceiling: 0.8726, IoU.road: 0.8843, IoU.bed : 0.9383, IoU.windowpane: 0.6885, IoU.grass: 0.6905, IoU.cabinet: 0.6349, IoU.sidewalk: 0.7341, IoU.person: 0.8847, IoU.earth: 0.4285, IoU.door: 0.6550, IoU.table: 0.7110, IoU.mountain: 0.6157, IoU.plant: 0.5729, IoU.curtain: 0.8250, IoU.chair: 0.6936, IoU.car: 0.8980, IoU.water: 0.7007, IoU.painting: 0.8014, IoU.sofa: 0.8510, IoU.shelf: 0.4897, IoU.house: 0.5756, IoU.sea: 0.8124, IoU.mirror: 0.8120, IoU.rug: 0.7320, IoU.field: 0.3497, IoU.armchair: 0.6444, IoU.seat: 0.6615, IoU.fence: 0.5495, IoU.desk: 0.6010, IoU.rock: 0.6231, IoU.wardrobe: 0.5786, IoU.lamp: 0.8126, IoU.bathtub: 0.9206, IoU.railing: 0.4683, IoU.cushion: 0.7819, IoU.base: 0.4499, IoU.box: 0.4545, IoU.column: 0.5871, IoU.signboard: 0.4493, IoU.chest of drawers: 0.4609, IoU.counter: 0.5608, IoU.sand: 0.6055, IoU.sink: 0.8344, IoU.skyscraper: 0.4141, IoU.fireplace: 0.7992, IoU.refrigerator: 0.8263, IoU.grandstand: 0.4927, IoU.path: 0.2955, IoU.stairs: 0.3800, IoU.runway: 0.7390, IoU.case: 0.6779, IoU.pool table: 0.9594, IoU.pillow: 0.7331, IoU.screen door: 0.8423, IoU.stairway: 0.5872, IoU.river: 0.2546, IoU.bridge: 0.7202, IoU.bookcase: 0.3821, IoU.blind: 0.4944, IoU.coffee table: 0.6815, IoU.toilet: 0.9326, IoU.flower: 0.4652, IoU.book: 0.6148, IoU.hill: 0.1369, IoU.bench: 0.7478, IoU.countertop: 0.7192, IoU.stove: 0.8657, IoU.palm: 0.5677, IoU.kitchen island: 0.4811, IoU.computer: 0.8256, IoU.swivel chair: 0.5517, IoU.boat: 0.5974, IoU.bar: 0.6686, IoU.arcade machine: 0.9206, IoU.hovel: 0.5832, IoU.bus: 0.9487, IoU.towel: 0.8315, IoU.light: 0.6735, IoU.truck: 0.5256, IoU.tower: 0.3304, IoU.chandelier: 0.7749, IoU.awning: 0.3156, IoU.streetlight: 0.4617, IoU.booth: 0.5806, IoU.television receiver: 0.7767, IoU.airplane: 0.8861, IoU.dirt track: 0.2016, IoU.apparel: 0.5366, IoU.pole: 0.3646, IoU.land: 0.0630, IoU.bannister: 0.2206, IoU.escalator: 0.6572, IoU.ottoman: 0.5842, IoU.bottle: 0.5209, IoU.buffet: 0.4574, IoU.poster: 0.3771, IoU.stage: 0.3246, IoU.van: 0.5176, IoU.ship: 0.6993, IoU.fountain: 0.4672, IoU.conveyer belt: 0.7798, IoU.canopy: 0.6508, IoU.washer: 0.9082, IoU.plaything: 0.3766, IoU.swimming pool: 0.5254, IoU.stool: 0.5907, IoU.barrel: 0.6375, IoU.basket: 0.4655, IoU.waterfall: 0.4548, IoU.tent: 0.9504, IoU.bag: 0.3544, IoU.minibike: 0.8138, IoU.cradle: 0.9146, IoU.oven: 0.6589, IoU.ball: 0.4741, IoU.food: 0.6708, IoU.step: 0.3261, IoU.tank: 0.6270, IoU.trade name: 0.3293, IoU.microwave: 0.8971, IoU.pot: 0.6235, IoU.animal: 0.8212, IoU.bicycle: 0.6340, IoU.lake: 0.6567, IoU.dishwasher: 0.7286, IoU.screen: 0.6099, IoU.blanket: 0.4519, IoU.sculpture: 0.7292, IoU.hood: 0.7211, IoU.sconce: 0.6811, IoU.vase: 0.5780, IoU.traffic light: 0.5356, IoU.tray: 0.3367, IoU.ashcan: 0.5491, IoU.fan: 0.7403, IoU.pier: 0.3857, IoU.crt screen: 0.0129, IoU.plate: 0.6970, IoU.monitor: 0.0406, IoU.bulletin board: 0.6393, IoU.shower: 0.1678, IoU.radiator: 0.7288, IoU.glass: 0.2897, IoU.clock: 0.6334, IoU.flag: 0.6707, Acc.wall: 0.8980, Acc.building: 0.9202, Acc.sky: 0.9732, Acc.floor: 0.9077, Acc.tree: 0.8944, Acc.ceiling: 0.9344, Acc.road: 0.9227, Acc.bed : 0.9730, Acc.windowpane: 0.8200, Acc.grass: 0.8236, Acc.cabinet: 0.7311, Acc.sidewalk: 0.8535, Acc.person: 0.9426, Acc.earth: 0.5763, Acc.door: 0.8304, Acc.table: 0.8107, Acc.mountain: 0.7127, Acc.plant: 0.7066, Acc.curtain: 0.9157, Acc.chair: 0.7990, Acc.car: 0.9531, Acc.water: 0.8654, Acc.painting: 0.9146, Acc.sofa: 0.9156, Acc.shelf: 0.6235, Acc.house: 0.7492, Acc.sea: 0.9059, Acc.mirror: 0.9184, Acc.rug: 0.8664, Acc.field: 0.6220, Acc.armchair: 0.8083, Acc.seat: 0.8879, Acc.fence: 0.7553, Acc.desk: 0.8266, Acc.rock: 0.7589, Acc.wardrobe: 0.8527, Acc.lamp: 0.9069, Acc.bathtub: 0.9416, Acc.railing: 0.6758, Acc.cushion: 0.9077, Acc.base: 0.6541, Acc.box: 0.6440, Acc.column: 0.7212, Acc.signboard: 0.6688, Acc.chest of drawers: 0.6759, Acc.counter: 0.6894, Acc.sand: 0.8712, Acc.sink: 0.8717, Acc.skyscraper: 0.5264, Acc.fireplace: 0.9514, Acc.refrigerator: 0.9264, Acc.grandstand: 0.7982, Acc.path: 0.4195, Acc.stairs: 0.5064, Acc.runway: 0.9331, Acc.case: 0.8629, Acc.pool table: 0.9870, Acc.pillow: 0.8309, Acc.screen door: 0.9264, Acc.stairway: 0.7496, Acc.river: 0.2959, Acc.bridge: 0.8888, Acc.bookcase: 0.5292, Acc.blind: 0.6110, Acc.coffee table: 0.9066, Acc.toilet: 0.9679, Acc.flower: 0.7071, Acc.book: 0.8455, Acc.hill: 0.2763, Acc.bench: 0.8432, Acc.countertop: 0.9160, Acc.stove: 0.9044, Acc.palm: 0.8219, Acc.kitchen island: 0.9262, Acc.computer: 0.9121, Acc.swivel chair: 0.8396, Acc.boat: 0.9031, Acc.bar: 0.7396, Acc.arcade machine: 0.9868, Acc.hovel: 0.7328, Acc.bus: 0.9699, Acc.towel: 0.9331, Acc.light: 0.7973, Acc.truck: 0.7147, Acc.tower: 0.6309, Acc.chandelier: 0.8741, Acc.awning: 0.5291, Acc.streetlight: 0.7145, Acc.booth: 0.6866, Acc.television receiver: 0.9232, Acc.airplane: 0.9645, Acc.dirt track: 0.3838, Acc.apparel: 0.8461, Acc.pole: 0.5024, Acc.land: 0.0931, Acc.bannister: 0.3401, Acc.escalator: 0.8443, Acc.ottoman: 0.7958, Acc.bottle: 0.8268, Acc.buffet: 0.6281, Acc.poster: 0.6270, Acc.stage: 0.6455, Acc.van: 0.7532, Acc.ship: 0.7703, Acc.fountain: 0.5394, Acc.conveyer belt: 0.9705, Acc.canopy: 0.8650, Acc.washer: 0.9356, Acc.plaything: 0.5952, Acc.swimming pool: 0.7596, Acc.stool: 0.8635, Acc.barrel: 0.9378, Acc.basket: 0.7309, Acc.waterfall: 0.5618, Acc.tent: 0.9817, Acc.bag: 0.4996, Acc.minibike: 0.9385, Acc.cradle: 0.9764, Acc.oven: 0.8399, Acc.ball: 0.5134, Acc.food: 0.8037, Acc.step: 0.4458, Acc.tank: 0.6748, Acc.trade name: 0.4242, Acc.microwave: 0.9460, Acc.pot: 0.7514, Acc.animal: 0.8447, Acc.bicycle: 0.8374, Acc.lake: 0.6864, Acc.dishwasher: 0.9057, Acc.screen: 0.9450, Acc.blanket: 0.5910, Acc.sculpture: 0.9038, Acc.hood: 0.7610, Acc.sconce: 0.8297, Acc.vase: 0.8197, Acc.traffic light: 0.7427, Acc.tray: 0.5272, Acc.ashcan: 0.8118, Acc.fan: 0.8729, Acc.pier: 0.4167, Acc.crt screen: 0.0350, Acc.plate: 0.8540, Acc.monitor: 0.0537, Acc.bulletin board: 0.8407, Acc.shower: 0.2850, Acc.radiator: 0.9391, Acc.glass: 0.3185, Acc.clock: 0.7750, Acc.flag: 0.8700
2022-12-01 16:17:14,285 - mmseg - INFO - Iter [36050/40000]	lr: 1.314e-08, eta: 4:47:46, time: 8.693, data_time: 4.593, memory: 51902, decode.loss_cls: 0.3225, decode.loss_mask: 0.5167, decode.loss_dice: 0.7742, decode.d0.loss_cls: 4.9432, decode.d0.loss_mask: 0.5152, decode.d0.loss_dice: 0.8398, decode.d1.loss_cls: 0.4435, decode.d1.loss_mask: 0.5455, decode.d1.loss_dice: 0.8319, decode.d2.loss_cls: 0.3853, decode.d2.loss_mask: 0.5303, decode.d2.loss_dice: 0.7997, decode.d3.loss_cls: 0.3506, decode.d3.loss_mask: 0.5263, decode.d3.loss_dice: 0.7898, decode.d4.loss_cls: 0.3424, decode.d4.loss_mask: 0.5239, decode.d4.loss_dice: 0.7843, decode.d5.loss_cls: 0.3319, decode.d5.loss_mask: 0.5212, decode.d5.loss_dice: 0.7819, decode.d6.loss_cls: 0.3289, decode.d6.loss_mask: 0.5193, decode.d6.loss_dice: 0.7788, decode.d7.loss_cls: 0.3249, decode.d7.loss_mask: 0.5198, decode.d7.loss_dice: 0.7771, decode.d8.loss_cls: 0.3229, decode.d8.loss_mask: 0.5188, decode.d8.loss_dice: 0.7757, loss: 21.2662
2022-12-01 16:20:40,126 - mmseg - INFO - Iter [36100/40000]	lr: 1.297e-08, eta: 4:44:06, time: 4.117, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3427, decode.loss_mask: 0.5221, decode.loss_dice: 0.7783, decode.d0.loss_cls: 4.9468, decode.d0.loss_mask: 0.5220, decode.d0.loss_dice: 0.8541, decode.d1.loss_cls: 0.4653, decode.d1.loss_mask: 0.5502, decode.d1.loss_dice: 0.8444, decode.d2.loss_cls: 0.4080, decode.d2.loss_mask: 0.5380, decode.d2.loss_dice: 0.8099, decode.d3.loss_cls: 0.3757, decode.d3.loss_mask: 0.5325, decode.d3.loss_dice: 0.7920, decode.d4.loss_cls: 0.3627, decode.d4.loss_mask: 0.5278, decode.d4.loss_dice: 0.7886, decode.d5.loss_cls: 0.3530, decode.d5.loss_mask: 0.5248, decode.d5.loss_dice: 0.7828, decode.d6.loss_cls: 0.3489, decode.d6.loss_mask: 0.5230, decode.d6.loss_dice: 0.7785, decode.d7.loss_cls: 0.3435, decode.d7.loss_mask: 0.5210, decode.d7.loss_dice: 0.7777, decode.d8.loss_cls: 0.3432, decode.d8.loss_mask: 0.5222, decode.d8.loss_dice: 0.7764, loss: 21.5559
2022-12-01 16:24:05,522 - mmseg - INFO - Iter [36150/40000]	lr: 1.281e-08, eta: 4:40:26, time: 4.108, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3253, decode.loss_mask: 0.5372, decode.loss_dice: 0.7799, decode.d0.loss_cls: 4.9429, decode.d0.loss_mask: 0.5327, decode.d0.loss_dice: 0.8418, decode.d1.loss_cls: 0.4423, decode.d1.loss_mask: 0.5642, decode.d1.loss_dice: 0.8386, decode.d2.loss_cls: 0.3915, decode.d2.loss_mask: 0.5484, decode.d2.loss_dice: 0.8034, decode.d3.loss_cls: 0.3567, decode.d3.loss_mask: 0.5428, decode.d3.loss_dice: 0.7902, decode.d4.loss_cls: 0.3479, decode.d4.loss_mask: 0.5402, decode.d4.loss_dice: 0.7859, decode.d5.loss_cls: 0.3341, decode.d5.loss_mask: 0.5407, decode.d5.loss_dice: 0.7842, decode.d6.loss_cls: 0.3323, decode.d6.loss_mask: 0.5391, decode.d6.loss_dice: 0.7833, decode.d7.loss_cls: 0.3278, decode.d7.loss_mask: 0.5372, decode.d7.loss_dice: 0.7801, decode.d8.loss_cls: 0.3267, decode.d8.loss_mask: 0.5376, decode.d8.loss_dice: 0.7798, loss: 21.5147
2022-12-01 16:27:31,285 - mmseg - INFO - Iter [36200/40000]	lr: 1.264e-08, eta: 4:36:46, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3247, decode.loss_mask: 0.5246, decode.loss_dice: 0.7826, decode.d0.loss_cls: 4.9445, decode.d0.loss_mask: 0.5162, decode.d0.loss_dice: 0.8464, decode.d1.loss_cls: 0.4406, decode.d1.loss_mask: 0.5513, decode.d1.loss_dice: 0.8390, decode.d2.loss_cls: 0.3858, decode.d2.loss_mask: 0.5366, decode.d2.loss_dice: 0.8076, decode.d3.loss_cls: 0.3521, decode.d3.loss_mask: 0.5311, decode.d3.loss_dice: 0.7955, decode.d4.loss_cls: 0.3445, decode.d4.loss_mask: 0.5298, decode.d4.loss_dice: 0.7884, decode.d5.loss_cls: 0.3392, decode.d5.loss_mask: 0.5271, decode.d5.loss_dice: 0.7849, decode.d6.loss_cls: 0.3352, decode.d6.loss_mask: 0.5241, decode.d6.loss_dice: 0.7790, decode.d7.loss_cls: 0.3313, decode.d7.loss_mask: 0.5214, decode.d7.loss_dice: 0.7793, decode.d8.loss_cls: 0.3309, decode.d8.loss_mask: 0.5224, decode.d8.loss_dice: 0.7794, loss: 21.3953
2022-12-01 16:30:56,755 - mmseg - INFO - Iter [36250/40000]	lr: 1.247e-08, eta: 4:33:07, time: 4.109, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3288, decode.loss_mask: 0.5265, decode.loss_dice: 0.7789, decode.d0.loss_cls: 4.9533, decode.d0.loss_mask: 0.5242, decode.d0.loss_dice: 0.8460, decode.d1.loss_cls: 0.4358, decode.d1.loss_mask: 0.5559, decode.d1.loss_dice: 0.8384, decode.d2.loss_cls: 0.3866, decode.d2.loss_mask: 0.5410, decode.d2.loss_dice: 0.8032, decode.d3.loss_cls: 0.3612, decode.d3.loss_mask: 0.5343, decode.d3.loss_dice: 0.7869, decode.d4.loss_cls: 0.3497, decode.d4.loss_mask: 0.5313, decode.d4.loss_dice: 0.7837, decode.d5.loss_cls: 0.3384, decode.d5.loss_mask: 0.5282, decode.d5.loss_dice: 0.7828, decode.d6.loss_cls: 0.3339, decode.d6.loss_mask: 0.5271, decode.d6.loss_dice: 0.7810, decode.d7.loss_cls: 0.3300, decode.d7.loss_mask: 0.5277, decode.d7.loss_dice: 0.7811, decode.d8.loss_cls: 0.3293, decode.d8.loss_mask: 0.5257, decode.d8.loss_dice: 0.7766, loss: 21.4275
2022-12-01 16:34:22,130 - mmseg - INFO - Iter [36300/40000]	lr: 1.231e-08, eta: 4:29:27, time: 4.107, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3306, decode.loss_mask: 0.5321, decode.loss_dice: 0.7912, decode.d0.loss_cls: 4.9385, decode.d0.loss_mask: 0.5303, decode.d0.loss_dice: 0.8599, decode.d1.loss_cls: 0.4526, decode.d1.loss_mask: 0.5586, decode.d1.loss_dice: 0.8513, decode.d2.loss_cls: 0.3920, decode.d2.loss_mask: 0.5457, decode.d2.loss_dice: 0.8185, decode.d3.loss_cls: 0.3617, decode.d3.loss_mask: 0.5380, decode.d3.loss_dice: 0.8019, decode.d4.loss_cls: 0.3503, decode.d4.loss_mask: 0.5362, decode.d4.loss_dice: 0.7987, decode.d5.loss_cls: 0.3453, decode.d5.loss_mask: 0.5342, decode.d5.loss_dice: 0.7945, decode.d6.loss_cls: 0.3318, decode.d6.loss_mask: 0.5346, decode.d6.loss_dice: 0.7944, decode.d7.loss_cls: 0.3353, decode.d7.loss_mask: 0.5316, decode.d7.loss_dice: 0.7911, decode.d8.loss_cls: 0.3304, decode.d8.loss_mask: 0.5323, decode.d8.loss_dice: 0.7934, loss: 21.6369
2022-12-01 16:37:47,821 - mmseg - INFO - Iter [36350/40000]	lr: 1.214e-08, eta: 4:25:47, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3223, decode.loss_mask: 0.5200, decode.loss_dice: 0.7756, decode.d0.loss_cls: 4.9484, decode.d0.loss_mask: 0.5149, decode.d0.loss_dice: 0.8373, decode.d1.loss_cls: 0.4387, decode.d1.loss_mask: 0.5464, decode.d1.loss_dice: 0.8302, decode.d2.loss_cls: 0.3838, decode.d2.loss_mask: 0.5353, decode.d2.loss_dice: 0.7992, decode.d3.loss_cls: 0.3513, decode.d3.loss_mask: 0.5301, decode.d3.loss_dice: 0.7845, decode.d4.loss_cls: 0.3434, decode.d4.loss_mask: 0.5259, decode.d4.loss_dice: 0.7800, decode.d5.loss_cls: 0.3320, decode.d5.loss_mask: 0.5255, decode.d5.loss_dice: 0.7774, decode.d6.loss_cls: 0.3260, decode.d6.loss_mask: 0.5249, decode.d6.loss_dice: 0.7771, decode.d7.loss_cls: 0.3214, decode.d7.loss_mask: 0.5223, decode.d7.loss_dice: 0.7752, decode.d8.loss_cls: 0.3210, decode.d8.loss_mask: 0.5221, decode.d8.loss_dice: 0.7759, loss: 21.2681
2022-12-01 16:41:13,539 - mmseg - INFO - Iter [36400/40000]	lr: 1.198e-08, eta: 4:22:07, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3213, decode.loss_mask: 0.5156, decode.loss_dice: 0.7909, decode.d0.loss_cls: 4.9409, decode.d0.loss_mask: 0.5098, decode.d0.loss_dice: 0.8548, decode.d1.loss_cls: 0.4443, decode.d1.loss_mask: 0.5436, decode.d1.loss_dice: 0.8513, decode.d2.loss_cls: 0.3869, decode.d2.loss_mask: 0.5309, decode.d2.loss_dice: 0.8176, decode.d3.loss_cls: 0.3504, decode.d3.loss_mask: 0.5251, decode.d3.loss_dice: 0.8063, decode.d4.loss_cls: 0.3412, decode.d4.loss_mask: 0.5230, decode.d4.loss_dice: 0.8013, decode.d5.loss_cls: 0.3312, decode.d5.loss_mask: 0.5201, decode.d5.loss_dice: 0.7993, decode.d6.loss_cls: 0.3272, decode.d6.loss_mask: 0.5165, decode.d6.loss_dice: 0.7951, decode.d7.loss_cls: 0.3236, decode.d7.loss_mask: 0.5164, decode.d7.loss_dice: 0.7955, decode.d8.loss_cls: 0.3221, decode.d8.loss_mask: 0.5166, decode.d8.loss_dice: 0.7959, loss: 21.4146
2022-12-01 16:44:38,932 - mmseg - INFO - Iter [36450/40000]	lr: 1.181e-08, eta: 4:18:28, time: 4.108, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3156, decode.loss_mask: 0.5232, decode.loss_dice: 0.7811, decode.d0.loss_cls: 4.9455, decode.d0.loss_mask: 0.5217, decode.d0.loss_dice: 0.8441, decode.d1.loss_cls: 0.4354, decode.d1.loss_mask: 0.5521, decode.d1.loss_dice: 0.8385, decode.d2.loss_cls: 0.3765, decode.d2.loss_mask: 0.5376, decode.d2.loss_dice: 0.8076, decode.d3.loss_cls: 0.3498, decode.d3.loss_mask: 0.5323, decode.d3.loss_dice: 0.7940, decode.d4.loss_cls: 0.3364, decode.d4.loss_mask: 0.5312, decode.d4.loss_dice: 0.7901, decode.d5.loss_cls: 0.3276, decode.d5.loss_mask: 0.5258, decode.d5.loss_dice: 0.7846, decode.d6.loss_cls: 0.3243, decode.d6.loss_mask: 0.5258, decode.d6.loss_dice: 0.7818, decode.d7.loss_cls: 0.3204, decode.d7.loss_mask: 0.5238, decode.d7.loss_dice: 0.7797, decode.d8.loss_cls: 0.3191, decode.d8.loss_mask: 0.5237, decode.d8.loss_dice: 0.7800, loss: 21.3293
2022-12-01 16:48:04,359 - mmseg - INFO - Iter [36500/40000]	lr: 1.164e-08, eta: 4:14:48, time: 4.109, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3050, decode.loss_mask: 0.5147, decode.loss_dice: 0.7753, decode.d0.loss_cls: 4.9338, decode.d0.loss_mask: 0.5038, decode.d0.loss_dice: 0.8263, decode.d1.loss_cls: 0.4146, decode.d1.loss_mask: 0.5406, decode.d1.loss_dice: 0.8319, decode.d2.loss_cls: 0.3584, decode.d2.loss_mask: 0.5312, decode.d2.loss_dice: 0.8020, decode.d3.loss_cls: 0.3299, decode.d3.loss_mask: 0.5209, decode.d3.loss_dice: 0.7883, decode.d4.loss_cls: 0.3216, decode.d4.loss_mask: 0.5184, decode.d4.loss_dice: 0.7862, decode.d5.loss_cls: 0.3131, decode.d5.loss_mask: 0.5164, decode.d5.loss_dice: 0.7785, decode.d6.loss_cls: 0.3119, decode.d6.loss_mask: 0.5153, decode.d6.loss_dice: 0.7776, decode.d7.loss_cls: 0.3046, decode.d7.loss_mask: 0.5159, decode.d7.loss_dice: 0.7773, decode.d8.loss_cls: 0.3053, decode.d8.loss_mask: 0.5150, decode.d8.loss_dice: 0.7751, loss: 21.0086
2022-12-01 16:51:30,102 - mmseg - INFO - Iter [36550/40000]	lr: 1.148e-08, eta: 4:11:08, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3265, decode.loss_mask: 0.5356, decode.loss_dice: 0.7813, decode.d0.loss_cls: 4.9174, decode.d0.loss_mask: 0.5272, decode.d0.loss_dice: 0.8422, decode.d1.loss_cls: 0.4410, decode.d1.loss_mask: 0.5590, decode.d1.loss_dice: 0.8375, decode.d2.loss_cls: 0.3861, decode.d2.loss_mask: 0.5453, decode.d2.loss_dice: 0.8048, decode.d3.loss_cls: 0.3531, decode.d3.loss_mask: 0.5406, decode.d3.loss_dice: 0.7922, decode.d4.loss_cls: 0.3440, decode.d4.loss_mask: 0.5369, decode.d4.loss_dice: 0.7873, decode.d5.loss_cls: 0.3353, decode.d5.loss_mask: 0.5362, decode.d5.loss_dice: 0.7860, decode.d6.loss_cls: 0.3305, decode.d6.loss_mask: 0.5356, decode.d6.loss_dice: 0.7817, decode.d7.loss_cls: 0.3264, decode.d7.loss_mask: 0.5337, decode.d7.loss_dice: 0.7797, decode.d8.loss_cls: 0.3272, decode.d8.loss_mask: 0.5362, decode.d8.loss_dice: 0.7819, loss: 21.4484
2022-12-01 16:54:55,448 - mmseg - INFO - Iter [36600/40000]	lr: 1.131e-08, eta: 4:07:29, time: 4.107, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3224, decode.loss_mask: 0.5160, decode.loss_dice: 0.7760, decode.d0.loss_cls: 4.9705, decode.d0.loss_mask: 0.5091, decode.d0.loss_dice: 0.8397, decode.d1.loss_cls: 0.4395, decode.d1.loss_mask: 0.5437, decode.d1.loss_dice: 0.8324, decode.d2.loss_cls: 0.3798, decode.d2.loss_mask: 0.5310, decode.d2.loss_dice: 0.7992, decode.d3.loss_cls: 0.3477, decode.d3.loss_mask: 0.5261, decode.d3.loss_dice: 0.7863, decode.d4.loss_cls: 0.3441, decode.d4.loss_mask: 0.5223, decode.d4.loss_dice: 0.7834, decode.d5.loss_cls: 0.3328, decode.d5.loss_mask: 0.5186, decode.d5.loss_dice: 0.7788, decode.d6.loss_cls: 0.3278, decode.d6.loss_mask: 0.5185, decode.d6.loss_dice: 0.7780, decode.d7.loss_cls: 0.3259, decode.d7.loss_mask: 0.5169, decode.d7.loss_dice: 0.7786, decode.d8.loss_cls: 0.3219, decode.d8.loss_mask: 0.5174, decode.d8.loss_dice: 0.7812, loss: 21.2653
2022-12-01 16:58:21,189 - mmseg - INFO - Iter [36650/40000]	lr: 1.114e-08, eta: 4:03:49, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3282, decode.loss_mask: 0.5252, decode.loss_dice: 0.7732, decode.d0.loss_cls: 4.9572, decode.d0.loss_mask: 0.5167, decode.d0.loss_dice: 0.8356, decode.d1.loss_cls: 0.4454, decode.d1.loss_mask: 0.5518, decode.d1.loss_dice: 0.8314, decode.d2.loss_cls: 0.3863, decode.d2.loss_mask: 0.5392, decode.d2.loss_dice: 0.7977, decode.d3.loss_cls: 0.3542, decode.d3.loss_mask: 0.5334, decode.d3.loss_dice: 0.7847, decode.d4.loss_cls: 0.3485, decode.d4.loss_mask: 0.5302, decode.d4.loss_dice: 0.7813, decode.d5.loss_cls: 0.3360, decode.d5.loss_mask: 0.5283, decode.d5.loss_dice: 0.7777, decode.d6.loss_cls: 0.3329, decode.d6.loss_mask: 0.5283, decode.d6.loss_dice: 0.7761, decode.d7.loss_cls: 0.3308, decode.d7.loss_mask: 0.5282, decode.d7.loss_dice: 0.7744, decode.d8.loss_cls: 0.3298, decode.d8.loss_mask: 0.5269, decode.d8.loss_dice: 0.7760, loss: 21.3655
2022-12-01 17:01:49,170 - mmseg - INFO - Iter [36700/40000]	lr: 1.098e-08, eta: 4:00:10, time: 4.160, data_time: 0.066, memory: 51902, decode.loss_cls: 0.3116, decode.loss_mask: 0.5133, decode.loss_dice: 0.7696, decode.d0.loss_cls: 4.9139, decode.d0.loss_mask: 0.5085, decode.d0.loss_dice: 0.8223, decode.d1.loss_cls: 0.4166, decode.d1.loss_mask: 0.5424, decode.d1.loss_dice: 0.8189, decode.d2.loss_cls: 0.3697, decode.d2.loss_mask: 0.5299, decode.d2.loss_dice: 0.7890, decode.d3.loss_cls: 0.3381, decode.d3.loss_mask: 0.5237, decode.d3.loss_dice: 0.7777, decode.d4.loss_cls: 0.3248, decode.d4.loss_mask: 0.5203, decode.d4.loss_dice: 0.7771, decode.d5.loss_cls: 0.3171, decode.d5.loss_mask: 0.5183, decode.d5.loss_dice: 0.7751, decode.d6.loss_cls: 0.3138, decode.d6.loss_mask: 0.5172, decode.d6.loss_dice: 0.7702, decode.d7.loss_cls: 0.3155, decode.d7.loss_mask: 0.5156, decode.d7.loss_dice: 0.7686, decode.d8.loss_cls: 0.3149, decode.d8.loss_mask: 0.5142, decode.d8.loss_dice: 0.7674, loss: 20.9754
2022-12-01 17:05:14,628 - mmseg - INFO - Iter [36750/40000]	lr: 1.081e-08, eta: 3:56:30, time: 4.109, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3213, decode.loss_mask: 0.5215, decode.loss_dice: 0.7696, decode.d0.loss_cls: 4.9325, decode.d0.loss_mask: 0.5205, decode.d0.loss_dice: 0.8357, decode.d1.loss_cls: 0.4343, decode.d1.loss_mask: 0.5509, decode.d1.loss_dice: 0.8259, decode.d2.loss_cls: 0.3775, decode.d2.loss_mask: 0.5379, decode.d2.loss_dice: 0.7945, decode.d3.loss_cls: 0.3508, decode.d3.loss_mask: 0.5285, decode.d3.loss_dice: 0.7805, decode.d4.loss_cls: 0.3408, decode.d4.loss_mask: 0.5257, decode.d4.loss_dice: 0.7768, decode.d5.loss_cls: 0.3335, decode.d5.loss_mask: 0.5232, decode.d5.loss_dice: 0.7727, decode.d6.loss_cls: 0.3257, decode.d6.loss_mask: 0.5224, decode.d6.loss_dice: 0.7701, decode.d7.loss_cls: 0.3198, decode.d7.loss_mask: 0.5225, decode.d7.loss_dice: 0.7703, decode.d8.loss_cls: 0.3208, decode.d8.loss_mask: 0.5197, decode.d8.loss_dice: 0.7671, loss: 21.1930
2022-12-01 17:08:40,359 - mmseg - INFO - Iter [36800/40000]	lr: 1.065e-08, eta: 3:52:51, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3346, decode.loss_mask: 0.5226, decode.loss_dice: 0.7919, decode.d0.loss_cls: 4.9490, decode.d0.loss_mask: 0.5264, decode.d0.loss_dice: 0.8636, decode.d1.loss_cls: 0.4506, decode.d1.loss_mask: 0.5499, decode.d1.loss_dice: 0.8512, decode.d2.loss_cls: 0.3922, decode.d2.loss_mask: 0.5377, decode.d2.loss_dice: 0.8220, decode.d3.loss_cls: 0.3640, decode.d3.loss_mask: 0.5315, decode.d3.loss_dice: 0.8030, decode.d4.loss_cls: 0.3515, decode.d4.loss_mask: 0.5301, decode.d4.loss_dice: 0.8017, decode.d5.loss_cls: 0.3439, decode.d5.loss_mask: 0.5260, decode.d5.loss_dice: 0.7981, decode.d6.loss_cls: 0.3374, decode.d6.loss_mask: 0.5246, decode.d6.loss_dice: 0.7926, decode.d7.loss_cls: 0.3305, decode.d7.loss_mask: 0.5240, decode.d7.loss_dice: 0.7946, decode.d8.loss_cls: 0.3319, decode.d8.loss_mask: 0.5235, decode.d8.loss_dice: 0.7965, loss: 21.5970
2022-12-01 17:12:06,064 - mmseg - INFO - Iter [36850/40000]	lr: 1.048e-08, eta: 3:49:12, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3181, decode.loss_mask: 0.5257, decode.loss_dice: 0.7680, decode.d0.loss_cls: 4.9236, decode.d0.loss_mask: 0.5228, decode.d0.loss_dice: 0.8379, decode.d1.loss_cls: 0.4352, decode.d1.loss_mask: 0.5543, decode.d1.loss_dice: 0.8272, decode.d2.loss_cls: 0.3825, decode.d2.loss_mask: 0.5406, decode.d2.loss_dice: 0.7941, decode.d3.loss_cls: 0.3488, decode.d3.loss_mask: 0.5347, decode.d3.loss_dice: 0.7801, decode.d4.loss_cls: 0.3362, decode.d4.loss_mask: 0.5327, decode.d4.loss_dice: 0.7764, decode.d5.loss_cls: 0.3290, decode.d5.loss_mask: 0.5299, decode.d5.loss_dice: 0.7736, decode.d6.loss_cls: 0.3267, decode.d6.loss_mask: 0.5274, decode.d6.loss_dice: 0.7728, decode.d7.loss_cls: 0.3217, decode.d7.loss_mask: 0.5260, decode.d7.loss_dice: 0.7720, decode.d8.loss_cls: 0.3213, decode.d8.loss_mask: 0.5260, decode.d8.loss_dice: 0.7703, loss: 21.2358
2022-12-01 17:15:31,903 - mmseg - INFO - Iter [36900/40000]	lr: 1.031e-08, eta: 3:45:32, time: 4.117, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3331, decode.loss_mask: 0.5207, decode.loss_dice: 0.7760, decode.d0.loss_cls: 4.9238, decode.d0.loss_mask: 0.5168, decode.d0.loss_dice: 0.8434, decode.d1.loss_cls: 0.4513, decode.d1.loss_mask: 0.5496, decode.d1.loss_dice: 0.8348, decode.d2.loss_cls: 0.3972, decode.d2.loss_mask: 0.5344, decode.d2.loss_dice: 0.8027, decode.d3.loss_cls: 0.3590, decode.d3.loss_mask: 0.5295, decode.d3.loss_dice: 0.7897, decode.d4.loss_cls: 0.3513, decode.d4.loss_mask: 0.5255, decode.d4.loss_dice: 0.7856, decode.d5.loss_cls: 0.3439, decode.d5.loss_mask: 0.5218, decode.d5.loss_dice: 0.7801, decode.d6.loss_cls: 0.3389, decode.d6.loss_mask: 0.5204, decode.d6.loss_dice: 0.7778, decode.d7.loss_cls: 0.3348, decode.d7.loss_mask: 0.5209, decode.d7.loss_dice: 0.7768, decode.d8.loss_cls: 0.3315, decode.d8.loss_mask: 0.5211, decode.d8.loss_dice: 0.7758, loss: 21.3682
2022-12-01 17:18:57,402 - mmseg - INFO - Iter [36950/40000]	lr: 1.015e-08, eta: 3:41:53, time: 4.110, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3173, decode.loss_mask: 0.5325, decode.loss_dice: 0.7668, decode.d0.loss_cls: 4.9133, decode.d0.loss_mask: 0.5231, decode.d0.loss_dice: 0.8335, decode.d1.loss_cls: 0.4283, decode.d1.loss_mask: 0.5588, decode.d1.loss_dice: 0.8250, decode.d2.loss_cls: 0.3725, decode.d2.loss_mask: 0.5470, decode.d2.loss_dice: 0.7959, decode.d3.loss_cls: 0.3421, decode.d3.loss_mask: 0.5430, decode.d3.loss_dice: 0.7802, decode.d4.loss_cls: 0.3348, decode.d4.loss_mask: 0.5371, decode.d4.loss_dice: 0.7774, decode.d5.loss_cls: 0.3227, decode.d5.loss_mask: 0.5348, decode.d5.loss_dice: 0.7712, decode.d6.loss_cls: 0.3200, decode.d6.loss_mask: 0.5335, decode.d6.loss_dice: 0.7669, decode.d7.loss_cls: 0.3193, decode.d7.loss_mask: 0.5337, decode.d7.loss_dice: 0.7665, decode.d8.loss_cls: 0.3165, decode.d8.loss_mask: 0.5333, decode.d8.loss_dice: 0.7681, loss: 21.2152
2022-12-01 17:22:22,955 - mmseg - INFO - Saving checkpoint at 37000 iterations
2022-12-01 17:23:11,055 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 17:23:11,056 - mmseg - INFO - Iter [37000/40000]	lr: 9.980e-09, eta: 3:38:18, time: 5.073, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3061, decode.loss_mask: 0.5217, decode.loss_dice: 0.7644, decode.d0.loss_cls: 4.9377, decode.d0.loss_mask: 0.5196, decode.d0.loss_dice: 0.8328, decode.d1.loss_cls: 0.4200, decode.d1.loss_mask: 0.5516, decode.d1.loss_dice: 0.8265, decode.d2.loss_cls: 0.3655, decode.d2.loss_mask: 0.5369, decode.d2.loss_dice: 0.7893, decode.d3.loss_cls: 0.3324, decode.d3.loss_mask: 0.5294, decode.d3.loss_dice: 0.7758, decode.d4.loss_cls: 0.3266, decode.d4.loss_mask: 0.5257, decode.d4.loss_dice: 0.7712, decode.d5.loss_cls: 0.3176, decode.d5.loss_mask: 0.5233, decode.d5.loss_dice: 0.7654, decode.d6.loss_cls: 0.3123, decode.d6.loss_mask: 0.5210, decode.d6.loss_dice: 0.7639, decode.d7.loss_cls: 0.3113, decode.d7.loss_mask: 0.5206, decode.d7.loss_dice: 0.7674, decode.d8.loss_cls: 0.3117, decode.d8.loss_mask: 0.5211, decode.d8.loss_dice: 0.7664, loss: 21.0352
2022-12-01 17:26:09,046 - mmseg - INFO - per class results:
2022-12-01 17:26:09,051 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 83.49 | 89.75 |
|       building      | 85.48 | 92.27 |
|         sky         | 95.17 | 97.38 |
|        floor        |  85.4 | 90.43 |
|         tree        | 78.59 | 89.59 |
|       ceiling       | 87.53 | 93.15 |
|         road        | 88.35 | 91.65 |
|         bed         | 93.76 | 97.25 |
|      windowpane     | 68.45 | 82.19 |
|        grass        | 68.35 | 80.54 |
|       cabinet       | 63.64 | 72.62 |
|       sidewalk      | 72.14 | 85.68 |
|        person       | 88.42 | 94.18 |
|        earth        | 42.55 | 59.55 |
|         door        | 65.17 | 82.98 |
|        table        | 71.39 | 81.07 |
|       mountain      |  59.0 | 66.85 |
|        plant        | 57.64 | 70.43 |
|       curtain       | 82.26 | 91.11 |
|        chair        | 69.52 | 79.89 |
|         car         | 89.72 | 95.21 |
|        water        |  70.4 | 85.94 |
|       painting      | 79.93 | 91.14 |
|         sofa        | 85.21 | 91.24 |
|        shelf        | 49.14 | 62.69 |
|        house        | 57.46 | 74.72 |
|         sea         |  80.7 | 91.02 |
|        mirror       | 81.33 | 91.77 |
|         rug         | 72.58 | 86.13 |
|        field        | 38.52 |  71.9 |
|       armchair      | 64.28 | 80.78 |
|         seat        | 66.21 | 89.87 |
|        fence        | 55.28 | 73.69 |
|         desk        | 59.03 | 83.99 |
|         rock        | 60.13 | 76.35 |
|       wardrobe      | 58.64 | 86.79 |
|         lamp        | 81.33 | 90.63 |
|       bathtub       |  91.5 | 93.82 |
|       railing       | 46.37 | 66.92 |
|       cushion       | 77.99 | 91.35 |
|         base        | 41.68 | 63.49 |
|         box         | 44.83 | 63.75 |
|        column       | 59.61 | 71.53 |
|      signboard      | 44.77 | 67.26 |
|   chest of drawers  | 44.37 | 67.61 |
|       counter       | 58.82 | 68.63 |
|         sand        | 58.98 | 85.16 |
|         sink        | 86.16 | 89.87 |
|      skyscraper     | 43.34 | 54.43 |
|      fireplace      | 79.11 | 94.99 |
|     refrigerator    | 82.31 | 92.88 |
|      grandstand     | 48.91 | 79.58 |
|         path        | 31.33 | 41.53 |
|        stairs       | 37.73 | 50.22 |
|        runway       | 74.52 | 93.73 |
|         case        |  67.1 | 86.56 |
|      pool table     | 95.95 | 98.63 |
|        pillow       | 73.34 |  83.4 |
|     screen door     | 84.05 | 92.26 |
|       stairway      | 55.32 | 70.03 |
|        river        | 29.39 | 35.64 |
|        bridge       | 71.07 | 86.88 |
|       bookcase      | 39.82 | 56.83 |
|        blind        | 46.64 | 57.91 |
|     coffee table    | 68.29 | 89.89 |
|        toilet       | 93.16 |  96.7 |
|        flower       | 47.47 | 70.16 |
|         book        | 61.85 | 83.47 |
|         hill        | 12.66 | 29.06 |
|        bench        | 75.41 | 83.71 |
|      countertop     | 70.85 | 90.72 |
|        stove        | 86.33 | 90.31 |
|         palm        | 56.79 | 82.23 |
|    kitchen island   | 50.63 | 94.79 |
|       computer      | 78.91 | 87.09 |
|     swivel chair    | 55.59 | 84.51 |
|         boat        | 52.52 | 90.52 |
|         bar         |  66.2 | 72.91 |
|    arcade machine   | 91.93 | 98.73 |
|        hovel        | 63.61 | 72.93 |
|         bus         | 95.36 | 97.46 |
|        towel        | 82.84 | 91.92 |
|        light        |  67.1 | 79.21 |
|        truck        |  52.9 | 71.91 |
|        tower        | 33.28 |  63.0 |
|      chandelier     | 77.42 | 86.48 |
|        awning       | 32.84 | 52.04 |
|     streetlight     | 46.37 | 71.71 |
|        booth        | 62.83 | 78.77 |
| television receiver | 81.57 | 92.37 |
|       airplane      | 88.81 | 96.33 |
|      dirt track     | 25.29 | 38.11 |
|       apparel       |  54.8 | 83.95 |
|         pole        | 36.26 | 49.78 |
|         land        |  6.21 |  9.65 |
|      bannister      | 22.71 | 35.16 |
|      escalator      | 65.65 | 83.71 |
|       ottoman       | 57.03 | 79.52 |
|        bottle       | 52.03 | 82.67 |
|        buffet       | 46.14 | 64.31 |
|        poster       |  37.7 | 62.21 |
|        stage        | 30.81 |  68.9 |
|         van         |  52.6 | 74.79 |
|         ship        | 27.64 | 29.19 |
|       fountain      | 57.92 | 63.32 |
|    conveyer belt    | 77.81 | 96.99 |
|        canopy       |  55.4 | 74.52 |
|        washer       | 90.97 | 93.44 |
|      plaything      |  36.5 | 59.66 |
|    swimming pool    | 48.69 | 75.72 |
|        stool        | 59.06 | 82.23 |
|        barrel       | 65.74 | 95.77 |
|        basket       |  47.4 | 69.78 |
|      waterfall      | 45.69 | 56.29 |
|         tent        |  91.3 | 98.12 |
|         bag         | 33.92 | 49.59 |
|       minibike      | 81.27 | 93.89 |
|        cradle       | 91.39 | 97.44 |
|         oven        | 65.79 | 84.03 |
|         ball        | 43.12 | 46.58 |
|         food        |  65.2 | 77.41 |
|         step        | 27.02 | 34.59 |
|         tank        | 60.29 | 67.62 |
|      trade name     | 29.56 | 37.92 |
|      microwave      | 89.64 | 94.59 |
|         pot         | 64.52 | 77.23 |
|        animal       |  80.2 | 82.46 |
|       bicycle       | 64.89 | 83.53 |
|         lake        | 60.61 | 69.51 |
|      dishwasher     | 80.26 | 90.55 |
|        screen       | 61.02 | 94.25 |
|       blanket       | 44.74 |  57.7 |
|      sculpture      | 74.77 | 90.55 |
|         hood        | 85.48 | 90.17 |
|        sconce       | 68.34 | 82.94 |
|         vase        | 58.89 | 82.06 |
|    traffic light    | 53.55 | 73.92 |
|         tray        | 34.97 | 55.21 |
|        ashcan       | 54.33 | 80.48 |
|         fan         |  74.3 | 87.41 |
|         pier        | 38.83 | 41.66 |
|      crt screen     |  1.48 |  4.01 |
|        plate        | 70.45 | 83.82 |
|       monitor       | 10.32 | 14.84 |
|    bulletin board   | 63.27 | 85.83 |
|        shower       | 15.81 | 28.67 |
|       radiator      | 74.48 | 93.35 |
|        glass        | 28.99 | 31.82 |
|        clock        | 63.58 | 77.35 |
|         flag        | 67.47 | 86.97 |
+---------------------+-------+-------+
2022-12-01 17:26:09,051 - mmseg - INFO - Summary:
2022-12-01 17:26:09,051 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 87.08 | 61.33 | 75.83 |
+-------+-------+-------+
2022-12-01 17:26:09,057 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 17:26:09,057 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8708, mIoU: 0.6133, mAcc: 0.7583, IoU.wall: 0.8349, IoU.building: 0.8548, IoU.sky: 0.9517, IoU.floor: 0.8540, IoU.tree: 0.7859, IoU.ceiling: 0.8753, IoU.road: 0.8835, IoU.bed : 0.9376, IoU.windowpane: 0.6845, IoU.grass: 0.6835, IoU.cabinet: 0.6364, IoU.sidewalk: 0.7214, IoU.person: 0.8842, IoU.earth: 0.4255, IoU.door: 0.6517, IoU.table: 0.7139, IoU.mountain: 0.5900, IoU.plant: 0.5764, IoU.curtain: 0.8226, IoU.chair: 0.6952, IoU.car: 0.8972, IoU.water: 0.7040, IoU.painting: 0.7993, IoU.sofa: 0.8521, IoU.shelf: 0.4914, IoU.house: 0.5746, IoU.sea: 0.8070, IoU.mirror: 0.8133, IoU.rug: 0.7258, IoU.field: 0.3852, IoU.armchair: 0.6428, IoU.seat: 0.6621, IoU.fence: 0.5528, IoU.desk: 0.5903, IoU.rock: 0.6013, IoU.wardrobe: 0.5864, IoU.lamp: 0.8133, IoU.bathtub: 0.9150, IoU.railing: 0.4637, IoU.cushion: 0.7799, IoU.base: 0.4168, IoU.box: 0.4483, IoU.column: 0.5961, IoU.signboard: 0.4477, IoU.chest of drawers: 0.4437, IoU.counter: 0.5882, IoU.sand: 0.5898, IoU.sink: 0.8616, IoU.skyscraper: 0.4334, IoU.fireplace: 0.7911, IoU.refrigerator: 0.8231, IoU.grandstand: 0.4891, IoU.path: 0.3133, IoU.stairs: 0.3773, IoU.runway: 0.7452, IoU.case: 0.6710, IoU.pool table: 0.9595, IoU.pillow: 0.7334, IoU.screen door: 0.8405, IoU.stairway: 0.5532, IoU.river: 0.2939, IoU.bridge: 0.7107, IoU.bookcase: 0.3982, IoU.blind: 0.4664, IoU.coffee table: 0.6829, IoU.toilet: 0.9316, IoU.flower: 0.4747, IoU.book: 0.6185, IoU.hill: 0.1266, IoU.bench: 0.7541, IoU.countertop: 0.7085, IoU.stove: 0.8633, IoU.palm: 0.5679, IoU.kitchen island: 0.5063, IoU.computer: 0.7891, IoU.swivel chair: 0.5559, IoU.boat: 0.5252, IoU.bar: 0.6620, IoU.arcade machine: 0.9193, IoU.hovel: 0.6361, IoU.bus: 0.9536, IoU.towel: 0.8284, IoU.light: 0.6710, IoU.truck: 0.5290, IoU.tower: 0.3328, IoU.chandelier: 0.7742, IoU.awning: 0.3284, IoU.streetlight: 0.4637, IoU.booth: 0.6283, IoU.television receiver: 0.8157, IoU.airplane: 0.8881, IoU.dirt track: 0.2529, IoU.apparel: 0.5480, IoU.pole: 0.3626, IoU.land: 0.0621, IoU.bannister: 0.2271, IoU.escalator: 0.6565, IoU.ottoman: 0.5703, IoU.bottle: 0.5203, IoU.buffet: 0.4614, IoU.poster: 0.3770, IoU.stage: 0.3081, IoU.van: 0.5260, IoU.ship: 0.2764, IoU.fountain: 0.5792, IoU.conveyer belt: 0.7781, IoU.canopy: 0.5540, IoU.washer: 0.9097, IoU.plaything: 0.3650, IoU.swimming pool: 0.4869, IoU.stool: 0.5906, IoU.barrel: 0.6574, IoU.basket: 0.4740, IoU.waterfall: 0.4569, IoU.tent: 0.9130, IoU.bag: 0.3392, IoU.minibike: 0.8127, IoU.cradle: 0.9139, IoU.oven: 0.6579, IoU.ball: 0.4312, IoU.food: 0.6520, IoU.step: 0.2702, IoU.tank: 0.6029, IoU.trade name: 0.2956, IoU.microwave: 0.8964, IoU.pot: 0.6452, IoU.animal: 0.8020, IoU.bicycle: 0.6489, IoU.lake: 0.6061, IoU.dishwasher: 0.8026, IoU.screen: 0.6102, IoU.blanket: 0.4474, IoU.sculpture: 0.7477, IoU.hood: 0.8548, IoU.sconce: 0.6834, IoU.vase: 0.5889, IoU.traffic light: 0.5355, IoU.tray: 0.3497, IoU.ashcan: 0.5433, IoU.fan: 0.7430, IoU.pier: 0.3883, IoU.crt screen: 0.0148, IoU.plate: 0.7045, IoU.monitor: 0.1032, IoU.bulletin board: 0.6327, IoU.shower: 0.1581, IoU.radiator: 0.7448, IoU.glass: 0.2899, IoU.clock: 0.6358, IoU.flag: 0.6747, Acc.wall: 0.8975, Acc.building: 0.9227, Acc.sky: 0.9738, Acc.floor: 0.9043, Acc.tree: 0.8959, Acc.ceiling: 0.9315, Acc.road: 0.9165, Acc.bed : 0.9725, Acc.windowpane: 0.8219, Acc.grass: 0.8054, Acc.cabinet: 0.7262, Acc.sidewalk: 0.8568, Acc.person: 0.9418, Acc.earth: 0.5955, Acc.door: 0.8298, Acc.table: 0.8107, Acc.mountain: 0.6685, Acc.plant: 0.7043, Acc.curtain: 0.9111, Acc.chair: 0.7989, Acc.car: 0.9521, Acc.water: 0.8594, Acc.painting: 0.9114, Acc.sofa: 0.9124, Acc.shelf: 0.6269, Acc.house: 0.7472, Acc.sea: 0.9102, Acc.mirror: 0.9177, Acc.rug: 0.8613, Acc.field: 0.7190, Acc.armchair: 0.8078, Acc.seat: 0.8987, Acc.fence: 0.7369, Acc.desk: 0.8399, Acc.rock: 0.7635, Acc.wardrobe: 0.8679, Acc.lamp: 0.9063, Acc.bathtub: 0.9382, Acc.railing: 0.6692, Acc.cushion: 0.9135, Acc.base: 0.6349, Acc.box: 0.6375, Acc.column: 0.7153, Acc.signboard: 0.6726, Acc.chest of drawers: 0.6761, Acc.counter: 0.6863, Acc.sand: 0.8516, Acc.sink: 0.8987, Acc.skyscraper: 0.5443, Acc.fireplace: 0.9499, Acc.refrigerator: 0.9288, Acc.grandstand: 0.7958, Acc.path: 0.4153, Acc.stairs: 0.5022, Acc.runway: 0.9373, Acc.case: 0.8656, Acc.pool table: 0.9863, Acc.pillow: 0.8340, Acc.screen door: 0.9226, Acc.stairway: 0.7003, Acc.river: 0.3564, Acc.bridge: 0.8688, Acc.bookcase: 0.5683, Acc.blind: 0.5791, Acc.coffee table: 0.8989, Acc.toilet: 0.9670, Acc.flower: 0.7016, Acc.book: 0.8347, Acc.hill: 0.2906, Acc.bench: 0.8371, Acc.countertop: 0.9072, Acc.stove: 0.9031, Acc.palm: 0.8223, Acc.kitchen island: 0.9479, Acc.computer: 0.8709, Acc.swivel chair: 0.8451, Acc.boat: 0.9052, Acc.bar: 0.7291, Acc.arcade machine: 0.9873, Acc.hovel: 0.7293, Acc.bus: 0.9746, Acc.towel: 0.9192, Acc.light: 0.7921, Acc.truck: 0.7191, Acc.tower: 0.6300, Acc.chandelier: 0.8648, Acc.awning: 0.5204, Acc.streetlight: 0.7171, Acc.booth: 0.7877, Acc.television receiver: 0.9237, Acc.airplane: 0.9633, Acc.dirt track: 0.3811, Acc.apparel: 0.8395, Acc.pole: 0.4978, Acc.land: 0.0965, Acc.bannister: 0.3516, Acc.escalator: 0.8371, Acc.ottoman: 0.7952, Acc.bottle: 0.8267, Acc.buffet: 0.6431, Acc.poster: 0.6221, Acc.stage: 0.6890, Acc.van: 0.7479, Acc.ship: 0.2919, Acc.fountain: 0.6332, Acc.conveyer belt: 0.9699, Acc.canopy: 0.7452, Acc.washer: 0.9344, Acc.plaything: 0.5966, Acc.swimming pool: 0.7572, Acc.stool: 0.8223, Acc.barrel: 0.9577, Acc.basket: 0.6978, Acc.waterfall: 0.5629, Acc.tent: 0.9812, Acc.bag: 0.4959, Acc.minibike: 0.9389, Acc.cradle: 0.9744, Acc.oven: 0.8403, Acc.ball: 0.4658, Acc.food: 0.7741, Acc.step: 0.3459, Acc.tank: 0.6762, Acc.trade name: 0.3792, Acc.microwave: 0.9459, Acc.pot: 0.7723, Acc.animal: 0.8246, Acc.bicycle: 0.8353, Acc.lake: 0.6951, Acc.dishwasher: 0.9055, Acc.screen: 0.9425, Acc.blanket: 0.5770, Acc.sculpture: 0.9055, Acc.hood: 0.9017, Acc.sconce: 0.8294, Acc.vase: 0.8206, Acc.traffic light: 0.7392, Acc.tray: 0.5521, Acc.ashcan: 0.8048, Acc.fan: 0.8741, Acc.pier: 0.4166, Acc.crt screen: 0.0401, Acc.plate: 0.8382, Acc.monitor: 0.1484, Acc.bulletin board: 0.8583, Acc.shower: 0.2867, Acc.radiator: 0.9335, Acc.glass: 0.3182, Acc.clock: 0.7735, Acc.flag: 0.8697
2022-12-01 17:29:34,741 - mmseg - INFO - Iter [37050/40000]	lr: 9.814e-09, eta: 3:34:52, time: 7.674, data_time: 3.579, memory: 51902, decode.loss_cls: 0.3096, decode.loss_mask: 0.5262, decode.loss_dice: 0.7830, decode.d0.loss_cls: 4.9299, decode.d0.loss_mask: 0.5239, decode.d0.loss_dice: 0.8466, decode.d1.loss_cls: 0.4284, decode.d1.loss_mask: 0.5565, decode.d1.loss_dice: 0.8455, decode.d2.loss_cls: 0.3696, decode.d2.loss_mask: 0.5438, decode.d2.loss_dice: 0.8107, decode.d3.loss_cls: 0.3395, decode.d3.loss_mask: 0.5338, decode.d3.loss_dice: 0.7954, decode.d4.loss_cls: 0.3287, decode.d4.loss_mask: 0.5322, decode.d4.loss_dice: 0.7921, decode.d5.loss_cls: 0.3195, decode.d5.loss_mask: 0.5293, decode.d5.loss_dice: 0.7876, decode.d6.loss_cls: 0.3169, decode.d6.loss_mask: 0.5269, decode.d6.loss_dice: 0.7833, decode.d7.loss_cls: 0.3128, decode.d7.loss_mask: 0.5272, decode.d7.loss_dice: 0.7859, decode.d8.loss_cls: 0.3072, decode.d8.loss_mask: 0.5262, decode.d8.loss_dice: 0.7845, loss: 21.3027
2022-12-01 17:33:00,545 - mmseg - INFO - Iter [37100/40000]	lr: 9.648e-09, eta: 3:31:13, time: 4.116, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3279, decode.loss_mask: 0.5205, decode.loss_dice: 0.7628, decode.d0.loss_cls: 4.9178, decode.d0.loss_mask: 0.5208, decode.d0.loss_dice: 0.8282, decode.d1.loss_cls: 0.4319, decode.d1.loss_mask: 0.5455, decode.d1.loss_dice: 0.8237, decode.d2.loss_cls: 0.3871, decode.d2.loss_mask: 0.5342, decode.d2.loss_dice: 0.7882, decode.d3.loss_cls: 0.3530, decode.d3.loss_mask: 0.5295, decode.d3.loss_dice: 0.7797, decode.d4.loss_cls: 0.3440, decode.d4.loss_mask: 0.5277, decode.d4.loss_dice: 0.7739, decode.d5.loss_cls: 0.3323, decode.d5.loss_mask: 0.5262, decode.d5.loss_dice: 0.7670, decode.d6.loss_cls: 0.3294, decode.d6.loss_mask: 0.5248, decode.d6.loss_dice: 0.7666, decode.d7.loss_cls: 0.3286, decode.d7.loss_mask: 0.5242, decode.d7.loss_dice: 0.7648, decode.d8.loss_cls: 0.3297, decode.d8.loss_mask: 0.5223, decode.d8.loss_dice: 0.7621, loss: 21.1743
2022-12-01 17:36:26,162 - mmseg - INFO - Iter [37150/40000]	lr: 9.482e-09, eta: 3:27:33, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3299, decode.loss_mask: 0.5120, decode.loss_dice: 0.7759, decode.d0.loss_cls: 4.9356, decode.d0.loss_mask: 0.5155, decode.d0.loss_dice: 0.8519, decode.d1.loss_cls: 0.4548, decode.d1.loss_mask: 0.5430, decode.d1.loss_dice: 0.8391, decode.d2.loss_cls: 0.3951, decode.d2.loss_mask: 0.5270, decode.d2.loss_dice: 0.8007, decode.d3.loss_cls: 0.3601, decode.d3.loss_mask: 0.5191, decode.d3.loss_dice: 0.7851, decode.d4.loss_cls: 0.3470, decode.d4.loss_mask: 0.5175, decode.d4.loss_dice: 0.7849, decode.d5.loss_cls: 0.3378, decode.d5.loss_mask: 0.5156, decode.d5.loss_dice: 0.7796, decode.d6.loss_cls: 0.3353, decode.d6.loss_mask: 0.5158, decode.d6.loss_dice: 0.7770, decode.d7.loss_cls: 0.3295, decode.d7.loss_mask: 0.5136, decode.d7.loss_dice: 0.7773, decode.d8.loss_cls: 0.3277, decode.d8.loss_mask: 0.5122, decode.d8.loss_dice: 0.7772, loss: 21.2928
2022-12-01 17:39:51,627 - mmseg - INFO - Iter [37200/40000]	lr: 9.315e-09, eta: 3:23:54, time: 4.109, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3275, decode.loss_mask: 0.5155, decode.loss_dice: 0.7832, decode.d0.loss_cls: 4.9512, decode.d0.loss_mask: 0.5104, decode.d0.loss_dice: 0.8486, decode.d1.loss_cls: 0.4467, decode.d1.loss_mask: 0.5426, decode.d1.loss_dice: 0.8424, decode.d2.loss_cls: 0.3903, decode.d2.loss_mask: 0.5292, decode.d2.loss_dice: 0.8112, decode.d3.loss_cls: 0.3526, decode.d3.loss_mask: 0.5232, decode.d3.loss_dice: 0.7947, decode.d4.loss_cls: 0.3428, decode.d4.loss_mask: 0.5193, decode.d4.loss_dice: 0.7932, decode.d5.loss_cls: 0.3339, decode.d5.loss_mask: 0.5163, decode.d5.loss_dice: 0.7881, decode.d6.loss_cls: 0.3302, decode.d6.loss_mask: 0.5146, decode.d6.loss_dice: 0.7844, decode.d7.loss_cls: 0.3290, decode.d7.loss_mask: 0.5147, decode.d7.loss_dice: 0.7839, decode.d8.loss_cls: 0.3249, decode.d8.loss_mask: 0.5161, decode.d8.loss_dice: 0.7852, loss: 21.3460
2022-12-01 17:43:17,445 - mmseg - INFO - Iter [37250/40000]	lr: 9.149e-09, eta: 3:20:15, time: 4.116, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3346, decode.loss_mask: 0.5329, decode.loss_dice: 0.7838, decode.d0.loss_cls: 4.9124, decode.d0.loss_mask: 0.5283, decode.d0.loss_dice: 0.8503, decode.d1.loss_cls: 0.4510, decode.d1.loss_mask: 0.5600, decode.d1.loss_dice: 0.8426, decode.d2.loss_cls: 0.3963, decode.d2.loss_mask: 0.5460, decode.d2.loss_dice: 0.8119, decode.d3.loss_cls: 0.3644, decode.d3.loss_mask: 0.5404, decode.d3.loss_dice: 0.7954, decode.d4.loss_cls: 0.3554, decode.d4.loss_mask: 0.5385, decode.d4.loss_dice: 0.7921, decode.d5.loss_cls: 0.3470, decode.d5.loss_mask: 0.5348, decode.d5.loss_dice: 0.7882, decode.d6.loss_cls: 0.3429, decode.d6.loss_mask: 0.5332, decode.d6.loss_dice: 0.7846, decode.d7.loss_cls: 0.3375, decode.d7.loss_mask: 0.5327, decode.d7.loss_dice: 0.7880, decode.d8.loss_cls: 0.3371, decode.d8.loss_mask: 0.5332, decode.d8.loss_dice: 0.7847, loss: 21.5805
2022-12-01 17:46:45,235 - mmseg - INFO - Iter [37300/40000]	lr: 8.983e-09, eta: 3:16:35, time: 4.156, data_time: 0.064, memory: 51902, decode.loss_cls: 0.3275, decode.loss_mask: 0.5201, decode.loss_dice: 0.7759, decode.d0.loss_cls: 4.9315, decode.d0.loss_mask: 0.5118, decode.d0.loss_dice: 0.8418, decode.d1.loss_cls: 0.4421, decode.d1.loss_mask: 0.5465, decode.d1.loss_dice: 0.8387, decode.d2.loss_cls: 0.3899, decode.d2.loss_mask: 0.5339, decode.d2.loss_dice: 0.8003, decode.d3.loss_cls: 0.3604, decode.d3.loss_mask: 0.5257, decode.d3.loss_dice: 0.7875, decode.d4.loss_cls: 0.3447, decode.d4.loss_mask: 0.5234, decode.d4.loss_dice: 0.7806, decode.d5.loss_cls: 0.3349, decode.d5.loss_mask: 0.5208, decode.d5.loss_dice: 0.7777, decode.d6.loss_cls: 0.3310, decode.d6.loss_mask: 0.5206, decode.d6.loss_dice: 0.7756, decode.d7.loss_cls: 0.3304, decode.d7.loss_mask: 0.5212, decode.d7.loss_dice: 0.7755, decode.d8.loss_cls: 0.3288, decode.d8.loss_mask: 0.5189, decode.d8.loss_dice: 0.7737, loss: 21.2915
2022-12-01 17:50:10,817 - mmseg - INFO - Iter [37350/40000]	lr: 8.816e-09, eta: 3:12:56, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3155, decode.loss_mask: 0.5169, decode.loss_dice: 0.7694, decode.d0.loss_cls: 4.9139, decode.d0.loss_mask: 0.5143, decode.d0.loss_dice: 0.8378, decode.d1.loss_cls: 0.4241, decode.d1.loss_mask: 0.5404, decode.d1.loss_dice: 0.8300, decode.d2.loss_cls: 0.3726, decode.d2.loss_mask: 0.5302, decode.d2.loss_dice: 0.7951, decode.d3.loss_cls: 0.3437, decode.d3.loss_mask: 0.5240, decode.d3.loss_dice: 0.7842, decode.d4.loss_cls: 0.3318, decode.d4.loss_mask: 0.5213, decode.d4.loss_dice: 0.7792, decode.d5.loss_cls: 0.3245, decode.d5.loss_mask: 0.5196, decode.d5.loss_dice: 0.7788, decode.d6.loss_cls: 0.3177, decode.d6.loss_mask: 0.5212, decode.d6.loss_dice: 0.7737, decode.d7.loss_cls: 0.3130, decode.d7.loss_mask: 0.5170, decode.d7.loss_dice: 0.7759, decode.d8.loss_cls: 0.3137, decode.d8.loss_mask: 0.5160, decode.d8.loss_dice: 0.7692, loss: 21.0849
2022-12-01 17:53:36,290 - mmseg - INFO - Iter [37400/40000]	lr: 8.650e-09, eta: 3:09:17, time: 4.109, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3210, decode.loss_mask: 0.5276, decode.loss_dice: 0.7800, decode.d0.loss_cls: 4.9248, decode.d0.loss_mask: 0.5224, decode.d0.loss_dice: 0.8390, decode.d1.loss_cls: 0.4372, decode.d1.loss_mask: 0.5572, decode.d1.loss_dice: 0.8380, decode.d2.loss_cls: 0.3826, decode.d2.loss_mask: 0.5426, decode.d2.loss_dice: 0.8015, decode.d3.loss_cls: 0.3493, decode.d3.loss_mask: 0.5357, decode.d3.loss_dice: 0.7906, decode.d4.loss_cls: 0.3402, decode.d4.loss_mask: 0.5329, decode.d4.loss_dice: 0.7902, decode.d5.loss_cls: 0.3347, decode.d5.loss_mask: 0.5279, decode.d5.loss_dice: 0.7823, decode.d6.loss_cls: 0.3259, decode.d6.loss_mask: 0.5282, decode.d6.loss_dice: 0.7781, decode.d7.loss_cls: 0.3224, decode.d7.loss_mask: 0.5275, decode.d7.loss_dice: 0.7813, decode.d8.loss_cls: 0.3212, decode.d8.loss_mask: 0.5273, decode.d8.loss_dice: 0.7786, loss: 21.3483
2022-12-01 17:57:02,066 - mmseg - INFO - Iter [37450/40000]	lr: 8.484e-09, eta: 3:05:37, time: 4.116, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3393, decode.loss_mask: 0.5156, decode.loss_dice: 0.7869, decode.d0.loss_cls: 4.9311, decode.d0.loss_mask: 0.5153, decode.d0.loss_dice: 0.8526, decode.d1.loss_cls: 0.4566, decode.d1.loss_mask: 0.5410, decode.d1.loss_dice: 0.8523, decode.d2.loss_cls: 0.3996, decode.d2.loss_mask: 0.5292, decode.d2.loss_dice: 0.8159, decode.d3.loss_cls: 0.3688, decode.d3.loss_mask: 0.5214, decode.d3.loss_dice: 0.8015, decode.d4.loss_cls: 0.3592, decode.d4.loss_mask: 0.5193, decode.d4.loss_dice: 0.8011, decode.d5.loss_cls: 0.3465, decode.d5.loss_mask: 0.5167, decode.d5.loss_dice: 0.7931, decode.d6.loss_cls: 0.3458, decode.d6.loss_mask: 0.5158, decode.d6.loss_dice: 0.7892, decode.d7.loss_cls: 0.3454, decode.d7.loss_mask: 0.5139, decode.d7.loss_dice: 0.7906, decode.d8.loss_cls: 0.3433, decode.d8.loss_mask: 0.5150, decode.d8.loss_dice: 0.7882, loss: 21.5103
2022-12-01 18:00:27,600 - mmseg - INFO - Iter [37500/40000]	lr: 8.318e-09, eta: 3:01:58, time: 4.111, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3231, decode.loss_mask: 0.5230, decode.loss_dice: 0.7673, decode.d0.loss_cls: 4.9242, decode.d0.loss_mask: 0.5244, decode.d0.loss_dice: 0.8397, decode.d1.loss_cls: 0.4374, decode.d1.loss_mask: 0.5514, decode.d1.loss_dice: 0.8210, decode.d2.loss_cls: 0.3830, decode.d2.loss_mask: 0.5387, decode.d2.loss_dice: 0.7964, decode.d3.loss_cls: 0.3508, decode.d3.loss_mask: 0.5300, decode.d3.loss_dice: 0.7785, decode.d4.loss_cls: 0.3404, decode.d4.loss_mask: 0.5272, decode.d4.loss_dice: 0.7736, decode.d5.loss_cls: 0.3320, decode.d5.loss_mask: 0.5255, decode.d5.loss_dice: 0.7731, decode.d6.loss_cls: 0.3260, decode.d6.loss_mask: 0.5252, decode.d6.loss_dice: 0.7681, decode.d7.loss_cls: 0.3221, decode.d7.loss_mask: 0.5235, decode.d7.loss_dice: 0.7680, decode.d8.loss_cls: 0.3241, decode.d8.loss_mask: 0.5237, decode.d8.loss_dice: 0.7680, loss: 21.2094
2022-12-01 18:03:53,002 - mmseg - INFO - Iter [37550/40000]	lr: 8.151e-09, eta: 2:58:19, time: 4.108, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3187, decode.loss_mask: 0.5240, decode.loss_dice: 0.7814, decode.d0.loss_cls: 4.9135, decode.d0.loss_mask: 0.5181, decode.d0.loss_dice: 0.8426, decode.d1.loss_cls: 0.4375, decode.d1.loss_mask: 0.5506, decode.d1.loss_dice: 0.8358, decode.d2.loss_cls: 0.3858, decode.d2.loss_mask: 0.5358, decode.d2.loss_dice: 0.8035, decode.d3.loss_cls: 0.3523, decode.d3.loss_mask: 0.5319, decode.d3.loss_dice: 0.7916, decode.d4.loss_cls: 0.3408, decode.d4.loss_mask: 0.5288, decode.d4.loss_dice: 0.7893, decode.d5.loss_cls: 0.3301, decode.d5.loss_mask: 0.5277, decode.d5.loss_dice: 0.7839, decode.d6.loss_cls: 0.3269, decode.d6.loss_mask: 0.5273, decode.d6.loss_dice: 0.7821, decode.d7.loss_cls: 0.3217, decode.d7.loss_mask: 0.5261, decode.d7.loss_dice: 0.7849, decode.d8.loss_cls: 0.3235, decode.d8.loss_mask: 0.5249, decode.d8.loss_dice: 0.7800, loss: 21.3211
2022-12-01 18:07:18,660 - mmseg - INFO - Iter [37600/40000]	lr: 7.985e-09, eta: 2:54:40, time: 4.113, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3202, decode.loss_mask: 0.5320, decode.loss_dice: 0.7864, decode.d0.loss_cls: 4.9275, decode.d0.loss_mask: 0.5301, decode.d0.loss_dice: 0.8459, decode.d1.loss_cls: 0.4297, decode.d1.loss_mask: 0.5613, decode.d1.loss_dice: 0.8400, decode.d2.loss_cls: 0.3811, decode.d2.loss_mask: 0.5464, decode.d2.loss_dice: 0.8077, decode.d3.loss_cls: 0.3492, decode.d3.loss_mask: 0.5405, decode.d3.loss_dice: 0.7971, decode.d4.loss_cls: 0.3419, decode.d4.loss_mask: 0.5382, decode.d4.loss_dice: 0.7954, decode.d5.loss_cls: 0.3298, decode.d5.loss_mask: 0.5368, decode.d5.loss_dice: 0.7910, decode.d6.loss_cls: 0.3237, decode.d6.loss_mask: 0.5367, decode.d6.loss_dice: 0.7885, decode.d7.loss_cls: 0.3203, decode.d7.loss_mask: 0.5340, decode.d7.loss_dice: 0.7895, decode.d8.loss_cls: 0.3185, decode.d8.loss_mask: 0.5328, decode.d8.loss_dice: 0.7875, loss: 21.4598
2022-12-01 18:10:44,240 - mmseg - INFO - Iter [37650/40000]	lr: 7.819e-09, eta: 2:51:01, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3310, decode.loss_mask: 0.5340, decode.loss_dice: 0.7858, decode.d0.loss_cls: 4.9178, decode.d0.loss_mask: 0.5341, decode.d0.loss_dice: 0.8597, decode.d1.loss_cls: 0.4508, decode.d1.loss_mask: 0.5680, decode.d1.loss_dice: 0.8475, decode.d2.loss_cls: 0.3930, decode.d2.loss_mask: 0.5517, decode.d2.loss_dice: 0.8141, decode.d3.loss_cls: 0.3563, decode.d3.loss_mask: 0.5447, decode.d3.loss_dice: 0.8001, decode.d4.loss_cls: 0.3479, decode.d4.loss_mask: 0.5409, decode.d4.loss_dice: 0.7951, decode.d5.loss_cls: 0.3369, decode.d5.loss_mask: 0.5380, decode.d5.loss_dice: 0.7917, decode.d6.loss_cls: 0.3353, decode.d6.loss_mask: 0.5345, decode.d6.loss_dice: 0.7885, decode.d7.loss_cls: 0.3306, decode.d7.loss_mask: 0.5367, decode.d7.loss_dice: 0.7884, decode.d8.loss_cls: 0.3292, decode.d8.loss_mask: 0.5345, decode.d8.loss_dice: 0.7867, loss: 21.6035
2022-12-01 18:14:09,752 - mmseg - INFO - Iter [37700/40000]	lr: 7.652e-09, eta: 2:47:22, time: 4.110, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3221, decode.loss_mask: 0.5169, decode.loss_dice: 0.7774, decode.d0.loss_cls: 4.9355, decode.d0.loss_mask: 0.5155, decode.d0.loss_dice: 0.8458, decode.d1.loss_cls: 0.4396, decode.d1.loss_mask: 0.5399, decode.d1.loss_dice: 0.8343, decode.d2.loss_cls: 0.3853, decode.d2.loss_mask: 0.5277, decode.d2.loss_dice: 0.8020, decode.d3.loss_cls: 0.3520, decode.d3.loss_mask: 0.5246, decode.d3.loss_dice: 0.7898, decode.d4.loss_cls: 0.3471, decode.d4.loss_mask: 0.5216, decode.d4.loss_dice: 0.7855, decode.d5.loss_cls: 0.3322, decode.d5.loss_mask: 0.5191, decode.d5.loss_dice: 0.7850, decode.d6.loss_cls: 0.3270, decode.d6.loss_mask: 0.5186, decode.d6.loss_dice: 0.7799, decode.d7.loss_cls: 0.3260, decode.d7.loss_mask: 0.5162, decode.d7.loss_dice: 0.7780, decode.d8.loss_cls: 0.3248, decode.d8.loss_mask: 0.5160, decode.d8.loss_dice: 0.7795, loss: 21.2649
2022-12-01 18:17:35,295 - mmseg - INFO - Iter [37750/40000]	lr: 7.486e-09, eta: 2:43:42, time: 4.111, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3192, decode.loss_mask: 0.5296, decode.loss_dice: 0.7691, decode.d0.loss_cls: 4.9035, decode.d0.loss_mask: 0.5232, decode.d0.loss_dice: 0.8339, decode.d1.loss_cls: 0.4336, decode.d1.loss_mask: 0.5586, decode.d1.loss_dice: 0.8284, decode.d2.loss_cls: 0.3780, decode.d2.loss_mask: 0.5451, decode.d2.loss_dice: 0.7980, decode.d3.loss_cls: 0.3466, decode.d3.loss_mask: 0.5389, decode.d3.loss_dice: 0.7852, decode.d4.loss_cls: 0.3371, decode.d4.loss_mask: 0.5351, decode.d4.loss_dice: 0.7812, decode.d5.loss_cls: 0.3290, decode.d5.loss_mask: 0.5331, decode.d5.loss_dice: 0.7759, decode.d6.loss_cls: 0.3282, decode.d6.loss_mask: 0.5294, decode.d6.loss_dice: 0.7708, decode.d7.loss_cls: 0.3205, decode.d7.loss_mask: 0.5296, decode.d7.loss_dice: 0.7731, decode.d8.loss_cls: 0.3209, decode.d8.loss_mask: 0.5292, decode.d8.loss_dice: 0.7717, loss: 21.2561
2022-12-01 18:21:01,136 - mmseg - INFO - Iter [37800/40000]	lr: 7.320e-09, eta: 2:40:03, time: 4.117, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3174, decode.loss_mask: 0.5284, decode.loss_dice: 0.7696, decode.d0.loss_cls: 4.9354, decode.d0.loss_mask: 0.5278, decode.d0.loss_dice: 0.8363, decode.d1.loss_cls: 0.4207, decode.d1.loss_mask: 0.5604, decode.d1.loss_dice: 0.8329, decode.d2.loss_cls: 0.3711, decode.d2.loss_mask: 0.5449, decode.d2.loss_dice: 0.7993, decode.d3.loss_cls: 0.3431, decode.d3.loss_mask: 0.5376, decode.d3.loss_dice: 0.7887, decode.d4.loss_cls: 0.3346, decode.d4.loss_mask: 0.5351, decode.d4.loss_dice: 0.7812, decode.d5.loss_cls: 0.3254, decode.d5.loss_mask: 0.5331, decode.d5.loss_dice: 0.7783, decode.d6.loss_cls: 0.3194, decode.d6.loss_mask: 0.5288, decode.d6.loss_dice: 0.7715, decode.d7.loss_cls: 0.3194, decode.d7.loss_mask: 0.5300, decode.d7.loss_dice: 0.7734, decode.d8.loss_cls: 0.3189, decode.d8.loss_mask: 0.5280, decode.d8.loss_dice: 0.7694, loss: 21.2599
2022-12-01 18:24:26,822 - mmseg - INFO - Iter [37850/40000]	lr: 7.154e-09, eta: 2:36:24, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3278, decode.loss_mask: 0.5236, decode.loss_dice: 0.7770, decode.d0.loss_cls: 4.9067, decode.d0.loss_mask: 0.5218, decode.d0.loss_dice: 0.8417, decode.d1.loss_cls: 0.4472, decode.d1.loss_mask: 0.5521, decode.d1.loss_dice: 0.8337, decode.d2.loss_cls: 0.3903, decode.d2.loss_mask: 0.5366, decode.d2.loss_dice: 0.7985, decode.d3.loss_cls: 0.3572, decode.d3.loss_mask: 0.5300, decode.d3.loss_dice: 0.7822, decode.d4.loss_cls: 0.3478, decode.d4.loss_mask: 0.5274, decode.d4.loss_dice: 0.7823, decode.d5.loss_cls: 0.3419, decode.d5.loss_mask: 0.5246, decode.d5.loss_dice: 0.7770, decode.d6.loss_cls: 0.3354, decode.d6.loss_mask: 0.5229, decode.d6.loss_dice: 0.7721, decode.d7.loss_cls: 0.3297, decode.d7.loss_mask: 0.5236, decode.d7.loss_dice: 0.7737, decode.d8.loss_cls: 0.3285, decode.d8.loss_mask: 0.5229, decode.d8.loss_dice: 0.7734, loss: 21.3095
2022-12-01 18:27:52,626 - mmseg - INFO - Iter [37900/40000]	lr: 6.987e-09, eta: 2:32:46, time: 4.116, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3163, decode.loss_mask: 0.5285, decode.loss_dice: 0.7743, decode.d0.loss_cls: 4.9066, decode.d0.loss_mask: 0.5233, decode.d0.loss_dice: 0.8410, decode.d1.loss_cls: 0.4375, decode.d1.loss_mask: 0.5533, decode.d1.loss_dice: 0.8291, decode.d2.loss_cls: 0.3815, decode.d2.loss_mask: 0.5406, decode.d2.loss_dice: 0.7987, decode.d3.loss_cls: 0.3439, decode.d3.loss_mask: 0.5360, decode.d3.loss_dice: 0.7825, decode.d4.loss_cls: 0.3345, decode.d4.loss_mask: 0.5325, decode.d4.loss_dice: 0.7799, decode.d5.loss_cls: 0.3240, decode.d5.loss_mask: 0.5307, decode.d5.loss_dice: 0.7777, decode.d6.loss_cls: 0.3205, decode.d6.loss_mask: 0.5297, decode.d6.loss_dice: 0.7751, decode.d7.loss_cls: 0.3198, decode.d7.loss_mask: 0.5268, decode.d7.loss_dice: 0.7740, decode.d8.loss_cls: 0.3160, decode.d8.loss_mask: 0.5268, decode.d8.loss_dice: 0.7744, loss: 21.2354
2022-12-01 18:31:20,615 - mmseg - INFO - Iter [37950/40000]	lr: 6.821e-09, eta: 2:29:07, time: 4.160, data_time: 0.063, memory: 51902, decode.loss_cls: 0.3102, decode.loss_mask: 0.5106, decode.loss_dice: 0.7822, decode.d0.loss_cls: 4.9227, decode.d0.loss_mask: 0.5056, decode.d0.loss_dice: 0.8434, decode.d1.loss_cls: 0.4241, decode.d1.loss_mask: 0.5383, decode.d1.loss_dice: 0.8359, decode.d2.loss_cls: 0.3720, decode.d2.loss_mask: 0.5239, decode.d2.loss_dice: 0.8054, decode.d3.loss_cls: 0.3345, decode.d3.loss_mask: 0.5171, decode.d3.loss_dice: 0.7910, decode.d4.loss_cls: 0.3240, decode.d4.loss_mask: 0.5162, decode.d4.loss_dice: 0.7908, decode.d5.loss_cls: 0.3160, decode.d5.loss_mask: 0.5150, decode.d5.loss_dice: 0.7878, decode.d6.loss_cls: 0.3146, decode.d6.loss_mask: 0.5119, decode.d6.loss_dice: 0.7813, decode.d7.loss_cls: 0.3094, decode.d7.loss_mask: 0.5121, decode.d7.loss_dice: 0.7828, decode.d8.loss_cls: 0.3087, decode.d8.loss_mask: 0.5107, decode.d8.loss_dice: 0.7825, loss: 21.0809
2022-12-01 18:34:45,945 - mmseg - INFO - Saving checkpoint at 38000 iterations
2022-12-01 18:35:34,125 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 18:35:34,125 - mmseg - INFO - Iter [38000/40000]	lr: 6.655e-09, eta: 2:25:30, time: 5.070, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3217, decode.loss_mask: 0.5111, decode.loss_dice: 0.7569, decode.d0.loss_cls: 4.8921, decode.d0.loss_mask: 0.5070, decode.d0.loss_dice: 0.8275, decode.d1.loss_cls: 0.4351, decode.d1.loss_mask: 0.5404, decode.d1.loss_dice: 0.8156, decode.d2.loss_cls: 0.3802, decode.d2.loss_mask: 0.5276, decode.d2.loss_dice: 0.7824, decode.d3.loss_cls: 0.3476, decode.d3.loss_mask: 0.5214, decode.d3.loss_dice: 0.7680, decode.d4.loss_cls: 0.3402, decode.d4.loss_mask: 0.5187, decode.d4.loss_dice: 0.7636, decode.d5.loss_cls: 0.3291, decode.d5.loss_mask: 0.5162, decode.d5.loss_dice: 0.7616, decode.d6.loss_cls: 0.3272, decode.d6.loss_mask: 0.5142, decode.d6.loss_dice: 0.7571, decode.d7.loss_cls: 0.3234, decode.d7.loss_mask: 0.5125, decode.d7.loss_dice: 0.7595, decode.d8.loss_cls: 0.3238, decode.d8.loss_mask: 0.5121, decode.d8.loss_dice: 0.7569, loss: 20.9507
2022-12-01 18:38:32,252 - mmseg - INFO - per class results:
2022-12-01 18:38:32,257 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 83.48 | 89.48 |
|       building      | 85.42 | 92.07 |
|         sky         | 95.22 | 97.39 |
|        floor        | 85.71 | 90.92 |
|         tree        | 78.53 | 89.81 |
|       ceiling       | 87.28 | 93.86 |
|         road        | 88.22 | 92.01 |
|         bed         | 93.86 |  97.3 |
|      windowpane     | 68.67 | 81.83 |
|        grass        | 67.97 | 81.24 |
|       cabinet       | 63.49 | 72.76 |
|       sidewalk      | 73.92 | 87.08 |
|        person       |  88.4 | 94.13 |
|        earth        | 41.94 | 56.04 |
|         door        | 66.17 | 84.56 |
|        table        | 72.15 | 81.87 |
|       mountain      | 61.29 | 69.89 |
|        plant        |  57.0 | 70.16 |
|       curtain       | 82.04 | 91.46 |
|        chair        | 69.21 | 79.72 |
|         car         | 89.63 |  94.9 |
|        water        |  70.0 | 86.53 |
|       painting      | 80.04 | 91.18 |
|         sofa        | 85.81 | 91.78 |
|        shelf        | 49.36 | 63.36 |
|        house        | 56.61 | 73.58 |
|         sea         | 81.34 | 90.86 |
|        mirror       | 81.87 | 92.08 |
|         rug         | 73.28 | 86.64 |
|        field        | 34.75 | 64.63 |
|       armchair      | 64.47 |  79.9 |
|         seat        | 65.73 | 89.86 |
|        fence        | 54.79 | 73.28 |
|         desk        | 58.55 | 84.07 |
|         rock        | 61.46 | 75.76 |
|       wardrobe      | 59.88 |  85.6 |
|         lamp        | 81.25 | 90.54 |
|       bathtub       | 90.53 | 92.82 |
|       railing       | 45.94 | 67.97 |
|       cushion       | 77.85 |  91.4 |
|         base        | 43.63 | 69.33 |
|         box         |  46.2 |  66.2 |
|        column       | 61.07 | 73.88 |
|      signboard      | 44.97 | 67.37 |
|   chest of drawers  | 43.76 | 67.69 |
|       counter       | 58.28 | 67.95 |
|         sand        | 60.09 | 87.16 |
|         sink        |  88.9 | 92.61 |
|      skyscraper     | 42.35 | 53.16 |
|      fireplace      | 79.63 | 95.35 |
|     refrigerator    |  82.1 | 92.16 |
|      grandstand     | 47.74 | 81.41 |
|         path        | 31.91 | 41.86 |
|        stairs       |  37.7 |  50.3 |
|        runway       | 74.24 | 93.73 |
|         case        |  66.7 | 87.07 |
|      pool table     | 95.95 |  98.6 |
|        pillow       | 73.48 | 83.49 |
|     screen door     | 85.08 |  93.5 |
|       stairway      | 57.81 | 73.54 |
|        river        | 25.89 | 30.41 |
|        bridge       |  71.7 | 87.37 |
|       bookcase      | 39.26 | 56.08 |
|        blind        | 49.85 | 62.35 |
|     coffee table    | 72.72 | 90.02 |
|        toilet       | 93.07 | 96.68 |
|        flower       | 50.37 | 77.37 |
|         book        |  61.7 | 83.14 |
|         hill        | 13.87 | 28.03 |
|        bench        | 75.95 | 84.73 |
|      countertop     | 71.51 | 91.55 |
|        stove        | 86.93 | 90.88 |
|         palm        | 56.99 | 81.88 |
|    kitchen island   | 47.71 | 92.03 |
|       computer      | 82.14 | 90.71 |
|     swivel chair    | 56.11 | 84.17 |
|         boat        |  56.3 | 90.09 |
|         bar         | 66.84 | 73.64 |
|    arcade machine   | 90.57 | 98.74 |
|        hovel        | 62.68 | 72.81 |
|         bus         | 95.08 | 97.16 |
|        towel        | 82.91 | 91.89 |
|        light        | 67.27 |  80.2 |
|        truck        | 53.65 | 73.92 |
|        tower        | 33.02 | 63.25 |
|      chandelier     |  77.3 | 86.77 |
|        awning       | 33.14 | 52.22 |
|     streetlight     | 46.26 | 71.05 |
|        booth        | 65.49 |  78.3 |
| television receiver | 77.76 | 92.28 |
|       airplane      | 88.69 | 96.56 |
|      dirt track     | 20.33 | 38.72 |
|       apparel       | 54.56 | 86.11 |
|         pole        | 35.92 | 49.43 |
|         land        |  6.26 |  9.6  |
|      bannister      | 22.25 | 32.46 |
|      escalator      |  65.7 | 84.33 |
|       ottoman       | 59.59 | 79.44 |
|        bottle       | 51.69 | 82.59 |
|        buffet       |  45.8 | 65.61 |
|        poster       | 37.84 |  61.1 |
|        stage        | 29.82 | 65.89 |
|         van         | 50.84 | 76.02 |
|         ship        | 32.15 | 33.97 |
|       fountain      | 51.39 | 53.25 |
|    conveyer belt    | 77.74 | 97.01 |
|        canopy       | 67.59 | 89.21 |
|        washer       | 90.83 | 93.53 |
|      plaything      | 38.57 | 58.79 |
|    swimming pool    | 50.23 | 76.12 |
|        stool        | 57.86 | 81.76 |
|        barrel       | 66.14 |  96.4 |
|        basket       |  48.1 | 70.51 |
|      waterfall      | 45.87 | 56.57 |
|         tent        | 94.92 | 98.05 |
|         bag         | 33.28 |  47.3 |
|       minibike      |  81.1 | 94.15 |
|        cradle       | 91.35 | 97.34 |
|         oven        | 66.96 | 83.94 |
|         ball        | 41.18 |  44.3 |
|         food        | 63.74 | 74.74 |
|         step        | 25.75 | 36.05 |
|         tank        |  60.2 | 67.43 |
|      trade name     | 30.22 | 38.32 |
|      microwave      | 89.64 | 94.61 |
|         pot         | 63.92 | 77.67 |
|        animal       | 80.53 |  82.6 |
|       bicycle       | 65.08 | 83.52 |
|         lake        | 64.74 | 67.63 |
|      dishwasher     | 80.66 | 90.48 |
|        screen       | 61.05 | 94.05 |
|       blanket       | 46.65 | 59.57 |
|      sculpture      | 76.54 | 90.62 |
|         hood        | 86.04 | 90.73 |
|        sconce       | 67.74 | 82.79 |
|         vase        | 59.19 | 81.66 |
|    traffic light    | 53.22 | 75.18 |
|         tray        | 35.17 | 55.17 |
|        ashcan       | 54.84 | 80.75 |
|         fan         | 73.75 | 87.69 |
|         pier        | 38.83 | 41.51 |
|      crt screen     |  1.42 |  3.86 |
|        plate        | 70.29 | 85.04 |
|       monitor       |  4.14 |  5.32 |
|    bulletin board   | 66.11 | 85.43 |
|        shower       | 11.74 | 28.58 |
|       radiator      | 75.08 | 92.94 |
|        glass        | 28.83 | 31.79 |
|        clock        | 64.49 | 77.94 |
|         flag        | 67.75 |  87.3 |
+---------------------+-------+-------+
2022-12-01 18:38:32,257 - mmseg - INFO - Summary:
2022-12-01 18:38:32,258 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 87.16 | 61.54 | 75.98 |
+-------+-------+-------+
2022-12-01 18:38:32,263 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 18:38:32,263 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8716, mIoU: 0.6154, mAcc: 0.7598, IoU.wall: 0.8348, IoU.building: 0.8542, IoU.sky: 0.9522, IoU.floor: 0.8571, IoU.tree: 0.7853, IoU.ceiling: 0.8728, IoU.road: 0.8822, IoU.bed : 0.9386, IoU.windowpane: 0.6867, IoU.grass: 0.6797, IoU.cabinet: 0.6349, IoU.sidewalk: 0.7392, IoU.person: 0.8840, IoU.earth: 0.4194, IoU.door: 0.6617, IoU.table: 0.7215, IoU.mountain: 0.6129, IoU.plant: 0.5700, IoU.curtain: 0.8204, IoU.chair: 0.6921, IoU.car: 0.8963, IoU.water: 0.7000, IoU.painting: 0.8004, IoU.sofa: 0.8581, IoU.shelf: 0.4936, IoU.house: 0.5661, IoU.sea: 0.8134, IoU.mirror: 0.8187, IoU.rug: 0.7328, IoU.field: 0.3475, IoU.armchair: 0.6447, IoU.seat: 0.6573, IoU.fence: 0.5479, IoU.desk: 0.5855, IoU.rock: 0.6146, IoU.wardrobe: 0.5988, IoU.lamp: 0.8125, IoU.bathtub: 0.9053, IoU.railing: 0.4594, IoU.cushion: 0.7785, IoU.base: 0.4363, IoU.box: 0.4620, IoU.column: 0.6107, IoU.signboard: 0.4497, IoU.chest of drawers: 0.4376, IoU.counter: 0.5828, IoU.sand: 0.6009, IoU.sink: 0.8890, IoU.skyscraper: 0.4235, IoU.fireplace: 0.7963, IoU.refrigerator: 0.8210, IoU.grandstand: 0.4774, IoU.path: 0.3191, IoU.stairs: 0.3770, IoU.runway: 0.7424, IoU.case: 0.6670, IoU.pool table: 0.9595, IoU.pillow: 0.7348, IoU.screen door: 0.8508, IoU.stairway: 0.5781, IoU.river: 0.2589, IoU.bridge: 0.7170, IoU.bookcase: 0.3926, IoU.blind: 0.4985, IoU.coffee table: 0.7272, IoU.toilet: 0.9307, IoU.flower: 0.5037, IoU.book: 0.6170, IoU.hill: 0.1387, IoU.bench: 0.7595, IoU.countertop: 0.7151, IoU.stove: 0.8693, IoU.palm: 0.5699, IoU.kitchen island: 0.4771, IoU.computer: 0.8214, IoU.swivel chair: 0.5611, IoU.boat: 0.5630, IoU.bar: 0.6684, IoU.arcade machine: 0.9057, IoU.hovel: 0.6268, IoU.bus: 0.9508, IoU.towel: 0.8291, IoU.light: 0.6727, IoU.truck: 0.5365, IoU.tower: 0.3302, IoU.chandelier: 0.7730, IoU.awning: 0.3314, IoU.streetlight: 0.4626, IoU.booth: 0.6549, IoU.television receiver: 0.7776, IoU.airplane: 0.8869, IoU.dirt track: 0.2033, IoU.apparel: 0.5456, IoU.pole: 0.3592, IoU.land: 0.0626, IoU.bannister: 0.2225, IoU.escalator: 0.6570, IoU.ottoman: 0.5959, IoU.bottle: 0.5169, IoU.buffet: 0.4580, IoU.poster: 0.3784, IoU.stage: 0.2982, IoU.van: 0.5084, IoU.ship: 0.3215, IoU.fountain: 0.5139, IoU.conveyer belt: 0.7774, IoU.canopy: 0.6759, IoU.washer: 0.9083, IoU.plaything: 0.3857, IoU.swimming pool: 0.5023, IoU.stool: 0.5786, IoU.barrel: 0.6614, IoU.basket: 0.4810, IoU.waterfall: 0.4587, IoU.tent: 0.9492, IoU.bag: 0.3328, IoU.minibike: 0.8110, IoU.cradle: 0.9135, IoU.oven: 0.6696, IoU.ball: 0.4118, IoU.food: 0.6374, IoU.step: 0.2575, IoU.tank: 0.6020, IoU.trade name: 0.3022, IoU.microwave: 0.8964, IoU.pot: 0.6392, IoU.animal: 0.8053, IoU.bicycle: 0.6508, IoU.lake: 0.6474, IoU.dishwasher: 0.8066, IoU.screen: 0.6105, IoU.blanket: 0.4665, IoU.sculpture: 0.7654, IoU.hood: 0.8604, IoU.sconce: 0.6774, IoU.vase: 0.5919, IoU.traffic light: 0.5322, IoU.tray: 0.3517, IoU.ashcan: 0.5484, IoU.fan: 0.7375, IoU.pier: 0.3883, IoU.crt screen: 0.0142, IoU.plate: 0.7029, IoU.monitor: 0.0414, IoU.bulletin board: 0.6611, IoU.shower: 0.1174, IoU.radiator: 0.7508, IoU.glass: 0.2883, IoU.clock: 0.6449, IoU.flag: 0.6775, Acc.wall: 0.8948, Acc.building: 0.9207, Acc.sky: 0.9739, Acc.floor: 0.9092, Acc.tree: 0.8981, Acc.ceiling: 0.9386, Acc.road: 0.9201, Acc.bed : 0.9730, Acc.windowpane: 0.8183, Acc.grass: 0.8124, Acc.cabinet: 0.7276, Acc.sidewalk: 0.8708, Acc.person: 0.9413, Acc.earth: 0.5604, Acc.door: 0.8456, Acc.table: 0.8187, Acc.mountain: 0.6989, Acc.plant: 0.7016, Acc.curtain: 0.9146, Acc.chair: 0.7972, Acc.car: 0.9490, Acc.water: 0.8653, Acc.painting: 0.9118, Acc.sofa: 0.9178, Acc.shelf: 0.6336, Acc.house: 0.7358, Acc.sea: 0.9086, Acc.mirror: 0.9208, Acc.rug: 0.8664, Acc.field: 0.6463, Acc.armchair: 0.7990, Acc.seat: 0.8986, Acc.fence: 0.7328, Acc.desk: 0.8407, Acc.rock: 0.7576, Acc.wardrobe: 0.8560, Acc.lamp: 0.9054, Acc.bathtub: 0.9282, Acc.railing: 0.6797, Acc.cushion: 0.9140, Acc.base: 0.6933, Acc.box: 0.6620, Acc.column: 0.7388, Acc.signboard: 0.6737, Acc.chest of drawers: 0.6769, Acc.counter: 0.6795, Acc.sand: 0.8716, Acc.sink: 0.9261, Acc.skyscraper: 0.5316, Acc.fireplace: 0.9535, Acc.refrigerator: 0.9216, Acc.grandstand: 0.8141, Acc.path: 0.4186, Acc.stairs: 0.5030, Acc.runway: 0.9373, Acc.case: 0.8707, Acc.pool table: 0.9860, Acc.pillow: 0.8349, Acc.screen door: 0.9350, Acc.stairway: 0.7354, Acc.river: 0.3041, Acc.bridge: 0.8737, Acc.bookcase: 0.5608, Acc.blind: 0.6235, Acc.coffee table: 0.9002, Acc.toilet: 0.9668, Acc.flower: 0.7737, Acc.book: 0.8314, Acc.hill: 0.2803, Acc.bench: 0.8473, Acc.countertop: 0.9155, Acc.stove: 0.9088, Acc.palm: 0.8188, Acc.kitchen island: 0.9203, Acc.computer: 0.9071, Acc.swivel chair: 0.8417, Acc.boat: 0.9009, Acc.bar: 0.7364, Acc.arcade machine: 0.9874, Acc.hovel: 0.7281, Acc.bus: 0.9716, Acc.towel: 0.9189, Acc.light: 0.8020, Acc.truck: 0.7392, Acc.tower: 0.6325, Acc.chandelier: 0.8677, Acc.awning: 0.5222, Acc.streetlight: 0.7105, Acc.booth: 0.7830, Acc.television receiver: 0.9228, Acc.airplane: 0.9656, Acc.dirt track: 0.3872, Acc.apparel: 0.8611, Acc.pole: 0.4943, Acc.land: 0.0960, Acc.bannister: 0.3246, Acc.escalator: 0.8433, Acc.ottoman: 0.7944, Acc.bottle: 0.8259, Acc.buffet: 0.6561, Acc.poster: 0.6110, Acc.stage: 0.6589, Acc.van: 0.7602, Acc.ship: 0.3397, Acc.fountain: 0.5325, Acc.conveyer belt: 0.9701, Acc.canopy: 0.8921, Acc.washer: 0.9353, Acc.plaything: 0.5879, Acc.swimming pool: 0.7612, Acc.stool: 0.8176, Acc.barrel: 0.9640, Acc.basket: 0.7051, Acc.waterfall: 0.5657, Acc.tent: 0.9805, Acc.bag: 0.4730, Acc.minibike: 0.9415, Acc.cradle: 0.9734, Acc.oven: 0.8394, Acc.ball: 0.4430, Acc.food: 0.7474, Acc.step: 0.3605, Acc.tank: 0.6743, Acc.trade name: 0.3832, Acc.microwave: 0.9461, Acc.pot: 0.7767, Acc.animal: 0.8260, Acc.bicycle: 0.8352, Acc.lake: 0.6763, Acc.dishwasher: 0.9048, Acc.screen: 0.9405, Acc.blanket: 0.5957, Acc.sculpture: 0.9062, Acc.hood: 0.9073, Acc.sconce: 0.8279, Acc.vase: 0.8166, Acc.traffic light: 0.7518, Acc.tray: 0.5517, Acc.ashcan: 0.8075, Acc.fan: 0.8769, Acc.pier: 0.4151, Acc.crt screen: 0.0386, Acc.plate: 0.8504, Acc.monitor: 0.0532, Acc.bulletin board: 0.8543, Acc.shower: 0.2858, Acc.radiator: 0.9294, Acc.glass: 0.3179, Acc.clock: 0.7794, Acc.flag: 0.8730
2022-12-01 18:41:58,385 - mmseg - INFO - Iter [38050/40000]	lr: 6.488e-09, eta: 2:22:01, time: 7.685, data_time: 3.581, memory: 51902, decode.loss_cls: 0.3179, decode.loss_mask: 0.5177, decode.loss_dice: 0.7711, decode.d0.loss_cls: 4.8875, decode.d0.loss_mask: 0.5254, decode.d0.loss_dice: 0.8359, decode.d1.loss_cls: 0.4340, decode.d1.loss_mask: 0.5471, decode.d1.loss_dice: 0.8318, decode.d2.loss_cls: 0.3806, decode.d2.loss_mask: 0.5313, decode.d2.loss_dice: 0.7956, decode.d3.loss_cls: 0.3474, decode.d3.loss_mask: 0.5246, decode.d3.loss_dice: 0.7806, decode.d4.loss_cls: 0.3400, decode.d4.loss_mask: 0.5204, decode.d4.loss_dice: 0.7786, decode.d5.loss_cls: 0.3283, decode.d5.loss_mask: 0.5203, decode.d5.loss_dice: 0.7735, decode.d6.loss_cls: 0.3228, decode.d6.loss_mask: 0.5178, decode.d6.loss_dice: 0.7721, decode.d7.loss_cls: 0.3189, decode.d7.loss_mask: 0.5174, decode.d7.loss_dice: 0.7743, decode.d8.loss_cls: 0.3185, decode.d8.loss_mask: 0.5168, decode.d8.loss_dice: 0.7718, loss: 21.1200
2022-12-01 18:45:24,078 - mmseg - INFO - Iter [38100/40000]	lr: 6.322e-09, eta: 2:18:21, time: 4.114, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3298, decode.loss_mask: 0.5297, decode.loss_dice: 0.7878, decode.d0.loss_cls: 4.9352, decode.d0.loss_mask: 0.5270, decode.d0.loss_dice: 0.8489, decode.d1.loss_cls: 0.4443, decode.d1.loss_mask: 0.5551, decode.d1.loss_dice: 0.8457, decode.d2.loss_cls: 0.3923, decode.d2.loss_mask: 0.5408, decode.d2.loss_dice: 0.8104, decode.d3.loss_cls: 0.3625, decode.d3.loss_mask: 0.5368, decode.d3.loss_dice: 0.7949, decode.d4.loss_cls: 0.3501, decode.d4.loss_mask: 0.5362, decode.d4.loss_dice: 0.7950, decode.d5.loss_cls: 0.3437, decode.d5.loss_mask: 0.5314, decode.d5.loss_dice: 0.7918, decode.d6.loss_cls: 0.3337, decode.d6.loss_mask: 0.5318, decode.d6.loss_dice: 0.7881, decode.d7.loss_cls: 0.3324, decode.d7.loss_mask: 0.5286, decode.d7.loss_dice: 0.7894, decode.d8.loss_cls: 0.3300, decode.d8.loss_mask: 0.5302, decode.d8.loss_dice: 0.7868, loss: 21.5404
2022-12-01 18:48:49,654 - mmseg - INFO - Iter [38150/40000]	lr: 6.156e-09, eta: 2:14:42, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3213, decode.loss_mask: 0.5188, decode.loss_dice: 0.7790, decode.d0.loss_cls: 4.9318, decode.d0.loss_mask: 0.5100, decode.d0.loss_dice: 0.8437, decode.d1.loss_cls: 0.4408, decode.d1.loss_mask: 0.5435, decode.d1.loss_dice: 0.8390, decode.d2.loss_cls: 0.3822, decode.d2.loss_mask: 0.5307, decode.d2.loss_dice: 0.8068, decode.d3.loss_cls: 0.3481, decode.d3.loss_mask: 0.5285, decode.d3.loss_dice: 0.7907, decode.d4.loss_cls: 0.3434, decode.d4.loss_mask: 0.5244, decode.d4.loss_dice: 0.7886, decode.d5.loss_cls: 0.3289, decode.d5.loss_mask: 0.5236, decode.d5.loss_dice: 0.7846, decode.d6.loss_cls: 0.3241, decode.d6.loss_mask: 0.5217, decode.d6.loss_dice: 0.7830, decode.d7.loss_cls: 0.3186, decode.d7.loss_mask: 0.5203, decode.d7.loss_dice: 0.7868, decode.d8.loss_cls: 0.3182, decode.d8.loss_mask: 0.5199, decode.d8.loss_dice: 0.7831, loss: 21.2839
2022-12-01 18:52:15,062 - mmseg - INFO - Iter [38200/40000]	lr: 5.990e-09, eta: 2:11:03, time: 4.108, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3161, decode.loss_mask: 0.5221, decode.loss_dice: 0.7671, decode.d0.loss_cls: 4.8900, decode.d0.loss_mask: 0.5205, decode.d0.loss_dice: 0.8356, decode.d1.loss_cls: 0.4289, decode.d1.loss_mask: 0.5491, decode.d1.loss_dice: 0.8276, decode.d2.loss_cls: 0.3794, decode.d2.loss_mask: 0.5343, decode.d2.loss_dice: 0.7912, decode.d3.loss_cls: 0.3435, decode.d3.loss_mask: 0.5277, decode.d3.loss_dice: 0.7788, decode.d4.loss_cls: 0.3373, decode.d4.loss_mask: 0.5246, decode.d4.loss_dice: 0.7769, decode.d5.loss_cls: 0.3222, decode.d5.loss_mask: 0.5231, decode.d5.loss_dice: 0.7707, decode.d6.loss_cls: 0.3181, decode.d6.loss_mask: 0.5231, decode.d6.loss_dice: 0.7735, decode.d7.loss_cls: 0.3180, decode.d7.loss_mask: 0.5197, decode.d7.loss_dice: 0.7687, decode.d8.loss_cls: 0.3167, decode.d8.loss_mask: 0.5211, decode.d8.loss_dice: 0.7684, loss: 21.0943
2022-12-01 18:55:40,963 - mmseg - INFO - Iter [38250/40000]	lr: 5.823e-09, eta: 2:07:24, time: 4.118, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3143, decode.loss_mask: 0.5191, decode.loss_dice: 0.7677, decode.d0.loss_cls: 4.9217, decode.d0.loss_mask: 0.5136, decode.d0.loss_dice: 0.8316, decode.d1.loss_cls: 0.4311, decode.d1.loss_mask: 0.5463, decode.d1.loss_dice: 0.8211, decode.d2.loss_cls: 0.3749, decode.d2.loss_mask: 0.5338, decode.d2.loss_dice: 0.7905, decode.d3.loss_cls: 0.3447, decode.d3.loss_mask: 0.5268, decode.d3.loss_dice: 0.7796, decode.d4.loss_cls: 0.3323, decode.d4.loss_mask: 0.5248, decode.d4.loss_dice: 0.7767, decode.d5.loss_cls: 0.3230, decode.d5.loss_mask: 0.5222, decode.d5.loss_dice: 0.7748, decode.d6.loss_cls: 0.3202, decode.d6.loss_mask: 0.5198, decode.d6.loss_dice: 0.7712, decode.d7.loss_cls: 0.3184, decode.d7.loss_mask: 0.5206, decode.d7.loss_dice: 0.7705, decode.d8.loss_cls: 0.3168, decode.d8.loss_mask: 0.5198, decode.d8.loss_dice: 0.7718, loss: 21.0999
2022-12-01 18:59:06,226 - mmseg - INFO - Iter [38300/40000]	lr: 5.657e-09, eta: 2:03:45, time: 4.105, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3411, decode.loss_mask: 0.5251, decode.loss_dice: 0.7785, decode.d0.loss_cls: 4.9293, decode.d0.loss_mask: 0.5267, decode.d0.loss_dice: 0.8495, decode.d1.loss_cls: 0.4582, decode.d1.loss_mask: 0.5564, decode.d1.loss_dice: 0.8420, decode.d2.loss_cls: 0.4066, decode.d2.loss_mask: 0.5413, decode.d2.loss_dice: 0.8012, decode.d3.loss_cls: 0.3718, decode.d3.loss_mask: 0.5344, decode.d3.loss_dice: 0.7904, decode.d4.loss_cls: 0.3632, decode.d4.loss_mask: 0.5304, decode.d4.loss_dice: 0.7877, decode.d5.loss_cls: 0.3531, decode.d5.loss_mask: 0.5285, decode.d5.loss_dice: 0.7836, decode.d6.loss_cls: 0.3491, decode.d6.loss_mask: 0.5285, decode.d6.loss_dice: 0.7808, decode.d7.loss_cls: 0.3445, decode.d7.loss_mask: 0.5273, decode.d7.loss_dice: 0.7791, decode.d8.loss_cls: 0.3434, decode.d8.loss_mask: 0.5250, decode.d8.loss_dice: 0.7776, loss: 21.5543
2022-12-01 19:02:31,908 - mmseg - INFO - Iter [38350/40000]	lr: 5.491e-09, eta: 2:00:06, time: 4.114, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3270, decode.loss_mask: 0.5166, decode.loss_dice: 0.7727, decode.d0.loss_cls: 4.9052, decode.d0.loss_mask: 0.5152, decode.d0.loss_dice: 0.8411, decode.d1.loss_cls: 0.4463, decode.d1.loss_mask: 0.5431, decode.d1.loss_dice: 0.8294, decode.d2.loss_cls: 0.3890, decode.d2.loss_mask: 0.5298, decode.d2.loss_dice: 0.7990, decode.d3.loss_cls: 0.3528, decode.d3.loss_mask: 0.5239, decode.d3.loss_dice: 0.7838, decode.d4.loss_cls: 0.3449, decode.d4.loss_mask: 0.5204, decode.d4.loss_dice: 0.7844, decode.d5.loss_cls: 0.3380, decode.d5.loss_mask: 0.5191, decode.d5.loss_dice: 0.7805, decode.d6.loss_cls: 0.3285, decode.d6.loss_mask: 0.5191, decode.d6.loss_dice: 0.7744, decode.d7.loss_cls: 0.3262, decode.d7.loss_mask: 0.5155, decode.d7.loss_dice: 0.7756, decode.d8.loss_cls: 0.3273, decode.d8.loss_mask: 0.5167, decode.d8.loss_dice: 0.7727, loss: 21.2181
2022-12-01 19:05:57,426 - mmseg - INFO - Iter [38400/40000]	lr: 5.324e-09, eta: 1:56:27, time: 4.110, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3106, decode.loss_mask: 0.5432, decode.loss_dice: 0.7871, decode.d0.loss_cls: 4.8875, decode.d0.loss_mask: 0.5389, decode.d0.loss_dice: 0.8506, decode.d1.loss_cls: 0.4262, decode.d1.loss_mask: 0.5705, decode.d1.loss_dice: 0.8447, decode.d2.loss_cls: 0.3686, decode.d2.loss_mask: 0.5576, decode.d2.loss_dice: 0.8147, decode.d3.loss_cls: 0.3354, decode.d3.loss_mask: 0.5524, decode.d3.loss_dice: 0.7987, decode.d4.loss_cls: 0.3264, decode.d4.loss_mask: 0.5477, decode.d4.loss_dice: 0.7966, decode.d5.loss_cls: 0.3200, decode.d5.loss_mask: 0.5465, decode.d5.loss_dice: 0.7922, decode.d6.loss_cls: 0.3152, decode.d6.loss_mask: 0.5456, decode.d6.loss_dice: 0.7893, decode.d7.loss_cls: 0.3116, decode.d7.loss_mask: 0.5436, decode.d7.loss_dice: 0.7892, decode.d8.loss_cls: 0.3122, decode.d8.loss_mask: 0.5430, decode.d8.loss_dice: 0.7833, loss: 21.4491
2022-12-01 19:09:22,942 - mmseg - INFO - Iter [38450/40000]	lr: 5.158e-09, eta: 1:52:49, time: 4.110, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3211, decode.loss_mask: 0.5116, decode.loss_dice: 0.7724, decode.d0.loss_cls: 4.9310, decode.d0.loss_mask: 0.5112, decode.d0.loss_dice: 0.8448, decode.d1.loss_cls: 0.4368, decode.d1.loss_mask: 0.5370, decode.d1.loss_dice: 0.8335, decode.d2.loss_cls: 0.3859, decode.d2.loss_mask: 0.5217, decode.d2.loss_dice: 0.8000, decode.d3.loss_cls: 0.3584, decode.d3.loss_mask: 0.5165, decode.d3.loss_dice: 0.7853, decode.d4.loss_cls: 0.3426, decode.d4.loss_mask: 0.5146, decode.d4.loss_dice: 0.7814, decode.d5.loss_cls: 0.3359, decode.d5.loss_mask: 0.5124, decode.d5.loss_dice: 0.7781, decode.d6.loss_cls: 0.3274, decode.d6.loss_mask: 0.5124, decode.d6.loss_dice: 0.7762, decode.d7.loss_cls: 0.3268, decode.d7.loss_mask: 0.5118, decode.d7.loss_dice: 0.7764, decode.d8.loss_cls: 0.3223, decode.d8.loss_mask: 0.5111, decode.d8.loss_dice: 0.7765, loss: 21.1733
2022-12-01 19:12:48,665 - mmseg - INFO - Iter [38500/40000]	lr: 4.992e-09, eta: 1:49:10, time: 4.114, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3300, decode.loss_mask: 0.5230, decode.loss_dice: 0.7741, decode.d0.loss_cls: 4.9168, decode.d0.loss_mask: 0.5197, decode.d0.loss_dice: 0.8542, decode.d1.loss_cls: 0.4449, decode.d1.loss_mask: 0.5551, decode.d1.loss_dice: 0.8441, decode.d2.loss_cls: 0.3875, decode.d2.loss_mask: 0.5404, decode.d2.loss_dice: 0.8095, decode.d3.loss_cls: 0.3557, decode.d3.loss_mask: 0.5339, decode.d3.loss_dice: 0.7973, decode.d4.loss_cls: 0.3432, decode.d4.loss_mask: 0.5314, decode.d4.loss_dice: 0.7920, decode.d5.loss_cls: 0.3364, decode.d5.loss_mask: 0.5271, decode.d5.loss_dice: 0.7854, decode.d6.loss_cls: 0.3289, decode.d6.loss_mask: 0.5256, decode.d6.loss_dice: 0.7821, decode.d7.loss_cls: 0.3279, decode.d7.loss_mask: 0.5238, decode.d7.loss_dice: 0.7826, decode.d8.loss_cls: 0.3255, decode.d8.loss_mask: 0.5238, decode.d8.loss_dice: 0.7819, loss: 21.4037
2022-12-01 19:16:14,383 - mmseg - INFO - Iter [38550/40000]	lr: 4.826e-09, eta: 1:45:31, time: 4.114, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3137, decode.loss_mask: 0.5298, decode.loss_dice: 0.7649, decode.d0.loss_cls: 4.8896, decode.d0.loss_mask: 0.5288, decode.d0.loss_dice: 0.8240, decode.d1.loss_cls: 0.4257, decode.d1.loss_mask: 0.5609, decode.d1.loss_dice: 0.8229, decode.d2.loss_cls: 0.3692, decode.d2.loss_mask: 0.5477, decode.d2.loss_dice: 0.7895, decode.d3.loss_cls: 0.3410, decode.d3.loss_mask: 0.5393, decode.d3.loss_dice: 0.7736, decode.d4.loss_cls: 0.3339, decode.d4.loss_mask: 0.5377, decode.d4.loss_dice: 0.7723, decode.d5.loss_cls: 0.3246, decode.d5.loss_mask: 0.5359, decode.d5.loss_dice: 0.7693, decode.d6.loss_cls: 0.3217, decode.d6.loss_mask: 0.5325, decode.d6.loss_dice: 0.7652, decode.d7.loss_cls: 0.3153, decode.d7.loss_mask: 0.5327, decode.d7.loss_dice: 0.7672, decode.d8.loss_cls: 0.3121, decode.d8.loss_mask: 0.5315, decode.d8.loss_dice: 0.7660, loss: 21.1386
2022-12-01 19:19:42,186 - mmseg - INFO - Iter [38600/40000]	lr: 4.659e-09, eta: 1:41:52, time: 4.156, data_time: 0.064, memory: 51902, decode.loss_cls: 0.3137, decode.loss_mask: 0.5107, decode.loss_dice: 0.7822, decode.d0.loss_cls: 4.9369, decode.d0.loss_mask: 0.5113, decode.d0.loss_dice: 0.8488, decode.d1.loss_cls: 0.4312, decode.d1.loss_mask: 0.5362, decode.d1.loss_dice: 0.8401, decode.d2.loss_cls: 0.3722, decode.d2.loss_mask: 0.5252, decode.d2.loss_dice: 0.8087, decode.d3.loss_cls: 0.3367, decode.d3.loss_mask: 0.5186, decode.d3.loss_dice: 0.7931, decode.d4.loss_cls: 0.3305, decode.d4.loss_mask: 0.5157, decode.d4.loss_dice: 0.7897, decode.d5.loss_cls: 0.3153, decode.d5.loss_mask: 0.5146, decode.d5.loss_dice: 0.7881, decode.d6.loss_cls: 0.3127, decode.d6.loss_mask: 0.5110, decode.d6.loss_dice: 0.7838, decode.d7.loss_cls: 0.3147, decode.d7.loss_mask: 0.5105, decode.d7.loss_dice: 0.7829, decode.d8.loss_cls: 0.3087, decode.d8.loss_mask: 0.5119, decode.d8.loss_dice: 0.7830, loss: 21.1389
2022-12-01 19:23:08,109 - mmseg - INFO - Iter [38650/40000]	lr: 4.493e-09, eta: 1:38:13, time: 4.118, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3346, decode.loss_mask: 0.5263, decode.loss_dice: 0.7860, decode.d0.loss_cls: 4.9009, decode.d0.loss_mask: 0.5258, decode.d0.loss_dice: 0.8555, decode.d1.loss_cls: 0.4566, decode.d1.loss_mask: 0.5556, decode.d1.loss_dice: 0.8441, decode.d2.loss_cls: 0.3981, decode.d2.loss_mask: 0.5418, decode.d2.loss_dice: 0.8091, decode.d3.loss_cls: 0.3644, decode.d3.loss_mask: 0.5352, decode.d3.loss_dice: 0.7957, decode.d4.loss_cls: 0.3544, decode.d4.loss_mask: 0.5307, decode.d4.loss_dice: 0.7941, decode.d5.loss_cls: 0.3441, decode.d5.loss_mask: 0.5306, decode.d5.loss_dice: 0.7883, decode.d6.loss_cls: 0.3415, decode.d6.loss_mask: 0.5282, decode.d6.loss_dice: 0.7860, decode.d7.loss_cls: 0.3358, decode.d7.loss_mask: 0.5271, decode.d7.loss_dice: 0.7842, decode.d8.loss_cls: 0.3345, decode.d8.loss_mask: 0.5259, decode.d8.loss_dice: 0.7819, loss: 21.5169
2022-12-01 19:26:33,729 - mmseg - INFO - Iter [38700/40000]	lr: 4.327e-09, eta: 1:34:35, time: 4.112, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3214, decode.loss_mask: 0.5160, decode.loss_dice: 0.7646, decode.d0.loss_cls: 4.8897, decode.d0.loss_mask: 0.5091, decode.d0.loss_dice: 0.8322, decode.d1.loss_cls: 0.4341, decode.d1.loss_mask: 0.5369, decode.d1.loss_dice: 0.8194, decode.d2.loss_cls: 0.3831, decode.d2.loss_mask: 0.5259, decode.d2.loss_dice: 0.7908, decode.d3.loss_cls: 0.3502, decode.d3.loss_mask: 0.5207, decode.d3.loss_dice: 0.7721, decode.d4.loss_cls: 0.3398, decode.d4.loss_mask: 0.5206, decode.d4.loss_dice: 0.7763, decode.d5.loss_cls: 0.3306, decode.d5.loss_mask: 0.5167, decode.d5.loss_dice: 0.7694, decode.d6.loss_cls: 0.3290, decode.d6.loss_mask: 0.5166, decode.d6.loss_dice: 0.7659, decode.d7.loss_cls: 0.3263, decode.d7.loss_mask: 0.5162, decode.d7.loss_dice: 0.7636, decode.d8.loss_cls: 0.3230, decode.d8.loss_mask: 0.5163, decode.d8.loss_dice: 0.7621, loss: 21.0385
2022-12-01 19:29:59,137 - mmseg - INFO - Iter [38750/40000]	lr: 4.160e-09, eta: 1:30:56, time: 4.108, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3185, decode.loss_mask: 0.5358, decode.loss_dice: 0.7888, decode.d0.loss_cls: 4.8949, decode.d0.loss_mask: 0.5364, decode.d0.loss_dice: 0.8566, decode.d1.loss_cls: 0.4362, decode.d1.loss_mask: 0.5610, decode.d1.loss_dice: 0.8510, decode.d2.loss_cls: 0.3766, decode.d2.loss_mask: 0.5503, decode.d2.loss_dice: 0.8168, decode.d3.loss_cls: 0.3464, decode.d3.loss_mask: 0.5417, decode.d3.loss_dice: 0.8002, decode.d4.loss_cls: 0.3366, decode.d4.loss_mask: 0.5408, decode.d4.loss_dice: 0.7985, decode.d5.loss_cls: 0.3282, decode.d5.loss_mask: 0.5384, decode.d5.loss_dice: 0.7926, decode.d6.loss_cls: 0.3245, decode.d6.loss_mask: 0.5371, decode.d6.loss_dice: 0.7937, decode.d7.loss_cls: 0.3167, decode.d7.loss_mask: 0.5369, decode.d7.loss_dice: 0.7924, decode.d8.loss_cls: 0.3171, decode.d8.loss_mask: 0.5359, decode.d8.loss_dice: 0.7892, loss: 21.4897
2022-12-01 19:33:25,079 - mmseg - INFO - Iter [38800/40000]	lr: 3.994e-09, eta: 1:27:17, time: 4.119, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3146, decode.loss_mask: 0.5183, decode.loss_dice: 0.7748, decode.d0.loss_cls: 4.9070, decode.d0.loss_mask: 0.5181, decode.d0.loss_dice: 0.8421, decode.d1.loss_cls: 0.4291, decode.d1.loss_mask: 0.5472, decode.d1.loss_dice: 0.8345, decode.d2.loss_cls: 0.3770, decode.d2.loss_mask: 0.5341, decode.d2.loss_dice: 0.8017, decode.d3.loss_cls: 0.3432, decode.d3.loss_mask: 0.5272, decode.d3.loss_dice: 0.7887, decode.d4.loss_cls: 0.3323, decode.d4.loss_mask: 0.5247, decode.d4.loss_dice: 0.7848, decode.d5.loss_cls: 0.3231, decode.d5.loss_mask: 0.5232, decode.d5.loss_dice: 0.7799, decode.d6.loss_cls: 0.3219, decode.d6.loss_mask: 0.5234, decode.d6.loss_dice: 0.7778, decode.d7.loss_cls: 0.3177, decode.d7.loss_mask: 0.5197, decode.d7.loss_dice: 0.7801, decode.d8.loss_cls: 0.3179, decode.d8.loss_mask: 0.5192, decode.d8.loss_dice: 0.7786, loss: 21.1822
2022-12-01 19:36:50,692 - mmseg - INFO - Iter [38850/40000]	lr: 3.828e-09, eta: 1:23:39, time: 4.112, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3251, decode.loss_mask: 0.5211, decode.loss_dice: 0.7749, decode.d0.loss_cls: 4.9145, decode.d0.loss_mask: 0.5223, decode.d0.loss_dice: 0.8484, decode.d1.loss_cls: 0.4442, decode.d1.loss_mask: 0.5512, decode.d1.loss_dice: 0.8340, decode.d2.loss_cls: 0.3899, decode.d2.loss_mask: 0.5379, decode.d2.loss_dice: 0.8003, decode.d3.loss_cls: 0.3567, decode.d3.loss_mask: 0.5318, decode.d3.loss_dice: 0.7841, decode.d4.loss_cls: 0.3497, decode.d4.loss_mask: 0.5284, decode.d4.loss_dice: 0.7832, decode.d5.loss_cls: 0.3338, decode.d5.loss_mask: 0.5271, decode.d5.loss_dice: 0.7800, decode.d6.loss_cls: 0.3290, decode.d6.loss_mask: 0.5225, decode.d6.loss_dice: 0.7733, decode.d7.loss_cls: 0.3249, decode.d7.loss_mask: 0.5220, decode.d7.loss_dice: 0.7759, decode.d8.loss_cls: 0.3246, decode.d8.loss_mask: 0.5218, decode.d8.loss_dice: 0.7724, loss: 21.3051
2022-12-01 19:40:16,359 - mmseg - INFO - Iter [38900/40000]	lr: 3.662e-09, eta: 1:20:00, time: 4.113, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3282, decode.loss_mask: 0.5133, decode.loss_dice: 0.7689, decode.d0.loss_cls: 4.9249, decode.d0.loss_mask: 0.5076, decode.d0.loss_dice: 0.8324, decode.d1.loss_cls: 0.4465, decode.d1.loss_mask: 0.5387, decode.d1.loss_dice: 0.8292, decode.d2.loss_cls: 0.3893, decode.d2.loss_mask: 0.5276, decode.d2.loss_dice: 0.7934, decode.d3.loss_cls: 0.3612, decode.d3.loss_mask: 0.5224, decode.d3.loss_dice: 0.7801, decode.d4.loss_cls: 0.3441, decode.d4.loss_mask: 0.5190, decode.d4.loss_dice: 0.7782, decode.d5.loss_cls: 0.3375, decode.d5.loss_mask: 0.5163, decode.d5.loss_dice: 0.7732, decode.d6.loss_cls: 0.3351, decode.d6.loss_mask: 0.5144, decode.d6.loss_dice: 0.7718, decode.d7.loss_cls: 0.3308, decode.d7.loss_mask: 0.5129, decode.d7.loss_dice: 0.7722, decode.d8.loss_cls: 0.3299, decode.d8.loss_mask: 0.5132, decode.d8.loss_dice: 0.7726, loss: 21.1848
2022-12-01 19:43:42,063 - mmseg - INFO - Iter [38950/40000]	lr: 3.495e-09, eta: 1:16:22, time: 4.114, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3177, decode.loss_mask: 0.5195, decode.loss_dice: 0.7771, decode.d0.loss_cls: 4.9108, decode.d0.loss_mask: 0.5169, decode.d0.loss_dice: 0.8426, decode.d1.loss_cls: 0.4320, decode.d1.loss_mask: 0.5440, decode.d1.loss_dice: 0.8369, decode.d2.loss_cls: 0.3799, decode.d2.loss_mask: 0.5367, decode.d2.loss_dice: 0.8037, decode.d3.loss_cls: 0.3494, decode.d3.loss_mask: 0.5274, decode.d3.loss_dice: 0.7877, decode.d4.loss_cls: 0.3424, decode.d4.loss_mask: 0.5235, decode.d4.loss_dice: 0.7824, decode.d5.loss_cls: 0.3273, decode.d5.loss_mask: 0.5237, decode.d5.loss_dice: 0.7803, decode.d6.loss_cls: 0.3228, decode.d6.loss_mask: 0.5211, decode.d6.loss_dice: 0.7787, decode.d7.loss_cls: 0.3202, decode.d7.loss_mask: 0.5211, decode.d7.loss_dice: 0.7778, decode.d8.loss_cls: 0.3203, decode.d8.loss_mask: 0.5213, decode.d8.loss_dice: 0.7777, loss: 21.2229
2022-12-01 19:47:07,841 - mmseg - INFO - Saving checkpoint at 39000 iterations
2022-12-01 19:47:55,548 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 19:47:55,548 - mmseg - INFO - Iter [39000/40000]	lr: 3.329e-09, eta: 1:12:44, time: 5.070, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3354, decode.loss_mask: 0.5174, decode.loss_dice: 0.7722, decode.d0.loss_cls: 4.9038, decode.d0.loss_mask: 0.5157, decode.d0.loss_dice: 0.8478, decode.d1.loss_cls: 0.4507, decode.d1.loss_mask: 0.5462, decode.d1.loss_dice: 0.8394, decode.d2.loss_cls: 0.3963, decode.d2.loss_mask: 0.5347, decode.d2.loss_dice: 0.8045, decode.d3.loss_cls: 0.3645, decode.d3.loss_mask: 0.5257, decode.d3.loss_dice: 0.7898, decode.d4.loss_cls: 0.3526, decode.d4.loss_mask: 0.5257, decode.d4.loss_dice: 0.7885, decode.d5.loss_cls: 0.3416, decode.d5.loss_mask: 0.5240, decode.d5.loss_dice: 0.7834, decode.d6.loss_cls: 0.3392, decode.d6.loss_mask: 0.5225, decode.d6.loss_dice: 0.7806, decode.d7.loss_cls: 0.3368, decode.d7.loss_mask: 0.5194, decode.d7.loss_dice: 0.7786, decode.d8.loss_cls: 0.3375, decode.d8.loss_mask: 0.5168, decode.d8.loss_dice: 0.7787, loss: 21.3700
2022-12-01 19:50:53,665 - mmseg - INFO - per class results:
2022-12-01 19:50:53,670 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        |  83.3 |  89.5 |
|       building      | 85.26 | 92.13 |
|         sky         | 95.22 | 97.39 |
|        floor        | 85.53 | 90.48 |
|         tree        | 78.46 | 89.71 |
|       ceiling       | 87.05 | 93.31 |
|         road        | 88.21 | 91.87 |
|         bed         | 93.82 | 97.41 |
|      windowpane     |  69.0 | 82.57 |
|        grass        | 68.33 | 81.07 |
|       cabinet       | 62.81 | 71.74 |
|       sidewalk      | 72.47 | 85.75 |
|        person       | 88.43 | 94.04 |
|        earth        | 41.85 | 56.86 |
|         door        | 65.98 | 83.99 |
|        table        | 72.33 | 81.96 |
|       mountain      | 62.49 | 71.85 |
|        plant        | 56.76 | 69.96 |
|       curtain       | 82.25 | 91.23 |
|        chair        | 69.37 | 80.14 |
|         car         |  89.9 | 95.19 |
|        water        |  70.4 | 86.57 |
|       painting      | 79.92 | 91.06 |
|         sofa        | 85.65 | 91.84 |
|        shelf        | 49.12 | 63.46 |
|        house        | 55.89 | 73.64 |
|         sea         | 81.34 | 90.85 |
|        mirror       | 81.42 | 91.77 |
|         rug         | 72.12 | 85.27 |
|        field        | 37.42 | 70.51 |
|       armchair      |  64.3 | 79.78 |
|         seat        | 66.39 |  89.8 |
|        fence        | 55.43 | 75.13 |
|         desk        | 60.09 | 83.97 |
|         rock        | 60.55 | 75.66 |
|       wardrobe      | 58.13 |  86.3 |
|         lamp        | 81.29 | 90.58 |
|       bathtub       | 91.47 | 93.76 |
|       railing       | 46.32 | 66.96 |
|       cushion       | 78.16 |  90.6 |
|         base        |  42.0 | 66.72 |
|         box         | 46.01 | 65.07 |
|        column       | 57.93 | 72.32 |
|      signboard      | 45.92 |  68.2 |
|   chest of drawers  |  45.7 | 70.62 |
|       counter       | 58.52 | 68.51 |
|         sand        | 60.45 | 87.15 |
|         sink        |  88.9 | 92.86 |
|      skyscraper     | 42.46 | 52.75 |
|      fireplace      | 79.26 | 94.71 |
|     refrigerator    | 81.73 | 92.09 |
|      grandstand     | 48.27 |  82.5 |
|         path        | 31.34 | 41.86 |
|        stairs       | 37.99 | 50.23 |
|        runway       | 74.29 | 93.74 |
|         case        |  67.1 | 87.81 |
|      pool table     | 95.94 |  98.7 |
|        pillow       | 73.33 | 83.11 |
|     screen door     | 84.26 | 92.69 |
|       stairway      | 56.34 | 71.46 |
|        river        |  30.3 | 35.57 |
|        bridge       |  71.1 | 87.09 |
|       bookcase      | 39.21 | 56.08 |
|        blind        | 46.46 | 57.96 |
|     coffee table    | 72.55 | 90.21 |
|        toilet       | 93.12 | 96.68 |
|        flower       | 46.73 | 70.74 |
|         book        | 61.54 |  83.1 |
|         hill        | 16.43 | 27.89 |
|        bench        | 75.81 | 84.92 |
|      countertop     | 70.96 | 90.54 |
|        stove        | 86.51 | 90.33 |
|         palm        | 56.98 |  82.7 |
|    kitchen island   | 47.48 | 92.06 |
|       computer      | 78.92 | 87.07 |
|     swivel chair    | 56.11 | 84.71 |
|         boat        | 51.99 | 90.34 |
|         bar         | 66.61 | 73.14 |
|    arcade machine   | 90.95 | 98.74 |
|        hovel        | 60.93 | 69.48 |
|         bus         | 94.95 | 97.41 |
|        towel        | 82.72 | 91.85 |
|        light        | 67.23 | 80.54 |
|        truck        | 54.01 | 73.72 |
|        tower        | 33.42 | 63.07 |
|      chandelier     |  77.5 | 86.93 |
|        awning       | 32.96 | 53.04 |
|     streetlight     |  45.9 | 71.59 |
|        booth        | 61.88 | 73.21 |
| television receiver | 77.51 | 92.25 |
|       airplane      | 88.71 | 96.48 |
|      dirt track     | 20.55 |  38.6 |
|       apparel       | 53.68 | 85.15 |
|         pole        | 35.88 | 49.16 |
|         land        |  6.24 |  9.69 |
|      bannister      | 22.95 | 34.17 |
|      escalator      | 65.73 | 83.76 |
|       ottoman       | 60.84 | 79.47 |
|        bottle       | 51.82 | 81.67 |
|        buffet       | 45.82 | 65.93 |
|        poster       | 37.98 | 61.19 |
|        stage        | 29.81 | 65.97 |
|         van         | 52.95 | 75.84 |
|         ship        | 38.85 | 41.11 |
|       fountain      | 51.34 | 53.26 |
|    conveyer belt    | 78.25 | 97.05 |
|        canopy       |  55.1 | 72.57 |
|        washer       | 90.74 | 93.49 |
|      plaything      | 38.34 | 59.03 |
|    swimming pool    | 52.35 | 75.93 |
|        stool        | 60.45 | 85.44 |
|        barrel       |  64.6 | 94.33 |
|        basket       | 47.54 | 71.66 |
|      waterfall      | 45.97 | 56.56 |
|         tent        | 95.01 | 98.12 |
|         bag         | 33.34 | 47.32 |
|       minibike      | 81.23 | 93.99 |
|        cradle       | 91.37 |  97.5 |
|         oven        | 65.99 | 84.04 |
|         ball        | 41.16 | 44.31 |
|         food        |  63.9 | 74.39 |
|         step        | 31.76 | 43.84 |
|         tank        | 60.39 | 67.45 |
|      trade name     | 29.86 |  38.7 |
|      microwave      | 89.64 | 94.62 |
|         pot         | 62.61 | 75.28 |
|        animal       | 80.15 | 82.37 |
|       bicycle       | 64.68 | 83.35 |
|         lake        | 65.88 | 68.82 |
|      dishwasher     | 80.54 | 90.57 |
|        screen       | 61.08 | 94.21 |
|       blanket       | 44.69 | 56.12 |
|      sculpture      | 77.02 | 90.52 |
|         hood        | 84.95 | 89.72 |
|        sconce       | 68.05 | 82.83 |
|         vase        | 58.88 | 81.72 |
|    traffic light    | 52.93 | 74.74 |
|         tray        | 34.64 | 54.06 |
|        ashcan       | 54.93 | 80.91 |
|         fan         | 73.69 | 88.12 |
|         pier        | 38.71 | 41.62 |
|      crt screen     |  1.48 |  3.99 |
|        plate        | 70.34 | 85.24 |
|       monitor       |  3.83 |  5.43 |
|    bulletin board   | 65.13 | 85.07 |
|        shower       | 16.29 | 28.64 |
|       radiator      | 75.73 | 93.13 |
|        glass        | 28.96 | 31.86 |
|        clock        | 63.88 | 77.62 |
|         flag        | 69.31 | 87.03 |
+---------------------+-------+-------+
2022-12-01 19:50:53,670 - mmseg - INFO - Summary:
2022-12-01 19:50:53,670 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 87.09 | 61.46 | 75.84 |
+-------+-------+-------+
2022-12-01 19:50:53,678 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 19:50:53,678 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8709, mIoU: 0.6146, mAcc: 0.7584, IoU.wall: 0.8330, IoU.building: 0.8526, IoU.sky: 0.9522, IoU.floor: 0.8553, IoU.tree: 0.7846, IoU.ceiling: 0.8705, IoU.road: 0.8821, IoU.bed : 0.9382, IoU.windowpane: 0.6900, IoU.grass: 0.6833, IoU.cabinet: 0.6281, IoU.sidewalk: 0.7247, IoU.person: 0.8843, IoU.earth: 0.4185, IoU.door: 0.6598, IoU.table: 0.7233, IoU.mountain: 0.6249, IoU.plant: 0.5676, IoU.curtain: 0.8225, IoU.chair: 0.6937, IoU.car: 0.8990, IoU.water: 0.7040, IoU.painting: 0.7992, IoU.sofa: 0.8565, IoU.shelf: 0.4912, IoU.house: 0.5589, IoU.sea: 0.8134, IoU.mirror: 0.8142, IoU.rug: 0.7212, IoU.field: 0.3742, IoU.armchair: 0.6430, IoU.seat: 0.6639, IoU.fence: 0.5543, IoU.desk: 0.6009, IoU.rock: 0.6055, IoU.wardrobe: 0.5813, IoU.lamp: 0.8129, IoU.bathtub: 0.9147, IoU.railing: 0.4632, IoU.cushion: 0.7816, IoU.base: 0.4200, IoU.box: 0.4601, IoU.column: 0.5793, IoU.signboard: 0.4592, IoU.chest of drawers: 0.4570, IoU.counter: 0.5852, IoU.sand: 0.6045, IoU.sink: 0.8890, IoU.skyscraper: 0.4246, IoU.fireplace: 0.7926, IoU.refrigerator: 0.8173, IoU.grandstand: 0.4827, IoU.path: 0.3134, IoU.stairs: 0.3799, IoU.runway: 0.7429, IoU.case: 0.6710, IoU.pool table: 0.9594, IoU.pillow: 0.7333, IoU.screen door: 0.8426, IoU.stairway: 0.5634, IoU.river: 0.3030, IoU.bridge: 0.7110, IoU.bookcase: 0.3921, IoU.blind: 0.4646, IoU.coffee table: 0.7255, IoU.toilet: 0.9312, IoU.flower: 0.4673, IoU.book: 0.6154, IoU.hill: 0.1643, IoU.bench: 0.7581, IoU.countertop: 0.7096, IoU.stove: 0.8651, IoU.palm: 0.5698, IoU.kitchen island: 0.4748, IoU.computer: 0.7892, IoU.swivel chair: 0.5611, IoU.boat: 0.5199, IoU.bar: 0.6661, IoU.arcade machine: 0.9095, IoU.hovel: 0.6093, IoU.bus: 0.9495, IoU.towel: 0.8272, IoU.light: 0.6723, IoU.truck: 0.5401, IoU.tower: 0.3342, IoU.chandelier: 0.7750, IoU.awning: 0.3296, IoU.streetlight: 0.4590, IoU.booth: 0.6188, IoU.television receiver: 0.7751, IoU.airplane: 0.8871, IoU.dirt track: 0.2055, IoU.apparel: 0.5368, IoU.pole: 0.3588, IoU.land: 0.0624, IoU.bannister: 0.2295, IoU.escalator: 0.6573, IoU.ottoman: 0.6084, IoU.bottle: 0.5182, IoU.buffet: 0.4582, IoU.poster: 0.3798, IoU.stage: 0.2981, IoU.van: 0.5295, IoU.ship: 0.3885, IoU.fountain: 0.5134, IoU.conveyer belt: 0.7825, IoU.canopy: 0.5510, IoU.washer: 0.9074, IoU.plaything: 0.3834, IoU.swimming pool: 0.5235, IoU.stool: 0.6045, IoU.barrel: 0.6460, IoU.basket: 0.4754, IoU.waterfall: 0.4597, IoU.tent: 0.9501, IoU.bag: 0.3334, IoU.minibike: 0.8123, IoU.cradle: 0.9137, IoU.oven: 0.6599, IoU.ball: 0.4116, IoU.food: 0.6390, IoU.step: 0.3176, IoU.tank: 0.6039, IoU.trade name: 0.2986, IoU.microwave: 0.8964, IoU.pot: 0.6261, IoU.animal: 0.8015, IoU.bicycle: 0.6468, IoU.lake: 0.6588, IoU.dishwasher: 0.8054, IoU.screen: 0.6108, IoU.blanket: 0.4469, IoU.sculpture: 0.7702, IoU.hood: 0.8495, IoU.sconce: 0.6805, IoU.vase: 0.5888, IoU.traffic light: 0.5293, IoU.tray: 0.3464, IoU.ashcan: 0.5493, IoU.fan: 0.7369, IoU.pier: 0.3871, IoU.crt screen: 0.0148, IoU.plate: 0.7034, IoU.monitor: 0.0383, IoU.bulletin board: 0.6513, IoU.shower: 0.1629, IoU.radiator: 0.7573, IoU.glass: 0.2896, IoU.clock: 0.6388, IoU.flag: 0.6931, Acc.wall: 0.8950, Acc.building: 0.9213, Acc.sky: 0.9739, Acc.floor: 0.9048, Acc.tree: 0.8971, Acc.ceiling: 0.9331, Acc.road: 0.9187, Acc.bed : 0.9741, Acc.windowpane: 0.8257, Acc.grass: 0.8107, Acc.cabinet: 0.7174, Acc.sidewalk: 0.8575, Acc.person: 0.9404, Acc.earth: 0.5686, Acc.door: 0.8399, Acc.table: 0.8196, Acc.mountain: 0.7185, Acc.plant: 0.6996, Acc.curtain: 0.9123, Acc.chair: 0.8014, Acc.car: 0.9519, Acc.water: 0.8657, Acc.painting: 0.9106, Acc.sofa: 0.9184, Acc.shelf: 0.6346, Acc.house: 0.7364, Acc.sea: 0.9085, Acc.mirror: 0.9177, Acc.rug: 0.8527, Acc.field: 0.7051, Acc.armchair: 0.7978, Acc.seat: 0.8980, Acc.fence: 0.7513, Acc.desk: 0.8397, Acc.rock: 0.7566, Acc.wardrobe: 0.8630, Acc.lamp: 0.9058, Acc.bathtub: 0.9376, Acc.railing: 0.6696, Acc.cushion: 0.9060, Acc.base: 0.6672, Acc.box: 0.6507, Acc.column: 0.7232, Acc.signboard: 0.6820, Acc.chest of drawers: 0.7062, Acc.counter: 0.6851, Acc.sand: 0.8715, Acc.sink: 0.9286, Acc.skyscraper: 0.5275, Acc.fireplace: 0.9471, Acc.refrigerator: 0.9209, Acc.grandstand: 0.8250, Acc.path: 0.4186, Acc.stairs: 0.5023, Acc.runway: 0.9374, Acc.case: 0.8781, Acc.pool table: 0.9870, Acc.pillow: 0.8311, Acc.screen door: 0.9269, Acc.stairway: 0.7146, Acc.river: 0.3557, Acc.bridge: 0.8709, Acc.bookcase: 0.5608, Acc.blind: 0.5796, Acc.coffee table: 0.9021, Acc.toilet: 0.9668, Acc.flower: 0.7074, Acc.book: 0.8310, Acc.hill: 0.2789, Acc.bench: 0.8492, Acc.countertop: 0.9054, Acc.stove: 0.9033, Acc.palm: 0.8270, Acc.kitchen island: 0.9206, Acc.computer: 0.8707, Acc.swivel chair: 0.8471, Acc.boat: 0.9034, Acc.bar: 0.7314, Acc.arcade machine: 0.9874, Acc.hovel: 0.6948, Acc.bus: 0.9741, Acc.towel: 0.9185, Acc.light: 0.8054, Acc.truck: 0.7372, Acc.tower: 0.6307, Acc.chandelier: 0.8693, Acc.awning: 0.5304, Acc.streetlight: 0.7159, Acc.booth: 0.7321, Acc.television receiver: 0.9225, Acc.airplane: 0.9648, Acc.dirt track: 0.3860, Acc.apparel: 0.8515, Acc.pole: 0.4916, Acc.land: 0.0969, Acc.bannister: 0.3417, Acc.escalator: 0.8376, Acc.ottoman: 0.7947, Acc.bottle: 0.8167, Acc.buffet: 0.6593, Acc.poster: 0.6119, Acc.stage: 0.6597, Acc.van: 0.7584, Acc.ship: 0.4111, Acc.fountain: 0.5326, Acc.conveyer belt: 0.9705, Acc.canopy: 0.7257, Acc.washer: 0.9349, Acc.plaything: 0.5903, Acc.swimming pool: 0.7593, Acc.stool: 0.8544, Acc.barrel: 0.9433, Acc.basket: 0.7166, Acc.waterfall: 0.5656, Acc.tent: 0.9812, Acc.bag: 0.4732, Acc.minibike: 0.9399, Acc.cradle: 0.9750, Acc.oven: 0.8404, Acc.ball: 0.4431, Acc.food: 0.7439, Acc.step: 0.4384, Acc.tank: 0.6745, Acc.trade name: 0.3870, Acc.microwave: 0.9462, Acc.pot: 0.7528, Acc.animal: 0.8237, Acc.bicycle: 0.8335, Acc.lake: 0.6882, Acc.dishwasher: 0.9057, Acc.screen: 0.9421, Acc.blanket: 0.5612, Acc.sculpture: 0.9052, Acc.hood: 0.8972, Acc.sconce: 0.8283, Acc.vase: 0.8172, Acc.traffic light: 0.7474, Acc.tray: 0.5406, Acc.ashcan: 0.8091, Acc.fan: 0.8812, Acc.pier: 0.4162, Acc.crt screen: 0.0399, Acc.plate: 0.8524, Acc.monitor: 0.0543, Acc.bulletin board: 0.8507, Acc.shower: 0.2864, Acc.radiator: 0.9313, Acc.glass: 0.3186, Acc.clock: 0.7762, Acc.flag: 0.8703
2022-12-01 19:54:19,440 - mmseg - INFO - Iter [39050/40000]	lr: 3.163e-09, eta: 1:09:10, time: 7.678, data_time: 3.582, memory: 51902, decode.loss_cls: 0.3223, decode.loss_mask: 0.5396, decode.loss_dice: 0.7810, decode.d0.loss_cls: 4.8932, decode.d0.loss_mask: 0.5326, decode.d0.loss_dice: 0.8364, decode.d1.loss_cls: 0.4277, decode.d1.loss_mask: 0.5651, decode.d1.loss_dice: 0.8373, decode.d2.loss_cls: 0.3771, decode.d2.loss_mask: 0.5541, decode.d2.loss_dice: 0.8056, decode.d3.loss_cls: 0.3518, decode.d3.loss_mask: 0.5467, decode.d3.loss_dice: 0.7893, decode.d4.loss_cls: 0.3378, decode.d4.loss_mask: 0.5457, decode.d4.loss_dice: 0.7877, decode.d5.loss_cls: 0.3305, decode.d5.loss_mask: 0.5422, decode.d5.loss_dice: 0.7858, decode.d6.loss_cls: 0.3284, decode.d6.loss_mask: 0.5405, decode.d6.loss_dice: 0.7803, decode.d7.loss_cls: 0.3255, decode.d7.loss_mask: 0.5402, decode.d7.loss_dice: 0.7826, decode.d8.loss_cls: 0.3189, decode.d8.loss_mask: 0.5391, decode.d8.loss_dice: 0.7802, loss: 21.4252
2022-12-01 19:57:45,447 - mmseg - INFO - Iter [39100/40000]	lr: 2.996e-09, eta: 1:05:31, time: 4.120, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3299, decode.loss_mask: 0.5148, decode.loss_dice: 0.7740, decode.d0.loss_cls: 4.9162, decode.d0.loss_mask: 0.5134, decode.d0.loss_dice: 0.8399, decode.d1.loss_cls: 0.4519, decode.d1.loss_mask: 0.5438, decode.d1.loss_dice: 0.8309, decode.d2.loss_cls: 0.3928, decode.d2.loss_mask: 0.5304, decode.d2.loss_dice: 0.7981, decode.d3.loss_cls: 0.3566, decode.d3.loss_mask: 0.5230, decode.d3.loss_dice: 0.7859, decode.d4.loss_cls: 0.3486, decode.d4.loss_mask: 0.5221, decode.d4.loss_dice: 0.7884, decode.d5.loss_cls: 0.3410, decode.d5.loss_mask: 0.5182, decode.d5.loss_dice: 0.7799, decode.d6.loss_cls: 0.3346, decode.d6.loss_mask: 0.5166, decode.d6.loss_dice: 0.7787, decode.d7.loss_cls: 0.3334, decode.d7.loss_mask: 0.5149, decode.d7.loss_dice: 0.7718, decode.d8.loss_cls: 0.3329, decode.d8.loss_mask: 0.5137, decode.d8.loss_dice: 0.7746, loss: 21.2712
2022-12-01 20:01:11,123 - mmseg - INFO - Iter [39150/40000]	lr: 2.830e-09, eta: 1:01:53, time: 4.114, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3271, decode.loss_mask: 0.5266, decode.loss_dice: 0.7813, decode.d0.loss_cls: 4.8864, decode.d0.loss_mask: 0.5204, decode.d0.loss_dice: 0.8443, decode.d1.loss_cls: 0.4415, decode.d1.loss_mask: 0.5527, decode.d1.loss_dice: 0.8464, decode.d2.loss_cls: 0.3876, decode.d2.loss_mask: 0.5407, decode.d2.loss_dice: 0.8083, decode.d3.loss_cls: 0.3487, decode.d3.loss_mask: 0.5375, decode.d3.loss_dice: 0.7947, decode.d4.loss_cls: 0.3428, decode.d4.loss_mask: 0.5341, decode.d4.loss_dice: 0.7924, decode.d5.loss_cls: 0.3348, decode.d5.loss_mask: 0.5296, decode.d5.loss_dice: 0.7878, decode.d6.loss_cls: 0.3307, decode.d6.loss_mask: 0.5288, decode.d6.loss_dice: 0.7857, decode.d7.loss_cls: 0.3261, decode.d7.loss_mask: 0.5285, decode.d7.loss_dice: 0.7862, decode.d8.loss_cls: 0.3260, decode.d8.loss_mask: 0.5268, decode.d8.loss_dice: 0.7818, loss: 21.3861
2022-12-01 20:04:38,824 - mmseg - INFO - Iter [39200/40000]	lr: 2.664e-09, eta: 0:58:14, time: 4.154, data_time: 0.063, memory: 51902, decode.loss_cls: 0.3157, decode.loss_mask: 0.5045, decode.loss_dice: 0.7715, decode.d0.loss_cls: 4.9182, decode.d0.loss_mask: 0.5011, decode.d0.loss_dice: 0.8429, decode.d1.loss_cls: 0.4329, decode.d1.loss_mask: 0.5281, decode.d1.loss_dice: 0.8333, decode.d2.loss_cls: 0.3774, decode.d2.loss_mask: 0.5167, decode.d2.loss_dice: 0.7972, decode.d3.loss_cls: 0.3403, decode.d3.loss_mask: 0.5115, decode.d3.loss_dice: 0.7846, decode.d4.loss_cls: 0.3321, decode.d4.loss_mask: 0.5094, decode.d4.loss_dice: 0.7808, decode.d5.loss_cls: 0.3245, decode.d5.loss_mask: 0.5074, decode.d5.loss_dice: 0.7757, decode.d6.loss_cls: 0.3205, decode.d6.loss_mask: 0.5044, decode.d6.loss_dice: 0.7741, decode.d7.loss_cls: 0.3172, decode.d7.loss_mask: 0.5058, decode.d7.loss_dice: 0.7746, decode.d8.loss_cls: 0.3159, decode.d8.loss_mask: 0.5054, decode.d8.loss_dice: 0.7744, loss: 20.9980
2022-12-01 20:08:04,598 - mmseg - INFO - Iter [39250/40000]	lr: 2.498e-09, eta: 0:54:35, time: 4.115, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3233, decode.loss_mask: 0.5117, decode.loss_dice: 0.7764, decode.d0.loss_cls: 4.9259, decode.d0.loss_mask: 0.5120, decode.d0.loss_dice: 0.8418, decode.d1.loss_cls: 0.4363, decode.d1.loss_mask: 0.5384, decode.d1.loss_dice: 0.8378, decode.d2.loss_cls: 0.3823, decode.d2.loss_mask: 0.5263, decode.d2.loss_dice: 0.8011, decode.d3.loss_cls: 0.3488, decode.d3.loss_mask: 0.5225, decode.d3.loss_dice: 0.7863, decode.d4.loss_cls: 0.3377, decode.d4.loss_mask: 0.5191, decode.d4.loss_dice: 0.7850, decode.d5.loss_cls: 0.3278, decode.d5.loss_mask: 0.5154, decode.d5.loss_dice: 0.7832, decode.d6.loss_cls: 0.3274, decode.d6.loss_mask: 0.5135, decode.d6.loss_dice: 0.7799, decode.d7.loss_cls: 0.3249, decode.d7.loss_mask: 0.5121, decode.d7.loss_dice: 0.7776, decode.d8.loss_cls: 0.3231, decode.d8.loss_mask: 0.5131, decode.d8.loss_dice: 0.7769, loss: 21.1875
2022-12-01 20:11:30,388 - mmseg - INFO - Iter [39300/40000]	lr: 2.331e-09, eta: 0:50:57, time: 4.116, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3225, decode.loss_mask: 0.5214, decode.loss_dice: 0.7721, decode.d0.loss_cls: 4.9077, decode.d0.loss_mask: 0.5261, decode.d0.loss_dice: 0.8476, decode.d1.loss_cls: 0.4379, decode.d1.loss_mask: 0.5542, decode.d1.loss_dice: 0.8350, decode.d2.loss_cls: 0.3833, decode.d2.loss_mask: 0.5387, decode.d2.loss_dice: 0.8032, decode.d3.loss_cls: 0.3463, decode.d3.loss_mask: 0.5341, decode.d3.loss_dice: 0.7894, decode.d4.loss_cls: 0.3397, decode.d4.loss_mask: 0.5295, decode.d4.loss_dice: 0.7862, decode.d5.loss_cls: 0.3293, decode.d5.loss_mask: 0.5266, decode.d5.loss_dice: 0.7782, decode.d6.loss_cls: 0.3260, decode.d6.loss_mask: 0.5239, decode.d6.loss_dice: 0.7789, decode.d7.loss_cls: 0.3237, decode.d7.loss_mask: 0.5227, decode.d7.loss_dice: 0.7750, decode.d8.loss_cls: 0.3185, decode.d8.loss_mask: 0.5253, decode.d8.loss_dice: 0.7747, loss: 21.2776
2022-12-01 20:14:55,809 - mmseg - INFO - Iter [39350/40000]	lr: 2.165e-09, eta: 0:47:18, time: 4.109, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3109, decode.loss_mask: 0.5116, decode.loss_dice: 0.7678, decode.d0.loss_cls: 4.8996, decode.d0.loss_mask: 0.5089, decode.d0.loss_dice: 0.8317, decode.d1.loss_cls: 0.4330, decode.d1.loss_mask: 0.5417, decode.d1.loss_dice: 0.8260, decode.d2.loss_cls: 0.3741, decode.d2.loss_mask: 0.5308, decode.d2.loss_dice: 0.7922, decode.d3.loss_cls: 0.3462, decode.d3.loss_mask: 0.5222, decode.d3.loss_dice: 0.7790, decode.d4.loss_cls: 0.3329, decode.d4.loss_mask: 0.5189, decode.d4.loss_dice: 0.7778, decode.d5.loss_cls: 0.3234, decode.d5.loss_mask: 0.5165, decode.d5.loss_dice: 0.7714, decode.d6.loss_cls: 0.3191, decode.d6.loss_mask: 0.5159, decode.d6.loss_dice: 0.7669, decode.d7.loss_cls: 0.3154, decode.d7.loss_mask: 0.5140, decode.d7.loss_dice: 0.7711, decode.d8.loss_cls: 0.3132, decode.d8.loss_mask: 0.5124, decode.d8.loss_dice: 0.7674, loss: 21.0119
2022-12-01 20:18:21,535 - mmseg - INFO - Iter [39400/40000]	lr: 1.999e-09, eta: 0:43:40, time: 4.115, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3217, decode.loss_mask: 0.5323, decode.loss_dice: 0.7721, decode.d0.loss_cls: 4.8909, decode.d0.loss_mask: 0.5331, decode.d0.loss_dice: 0.8341, decode.d1.loss_cls: 0.4303, decode.d1.loss_mask: 0.5622, decode.d1.loss_dice: 0.8358, decode.d2.loss_cls: 0.3832, decode.d2.loss_mask: 0.5496, decode.d2.loss_dice: 0.7984, decode.d3.loss_cls: 0.3453, decode.d3.loss_mask: 0.5423, decode.d3.loss_dice: 0.7861, decode.d4.loss_cls: 0.3394, decode.d4.loss_mask: 0.5387, decode.d4.loss_dice: 0.7827, decode.d5.loss_cls: 0.3302, decode.d5.loss_mask: 0.5371, decode.d5.loss_dice: 0.7776, decode.d6.loss_cls: 0.3224, decode.d6.loss_mask: 0.5368, decode.d6.loss_dice: 0.7756, decode.d7.loss_cls: 0.3212, decode.d7.loss_mask: 0.5349, decode.d7.loss_dice: 0.7755, decode.d8.loss_cls: 0.3247, decode.d8.loss_mask: 0.5342, decode.d8.loss_dice: 0.7749, loss: 21.3232
2022-12-01 20:21:47,290 - mmseg - INFO - Iter [39450/40000]	lr: 1.832e-09, eta: 0:40:01, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3148, decode.loss_mask: 0.5343, decode.loss_dice: 0.7773, decode.d0.loss_cls: 4.8927, decode.d0.loss_mask: 0.5318, decode.d0.loss_dice: 0.8391, decode.d1.loss_cls: 0.4199, decode.d1.loss_mask: 0.5669, decode.d1.loss_dice: 0.8363, decode.d2.loss_cls: 0.3680, decode.d2.loss_mask: 0.5526, decode.d2.loss_dice: 0.8063, decode.d3.loss_cls: 0.3402, decode.d3.loss_mask: 0.5456, decode.d3.loss_dice: 0.7925, decode.d4.loss_cls: 0.3329, decode.d4.loss_mask: 0.5422, decode.d4.loss_dice: 0.7869, decode.d5.loss_cls: 0.3244, decode.d5.loss_mask: 0.5409, decode.d5.loss_dice: 0.7865, decode.d6.loss_cls: 0.3200, decode.d6.loss_mask: 0.5370, decode.d6.loss_dice: 0.7801, decode.d7.loss_cls: 0.3153, decode.d7.loss_mask: 0.5345, decode.d7.loss_dice: 0.7813, decode.d8.loss_cls: 0.3106, decode.d8.loss_mask: 0.5352, decode.d8.loss_dice: 0.7791, loss: 21.3251
2022-12-01 20:25:12,852 - mmseg - INFO - Iter [39500/40000]	lr: 1.666e-09, eta: 0:36:23, time: 4.111, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3173, decode.loss_mask: 0.5308, decode.loss_dice: 0.7765, decode.d0.loss_cls: 4.9033, decode.d0.loss_mask: 0.5269, decode.d0.loss_dice: 0.8409, decode.d1.loss_cls: 0.4329, decode.d1.loss_mask: 0.5589, decode.d1.loss_dice: 0.8392, decode.d2.loss_cls: 0.3793, decode.d2.loss_mask: 0.5484, decode.d2.loss_dice: 0.8036, decode.d3.loss_cls: 0.3506, decode.d3.loss_mask: 0.5406, decode.d3.loss_dice: 0.7902, decode.d4.loss_cls: 0.3420, decode.d4.loss_mask: 0.5371, decode.d4.loss_dice: 0.7848, decode.d5.loss_cls: 0.3301, decode.d5.loss_mask: 0.5339, decode.d5.loss_dice: 0.7807, decode.d6.loss_cls: 0.3275, decode.d6.loss_mask: 0.5320, decode.d6.loss_dice: 0.7762, decode.d7.loss_cls: 0.3209, decode.d7.loss_mask: 0.5292, decode.d7.loss_dice: 0.7759, decode.d8.loss_cls: 0.3205, decode.d8.loss_mask: 0.5299, decode.d8.loss_dice: 0.7722, loss: 21.3323
2022-12-01 20:28:38,370 - mmseg - INFO - Iter [39550/40000]	lr: 1.500e-09, eta: 0:32:44, time: 4.110, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3139, decode.loss_mask: 0.5205, decode.loss_dice: 0.7705, decode.d0.loss_cls: 4.9133, decode.d0.loss_mask: 0.5150, decode.d0.loss_dice: 0.8387, decode.d1.loss_cls: 0.4286, decode.d1.loss_mask: 0.5497, decode.d1.loss_dice: 0.8340, decode.d2.loss_cls: 0.3746, decode.d2.loss_mask: 0.5372, decode.d2.loss_dice: 0.8017, decode.d3.loss_cls: 0.3383, decode.d3.loss_mask: 0.5276, decode.d3.loss_dice: 0.7806, decode.d4.loss_cls: 0.3304, decode.d4.loss_mask: 0.5261, decode.d4.loss_dice: 0.7826, decode.d5.loss_cls: 0.3198, decode.d5.loss_mask: 0.5224, decode.d5.loss_dice: 0.7770, decode.d6.loss_cls: 0.3207, decode.d6.loss_mask: 0.5217, decode.d6.loss_dice: 0.7719, decode.d7.loss_cls: 0.3127, decode.d7.loss_mask: 0.5192, decode.d7.loss_dice: 0.7733, decode.d8.loss_cls: 0.3141, decode.d8.loss_mask: 0.5203, decode.d8.loss_dice: 0.7725, loss: 21.1293
2022-12-01 20:32:04,113 - mmseg - INFO - Iter [39600/40000]	lr: 1.334e-09, eta: 0:29:06, time: 4.115, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3184, decode.loss_mask: 0.5248, decode.loss_dice: 0.7737, decode.d0.loss_cls: 4.9008, decode.d0.loss_mask: 0.5237, decode.d0.loss_dice: 0.8438, decode.d1.loss_cls: 0.4387, decode.d1.loss_mask: 0.5543, decode.d1.loss_dice: 0.8314, decode.d2.loss_cls: 0.3809, decode.d2.loss_mask: 0.5424, decode.d2.loss_dice: 0.7980, decode.d3.loss_cls: 0.3512, decode.d3.loss_mask: 0.5339, decode.d3.loss_dice: 0.7842, decode.d4.loss_cls: 0.3391, decode.d4.loss_mask: 0.5292, decode.d4.loss_dice: 0.7810, decode.d5.loss_cls: 0.3308, decode.d5.loss_mask: 0.5270, decode.d5.loss_dice: 0.7775, decode.d6.loss_cls: 0.3271, decode.d6.loss_mask: 0.5243, decode.d6.loss_dice: 0.7736, decode.d7.loss_cls: 0.3238, decode.d7.loss_mask: 0.5224, decode.d7.loss_dice: 0.7730, decode.d8.loss_cls: 0.3193, decode.d8.loss_mask: 0.5224, decode.d8.loss_dice: 0.7730, loss: 21.2436
2022-12-01 20:35:29,663 - mmseg - INFO - Iter [39650/40000]	lr: 1.167e-09, eta: 0:25:27, time: 4.111, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3239, decode.loss_mask: 0.5297, decode.loss_dice: 0.7835, decode.d0.loss_cls: 4.9043, decode.d0.loss_mask: 0.5294, decode.d0.loss_dice: 0.8542, decode.d1.loss_cls: 0.4404, decode.d1.loss_mask: 0.5587, decode.d1.loss_dice: 0.8463, decode.d2.loss_cls: 0.3863, decode.d2.loss_mask: 0.5430, decode.d2.loss_dice: 0.8134, decode.d3.loss_cls: 0.3525, decode.d3.loss_mask: 0.5361, decode.d3.loss_dice: 0.7981, decode.d4.loss_cls: 0.3419, decode.d4.loss_mask: 0.5344, decode.d4.loss_dice: 0.7964, decode.d5.loss_cls: 0.3350, decode.d5.loss_mask: 0.5321, decode.d5.loss_dice: 0.7904, decode.d6.loss_cls: 0.3306, decode.d6.loss_mask: 0.5289, decode.d6.loss_dice: 0.7854, decode.d7.loss_cls: 0.3290, decode.d7.loss_mask: 0.5291, decode.d7.loss_dice: 0.7858, decode.d8.loss_cls: 0.3248, decode.d8.loss_mask: 0.5293, decode.d8.loss_dice: 0.7858, loss: 21.4589
2022-12-01 20:38:55,216 - mmseg - INFO - Iter [39700/40000]	lr: 1.001e-09, eta: 0:21:49, time: 4.111, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3143, decode.loss_mask: 0.5088, decode.loss_dice: 0.7705, decode.d0.loss_cls: 4.8835, decode.d0.loss_mask: 0.5073, decode.d0.loss_dice: 0.8342, decode.d1.loss_cls: 0.4329, decode.d1.loss_mask: 0.5331, decode.d1.loss_dice: 0.8256, decode.d2.loss_cls: 0.3804, decode.d2.loss_mask: 0.5214, decode.d2.loss_dice: 0.7979, decode.d3.loss_cls: 0.3436, decode.d3.loss_mask: 0.5178, decode.d3.loss_dice: 0.7837, decode.d4.loss_cls: 0.3317, decode.d4.loss_mask: 0.5155, decode.d4.loss_dice: 0.7826, decode.d5.loss_cls: 0.3212, decode.d5.loss_mask: 0.5115, decode.d5.loss_dice: 0.7770, decode.d6.loss_cls: 0.3211, decode.d6.loss_mask: 0.5104, decode.d6.loss_dice: 0.7701, decode.d7.loss_cls: 0.3178, decode.d7.loss_mask: 0.5092, decode.d7.loss_dice: 0.7753, decode.d8.loss_cls: 0.3168, decode.d8.loss_mask: 0.5087, decode.d8.loss_dice: 0.7690, loss: 20.9929
2022-12-01 20:42:20,941 - mmseg - INFO - Iter [39750/40000]	lr: 8.348e-10, eta: 0:18:11, time: 4.114, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3248, decode.loss_mask: 0.5209, decode.loss_dice: 0.7935, decode.d0.loss_cls: 4.9106, decode.d0.loss_mask: 0.5183, decode.d0.loss_dice: 0.8678, decode.d1.loss_cls: 0.4463, decode.d1.loss_mask: 0.5477, decode.d1.loss_dice: 0.8533, decode.d2.loss_cls: 0.3911, decode.d2.loss_mask: 0.5339, decode.d2.loss_dice: 0.8177, decode.d3.loss_cls: 0.3549, decode.d3.loss_mask: 0.5289, decode.d3.loss_dice: 0.8080, decode.d4.loss_cls: 0.3501, decode.d4.loss_mask: 0.5270, decode.d4.loss_dice: 0.8012, decode.d5.loss_cls: 0.3374, decode.d5.loss_mask: 0.5225, decode.d5.loss_dice: 0.7973, decode.d6.loss_cls: 0.3307, decode.d6.loss_mask: 0.5226, decode.d6.loss_dice: 0.7970, decode.d7.loss_cls: 0.3262, decode.d7.loss_mask: 0.5205, decode.d7.loss_dice: 0.7950, decode.d8.loss_cls: 0.3261, decode.d8.loss_mask: 0.5189, decode.d8.loss_dice: 0.7937, loss: 21.4838
2022-12-01 20:45:46,610 - mmseg - INFO - Iter [39800/40000]	lr: 6.685e-10, eta: 0:14:32, time: 4.113, data_time: 0.020, memory: 51902, decode.loss_cls: 0.3293, decode.loss_mask: 0.5005, decode.loss_dice: 0.7693, decode.d0.loss_cls: 4.9053, decode.d0.loss_mask: 0.5001, decode.d0.loss_dice: 0.8455, decode.d1.loss_cls: 0.4444, decode.d1.loss_mask: 0.5267, decode.d1.loss_dice: 0.8290, decode.d2.loss_cls: 0.3885, decode.d2.loss_mask: 0.5158, decode.d2.loss_dice: 0.7963, decode.d3.loss_cls: 0.3587, decode.d3.loss_mask: 0.5088, decode.d3.loss_dice: 0.7793, decode.d4.loss_cls: 0.3491, decode.d4.loss_mask: 0.5065, decode.d4.loss_dice: 0.7779, decode.d5.loss_cls: 0.3376, decode.d5.loss_mask: 0.5050, decode.d5.loss_dice: 0.7744, decode.d6.loss_cls: 0.3319, decode.d6.loss_mask: 0.5024, decode.d6.loss_dice: 0.7722, decode.d7.loss_cls: 0.3301, decode.d7.loss_mask: 0.5022, decode.d7.loss_dice: 0.7745, decode.d8.loss_cls: 0.3313, decode.d8.loss_mask: 0.5019, decode.d8.loss_dice: 0.7746, loss: 21.0687
2022-12-01 20:49:14,324 - mmseg - INFO - Iter [39850/40000]	lr: 5.022e-10, eta: 0:10:54, time: 4.154, data_time: 0.065, memory: 51902, decode.loss_cls: 0.3201, decode.loss_mask: 0.5248, decode.loss_dice: 0.7736, decode.d0.loss_cls: 4.8725, decode.d0.loss_mask: 0.5244, decode.d0.loss_dice: 0.8372, decode.d1.loss_cls: 0.4283, decode.d1.loss_mask: 0.5536, decode.d1.loss_dice: 0.8314, decode.d2.loss_cls: 0.3794, decode.d2.loss_mask: 0.5390, decode.d2.loss_dice: 0.7974, decode.d3.loss_cls: 0.3439, decode.d3.loss_mask: 0.5339, decode.d3.loss_dice: 0.7885, decode.d4.loss_cls: 0.3343, decode.d4.loss_mask: 0.5313, decode.d4.loss_dice: 0.7857, decode.d5.loss_cls: 0.3245, decode.d5.loss_mask: 0.5266, decode.d5.loss_dice: 0.7778, decode.d6.loss_cls: 0.3202, decode.d6.loss_mask: 0.5261, decode.d6.loss_dice: 0.7737, decode.d7.loss_cls: 0.3192, decode.d7.loss_mask: 0.5248, decode.d7.loss_dice: 0.7735, decode.d8.loss_cls: 0.3185, decode.d8.loss_mask: 0.5244, decode.d8.loss_dice: 0.7738, loss: 21.1824
2022-12-01 20:52:39,959 - mmseg - INFO - Iter [39900/40000]	lr: 3.359e-10, eta: 0:07:16, time: 4.113, data_time: 0.018, memory: 51902, decode.loss_cls: 0.3232, decode.loss_mask: 0.5318, decode.loss_dice: 0.7914, decode.d0.loss_cls: 4.9041, decode.d0.loss_mask: 0.5300, decode.d0.loss_dice: 0.8591, decode.d1.loss_cls: 0.4500, decode.d1.loss_mask: 0.5622, decode.d1.loss_dice: 0.8544, decode.d2.loss_cls: 0.3911, decode.d2.loss_mask: 0.5488, decode.d2.loss_dice: 0.8189, decode.d3.loss_cls: 0.3563, decode.d3.loss_mask: 0.5399, decode.d3.loss_dice: 0.8062, decode.d4.loss_cls: 0.3453, decode.d4.loss_mask: 0.5369, decode.d4.loss_dice: 0.8010, decode.d5.loss_cls: 0.3331, decode.d5.loss_mask: 0.5350, decode.d5.loss_dice: 0.7955, decode.d6.loss_cls: 0.3336, decode.d6.loss_mask: 0.5329, decode.d6.loss_dice: 0.7960, decode.d7.loss_cls: 0.3268, decode.d7.loss_mask: 0.5326, decode.d7.loss_dice: 0.7954, decode.d8.loss_cls: 0.3229, decode.d8.loss_mask: 0.5322, decode.d8.loss_dice: 0.7965, loss: 21.5832
2022-12-01 20:56:05,694 - mmseg - INFO - Iter [39950/40000]	lr: 1.696e-10, eta: 0:03:38, time: 4.115, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3147, decode.loss_mask: 0.5230, decode.loss_dice: 0.7791, decode.d0.loss_cls: 4.9010, decode.d0.loss_mask: 0.5208, decode.d0.loss_dice: 0.8419, decode.d1.loss_cls: 0.4299, decode.d1.loss_mask: 0.5506, decode.d1.loss_dice: 0.8353, decode.d2.loss_cls: 0.3753, decode.d2.loss_mask: 0.5375, decode.d2.loss_dice: 0.8020, decode.d3.loss_cls: 0.3461, decode.d3.loss_mask: 0.5308, decode.d3.loss_dice: 0.7898, decode.d4.loss_cls: 0.3372, decode.d4.loss_mask: 0.5273, decode.d4.loss_dice: 0.7847, decode.d5.loss_cls: 0.3256, decode.d5.loss_mask: 0.5257, decode.d5.loss_dice: 0.7834, decode.d6.loss_cls: 0.3213, decode.d6.loss_mask: 0.5236, decode.d6.loss_dice: 0.7795, decode.d7.loss_cls: 0.3163, decode.d7.loss_mask: 0.5240, decode.d7.loss_dice: 0.7817, decode.d8.loss_cls: 0.3177, decode.d8.loss_mask: 0.5239, decode.d8.loss_dice: 0.7789, loss: 21.2286
2022-12-01 20:59:30,914 - mmseg - INFO - Saving checkpoint at 40000 iterations
2022-12-01 21:00:19,510 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 21:00:19,511 - mmseg - INFO - Iter [40000/40000]	lr: 3.326e-12, eta: 0:00:00, time: 5.076, data_time: 0.019, memory: 51902, decode.loss_cls: 0.3230, decode.loss_mask: 0.5348, decode.loss_dice: 0.8008, decode.d0.loss_cls: 4.9032, decode.d0.loss_mask: 0.5285, decode.d0.loss_dice: 0.8619, decode.d1.loss_cls: 0.4395, decode.d1.loss_mask: 0.5611, decode.d1.loss_dice: 0.8568, decode.d2.loss_cls: 0.3870, decode.d2.loss_mask: 0.5492, decode.d2.loss_dice: 0.8258, decode.d3.loss_cls: 0.3577, decode.d3.loss_mask: 0.5419, decode.d3.loss_dice: 0.8132, decode.d4.loss_cls: 0.3483, decode.d4.loss_mask: 0.5375, decode.d4.loss_dice: 0.8075, decode.d5.loss_cls: 0.3368, decode.d5.loss_mask: 0.5377, decode.d5.loss_dice: 0.8037, decode.d6.loss_cls: 0.3288, decode.d6.loss_mask: 0.5366, decode.d6.loss_dice: 0.8018, decode.d7.loss_cls: 0.3288, decode.d7.loss_mask: 0.5336, decode.d7.loss_dice: 0.7980, decode.d8.loss_cls: 0.3288, decode.d8.loss_mask: 0.5335, decode.d8.loss_dice: 0.7974, loss: 21.6431
2022-12-01 21:03:17,488 - mmseg - INFO - per class results:
2022-12-01 21:03:17,493 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 83.25 | 89.27 |
|       building      | 85.28 | 92.05 |
|         sky         | 95.21 | 97.36 |
|        floor        | 85.62 |  90.6 |
|         tree        | 78.42 | 89.68 |
|       ceiling       | 87.04 | 93.57 |
|         road        | 88.44 | 92.06 |
|         bed         | 93.85 | 97.34 |
|      windowpane     | 68.62 | 82.55 |
|        grass        |  67.9 | 81.16 |
|       cabinet       | 62.66 | 72.02 |
|       sidewalk      | 72.97 | 85.84 |
|        person       | 88.43 | 94.17 |
|        earth        | 41.95 | 57.09 |
|         door        | 65.82 | 84.13 |
|        table        | 72.04 | 81.85 |
|       mountain      | 62.36 | 71.77 |
|        plant        | 56.62 | 69.87 |
|       curtain       | 82.52 | 91.92 |
|        chair        | 69.25 | 80.06 |
|         car         | 89.64 | 94.93 |
|        water        | 70.11 | 86.67 |
|       painting      | 80.03 | 91.36 |
|         sofa        | 85.68 | 91.82 |
|        shelf        | 49.02 | 62.95 |
|        house        | 57.11 | 75.48 |
|         sea         |  80.8 | 90.93 |
|        mirror       | 81.43 | 91.58 |
|         rug         | 72.22 | 85.32 |
|        field        | 36.02 | 66.82 |
|       armchair      | 64.06 | 79.96 |
|         seat        | 66.19 | 89.86 |
|        fence        | 55.16 | 74.38 |
|         desk        | 59.24 | 82.68 |
|         rock        | 60.72 | 75.65 |
|       wardrobe      | 58.46 | 86.57 |
|         lamp        | 81.17 |  90.7 |
|       bathtub       | 91.45 | 93.72 |
|       railing       | 45.71 | 66.44 |
|       cushion       | 77.56 | 90.54 |
|         base        | 42.15 | 66.54 |
|         box         | 46.13 | 64.78 |
|        column       | 57.53 | 72.48 |
|      signboard      | 45.71 | 68.27 |
|   chest of drawers  | 43.97 | 67.83 |
|       counter       |  59.1 | 68.63 |
|         sand        | 59.47 | 85.39 |
|         sink        | 86.18 | 89.94 |
|      skyscraper     | 42.02 | 53.13 |
|      fireplace      | 79.68 |  94.9 |
|     refrigerator    | 81.86 | 92.15 |
|      grandstand     | 47.49 | 81.97 |
|         path        | 32.12 | 41.57 |
|        stairs       | 37.96 |  50.0 |
|        runway       | 74.14 | 93.56 |
|         case        | 67.13 | 87.36 |
|      pool table     | 95.94 | 98.67 |
|        pillow       | 73.18 | 83.12 |
|     screen door     | 83.72 | 92.03 |
|       stairway      | 56.21 | 71.27 |
|        river        | 25.87 | 30.25 |
|        bridge       | 71.32 | 86.99 |
|       bookcase      | 39.39 | 56.65 |
|        blind        | 46.64 | 57.66 |
|     coffee table    | 72.32 |  90.5 |
|        toilet       | 92.94 | 96.43 |
|        flower       | 46.55 |  70.8 |
|         book        |  61.8 | 83.35 |
|         hill        | 15.56 | 27.72 |
|        bench        | 75.85 | 84.34 |
|      countertop     | 70.81 |  90.2 |
|        stove        | 86.34 | 90.25 |
|         palm        | 57.15 | 82.33 |
|    kitchen island   | 47.34 | 91.98 |
|       computer      | 78.85 | 87.07 |
|     swivel chair    | 55.72 | 83.97 |
|         boat        | 52.13 |  90.3 |
|         bar         | 66.43 | 73.14 |
|    arcade machine   | 91.23 | 98.71 |
|        hovel        | 62.84 | 72.71 |
|         bus         | 94.96 | 97.39 |
|        towel        | 82.56 | 92.09 |
|        light        | 67.47 | 80.47 |
|        truck        | 53.96 |  73.4 |
|        tower        |  33.6 | 63.05 |
|      chandelier     | 77.27 | 86.99 |
|        awning       | 33.33 | 52.72 |
|     streetlight     | 46.04 | 71.89 |
|        booth        | 61.89 | 73.19 |
| television receiver | 77.56 | 92.27 |
|       airplane      | 88.82 | 96.49 |
|      dirt track     | 20.78 |  38.6 |
|       apparel       | 54.65 | 85.35 |
|         pole        | 35.76 | 49.13 |
|         land        |  6.25 |  9.63 |
|      bannister      | 22.34 | 34.15 |
|      escalator      | 65.64 | 83.99 |
|       ottoman       | 58.98 | 79.49 |
|        bottle       | 51.69 | 82.11 |
|        buffet       |  45.8 | 65.95 |
|        poster       | 38.59 | 61.66 |
|        stage        | 31.04 | 67.66 |
|         van         | 50.73 | 75.87 |
|         ship        | 44.68 | 47.63 |
|       fountain      | 50.37 | 55.21 |
|    conveyer belt    | 78.12 | 97.04 |
|        canopy       | 55.15 | 72.57 |
|        washer       | 90.85 | 93.42 |
|      plaything      | 38.08 | 59.13 |
|    swimming pool    | 50.44 | 76.03 |
|        stool        | 57.98 | 81.94 |
|        barrel       | 65.86 | 96.23 |
|        basket       | 48.04 | 72.33 |
|      waterfall      |  45.9 | 56.49 |
|         tent        |  95.0 |  98.1 |
|         bag         | 33.95 | 48.69 |
|       minibike      | 81.34 | 93.96 |
|        cradle       | 91.42 | 97.47 |
|         oven        | 65.89 | 83.99 |
|         ball        |  43.0 | 46.41 |
|         food        | 64.54 | 75.49 |
|         step        | 25.77 | 35.66 |
|         tank        |  60.3 | 67.46 |
|      trade name     | 29.76 |  37.8 |
|      microwave      | 89.67 | 94.57 |
|         pot         | 62.81 | 75.49 |
|        animal       | 80.94 | 83.27 |
|       bicycle       | 64.75 | 83.19 |
|         lake        | 66.04 | 69.04 |
|      dishwasher     | 80.56 | 90.52 |
|        screen       | 61.08 | 94.21 |
|       blanket       | 45.35 | 58.76 |
|      sculpture      | 76.81 | 90.59 |
|         hood        | 84.52 | 89.22 |
|        sconce       | 67.11 | 83.21 |
|         vase        | 59.03 | 81.74 |
|    traffic light    | 53.13 | 74.59 |
|         tray        | 33.38 | 52.11 |
|        ashcan       | 55.27 | 80.39 |
|         fan         | 73.61 | 87.82 |
|         pier        | 38.65 | 41.37 |
|      crt screen     |  1.51 |  4.1  |
|        plate        | 70.32 | 85.22 |
|       monitor       |  3.72 |  5.23 |
|    bulletin board   | 65.57 | 84.84 |
|        shower       | 15.64 | 28.64 |
|       radiator      | 75.78 |  93.1 |
|        glass        |  29.1 | 32.07 |
|        clock        | 64.02 | 77.78 |
|         flag        | 69.46 | 87.25 |
+---------------------+-------+-------+
2022-12-01 21:03:17,493 - mmseg - INFO - Summary:
2022-12-01 21:03:17,493 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 87.06 | 61.35 | 75.78 |
+-------+-------+-------+
2022-12-01 21:03:17,498 - mmseg - INFO - Exp name: hwy_mask2former_beitXclip_adapter_giant_896_relpos_40k_ls_coco2ade20k_ss_bsz2_tune.py
2022-12-01 21:03:17,498 - mmseg - INFO - Iter(val) [125]	aAcc: 0.8706, mIoU: 0.6135, mAcc: 0.7578, IoU.wall: 0.8325, IoU.building: 0.8528, IoU.sky: 0.9521, IoU.floor: 0.8562, IoU.tree: 0.7842, IoU.ceiling: 0.8704, IoU.road: 0.8844, IoU.bed : 0.9385, IoU.windowpane: 0.6862, IoU.grass: 0.6790, IoU.cabinet: 0.6266, IoU.sidewalk: 0.7297, IoU.person: 0.8843, IoU.earth: 0.4195, IoU.door: 0.6582, IoU.table: 0.7204, IoU.mountain: 0.6236, IoU.plant: 0.5662, IoU.curtain: 0.8252, IoU.chair: 0.6925, IoU.car: 0.8964, IoU.water: 0.7011, IoU.painting: 0.8003, IoU.sofa: 0.8568, IoU.shelf: 0.4902, IoU.house: 0.5711, IoU.sea: 0.8080, IoU.mirror: 0.8143, IoU.rug: 0.7222, IoU.field: 0.3602, IoU.armchair: 0.6406, IoU.seat: 0.6619, IoU.fence: 0.5516, IoU.desk: 0.5924, IoU.rock: 0.6072, IoU.wardrobe: 0.5846, IoU.lamp: 0.8117, IoU.bathtub: 0.9145, IoU.railing: 0.4571, IoU.cushion: 0.7756, IoU.base: 0.4215, IoU.box: 0.4613, IoU.column: 0.5753, IoU.signboard: 0.4571, IoU.chest of drawers: 0.4397, IoU.counter: 0.5910, IoU.sand: 0.5947, IoU.sink: 0.8618, IoU.skyscraper: 0.4202, IoU.fireplace: 0.7968, IoU.refrigerator: 0.8186, IoU.grandstand: 0.4749, IoU.path: 0.3212, IoU.stairs: 0.3796, IoU.runway: 0.7414, IoU.case: 0.6713, IoU.pool table: 0.9594, IoU.pillow: 0.7318, IoU.screen door: 0.8372, IoU.stairway: 0.5621, IoU.river: 0.2587, IoU.bridge: 0.7132, IoU.bookcase: 0.3939, IoU.blind: 0.4664, IoU.coffee table: 0.7232, IoU.toilet: 0.9294, IoU.flower: 0.4655, IoU.book: 0.6180, IoU.hill: 0.1556, IoU.bench: 0.7585, IoU.countertop: 0.7081, IoU.stove: 0.8634, IoU.palm: 0.5715, IoU.kitchen island: 0.4734, IoU.computer: 0.7885, IoU.swivel chair: 0.5572, IoU.boat: 0.5213, IoU.bar: 0.6643, IoU.arcade machine: 0.9123, IoU.hovel: 0.6284, IoU.bus: 0.9496, IoU.towel: 0.8256, IoU.light: 0.6747, IoU.truck: 0.5396, IoU.tower: 0.3360, IoU.chandelier: 0.7727, IoU.awning: 0.3333, IoU.streetlight: 0.4604, IoU.booth: 0.6189, IoU.television receiver: 0.7756, IoU.airplane: 0.8882, IoU.dirt track: 0.2078, IoU.apparel: 0.5465, IoU.pole: 0.3576, IoU.land: 0.0625, IoU.bannister: 0.2234, IoU.escalator: 0.6564, IoU.ottoman: 0.5898, IoU.bottle: 0.5169, IoU.buffet: 0.4580, IoU.poster: 0.3859, IoU.stage: 0.3104, IoU.van: 0.5073, IoU.ship: 0.4468, IoU.fountain: 0.5037, IoU.conveyer belt: 0.7812, IoU.canopy: 0.5515, IoU.washer: 0.9085, IoU.plaything: 0.3808, IoU.swimming pool: 0.5044, IoU.stool: 0.5798, IoU.barrel: 0.6586, IoU.basket: 0.4804, IoU.waterfall: 0.4590, IoU.tent: 0.9500, IoU.bag: 0.3395, IoU.minibike: 0.8134, IoU.cradle: 0.9142, IoU.oven: 0.6589, IoU.ball: 0.4300, IoU.food: 0.6454, IoU.step: 0.2577, IoU.tank: 0.6030, IoU.trade name: 0.2976, IoU.microwave: 0.8967, IoU.pot: 0.6281, IoU.animal: 0.8094, IoU.bicycle: 0.6475, IoU.lake: 0.6604, IoU.dishwasher: 0.8056, IoU.screen: 0.6108, IoU.blanket: 0.4535, IoU.sculpture: 0.7681, IoU.hood: 0.8452, IoU.sconce: 0.6711, IoU.vase: 0.5903, IoU.traffic light: 0.5313, IoU.tray: 0.3338, IoU.ashcan: 0.5527, IoU.fan: 0.7361, IoU.pier: 0.3865, IoU.crt screen: 0.0151, IoU.plate: 0.7032, IoU.monitor: 0.0372, IoU.bulletin board: 0.6557, IoU.shower: 0.1564, IoU.radiator: 0.7578, IoU.glass: 0.2910, IoU.clock: 0.6402, IoU.flag: 0.6946, Acc.wall: 0.8927, Acc.building: 0.9205, Acc.sky: 0.9736, Acc.floor: 0.9060, Acc.tree: 0.8968, Acc.ceiling: 0.9357, Acc.road: 0.9206, Acc.bed : 0.9734, Acc.windowpane: 0.8255, Acc.grass: 0.8116, Acc.cabinet: 0.7202, Acc.sidewalk: 0.8584, Acc.person: 0.9417, Acc.earth: 0.5709, Acc.door: 0.8413, Acc.table: 0.8185, Acc.mountain: 0.7177, Acc.plant: 0.6987, Acc.curtain: 0.9192, Acc.chair: 0.8006, Acc.car: 0.9493, Acc.water: 0.8667, Acc.painting: 0.9136, Acc.sofa: 0.9182, Acc.shelf: 0.6295, Acc.house: 0.7548, Acc.sea: 0.9093, Acc.mirror: 0.9158, Acc.rug: 0.8532, Acc.field: 0.6682, Acc.armchair: 0.7996, Acc.seat: 0.8986, Acc.fence: 0.7438, Acc.desk: 0.8268, Acc.rock: 0.7565, Acc.wardrobe: 0.8657, Acc.lamp: 0.9070, Acc.bathtub: 0.9372, Acc.railing: 0.6644, Acc.cushion: 0.9054, Acc.base: 0.6654, Acc.box: 0.6478, Acc.column: 0.7248, Acc.signboard: 0.6827, Acc.chest of drawers: 0.6783, Acc.counter: 0.6863, Acc.sand: 0.8539, Acc.sink: 0.8994, Acc.skyscraper: 0.5313, Acc.fireplace: 0.9490, Acc.refrigerator: 0.9215, Acc.grandstand: 0.8197, Acc.path: 0.4157, Acc.stairs: 0.5000, Acc.runway: 0.9356, Acc.case: 0.8736, Acc.pool table: 0.9867, Acc.pillow: 0.8312, Acc.screen door: 0.9203, Acc.stairway: 0.7127, Acc.river: 0.3025, Acc.bridge: 0.8699, Acc.bookcase: 0.5665, Acc.blind: 0.5766, Acc.coffee table: 0.9050, Acc.toilet: 0.9643, Acc.flower: 0.7080, Acc.book: 0.8335, Acc.hill: 0.2772, Acc.bench: 0.8434, Acc.countertop: 0.9020, Acc.stove: 0.9025, Acc.palm: 0.8233, Acc.kitchen island: 0.9198, Acc.computer: 0.8707, Acc.swivel chair: 0.8397, Acc.boat: 0.9030, Acc.bar: 0.7314, Acc.arcade machine: 0.9871, Acc.hovel: 0.7271, Acc.bus: 0.9739, Acc.towel: 0.9209, Acc.light: 0.8047, Acc.truck: 0.7340, Acc.tower: 0.6305, Acc.chandelier: 0.8699, Acc.awning: 0.5272, Acc.streetlight: 0.7189, Acc.booth: 0.7319, Acc.television receiver: 0.9227, Acc.airplane: 0.9649, Acc.dirt track: 0.3860, Acc.apparel: 0.8535, Acc.pole: 0.4913, Acc.land: 0.0963, Acc.bannister: 0.3415, Acc.escalator: 0.8399, Acc.ottoman: 0.7949, Acc.bottle: 0.8211, Acc.buffet: 0.6595, Acc.poster: 0.6166, Acc.stage: 0.6766, Acc.van: 0.7587, Acc.ship: 0.4763, Acc.fountain: 0.5521, Acc.conveyer belt: 0.9704, Acc.canopy: 0.7257, Acc.washer: 0.9342, Acc.plaything: 0.5913, Acc.swimming pool: 0.7603, Acc.stool: 0.8194, Acc.barrel: 0.9623, Acc.basket: 0.7233, Acc.waterfall: 0.5649, Acc.tent: 0.9810, Acc.bag: 0.4869, Acc.minibike: 0.9396, Acc.cradle: 0.9747, Acc.oven: 0.8399, Acc.ball: 0.4641, Acc.food: 0.7549, Acc.step: 0.3566, Acc.tank: 0.6746, Acc.trade name: 0.3780, Acc.microwave: 0.9457, Acc.pot: 0.7549, Acc.animal: 0.8327, Acc.bicycle: 0.8319, Acc.lake: 0.6904, Acc.dishwasher: 0.9052, Acc.screen: 0.9421, Acc.blanket: 0.5876, Acc.sculpture: 0.9059, Acc.hood: 0.8922, Acc.sconce: 0.8321, Acc.vase: 0.8174, Acc.traffic light: 0.7459, Acc.tray: 0.5211, Acc.ashcan: 0.8039, Acc.fan: 0.8782, Acc.pier: 0.4137, Acc.crt screen: 0.0410, Acc.plate: 0.8522, Acc.monitor: 0.0523, Acc.bulletin board: 0.8484, Acc.shower: 0.2864, Acc.radiator: 0.9310, Acc.glass: 0.3207, Acc.clock: 0.7778, Acc.flag: 0.8725
