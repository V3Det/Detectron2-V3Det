{"train_lr": 7.498500899460321e-06, "train_min_lr": 9.154660955152609e-07, "train_loss": 4.4626520463316846, "train_class_acc": 0.7030211768085531, "train_loss_scale": 3031.8912869704236, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 4.941287110809729, "test_loss": 0.7740445928083677, "ema_test_loss": 6.44433802072749, "ema_test_acc1": 84.7728751739934, "ema_test_acc5": 97.46481260182533, "epoch": 0, "n_parameters": 1014447464}
{"train_lr": 2.250149910053968e-05, "train_min_lr": 2.747130366590178e-06, "train_loss": 3.238073896351669, "train_class_acc": 0.8051956872002398, "train_loss_scale": 3230.7977617905676, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 4.562452393871333, "test_loss": 0.704740686412675, "ema_test_loss": 5.3453851583780665, "ema_test_acc1": 87.36204661929447, "ema_test_acc5": 98.36652364840663, "epoch": 1, "n_parameters": 1014447464}
{"train_lr": 2.9854512756282948e-05, "train_min_lr": 3.6448344266347893e-06, "train_loss": 3.2094054980624875, "train_class_acc": 0.8123454361510791, "train_loss_scale": 1508.988009592326, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 4.179597097841138, "test_loss": 0.6860131640551668, "ema_test_loss": 4.184046116629333, "ema_test_acc1": 88.36372606310414, "ema_test_acc5": 98.64043585306852, "epoch": 2, "n_parameters": 1014447464}
{"train_lr": 2.8991396678572406e-05, "train_min_lr": 3.539459563547813e-06, "train_loss": 3.180451317656812, "train_class_acc": 0.8217878821942446, "train_loss_scale": 1055.9232613908873, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 4.251796593192439, "test_loss": 0.7101381657588662, "ema_test_loss": 3.206090754631794, "ema_test_acc1": 88.99152517410249, "ema_test_acc5": 98.79638586483624, "epoch": 3, "n_parameters": 1014447464}
{"train_lr": 2.7315151482560892e-05, "train_min_lr": 3.3348125727300472e-06, "train_loss": 3.157310479741207, "train_class_acc": 0.8298306667166268, "train_loss_scale": 947.0567545963229, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 3.96662220072685, "test_loss": 0.6935072210335145, "ema_test_loss": 2.4479067843746054, "ema_test_acc1": 89.28143245016086, "ema_test_acc5": 98.914348052239, "epoch": 4, "n_parameters": 1014447464}
{"train_lr": 2.492319444613717e-05, "train_min_lr": 3.042786793426264e-06, "train_loss": 3.1333151984271956, "train_class_acc": 0.8381872626898481, "train_loss_scale": 1500.802557953637, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 3.836466956703742, "test_loss": 0.6957851070840138, "ema_test_loss": 1.8943103917620399, "ema_test_acc1": 89.4633742916378, "ema_test_acc5": 98.95033651487384, "epoch": 5, "n_parameters": 1014447464}
{"train_lr": 2.1954537417848227e-05, "train_min_lr": 2.6803537024590747e-06, "train_loss": 3.113393196575552, "train_class_acc": 0.8451996215527577, "train_loss_scale": 1434.0911270983213, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 3.7748921941273497, "test_loss": 0.6916289071721787, "ema_test_loss": 1.5104932648440201, "ema_test_acc1": 89.483367897041, "ema_test_acc5": 98.94633780056593, "epoch": 6, "n_parameters": 1014447464}
{"train_lr": 1.8581707953548876e-05, "train_min_lr": 2.268576593684819e-06, "train_loss": 3.0927929043483964, "train_class_acc": 0.8527974495403677, "train_loss_scale": 691.4660271782574, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 3.839622701024405, "test_loss": 0.6951396271417086, "ema_test_loss": 1.2497664556528132, "ema_test_acc1": 89.59733143969369, "ema_test_acc5": 98.9623326724413, "epoch": 7, "n_parameters": 1014447464}
{"train_lr": 1.5000722641967987e-05, "train_min_lr": 1.8313864559165575e-06, "train_loss": 3.0735403864408473, "train_class_acc": 0.8596084070243805, "train_loss_scale": 696.3772981614708, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 3.92998809069706, "test_loss": 0.6890051116052112, "ema_test_loss": 1.0767927702064768, "ema_test_acc1": 89.66530964882497, "ema_test_acc5": 98.97632818533225, "epoch": 8, "n_parameters": 1014447464}
{"train_lr": 1.1419695333062536e-05, "train_min_lr": 1.3941911908398981e-06, "train_loss": 3.055963920270034, "train_class_acc": 0.8659580148381295, "train_loss_scale": 1224.952837729816, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 3.761093955124064, "test_loss": 0.6938566350321652, "ema_test_loss": 0.9609573541604208, "ema_test_acc1": 89.6992987639158, "ema_test_acc5": 98.9803269033011, "epoch": 9, "n_parameters": 1014447464}
{"train_lr": 8.046742317521608e-06, "train_min_lr": 9.823989981209579e-07, "train_loss": 3.0416182922802384, "train_class_acc": 0.8712553394784173, "train_loss_scale": 1299.0311750599521, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 3.7901082641728028, "test_loss": 0.6972967310469936, "ema_test_loss": 0.8831125771711495, "ema_test_acc1": 89.72529046366174, "ema_test_acc5": 98.95833395447247, "epoch": 10, "n_parameters": 1014447464}
{"train_lr": 5.077887364423012e-06, "train_min_lr": 6.199417431968533e-07, "train_loss": 3.029433508856977, "train_class_acc": 0.8758766424360511, "train_loss_scale": 366.1966426858513, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 4.119040452436737, "test_loss": 0.6966104307353045, "ema_test_loss": 0.830208124113128, "ema_test_acc1": 89.65731218771833, "ema_test_acc5": 98.93034292502962, "epoch": 11, "n_parameters": 1014447464}
{"train_lr": 2.685669532292132e-06, "train_min_lr": 3.2788412424525037e-07, "train_loss": 3.0185232185345474, "train_class_acc": 0.879917940647482, "train_loss_scale": 492.7641886490807, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 4.047446929345666, "test_loss": 0.6995059916975371, "ema_test_loss": 0.7937420680272308, "ema_test_acc1": 89.65331346608856, "ema_test_acc5": 98.9283435660452, "epoch": 12, "n_parameters": 1014447464}
{"train_lr": 1.0091158261744352e-06, "train_min_lr": 1.2319946849336977e-07, "train_loss": 3.013889645119842, "train_class_acc": 0.8817508493205436, "train_loss_scale": 968.3389288569144, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 3.8844443662063823, "test_loss": 0.7014263812875883, "ema_test_loss": 0.7687274380728151, "ema_test_acc1": 89.6273217736645, "ema_test_acc5": 98.91634741213866, "epoch": 13, "n_parameters": 1014447464}
{"train_lr": 1.4566145344469748e-07, "train_min_lr": 1.7783304135056203e-08, "train_loss": 3.0129157416254495, "train_class_acc": 0.8821606777078337, "train_loss_scale": 707.2230215827338, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 3.902869244309805, "test_loss": 0.7015515054068104, "ema_test_loss": 0.7510218796687145, "ema_test_acc1": 89.57533839979922, "ema_test_acc5": 98.89835317761793, "epoch": 14, "n_parameters": 1014447464}
