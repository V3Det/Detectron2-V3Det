{"train_lr": 7.498500899460321e-06, "train_min_lr": 9.154660955152609e-07, "train_loss": 4.419087093606365, "train_class_acc": 0.732425778127498, "train_loss_scale": 3434.615507593925, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 4.963585273892194, "test_loss": 0.7544717356477949, "ema_test_loss": 6.419887887257518, "ema_test_acc1": 86.41834863957425, "ema_test_acc5": 97.86668384281093, "epoch": 0, "n_parameters": 1013005672}
{"train_lr": 2.250149910053968e-05, "train_min_lr": 2.747130366590178e-06, "train_loss": 3.2193286386515787, "train_class_acc": 0.811656143834932, "train_loss_scale": 2278.829736211031, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 4.539531811706021, "test_loss": 0.7102524379522286, "ema_test_loss": 5.2849551884062365, "ema_test_acc1": 88.13180034311628, "ema_test_acc5": 98.50847815094433, "epoch": 1, "n_parameters": 1013005672}
{"train_lr": 2.9617658524918062e-05, "train_min_lr": 3.615917710973717e-06, "train_loss": 3.1993322334320045, "train_class_acc": 0.815728667066347, "train_loss_scale": 3097.374900079936, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 4.224096440626259, "test_loss": 0.7007125540862255, "ema_test_loss": 4.086038376910217, "ema_test_acc1": 88.82357895442941, "ema_test_acc5": 98.75639868331733, "epoch": 2, "n_parameters": 1013005672}
{"train_lr": 2.739270888162252e-05, "train_min_lr": 3.344281287910492e-06, "train_loss": 3.1705097835793863, "train_class_acc": 0.8249876661171063, "train_loss_scale": 2092.610711430855, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 4.088015956981229, "test_loss": 0.6984260067287268, "ema_test_loss": 3.0926264747977257, "ema_test_acc1": 89.17946505226237, "ema_test_acc5": 98.82837560492605, "epoch": 3, "n_parameters": 1013005672}
{"train_lr": 2.3281081651285687e-05, "train_min_lr": 2.8423069096662315e-06, "train_loss": 3.1441999232645133, "train_class_acc": 0.8340405800359713, "train_loss_scale": 750.4012789768185, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 4.250160770754514, "test_loss": 0.6860779548120318, "ema_test_loss": 2.3475325606537587, "ema_test_acc1": 89.32941716737803, "ema_test_acc5": 98.90035253660236, "epoch": 4, "n_parameters": 1013005672}
{"train_lr": 1.790873480773282e-05, "train_min_lr": 2.186415624919561e-06, "train_loss": 3.114753143774043, "train_class_acc": 0.844496277977618, "train_loss_scale": 1442.6858513189447, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 4.007973384194767, "test_loss": 0.6867631875458314, "ema_test_loss": 1.8184334917389082, "ema_test_acc1": 89.4453800154739, "ema_test_acc5": 98.93034292136868, "epoch": 5, "n_parameters": 1013005672}
{"train_lr": 1.209355945744924e-05, "train_min_lr": 1.4764609361038462e-06, "train_loss": 3.090236429020846, "train_class_acc": 0.8535023543665068, "train_loss_scale": 1260.2525979216628, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 4.066610779431104, "test_loss": 0.6851152015116179, "ema_test_loss": 1.4586366985106107, "ema_test_acc1": 89.46937231230416, "ema_test_acc5": 98.93434163201565, "epoch": 6, "n_parameters": 1013005672}
{"train_lr": 6.7208633328199074e-06, "train_min_lr": 8.205270088360129e-07, "train_loss": 3.0689266701872877, "train_class_acc": 0.8609268834932055, "train_loss_scale": 569.6051159072741, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 4.224399833651361, "test_loss": 0.6844019733623348, "ema_test_loss": 1.2176333250421467, "ema_test_acc1": 89.54534801228719, "ema_test_acc5": 98.93434163201565, "epoch": 7, "n_parameters": 1013005672}
{"train_lr": 2.608590715207975e-06, "train_min_lr": 3.184738374867285e-07, "train_loss": 3.0527807490335856, "train_class_acc": 0.8669306742106315, "train_loss_scale": 1742.273381294964, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 3.991866744064436, "test_loss": 0.6858035235341187, "ema_test_loss": 1.05770327825325, "ema_test_acc1": 89.55934352517815, "ema_test_acc5": 98.93234227303122, "epoch": 8, "n_parameters": 1013005672}
{"train_lr": 3.827978328007433e-07, "train_min_lr": 4.673446627058796e-08, "train_loss": 3.0487171298117755, "train_class_acc": 0.8683701476318945, "train_loss_scale": 1143.9168665067946, "train_weight_decay": 0.04999999999999802, "train_grad_norm": 4.026621277972082, "test_loss": 0.6859378248495474, "ema_test_loss": 0.9500173816570279, "ema_test_acc1": 89.62532241925626, "ema_test_acc5": 98.92634419607796, "epoch": 9, "n_parameters": 1013005672}
